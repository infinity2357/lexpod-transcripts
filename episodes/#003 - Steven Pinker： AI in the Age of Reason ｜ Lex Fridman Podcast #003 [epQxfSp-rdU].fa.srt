1
00:00:00,060 --> 00:00:02,600

شما روانشناسی تکامل بینایی ذهن انسان را

2
00:00:02,600 --> 00:00:05,210
شما روانشناسی تکامل بینایی ذهن انسان را
 

3
00:00:05,210 --> 00:00:05,220

 

4
00:00:05,220 --> 00:00:08,540

از کودک تا بزرگسال از سطح

5
00:00:08,540 --> 00:00:08,550
از کودک تا بزرگسال از سطح
 

6
00:00:08,550 --> 00:00:10,310
از کودک تا بزرگسال از سطح
فردی تا سطح

7
00:00:10,310 --> 00:00:10,320
فردی تا سطح
 

8
00:00:10,320 --> 00:00:13,039
فردی تا سطح
تمدن ما مطالعه کرده اید، بنابراین احساس می کنم می توانم

9
00:00:13,039 --> 00:00:13,049
تمدن ما مطالعه کرده اید، بنابراین احساس می کنم می توانم
 

10
00:00:13,049 --> 00:00:15,580
تمدن ما مطالعه کرده اید، بنابراین احساس می کنم می توانم
با یک سوال ساده چند گزینه ای شروع کنم.

11
00:00:15,580 --> 00:00:15,590
با یک سوال ساده چند گزینه ای شروع کنم.
 

12
00:00:15,590 --> 00:00:20,390
با یک سوال ساده چند گزینه ای شروع کنم.
معنای زندگی چیست؟  الف

13
00:00:20,390 --> 00:00:20,400
معنای زندگی چیست؟  الف
 

14
00:00:20,400 --> 00:00:23,060
معنای زندگی چیست؟  الف
دستیابی به دانش همانطور که افلاطون گفت B برای

15
00:00:23,060 --> 00:00:23,070
دستیابی به دانش همانطور که افلاطون گفت B برای
 

16
00:00:23,070 --> 00:00:26,060
دستیابی به دانش همانطور که افلاطون گفت B برای
رسیدن به قدرت همانطور که نیچه گفت ج برای

17
00:00:26,060 --> 00:00:26,070
رسیدن به قدرت همانطور که نیچه گفت ج برای
 

18
00:00:26,070 --> 00:00:29,150
رسیدن به قدرت همانطور که نیچه گفت ج برای
فرار از مرگ همانطور که ارنست بکر گفت d

19
00:00:29,150 --> 00:00:29,160
فرار از مرگ همانطور که ارنست بکر گفت d
 

20
00:00:29,160 --> 00:00:32,060
فرار از مرگ همانطور که ارنست بکر گفت d
انتشار ژن هایمان همانطور که داروین و دیگران

21
00:00:32,060 --> 00:00:32,070
انتشار ژن هایمان همانطور که داروین و دیگران
 

22
00:00:32,070 --> 00:00:35,360
انتشار ژن هایمان همانطور که داروین و دیگران
گفته اند e هیچ معنایی ندارد همانطور که

23
00:00:35,360 --> 00:00:35,370
گفته اند e هیچ معنایی ندارد همانطور که
 

24
00:00:35,370 --> 00:00:38,840
گفته اند e هیچ معنایی ندارد همانطور که
نیهیلیست ها گفته اند F دانستن

25
00:00:38,840 --> 00:00:38,850
نیهیلیست ها گفته اند F دانستن
 

26
00:00:38,850 --> 00:00:40,639
نیهیلیست ها گفته اند F دانستن
معنای زندگی است.

27
00:00:40,639 --> 00:00:40,649
معنای زندگی است.
 

28
00:00:40,649 --> 00:00:43,310
معنای زندگی است.
همانطور که استیون پینکر بر اساس

29
00:00:43,310 --> 00:00:43,320
همانطور که استیون پینکر بر اساس
 

30
00:00:43,320 --> 00:00:44,810
همانطور که استیون پینکر بر اساس
تفسیر من بیست سال پیش گفت فراتر از توانایی‌های شناختی ما است

31
00:00:44,810 --> 00:00:44,820
تفسیر من بیست سال پیش گفت فراتر از توانایی‌های شناختی ما است
 

32
00:00:44,820 --> 00:00:47,450
تفسیر من بیست سال پیش گفت فراتر از توانایی‌های شناختی ما است
و هیچ یک از موارد بالا را نمی‌توان

33
00:00:47,450 --> 00:00:47,460
و هیچ یک از موارد بالا را نمی‌توان
 

34
00:00:47,460 --> 00:00:50,420
و هیچ یک از موارد بالا را نمی‌توان
نزدیک‌تر کرد، اما من

35
00:00:50,420 --> 00:00:50,430
نزدیک‌تر کرد، اما من
 

36
00:00:50,430 --> 00:00:52,970
نزدیک‌تر کرد، اما من
آن را اصلاح می‌کنم تا نه تنها به

37
00:00:52,970 --> 00:00:52,980
آن را اصلاح می‌کنم تا نه تنها به
 

38
00:00:52,980 --> 00:00:55,459
آن را اصلاح می‌کنم تا نه تنها به
دانش، بلکه به طور کلی‌تر تحقق،

39
00:00:55,459 --> 00:00:55,469
دانش، بلکه به طور کلی‌تر تحقق،
 

40
00:00:55,469 --> 00:01:01,130
دانش، بلکه به طور کلی‌تر تحقق،
دسترسی به سلامت زندگی را به  در

41
00:01:01,130 --> 00:01:01,140
دسترسی به سلامت زندگی را به  در
 

42
00:01:01,140 --> 00:01:05,570
دسترسی به سلامت زندگی را به  در
دنیای فرهنگی و اجتماعی زندگی می کنیم که

43
00:01:05,570 --> 00:01:05,580
دنیای فرهنگی و اجتماعی زندگی می کنیم که
 

44
00:01:05,580 --> 00:01:08,090
دنیای فرهنگی و اجتماعی زندگی می کنیم که
اکنون معنای زندگی ما این است،

45
00:01:08,090 --> 00:01:08,100
اکنون معنای زندگی ما این است،
 

46
00:01:08,100 --> 00:01:10,219
اکنون معنای زندگی ما این است،
اگر از

47
00:01:10,219 --> 00:01:10,229
اگر از
 

48
00:01:10,229 --> 00:01:14,600
اگر از
ژن های ما بپرسید معنای آنها این است که

49
00:01:14,600 --> 00:01:14,610
ژن های ما بپرسید معنای آنها این است که
 

50
00:01:14,610 --> 00:01:16,850
ژن های ما بپرسید معنای آنها این است که
نسخه هایی از خودشان را منتشر کنند، اما این

51
00:01:16,850 --> 00:01:16,860
نسخه هایی از خودشان را منتشر کنند، اما این
 

52
00:01:16,860 --> 00:01:18,649
نسخه هایی از خودشان را منتشر کنند، اما این
با معنایی که مغز

53
00:01:18,649 --> 00:01:18,659
با معنایی که مغز
 

54
00:01:18,659 --> 00:01:23,210
با معنایی که مغز
آنها را برای خود تعیین می کند متفاوت است.  بنابراین برای

55
00:01:23,210 --> 00:01:23,220
آنها را برای خود تعیین می کند متفاوت است.  بنابراین برای
 

56
00:01:23,220 --> 00:01:26,929
آنها را برای خود تعیین می کند متفاوت است.  بنابراین برای
شما دانش یک زیرمجموعه کوچک یا یک

57
00:01:26,929 --> 00:01:26,939
شما دانش یک زیرمجموعه کوچک یا یک
 

58
00:01:26,939 --> 00:01:28,999
شما دانش یک زیرمجموعه کوچک یا یک
زیرمجموعه بزرگ است، یک زیرمجموعه بزرگ است، اما

59
00:01:28,999 --> 00:01:29,009
زیرمجموعه بزرگ است، یک زیرمجموعه بزرگ است، اما
 

60
00:01:29,009 --> 00:01:31,370
زیرمجموعه بزرگ است، یک زیرمجموعه بزرگ است، اما
تمام گام های انسان نیست

61
00:01:31,370 --> 00:01:31,380
تمام گام های انسان نیست
 

62
00:01:31,380 --> 00:01:35,780
تمام گام های انسان نیست
زیرا ما همچنین می خواهیم با

63
00:01:35,780 --> 00:01:35,790
زیرا ما همچنین می خواهیم با
 

64
00:01:35,790 --> 00:01:37,910
زیرا ما همچنین می خواهیم با
افرادی تعامل داشته باشیم که می خواهیم زیبایی را تجربه کنیم، می

65
00:01:37,910 --> 00:01:37,920
افرادی تعامل داشته باشیم که می خواهیم زیبایی را تجربه کنیم، می
 

66
00:01:37,920 --> 00:01:39,770
افرادی تعامل داشته باشیم که می خواهیم زیبایی را تجربه کنیم، می
خواهیم غنای

67
00:01:39,770 --> 00:01:39,780
خواهیم غنای
 

68
00:01:39,780 --> 00:01:43,160
خواهیم غنای
جهان طبیعی را تجربه کنیم اما درک کنیم.  چیزی

69
00:01:43,160 --> 00:01:43,170
جهان طبیعی را تجربه کنیم اما درک کنیم.  چیزی
 

70
00:01:43,170 --> 00:01:46,999
جهان طبیعی را تجربه کنیم اما درک کنیم.  چیزی
که باعث می شود جهان به سمت

71
00:01:46,999 --> 00:01:47,009
که باعث می شود جهان به سمت
 

72
00:01:47,009 --> 00:01:49,330
که باعث می شود جهان به سمت
بالا حرکت کند، برای برخی از ما بیشتر از دیگران است،

73
00:01:49,330 --> 00:01:49,340
بالا حرکت کند، برای برخی از ما بیشتر از دیگران است،
 

74
00:01:49,340 --> 00:01:53,240
بالا حرکت کند، برای برخی از ما بیشتر از دیگران است،
مطمئناً برای من این یکی از

75
00:01:53,240 --> 00:01:53,250
مطمئناً برای من این یکی از
 

76
00:01:53,250 --> 00:01:56,600
مطمئناً برای من این یکی از
پنج مورد برتر است، بنابراین یک

77
00:01:56,600 --> 00:01:56,610
پنج مورد برتر است، بنابراین یک
 

78
00:01:56,610 --> 00:01:58,819
پنج مورد برتر است، بنابراین یک
جنبه اساسی این است که شما فقط ترجیحات خود را توصیف می کنید

79
00:01:58,819 --> 00:01:58,829
جنبه اساسی این است که شما فقط ترجیحات خود را توصیف می کنید
 

80
00:01:58,829 --> 00:02:00,620
جنبه اساسی این است که شما فقط ترجیحات خود را توصیف می کنید
یا این یک

81
00:02:00,620 --> 00:02:00,630
یا این یک
 

82
00:02:00,630 --> 00:02:02,209
یا این یک
جنبه اساسی از طبیعت انسان است.  جستجوی

83
00:02:02,209 --> 00:02:02,219
جنبه اساسی از طبیعت انسان است.  جستجوی
 

84
00:02:02,219 --> 00:02:05,510
جنبه اساسی از طبیعت انسان است.  جستجوی
دانش فقط در آخرین کتابتان

85
00:02:05,510 --> 00:02:05,520
دانش فقط در آخرین کتابتان
 

86
00:02:05,520 --> 00:02:07,730
دانش فقط در آخرین کتابتان
در مورد قدرت

87
00:02:07,730 --> 00:02:07,740
در مورد قدرت
 

88
00:02:07,740 --> 00:02:10,339
در مورد قدرت
سودمندی عقلانیت و عقل صحبت می کنید و به همین ترتیب این است

89
00:02:10,339 --> 00:02:10,349
سودمندی عقلانیت و عقل صحبت می کنید و به همین ترتیب این است
 

90
00:02:10,349 --> 00:02:12,480
سودمندی عقلانیت و عقل صحبت می کنید و به همین ترتیب این است
که طبیعت بنیادی

91
00:02:12,480 --> 00:02:12,490
که طبیعت بنیادی
 

92
00:02:12,490 --> 00:02:15,360
که طبیعت بنیادی
انسان هاست یا چیزی است که ما

93
00:02:15,360 --> 00:02:15,370
انسان هاست یا چیزی است که ما
 

94
00:02:15,370 --> 00:02:17,880
انسان هاست یا چیزی است که ما
فقط باید برای آن تلاش کنیم و هم

95
00:02:17,880 --> 00:02:17,890
فقط باید برای آن تلاش کنیم و هم
 

96
00:02:17,890 --> 00:02:20,430
فقط باید برای آن تلاش کنیم و هم
توانایی تلاش برای آن را داریم.  زیرا

97
00:02:20,430 --> 00:02:20,440
توانایی تلاش برای آن را داریم.  زیرا
 

98
00:02:20,440 --> 00:02:23,100
توانایی تلاش برای آن را داریم.  زیرا
این یکی از چیزهایی است که ما را به آن چیزی تبدیل می کند

99
00:02:23,100 --> 00:02:23,110
این یکی از چیزهایی است که ما را به آن چیزی تبدیل می کند
 

100
00:02:23,110 --> 00:02:27,930
این یکی از چیزهایی است که ما را به آن چیزی تبدیل می کند
که ما انسان های خردمند انسان های همو ساپینس هستیم، ما در

101
00:02:27,930 --> 00:02:27,940
که ما انسان های خردمند انسان های همو ساپینس هستیم، ما در
 

102
00:02:27,940 --> 00:02:31,290
که ما انسان های خردمند انسان های همو ساپینس هستیم، ما در
بین حیوانات غیرعادی هستیم در میزان

103
00:02:31,290 --> 00:02:31,300
بین حیوانات غیرعادی هستیم در میزان
 

104
00:02:31,300 --> 00:02:33,870
بین حیوانات غیرعادی هستیم در میزان
کسب دانش و استفاده از آن برای

105
00:02:33,870 --> 00:02:33,880
کسب دانش و استفاده از آن برای
 

106
00:02:33,880 --> 00:02:37,110
کسب دانش و استفاده از آن برای
زنده ماندن، ابزارهایی را می سازیم و

107
00:02:37,110 --> 00:02:37,120
زنده ماندن، ابزارهایی را می سازیم و
 

108
00:02:37,120 --> 00:02:41,550
زنده ماندن، ابزارهایی را می سازیم و
از طریق زبان توافق می کنیم و

109
00:02:41,550 --> 00:02:41,560
از طریق زبان توافق می کنیم و
 

110
00:02:41,560 --> 00:02:44,310
از طریق زبان توافق می کنیم و
سموم را استخراج می کنیم.  رفتار

111
00:02:44,310 --> 00:02:44,320
سموم را استخراج می کنیم.  رفتار
 

112
00:02:44,320 --> 00:02:47,430
سموم را استخراج می کنیم.  رفتار
حیوانات را که ما سعی می کنیم در عملکرد گیاهان انجام دهیم را پیش بینی کنیم

113
00:02:47,430 --> 00:02:47,440
حیوانات را که ما سعی می کنیم در عملکرد گیاهان انجام دهیم را پیش بینی کنیم
 

114
00:02:47,440 --> 00:02:49,110
حیوانات را که ما سعی می کنیم در عملکرد گیاهان انجام دهیم را پیش بینی کنیم
و وقتی می گویم ما فقط

115
00:02:49,110 --> 00:02:49,120
و وقتی می گویم ما فقط
 

116
00:02:49,120 --> 00:02:51,660
و وقتی می گویم ما فقط
منظور ما در غرب مدرن نیست، بلکه ما به عنوان یک

117
00:02:51,660 --> 00:02:51,670
منظور ما در غرب مدرن نیست، بلکه ما به عنوان یک
 

118
00:02:51,670 --> 00:02:53,460
منظور ما در غرب مدرن نیست، بلکه ما به عنوان یک
گونه در همه جا هستیم که چگونه

119
00:02:53,460 --> 00:02:53,470
گونه در همه جا هستیم که چگونه
 

120
00:02:53,470 --> 00:02:56,340
گونه در همه جا هستیم که چگونه
توانسته ایم همه جاهای روی

121
00:02:56,340 --> 00:02:56,350
توانسته ایم همه جاهای روی
 

122
00:02:56,350 --> 00:02:57,930
توانسته ایم همه جاهای روی
کره زمین را اشغال کنیم.  و اینکه چگونه توانسته‌ایم

123
00:02:57,930 --> 00:02:57,940
کره زمین را اشغال کنیم.  و اینکه چگونه توانسته‌ایم
 

124
00:02:57,940 --> 00:02:59,790
کره زمین را اشغال کنیم.  و اینکه چگونه توانسته‌ایم
حیوانات دیگر را به سوی انقراض سوق دهیم و

125
00:02:59,790 --> 00:02:59,800
حیوانات دیگر را به سوی انقراض سوق دهیم و
 

126
00:02:59,800 --> 00:03:03,390
حیوانات دیگر را به سوی انقراض سوق دهیم و
اصلاح عقل به دنبال

127
00:03:03,390 --> 00:03:03,400
اصلاح عقل به دنبال
 

128
00:03:03,400 --> 00:03:07,830
اصلاح عقل به دنبال
رفاه انسان سلامت شادی

129
00:03:07,830 --> 00:03:07,840
رفاه انسان سلامت شادی
 

130
00:03:07,840 --> 00:03:11,640
رفاه انسان سلامت شادی
غنای اجتماعی غنای فرهنگی غنای فرهنگی

131
00:03:11,640 --> 00:03:11,650
غنای اجتماعی غنای فرهنگی غنای فرهنگی
 

132
00:03:11,650 --> 00:03:13,910
غنای اجتماعی غنای فرهنگی غنای فرهنگی
چالش اصلی ما در حال حاضر است که

133
00:03:13,910 --> 00:03:13,920
چالش اصلی ما در حال حاضر است که
 

134
00:03:13,920 --> 00:03:16,170
چالش اصلی ما در حال حاضر است که
استفاده از عقل ما با استفاده از دانش خود

135
00:03:16,170 --> 00:03:16,180
استفاده از عقل ما با استفاده از دانش خود
 

136
00:03:16,180 --> 00:03:18,570
استفاده از عقل ما با استفاده از دانش خود
برای کشف کردن است.  جهان چگونه کار می کند ما چگونه

137
00:03:18,570 --> 00:03:18,580
برای کشف کردن است.  جهان چگونه کار می کند ما چگونه
 

138
00:03:18,580 --> 00:03:21,390
برای کشف کردن است.  جهان چگونه کار می کند ما چگونه
برای دستیابی به اکتشافات و

139
00:03:21,390 --> 00:03:21,400
برای دستیابی به اکتشافات و
 

140
00:03:21,400 --> 00:03:23,670
برای دستیابی به اکتشافات و
توافقاتی کار می کنیم که

141
00:03:23,670 --> 00:03:23,680
توافقاتی کار می کنیم که
 

142
00:03:23,680 --> 00:03:26,340
توافقاتی کار می کنیم که
در درازمدت وضعیت همه ما را بهتر می کند، درست است و شما

143
00:03:26,340 --> 00:03:26,350
در درازمدت وضعیت همه ما را بهتر می کند، درست است و شما
 

144
00:03:26,350 --> 00:03:30,120
در درازمدت وضعیت همه ما را بهتر می کند، درست است و شما
این کار را تقریبا غیرقابل انکار و به

145
00:03:30,120 --> 00:03:30,130
این کار را تقریبا غیرقابل انکار و به
 

146
00:03:30,130 --> 00:03:32,250
این کار را تقریبا غیرقابل انکار و به
روشی مبتنی بر داده در کتاب اخیر انجام می دهید، اما من می

147
00:03:32,250 --> 00:03:32,260
روشی مبتنی بر داده در کتاب اخیر انجام می دهید، اما من می
 

148
00:03:32,260 --> 00:03:33,600
روشی مبتنی بر داده در کتاب اخیر انجام می دهید، اما من می
خواهم تمرکز کنم  در مورد

149
00:03:33,600 --> 00:03:33,610
خواهم تمرکز کنم  در مورد
 

150
00:03:33,610 --> 00:03:36,390
خواهم تمرکز کنم  در مورد
جنبه هوش مصنوعی اشیا و نه

151
00:03:36,390 --> 00:03:36,400
جنبه هوش مصنوعی اشیا و نه
 

152
00:03:36,400 --> 00:03:37,980
جنبه هوش مصنوعی اشیا و نه
فقط هوش مصنوعی، بلکه

153
00:03:37,980 --> 00:03:37,990
فقط هوش مصنوعی، بلکه
 

154
00:03:37,990 --> 00:03:40,920
فقط هوش مصنوعی، بلکه
هوش طبیعی نیز، بنابراین بیست سال پیش در

155
00:03:40,920 --> 00:03:40,930
هوش طبیعی نیز، بنابراین بیست سال پیش در
 

156
00:03:40,930 --> 00:03:42,570
هوش طبیعی نیز، بنابراین بیست سال پیش در
کتابی که در مورد نحوه عملکرد ذهن نوشته‌اید،

157
00:03:42,570 --> 00:03:42,580
کتابی که در مورد نحوه عملکرد ذهن نوشته‌اید،
 

158
00:03:42,580 --> 00:03:43,110
کتابی که در مورد نحوه عملکرد ذهن نوشته‌اید،

159
00:03:43,110 --> 00:03:43,120

 

160
00:03:43,120 --> 00:03:46,170

دوباره حدس می‌زنید که حق من برای

161
00:03:46,170 --> 00:03:46,180
دوباره حدس می‌زنید که حق من برای
 

162
00:03:46,180 --> 00:03:49,290
دوباره حدس می‌زنید که حق من برای
تفسیر چیزهایی است که می‌توانید

163
00:03:49,290 --> 00:03:49,300
تفسیر چیزهایی است که می‌توانید
 

164
00:03:49,300 --> 00:03:50,580
تفسیر چیزهایی است که می‌توانید
اگر هستم می‌توانید مرا اصلاح کنید.  اشتباه است، اما شما

165
00:03:50,580 --> 00:03:50,590
اگر هستم می‌توانید مرا اصلاح کنید.  اشتباه است، اما شما
 

166
00:03:50,590 --> 00:03:52,590
اگر هستم می‌توانید مرا اصلاح کنید.  اشتباه است، اما شما
حدس می زنید که فکر انسان در

167
00:03:52,590 --> 00:03:52,600
حدس می زنید که فکر انسان در
 

168
00:03:52,600 --> 00:03:54,900
حدس می زنید که فکر انسان در
مغز ممکن است نتیجه این باشد و اکنون ما یک

169
00:03:54,900 --> 00:03:54,910
مغز ممکن است نتیجه این باشد و اکنون ما یک
 

170
00:03:54,910 --> 00:03:56,280
مغز ممکن است نتیجه این باشد و اکنون ما یک
شبکه عظیم از نورون های بسیار به هم پیوسته هستیم،

171
00:03:56,280 --> 00:03:56,290
شبکه عظیم از نورون های بسیار به هم پیوسته هستیم،
 

172
00:03:56,290 --> 00:03:59,610
شبکه عظیم از نورون های بسیار به هم پیوسته هستیم،
بنابراین از این ارتباط متقابل

173
00:03:59,610 --> 00:03:59,620
بنابراین از این ارتباط متقابل
 

174
00:03:59,620 --> 00:04:02,580
بنابراین از این ارتباط متقابل
فکر در مقایسه با

175
00:04:02,580 --> 00:04:02,590
فکر در مقایسه با
 

176
00:04:02,590 --> 00:04:05,010
فکر در مقایسه با
شبکه های عصبی مصنوعی که امروزه برای یادگیری ماشین استفاده می کنیم، پدید می آید،

177
00:04:05,010 --> 00:04:05,020
شبکه های عصبی مصنوعی که امروزه برای یادگیری ماشین استفاده می کنیم، پدید می آید،
 

178
00:04:05,020 --> 00:04:07,170
شبکه های عصبی مصنوعی که امروزه برای یادگیری ماشین استفاده می کنیم، پدید می آید،
آیا چیزی

179
00:04:07,170 --> 00:04:07,180
آیا چیزی
 

180
00:04:07,180 --> 00:04:10,050
آیا چیزی
اساساً پیچیده تر است.  اسرارآمیز

181
00:04:10,050 --> 00:04:10,060
اساساً پیچیده تر است.  اسرارآمیز
 

182
00:04:10,060 --> 00:04:13,050
اساساً پیچیده تر است.  اسرارآمیز
حتی جادویی در مورد

183
00:04:13,050 --> 00:04:13,060
حتی جادویی در مورد
 

184
00:04:13,060 --> 00:04:15,150
حتی جادویی در مورد
شبکه های عصبی بیولوژیکی در مقابل شبکه هایی که

185
00:04:15,150 --> 00:04:15,160
شبکه های عصبی بیولوژیکی در مقابل شبکه هایی که
 

186
00:04:15,160 --> 00:04:19,260
شبکه های عصبی بیولوژیکی در مقابل شبکه هایی که
در 60 سال گذشته شروع به استفاده از آن کرده ایم

187
00:04:19,260 --> 00:04:19,270
در 60 سال گذشته شروع به استفاده از آن کرده ایم
 

188
00:04:19,270 --> 00:04:21,469
در 60 سال گذشته شروع به استفاده از آن کرده ایم
و در 10 سال گذشته موفقیت آمیز بوده است.

189
00:04:21,469 --> 00:04:23,720
و در 10 سال گذشته موفقیت آمیز بوده است.
 

190
00:04:23,720 --> 00:04:26,480

 

191
00:04:26,480 --> 00:04:29,150

 

192
00:04:29,150 --> 00:04:29,160

 

193
00:04:29,160 --> 00:04:31,700

ما که یک شبکه عصبی هستیم می دانیم که

194
00:04:31,700 --> 00:04:31,710
ما که یک شبکه عصبی هستیم می دانیم که
 

195
00:04:31,710 --> 00:04:34,580
ما که یک شبکه عصبی هستیم می دانیم که
خودمان آگاه هستیم نه

196
00:04:34,580 --> 00:04:34,590
خودمان آگاه هستیم نه
 

197
00:04:34,590 --> 00:04:36,080
خودمان آگاه هستیم نه
از حس ثبت

198
00:04:36,080 --> 00:04:36,090
از حس ثبت
 

199
00:04:36,090 --> 00:04:37,700
از حس ثبت
محیط اطراف خود یا حتی ثبت

200
00:04:37,700 --> 00:04:37,710
محیط اطراف خود یا حتی ثبت
 

201
00:04:37,710 --> 00:04:40,640
محیط اطراف خود یا حتی ثبت
وضعیت درونی خود، بلکه در داشتن

202
00:04:40,640 --> 00:04:40,650
وضعیت درونی خود، بلکه در داشتن
 

203
00:04:40,650 --> 00:04:42,650
وضعیت درونی خود، بلکه در داشتن
تجربه ذهنی اول شخص زمان حال،

204
00:04:42,650 --> 00:04:42,660
تجربه ذهنی اول شخص زمان حال،
 

205
00:04:42,660 --> 00:04:45,380
تجربه ذهنی اول شخص زمان حال،
یعنی زمانی که من قرمز را می بینم، فقط

206
00:04:45,380 --> 00:04:45,390
یعنی زمانی که من قرمز را می بینم، فقط
 

207
00:04:45,390 --> 00:04:48,200
یعنی زمانی که من قرمز را می بینم، فقط
با سبز متفاوت نیست.  اما فقط

208
00:04:48,200 --> 00:04:48,210
با سبز متفاوت نیست.  اما فقط
 

209
00:04:48,210 --> 00:04:50,690
با سبز متفاوت نیست.  اما فقط
یک قرمزی در آن وجود دارد، من احساس می کنم که آیا

210
00:04:50,690 --> 00:04:50,700
یک قرمزی در آن وجود دارد، من احساس می کنم که آیا
 

211
00:04:50,700 --> 00:04:52,580
یک قرمزی در آن وجود دارد، من احساس می کنم که آیا
یک سیستم مصنوعی آن را تجربه می کند

212
00:04:52,580 --> 00:04:52,590
یک سیستم مصنوعی آن را تجربه می کند
 

213
00:04:52,590 --> 00:04:54,350
یک سیستم مصنوعی آن را تجربه می کند
یا نه.  آیا ما

214
00:04:54,350 --> 00:04:56,210
یا نه.  آیا ما
 

215
00:04:56,210 --> 00:04:57,950

 

216
00:04:57,950 --> 00:05:00,560

 

217
00:05:00,560 --> 00:05:03,410

 

218
00:05:03,410 --> 00:05:03,420

 

219
00:05:03,420 --> 00:05:05,930

آگاهی را به یک انسان نسبت می دهیم یا باید

220
00:05:05,930 --> 00:05:05,940
آگاهی را به یک انسان نسبت می دهیم یا باید
 

221
00:05:05,940 --> 00:05:07,940
آگاهی را به یک انسان نسبت می دهیم یا باید
آگاهی را به آن نسبت دهیم و

222
00:05:07,940 --> 00:05:07,950
آگاهی را به آن نسبت دهیم و
 

223
00:05:07,950 --> 00:05:10,790
آگاهی را به آن نسبت دهیم و
این چیزی است که دانستن آن بسیار سخت است،

224
00:05:10,790 --> 00:05:10,800
این چیزی است که دانستن آن بسیار سخت است،
 

225
00:05:10,800 --> 00:05:12,680
این چیزی است که دانستن آن بسیار سخت است،
اما با کنار گذاشتن آن در

226
00:05:12,680 --> 00:05:12,690
اما با کنار گذاشتن آن در
 

227
00:05:12,690 --> 00:05:15,070
اما با کنار گذاشتن آن در
آن سؤال عمدتاً فلسفی،

228
00:05:15,070 --> 00:05:15,080
آن سؤال عمدتاً فلسفی،
 

229
00:05:15,080 --> 00:05:18,680
آن سؤال عمدتاً فلسفی،
سؤال این است که آیا تفاوتی

230
00:05:18,680 --> 00:05:18,690
سؤال این است که آیا تفاوتی
 

231
00:05:18,690 --> 00:05:20,810
سؤال این است که آیا تفاوتی
بین شبکه عصبی انسان و

232
00:05:20,810 --> 00:05:20,820
بین شبکه عصبی انسان و
 

233
00:05:20,820 --> 00:05:22,670
بین شبکه عصبی انسان و
مواردی که ما در

234
00:05:22,670 --> 00:05:22,680
مواردی که ما در
 

235
00:05:22,680 --> 00:05:24,680
مواردی که ما در
هوش مصنوعی می‌سازیم به این معنی است که ما در

236
00:05:24,680 --> 00:05:24,690
هوش مصنوعی می‌سازیم به این معنی است که ما در
 

237
00:05:24,690 --> 00:05:26,810
هوش مصنوعی می‌سازیم به این معنی است که ما در
مسیر فعلی هستیم و به نقطه‌ای نخواهیم رسید که

238
00:05:26,810 --> 00:05:26,820
مسیر فعلی هستیم و به نقطه‌ای نخواهیم رسید که
 

239
00:05:26,820 --> 00:05:29,960
مسیر فعلی هستیم و به نقطه‌ای نخواهیم رسید که
یک ربات واقعی داشته باشیم که

240
00:05:29,960 --> 00:05:29,970
یک ربات واقعی داشته باشیم که
 

241
00:05:29,970 --> 00:05:31,760
یک ربات واقعی داشته باشیم که
از انسان قابل تشخیص نیست،

242
00:05:31,760 --> 00:05:31,770
از انسان قابل تشخیص نیست،
 

243
00:05:31,770 --> 00:05:33,920
از انسان قابل تشخیص نیست،
زیرا نحوه سازماندهی شبکه‌های عصبی به اصطلاح عصبی آنها

244
00:05:33,920 --> 00:05:35,330
زیرا نحوه سازماندهی شبکه‌های عصبی به اصطلاح عصبی آنها
 

245
00:05:35,330 --> 00:05:35,340

 

246
00:05:35,340 --> 00:05:36,620

متفاوت است.  از نحوه

247
00:05:36,620 --> 00:05:36,630
متفاوت است.  از نحوه
 

248
00:05:36,630 --> 00:05:39,410
متفاوت است.  از نحوه
سازماندهی شبکه های ما که همپوشانی وجود دارد، اما من

249
00:05:39,410 --> 00:05:39,420
سازماندهی شبکه های ما که همپوشانی وجود دارد، اما من
 

250
00:05:39,420 --> 00:05:40,910
سازماندهی شبکه های ما که همپوشانی وجود دارد، اما من
فکر می کنم برخی

251
00:05:40,910 --> 00:05:40,920
فکر می کنم برخی
 

252
00:05:40,920 --> 00:05:44,200
فکر می کنم برخی
تفاوت های بزرگ وجود دارد که آنها

253
00:05:44,200 --> 00:05:44,210
تفاوت های بزرگ وجود دارد که آنها
 

254
00:05:44,210 --> 00:05:46,760
تفاوت های بزرگ وجود دارد که آنها
شبکه های عصبی فعلی هستند که

255
00:05:46,760 --> 00:05:46,770
شبکه های عصبی فعلی هستند که
 

256
00:05:46,770 --> 00:05:49,580
شبکه های عصبی فعلی هستند که
سیستم های یادگیری عمیق نامیده می شوند در واقع

257
00:05:49,580 --> 00:05:49,590
سیستم های یادگیری عمیق نامیده می شوند در واقع
 

258
00:05:49,590 --> 00:05:51,800
سیستم های یادگیری عمیق نامیده می شوند در واقع
آنقدر عمیق نیستند، یعنی در

259
00:05:51,800 --> 00:05:51,810
آنقدر عمیق نیستند، یعنی در
 

260
00:05:51,810 --> 00:05:53,990
آنقدر عمیق نیستند، یعنی در
استخراج آماری مرتبه بالا بسیار خوب هستند.

261
00:05:53,990 --> 00:05:54,000
استخراج آماری مرتبه بالا بسیار خوب هستند.
 

262
00:05:54,000 --> 00:05:56,060
استخراج آماری مرتبه بالا بسیار خوب هستند.
قاعده مندی ها اما اکثر سیستم ها

263
00:05:56,060 --> 00:05:56,070
قاعده مندی ها اما اکثر سیستم ها
 

264
00:05:56,070 --> 00:05:58,990
قاعده مندی ها اما اکثر سیستم ها
سطح معنایی سطحی از

265
00:05:58,990 --> 00:05:59,000
سطح معنایی سطحی از
 

266
00:05:59,000 --> 00:06:01,880
سطح معنایی سطحی از
درک واقعی از اینکه چه کسی چه

267
00:06:01,880 --> 00:06:01,890
درک واقعی از اینکه چه کسی چه
 

268
00:06:01,890 --> 00:06:05,630
درک واقعی از اینکه چه کسی چه
کاری را انجام داده است ندارند تا چه کسی چرا کجا چگونه کار می کنند

269
00:06:05,630 --> 00:06:05,640
کاری را انجام داده است ندارند تا چه کسی چرا کجا چگونه کار می کنند
 

270
00:06:05,640 --> 00:06:07,790
کاری را انجام داده است ندارند تا چه کسی چرا کجا چگونه کار می کنند
چه عواملی باعث می شوند فکر می کنید این نوع

271
00:06:07,790 --> 00:06:07,800
چه عواملی باعث می شوند فکر می کنید این نوع
 

272
00:06:07,800 --> 00:06:09,280
چه عواملی باعث می شوند فکر می کنید این نوع
چیزها می تواند ظاهر شود زیرا آنقدر

273
00:06:09,280 --> 00:06:09,290
چیزها می تواند ظاهر شود زیرا آنقدر
 

274
00:06:09,290 --> 00:06:11,660
چیزها می تواند ظاهر شود زیرا آنقدر
مصنوعی است.

275
00:06:11,660 --> 00:06:11,670
مصنوعی است.
 

276
00:06:11,670 --> 00:06:13,190
مصنوعی است.
تعداد اتصالات و غیره در

277
00:06:13,190 --> 00:06:13,200
تعداد اتصالات و غیره در
 

278
00:06:13,200 --> 00:06:16,460
تعداد اتصالات و غیره در
شبکه‌های بیولوژیکی کنونی انسان بسیار کمتر است، اما آیا

279
00:06:16,460 --> 00:06:16,470
شبکه‌های بیولوژیکی کنونی انسان بسیار کمتر است، اما آیا
 

280
00:06:16,470 --> 00:06:18,740
شبکه‌های بیولوژیکی کنونی انسان بسیار کمتر است، اما آیا
فکر می‌کنید به نوعی برای رفتن به

281
00:06:18,740 --> 00:06:18,750
فکر می‌کنید به نوعی برای رفتن به
 

282
00:06:18,750 --> 00:06:20,840
فکر می‌کنید به نوعی برای رفتن به
آگاهی یا رفتن به این

283
00:06:20,840 --> 00:06:20,850
آگاهی یا رفتن به این
 

284
00:06:20,850 --> 00:06:22,850
آگاهی یا رفتن به این
سطح بالاتر استدلال معنایی در مورد چیزهایی

285
00:06:22,850 --> 00:06:22,860
سطح بالاتر استدلال معنایی در مورد چیزهایی
 

286
00:06:22,860 --> 00:06:24,680
سطح بالاتر استدلال معنایی در مورد چیزهایی
که می‌توانند فقط با یک

287
00:06:24,680 --> 00:06:24,690
که می‌توانند فقط با یک
 

288
00:06:24,690 --> 00:06:27,310
که می‌توانند فقط با یک
شبکه بزرگتر با

289
00:06:27,310 --> 00:06:27,320
شبکه بزرگتر با
 

290
00:06:27,320 --> 00:06:29,770
شبکه بزرگتر با
شبکه‌ای به‌طور عجیب و غریب‌تر که هوشیاری را از هم

291
00:06:29,770 --> 00:06:29,780
شبکه‌ای به‌طور عجیب و غریب‌تر که هوشیاری را از هم
 

292
00:06:29,780 --> 00:06:31,730
شبکه‌ای به‌طور عجیب و غریب‌تر که هوشیاری را از هم
جدا می‌کند، زیرا

293
00:06:31,730 --> 00:06:31,740
جدا می‌کند، زیرا
 

294
00:06:31,740 --> 00:06:32,810
جدا می‌کند، زیرا
آگاهی حتی موضوع پیچیده‌ای است،

295
00:06:32,810 --> 00:06:34,250
آگاهی حتی موضوع پیچیده‌ای است،
 

296
00:06:34,250 --> 00:06:34,260

 

297
00:06:34,260 --> 00:06:36,110

بله می‌توانید داشته باشید، می‌توانید به طور معقولی

298
00:06:36,110 --> 00:06:36,120
بله می‌توانید داشته باشید، می‌توانید به طور معقولی
 

299
00:06:36,120 --> 00:06:37,610
بله می‌توانید داشته باشید، می‌توانید به طور معقولی
این سوال را بپرسید که آیا میگوها

300
00:06:37,610 --> 00:06:37,620
این سوال را بپرسید که آیا میگوها
 

301
00:06:37,620 --> 00:06:38,780
این سوال را بپرسید که آیا میگوها
هوشیار هستند، به عنوان مثال، آنها

302
00:06:38,780 --> 00:06:38,790
هوشیار هستند، به عنوان مثال، آنها
 

303
00:06:38,790 --> 00:06:41,420
هوشیار هستند، به عنوان مثال، آنها
خیلی پیچیده نیستند، اما شاید احساس

304
00:06:41,420 --> 00:06:41,430
خیلی پیچیده نیستند، اما شاید احساس
 

305
00:06:41,430 --> 00:06:43,310
خیلی پیچیده نیستند، اما شاید احساس
درد می‌کنند.

306
00:06:43,310 --> 00:06:43,320
درد می‌کنند.
 

307
00:06:43,320 --> 00:06:47,060
درد می‌کنند.
هنوز آن بخش را کنار بگذارید، اما من فکر می کنم

308
00:06:47,060 --> 00:06:47,070
هنوز آن بخش را کنار بگذارید، اما من فکر می کنم
 

309
00:06:47,070 --> 00:06:49,550
هنوز آن بخش را کنار بگذارید، اما من فکر می کنم
اندازه یک شبکه عصبی

310
00:06:49,550 --> 00:06:49,560
اندازه یک شبکه عصبی
 

311
00:06:49,560 --> 00:06:52,730
اندازه یک شبکه عصبی
برای دادن ساختار و دانش کافی نیست، اما

312
00:06:52,730 --> 00:06:52,740
برای دادن ساختار و دانش کافی نیست، اما
 

313
00:06:52,740 --> 00:06:55,490
برای دادن ساختار و دانش کافی نیست، اما
اگر به درستی مهندسی شده باشد، پس

314
00:06:55,490 --> 00:06:55,500
اگر به درستی مهندسی شده باشد، پس
 

315
00:06:55,500 --> 00:06:56,240
اگر به درستی مهندسی شده باشد، پس
چرا

316
00:06:56,240 --> 00:06:56,250
چرا
 

317
00:06:56,250 --> 00:06:58,970
چرا
این جایی نیست که انتخاب طبیعی شبکه های عصبی

318
00:06:58,970 --> 00:06:58,980
این جایی نیست که انتخاب طبیعی شبکه های عصبی
 

319
00:06:58,980 --> 00:07:01,820
این جایی نیست که انتخاب طبیعی شبکه های عصبی
نوعی معادل مهندسی را انجام می دهد.

320
00:07:01,820 --> 00:07:01,830
نوعی معادل مهندسی را انجام می دهد.
 

321
00:07:01,830 --> 00:07:03,710
نوعی معادل مهندسی را انجام می دهد.
از مغز ما، بنابراین نمی‌دانم

322
00:07:03,710 --> 00:07:03,720
از مغز ما، بنابراین نمی‌دانم
 

323
00:07:03,720 --> 00:07:05,120
از مغز ما، بنابراین نمی‌دانم
هیچ چیز مرموزی وجود دارد به این

324
00:07:05,120 --> 00:07:05,130
هیچ چیز مرموزی وجود دارد به این
 

325
00:07:05,130 --> 00:07:08,900
هیچ چیز مرموزی وجود دارد به این
معنا که هیچ سیستمی از

326
00:07:08,900 --> 00:07:08,910
معنا که هیچ سیستمی از
 

327
00:07:08,910 --> 00:07:11,090
معنا که هیچ سیستمی از
سیلیکون نمی‌تواند کاری را انجام دهد که مغز انسان

328
00:07:11,090 --> 00:07:12,560
سیلیکون نمی‌تواند کاری را انجام دهد که مغز انسان
 

329
00:07:12,560 --> 00:07:12,570

 

330
00:07:12,570 --> 00:07:14,200

می‌تواند انجام دهد.

331
00:07:14,200 --> 00:07:14,210
می‌تواند انجام دهد.
 

332
00:07:14,210 --> 00:07:17,390
می‌تواند انجام دهد.
ما در حال

333
00:07:17,390 --> 00:07:17,400
ما در حال
 

334
00:07:17,400 --> 00:07:19,520
ما در حال
مهندسی این سیستم ها هستیم، اما آیا

335
00:07:19,520 --> 00:07:19,530
مهندسی این سیستم ها هستیم، اما آیا
 

336
00:07:19,530 --> 00:07:21,260
مهندسی این سیستم ها هستیم، اما آیا
حتی می خواهیم بدانیم که آیا این

337
00:07:21,260 --> 00:07:21,270
حتی می خواهیم بدانیم که آیا این
 

338
00:07:21,270 --> 00:07:23,480
حتی می خواهیم بدانیم که آیا این
یک هدف معقول است یا نه، می توانید این

339
00:07:23,480 --> 00:07:23,490
یک هدف معقول است یا نه، می توانید این
 

340
00:07:23,490 --> 00:07:26,660
یک هدف معقول است یا نه، می توانید این
سوال را بپرسید که آیا سیستم حرکتی وجود دارد

341
00:07:26,660 --> 00:07:26,670
سوال را بپرسید که آیا سیستم حرکتی وجود دارد
 

342
00:07:26,670 --> 00:07:30,350
سوال را بپرسید که آیا سیستم حرکتی وجود دارد
که به خوبی یک انسان باشد که ما

343
00:07:30,350 --> 00:07:30,360
که به خوبی یک انسان باشد که ما
 

344
00:07:30,360 --> 00:07:31,790
که به خوبی یک انسان باشد که ما
می خواهیم بهتر از یک انسان انجام دهیم.

345
00:07:31,790 --> 00:07:31,800
می خواهیم بهتر از یک انسان انجام دهیم.
 

346
00:07:31,800 --> 00:07:34,900
می خواهیم بهتر از یک انسان انجام دهیم.
در نهایت از نظر حرکت پاها،

347
00:07:34,900 --> 00:07:34,910
در نهایت از نظر حرکت پاها،
 

348
00:07:34,910 --> 00:07:37,370
در نهایت از نظر حرکت پاها،
هیچ دلیلی وجود ندارد که انسان ها باید

349
00:07:37,370 --> 00:07:37,380
هیچ دلیلی وجود ندارد که انسان ها باید
 

350
00:07:37,380 --> 00:07:39,380
هیچ دلیلی وجود ندارد که انسان ها باید
معیار ما باشند، آنها ابزار آنها هستند که

351
00:07:39,380 --> 00:07:39,390
معیار ما باشند، آنها ابزار آنها هستند که
 

352
00:07:39,390 --> 00:07:40,880
معیار ما باشند، آنها ابزار آنها هستند که
ممکن است از جهاتی بهتر باشند، ممکن است

353
00:07:40,880 --> 00:07:40,890
ممکن است از جهاتی بهتر باشند، ممکن است
 

354
00:07:40,890 --> 00:07:45,770
ممکن است از جهاتی بهتر باشند، ممکن است
اینطور نباشد که ما نتوانیم

355
00:07:45,770 --> 00:07:45,780
اینطور نباشد که ما نتوانیم
 

356
00:07:45,780 --> 00:07:49,220
اینطور نباشد که ما نتوانیم
یک سیستم طبیعی را کپی کنیم، زیرا در برخی مواقع

357
00:07:49,220 --> 00:07:49,230
یک سیستم طبیعی را کپی کنیم، زیرا در برخی مواقع
 

358
00:07:49,230 --> 00:07:50,720
یک سیستم طبیعی را کپی کنیم، زیرا در برخی مواقع
بسیار زیاد است.  استفاده از یک سیستم طبیعی ارزان تر است

359
00:07:50,720 --> 00:07:50,730
بسیار زیاد است.  استفاده از یک سیستم طبیعی ارزان تر است
 

360
00:07:50,730 --> 00:07:52,340
بسیار زیاد است.  استفاده از یک سیستم طبیعی ارزان تر است
که ما قصد نداریم

361
00:07:52,340 --> 00:07:52,350
که ما قصد نداریم
 

362
00:07:52,350 --> 00:07:55,040
که ما قصد نداریم
نیروی فکری و منابع بیشتری را سرمایه گذاری کنیم، به عنوان

363
00:07:55,040 --> 00:07:55,050
نیروی فکری و منابع بیشتری را سرمایه گذاری کنیم، به عنوان
 

364
00:07:55,050 --> 00:07:57,980
نیروی فکری و منابع بیشتری را سرمایه گذاری کنیم، به عنوان
مثال ما واقعاً یارانه

365
00:07:57,980 --> 00:07:57,990
مثال ما واقعاً یارانه
 

366
00:07:57,990 --> 00:07:59,990
مثال ما واقعاً یارانه
و جایگزین دقیقی برای چوب نداریم، هنوز

367
00:07:59,990 --> 00:08:00,000
و جایگزین دقیقی برای چوب نداریم، هنوز
 

368
00:08:00,000 --> 00:08:01,280
و جایگزین دقیقی برای چوب نداریم، هنوز
خانه ها را از آن می سازیم، آیا هنوز

369
00:08:01,280 --> 00:08:01,290
خانه ها را از آن می سازیم، آیا هنوز
 

370
00:08:01,290 --> 00:08:03,380
خانه ها را از آن می سازیم، آیا هنوز
مبلمان را از چوبی که دوست داریم می سازیم.  ظاهری که

371
00:08:03,380 --> 00:08:03,390
مبلمان را از چوبی که دوست داریم می سازیم.  ظاهری که
 

372
00:08:03,390 --> 00:08:05,120
مبلمان را از چوبی که دوست داریم می سازیم.  ظاهری که
ما دوست داریم احساس چوب آن را داشته باشیم ویژگی‌های خاصی دارد

373
00:08:05,120 --> 00:08:05,130
ما دوست داریم احساس چوب آن را داشته باشیم ویژگی‌های خاصی دارد
 

374
00:08:05,130 --> 00:08:07,760
ما دوست داریم احساس چوب آن را داشته باشیم ویژگی‌های خاصی دارد
که مواد مصنوعی ندارند،

375
00:08:07,760 --> 00:08:07,770
که مواد مصنوعی ندارند،
 

376
00:08:07,770 --> 00:08:09,410
که مواد مصنوعی ندارند،
نه اینکه چیز جادویی یا

377
00:08:09,410 --> 00:08:09,420
نه اینکه چیز جادویی یا
 

378
00:08:09,420 --> 00:08:12,490
نه اینکه چیز جادویی یا
اسرارآمیزی در مورد چوب وجود دارد، فقط این است که

379
00:08:12,490 --> 00:08:12,500
اسرارآمیزی در مورد چوب وجود دارد، فقط این است که
 

380
00:08:12,500 --> 00:08:15,710
اسرارآمیزی در مورد چوب وجود دارد، فقط این است که
مراحل اضافی تکرار کردن همه چیز

381
00:08:15,710 --> 00:08:15,720
مراحل اضافی تکرار کردن همه چیز
 

382
00:08:15,720 --> 00:08:17,780
مراحل اضافی تکرار کردن همه چیز
در مورد چوب چیزی است که ما

383
00:08:17,780 --> 00:08:17,790
در مورد چوب چیزی است که ما
 

384
00:08:17,790 --> 00:08:19,160
در مورد چوب چیزی است که ما
اذیت نکرده‌ایم زیرا چوب را نیز داریم.

385
00:08:19,160 --> 00:08:19,170
اذیت نکرده‌ایم زیرا چوب را نیز داریم.
 

386
00:08:19,170 --> 00:08:20,480
اذیت نکرده‌ایم زیرا چوب را نیز داریم.
منظورم این است که یک پنبه

387
00:08:20,480 --> 00:08:20,490
منظورم این است که یک پنبه
 

388
00:08:20,490 --> 00:08:22,670
منظورم این است که یک پنبه
لباس پنبه‌ای می‌پوشم که الان خیلی بهتر از

389
00:08:22,670 --> 00:08:22,680
لباس پنبه‌ای می‌پوشم که الان خیلی بهتر از
 

390
00:08:22,680 --> 00:08:26,000
لباس پنبه‌ای می‌پوشم که الان خیلی بهتر از
پلی استر است، این به این معنی نیست که پنبه

391
00:08:26,000 --> 00:08:26,010
پلی استر است، این به این معنی نیست که پنبه
 

392
00:08:26,010 --> 00:08:28,370
پلی استر است، این به این معنی نیست که پنبه
چیزی جادویی در آن دارد و اینطور نیست که

393
00:08:28,370 --> 00:08:28,380
چیزی جادویی در آن دارد و اینطور نیست که
 

394
00:08:28,380 --> 00:08:30,050
چیزی جادویی در آن دارد و اینطور نیست که
اگر وجود داشت نمی‌توانستیم

395
00:08:30,050 --> 00:08:30,060
اگر وجود داشت نمی‌توانستیم
 

396
00:08:30,060 --> 00:08:32,810
اگر وجود داشت نمی‌توانستیم
چیزی دقیقاً شبیه پنبه را سنتز کنیم،

397
00:08:32,810 --> 00:08:32,820
چیزی دقیقاً شبیه پنبه را سنتز کنیم،
 

398
00:08:32,820 --> 00:08:35,240
چیزی دقیقاً شبیه پنبه را سنتز کنیم،
اما در بعضی مواقع آن را فقط  این فقط

399
00:08:35,240 --> 00:08:35,250
اما در بعضی مواقع آن را فقط  این فقط
 

400
00:08:35,250 --> 00:08:36,920
اما در بعضی مواقع آن را فقط  این فقط
ارزشش را ندارد که ما پنبه داشته باشیم و همینطور

401
00:08:36,920 --> 00:08:36,930
ارزشش را ندارد که ما پنبه داشته باشیم و همینطور
 

402
00:08:36,930 --> 00:08:38,960
ارزشش را ندارد که ما پنبه داشته باشیم و همینطور
در مورد هوش انسانی،

403
00:08:38,960 --> 00:08:38,970
در مورد هوش انسانی،
 

404
00:08:38,970 --> 00:08:41,900
در مورد هوش انسانی،
هدف از ساختن یک سیستم مصنوعی که

405
00:08:41,900 --> 00:08:41,910
هدف از ساختن یک سیستم مصنوعی که
 

406
00:08:41,910 --> 00:08:44,690
هدف از ساختن یک سیستم مصنوعی که
دقیقاً شبیه مغز انسان است،

407
00:08:44,690 --> 00:08:44,700
دقیقاً شبیه مغز انسان است،
 

408
00:08:44,700 --> 00:08:46,490
دقیقاً شبیه مغز انسان است،
هدفی است که ما

409
00:08:46,490 --> 00:08:46,500
هدفی است که ما
 

410
00:08:46,500 --> 00:08:48,140
هدفی است که ما
هیچ کس تا پایان تلخ آن را دنبال نخواهیم کرد،

411
00:08:48,140 --> 00:08:48,150
هیچ کس تا پایان تلخ آن را دنبال نخواهیم کرد،
 

412
00:08:48,150 --> 00:08:51,530
هیچ کس تا پایان تلخ آن را دنبال نخواهیم کرد،
زیرا اگر شما  ابزارهایی می‌خواهید که

413
00:08:51,530 --> 00:08:51,540
زیرا اگر شما  ابزارهایی می‌خواهید که
 

414
00:08:51,540 --> 00:08:53,000
زیرا اگر شما  ابزارهایی می‌خواهید که
کارها را بهتر از انسان‌ها انجام می‌دهند،

415
00:08:53,000 --> 00:08:53,010
کارها را بهتر از انسان‌ها انجام می‌دهند،
 

416
00:08:53,010 --> 00:08:54,110
کارها را بهتر از انسان‌ها انجام می‌دهند،
اهمیتی نمی‌دهید که آیا این کار

417
00:08:54,110 --> 00:08:54,120
اهمیتی نمی‌دهید که آیا این کار
 

418
00:08:54,120 --> 00:08:55,610
اهمیتی نمی‌دهید که آیا این کار
مانند انسان‌ها انجام می‌دهد، مثلاً

419
00:08:55,610 --> 00:08:55,620
مانند انسان‌ها انجام می‌دهد، مثلاً
 

420
00:08:55,620 --> 00:08:58,220
مانند انسان‌ها انجام می‌دهد، مثلاً
سرطان را تشخیص می‌دهید یا به‌خصوص اینکه

421
00:08:58,220 --> 00:08:58,230
سرطان را تشخیص می‌دهید یا به‌خصوص اینکه
 

422
00:08:58,230 --> 00:09:00,410
سرطان را تشخیص می‌دهید یا به‌خصوص اینکه
چرا انسان‌ها را معیار خود قرار می‌دهید،

423
00:09:00,410 --> 00:09:00,420
چرا انسان‌ها را معیار خود قرار می‌دهید،
 

424
00:09:00,420 --> 00:09:04,460
چرا انسان‌ها را معیار خود قرار می‌دهید،
اما به طور کلی من گمان می‌کنم که شما نیز

425
00:09:04,460 --> 00:09:04,470
اما به طور کلی من گمان می‌کنم که شما نیز
 

426
00:09:04,470 --> 00:09:07,610
اما به طور کلی من گمان می‌کنم که شما نیز
معتقدید که حتی اگر  انسان نباید

427
00:09:07,610 --> 00:09:07,620
معتقدید که حتی اگر  انسان نباید
 

428
00:09:07,620 --> 00:09:09,440
معتقدید که حتی اگر  انسان نباید
معیاری برای زنان باشد که نمی‌خواهند از

429
00:09:09,440 --> 00:09:09,450
معیاری برای زنان باشد که نمی‌خواهند از
 

430
00:09:09,450 --> 00:09:10,880
معیاری برای زنان باشد که نمی‌خواهند از
انسان‌ها در سیستم خود تقلید کنند، در

431
00:09:10,880 --> 00:09:10,890
انسان‌ها در سیستم خود تقلید کنند، در
 

432
00:09:10,890 --> 00:09:13,490
انسان‌ها در سیستم خود تقلید کنند، در
مورد چگونگی

433
00:09:13,490 --> 00:09:13,500
مورد چگونگی
 

434
00:09:13,500 --> 00:09:15,260
مورد چگونگی
ایجاد یک سیستم هوش مصنوعی

435
00:09:15,260 --> 00:09:15,270
ایجاد یک سیستم هوش مصنوعی
 

436
00:09:15,270 --> 00:09:17,750
ایجاد یک سیستم هوش مصنوعی
با مطالعه انسان‌ها چیزهای زیادی باید آموخت.

437
00:09:17,750 --> 00:09:18,440
با مطالعه انسان‌ها چیزهای زیادی باید آموخت.
 

438
00:09:18,440 --> 00:09:21,740

 

439
00:09:21,740 --> 00:09:21,750

 

440
00:09:21,750 --> 00:09:23,660

ماشین‌های پرنده بسازیم که می‌خواهیم

441
00:09:23,660 --> 00:09:23,670
ماشین‌های پرنده بسازیم که می‌خواهیم
 

442
00:09:23,670 --> 00:09:26,180
ماشین‌های پرنده بسازیم که می‌خواهیم
قوانین آیرودینامیک و شامل پرندگان را درک کنیم،

443
00:09:26,180 --> 00:09:26,190
قوانین آیرودینامیک و شامل پرندگان را درک کنیم،
 

444
00:09:26,190 --> 00:09:28,460
قوانین آیرودینامیک و شامل پرندگان را درک کنیم،
اما از پرندگان تقلید نکنیم، اما

445
00:09:28,460 --> 00:09:28,470
اما از پرندگان تقلید نکنیم، اما
 

446
00:09:28,470 --> 00:09:33,260
اما از پرندگان تقلید نکنیم، اما
همان قوانینی را که شما در مورد

447
00:09:33,260 --> 00:09:33,270
همان قوانینی را که شما در مورد
 

448
00:09:33,270 --> 00:09:36,640
همان قوانینی را که شما در مورد
هوش مصنوعی و ایمنی هوش مصنوعی می‌بینید که

449
00:09:36,640 --> 00:09:36,650
هوش مصنوعی و ایمنی هوش مصنوعی می‌بینید که
 

450
00:09:36,650 --> 00:09:41,560
هوش مصنوعی و ایمنی هوش مصنوعی می‌بینید که
از دیدگاه من بسیار

451
00:09:41,560 --> 00:09:41,570
از دیدگاه من بسیار
 

452
00:09:41,570 --> 00:09:46,820
از دیدگاه من بسیار
منطقی است یا شاید مهم‌تر

453
00:09:46,820 --> 00:09:46,830
منطقی است یا شاید مهم‌تر
 

454
00:09:46,830 --> 00:09:49,820
منطقی است یا شاید مهم‌تر
از آن دارای عناصر مثبت باشد.  که

455
00:09:49,820 --> 00:09:49,830
از آن دارای عناصر مثبت باشد.  که
 

456
00:09:49,830 --> 00:09:52,190
از آن دارای عناصر مثبت باشد.  که
فکر می‌کنم

457
00:09:52,190 --> 00:09:52,200
فکر می‌کنم
 

458
00:09:52,200 --> 00:09:55,070
فکر می‌کنم
برای بسیاری از افراد از

459
00:09:55,070 --> 00:09:55,080
برای بسیاری از افراد از
 

460
00:09:55,080 --> 00:09:57,620
برای بسیاری از افراد از
جمله محققان هوش مصنوعی می‌تواند الهام‌بخش و قدرت‌بخش باشد.

461
00:09:57,620 --> 00:10:01,190
جمله محققان هوش مصنوعی می‌تواند الهام‌بخش و قدرت‌بخش باشد.
 

462
00:10:01,190 --> 00:10:03,800

 

463
00:10:03,800 --> 00:10:06,500

 

464
00:10:06,500 --> 00:10:11,060

 

465
00:10:11,060 --> 00:10:11,070

 

466
00:10:11,070 --> 00:10:14,000

به شدت نگران

467
00:10:14,000 --> 00:10:14,010
به شدت نگران
 

468
00:10:14,010 --> 00:10:16,550
به شدت نگران
اردوگاه هوش مصنوعی است که می گوید چیزهایی مانند هوش مصنوعی بسیار

469
00:10:16,550 --> 00:10:16,560
اردوگاه هوش مصنوعی است که می گوید چیزهایی مانند هوش مصنوعی بسیار
 

470
00:10:16,560 --> 00:10:18,290
اردوگاه هوش مصنوعی است که می گوید چیزهایی مانند هوش مصنوعی بسیار
خطرناک تر است و سلاح های هسته ای و

471
00:10:18,290 --> 00:10:18,300
خطرناک تر است و سلاح های هسته ای و
 

472
00:10:18,300 --> 00:10:21,620
خطرناک تر است و سلاح های هسته ای و
اینکه هوش مصنوعی احتمالا تمدن بشری را نابود خواهد کرد،

473
00:10:21,620 --> 00:10:21,630
اینکه هوش مصنوعی احتمالا تمدن بشری را نابود خواهد کرد،
 

474
00:10:21,630 --> 00:10:24,500
اینکه هوش مصنوعی احتمالا تمدن بشری را نابود خواهد کرد،
بنابراین در ماه فوریه گفتید

475
00:10:24,500 --> 00:10:24,510
بنابراین در ماه فوریه گفتید
 

476
00:10:24,510 --> 00:10:27,550
بنابراین در ماه فوریه گفتید
که اگر ایلان واقعاً در مورد هوش مصنوعی جدی بود،

477
00:10:27,550 --> 00:10:27,560
که اگر ایلان واقعاً در مورد هوش مصنوعی جدی بود،
 

478
00:10:27,560 --> 00:10:31,220
که اگر ایلان واقعاً در مورد هوش مصنوعی جدی بود،
تهدید هوش مصنوعی بود، او

479
00:10:31,220 --> 00:10:31,230
تهدید هوش مصنوعی بود، او
 

480
00:10:31,230 --> 00:10:33,260
تهدید هوش مصنوعی بود، او
ساخت خودران را متوقف می کرد.  خودروهایی که او

481
00:10:33,260 --> 00:10:33,270
ساخت خودران را متوقف می کرد.  خودروهایی که او
 

482
00:10:33,270 --> 00:10:35,050
ساخت خودران را متوقف می کرد.  خودروهایی که او
به عنوان بخشی از تسلا با موفقیت انجام می دهد،

483
00:10:35,050 --> 00:10:35,060
به عنوان بخشی از تسلا با موفقیت انجام می دهد،
 

484
00:10:35,060 --> 00:10:39,079
به عنوان بخشی از تسلا با موفقیت انجام می دهد،
سپس گفت وای اگر حتی پینکر هم

485
00:10:39,079 --> 00:10:39,089
سپس گفت وای اگر حتی پینکر هم
 

486
00:10:39,089 --> 00:10:40,370
سپس گفت وای اگر حتی پینکر هم
تفاوت بین

487
00:10:40,370 --> 00:10:40,380
تفاوت بین
 

488
00:10:40,380 --> 00:10:43,790
تفاوت بین
هوش مصنوعی پیکان مانند یک ماشین را در هوش مصنوعی عمومی درک نمی کند، در حالی که

489
00:10:43,790 --> 00:10:43,800
هوش مصنوعی پیکان مانند یک ماشین را در هوش مصنوعی عمومی درک نمی کند، در حالی که
 

490
00:10:43,800 --> 00:10:45,740
هوش مصنوعی پیکان مانند یک ماشین را در هوش مصنوعی عمومی درک نمی کند، در حالی که
دومی به معنای واقعی کلمه یک میلیون برابر

491
00:10:45,740 --> 00:10:45,750
دومی به معنای واقعی کلمه یک میلیون برابر
 

492
00:10:45,750 --> 00:10:48,320
دومی به معنای واقعی کلمه یک میلیون برابر
قدرت محاسباتی بیشتری دارد و یک

493
00:10:48,320 --> 00:10:48,330
قدرت محاسباتی بیشتری دارد و یک
 

494
00:10:48,330 --> 00:10:51,020
قدرت محاسباتی بیشتری دارد و یک
تابع ابزار با پایان باز دارد.  بشریت در مشکل عمیقی قرار دارد،

495
00:10:51,020 --> 00:10:51,030
تابع ابزار با پایان باز دارد.  بشریت در مشکل عمیقی قرار دارد،
 

496
00:10:51,030 --> 00:10:54,260
تابع ابزار با پایان باز دارد.  بشریت در مشکل عمیقی قرار دارد،
بنابراین ابتدا منظور شما از

497
00:10:54,260 --> 00:10:54,270
بنابراین ابتدا منظور شما از
 

498
00:10:54,270 --> 00:10:56,720
بنابراین ابتدا منظور شما از
این جمله در مورد ایلان ماسک چیست،

499
00:10:56,720 --> 00:10:56,730
این جمله در مورد ایلان ماسک چیست،
 

500
00:10:56,730 --> 00:10:58,340
این جمله در مورد ایلان ماسک چیست،
اگر بیل

501
00:10:58,340 --> 00:10:58,350
اگر بیل
 

502
00:10:58,350 --> 00:10:59,720
اگر بیل
عمیقاً نگران است که

503
00:10:59,720 --> 00:10:59,730
عمیقاً نگران است که
 

504
00:10:59,730 --> 00:11:02,179
عمیقاً نگران است که
آخرین باری که ایلان ماسک

505
00:11:02,179 --> 00:11:02,189
آخرین باری که ایلان ماسک
 

506
00:11:02,189 --> 00:11:05,509
آخرین باری که ایلان ماسک
یک توییت نامتعادل منتشر کرده است، باید خودمان از رانندگی ماشین جلوگیری کنیم، خوب ما در دنیایی زندگی می کنیم

507
00:11:05,509 --> 00:11:05,519
یک توییت نامتعادل منتشر کرده است، باید خودمان از رانندگی ماشین جلوگیری کنیم، خوب ما در دنیایی زندگی می کنیم
 

508
00:11:05,519 --> 00:11:09,049
یک توییت نامتعادل منتشر کرده است، باید خودمان از رانندگی ماشین جلوگیری کنیم، خوب ما در دنیایی زندگی می کنیم
که توییتر قدرت دارد، بله.  بله،

509
00:11:09,049 --> 00:11:09,059
که توییتر قدرت دارد، بله.  بله،
 

510
00:11:09,059 --> 00:11:14,720
که توییتر قدرت دارد، بله.  بله،
من فکر می کنم که دو نوع

511
00:11:14,720 --> 00:11:14,730
من فکر می کنم که دو نوع
 

512
00:11:14,730 --> 00:11:16,159
من فکر می کنم که دو نوع
تهدید وجودی وجود دارد که

513
00:11:16,159 --> 00:11:16,169
تهدید وجودی وجود دارد که
 

514
00:11:16,169 --> 00:11:17,809
تهدید وجودی وجود دارد که
در ارتباط با هوش مصنوعی مورد بحث قرار گرفته است

515
00:11:17,809 --> 00:11:17,819
در ارتباط با هوش مصنوعی مورد بحث قرار گرفته است
 

516
00:11:17,819 --> 00:11:19,009
در ارتباط با هوش مصنوعی مورد بحث قرار گرفته است
و فکر می کنم هر

517
00:11:19,009 --> 00:11:19,019
و فکر می کنم هر
 

518
00:11:19,019 --> 00:11:21,949
و فکر می کنم هر
دو نامنسجم هستند، یکی از آنها

519
00:11:21,949 --> 00:11:21,959
دو نامنسجم هستند، یکی از آنها
 

520
00:11:21,959 --> 00:11:26,299
دو نامنسجم هستند، یکی از آنها
ترس مبهم از تسخیر هوش مصنوعی است که همانطور که ما

521
00:11:26,299 --> 00:11:26,309
ترس مبهم از تسخیر هوش مصنوعی است که همانطور که ما
 

522
00:11:26,309 --> 00:11:28,759
ترس مبهم از تسخیر هوش مصنوعی است که همانطور که ما
حیوانات را تحت سلطه خود درآوردیم و کمتر از نظر

523
00:11:28,759 --> 00:11:28,769
حیوانات را تحت سلطه خود درآوردیم و کمتر از نظر
 

524
00:11:28,769 --> 00:11:31,249
حیوانات را تحت سلطه خود درآوردیم و کمتر از نظر
فناوری  افراد پیشرفته، بنابراین اگر

525
00:11:31,249 --> 00:11:31,259
فناوری  افراد پیشرفته، بنابراین اگر
 

526
00:11:31,259 --> 00:11:32,869
فناوری  افراد پیشرفته، بنابراین اگر
چیزی پیشرفته‌تر

527
00:11:32,869 --> 00:11:32,879
چیزی پیشرفته‌تر
 

528
00:11:32,879 --> 00:11:34,849
چیزی پیشرفته‌تر
از خود بسازیم، ناگزیر ما را به

529
00:11:34,849 --> 00:11:34,859
از خود بسازیم، ناگزیر ما را به
 

530
00:11:34,859 --> 00:11:38,720
از خود بسازیم، ناگزیر ما را به
حیوانات خانگی یا برده یا حیوانات اهلی تبدیل می‌کند،

531
00:11:38,720 --> 00:11:38,730
حیوانات خانگی یا برده یا حیوانات اهلی تبدیل می‌کند،
 

532
00:11:38,730 --> 00:11:39,590
حیوانات خانگی یا برده یا حیوانات اهلی تبدیل می‌کند،

533
00:11:39,590 --> 00:11:39,600

 

534
00:11:39,600 --> 00:11:42,559

فکر می‌کنم این هوش را با

535
00:11:42,559 --> 00:11:42,569
فکر می‌کنم این هوش را با
 

536
00:11:42,569 --> 00:11:46,280
فکر می‌کنم این هوش را با
اراده به قدرت اشتباه می‌گیرد که

537
00:11:46,280 --> 00:11:46,290
اراده به قدرت اشتباه می‌گیرد که
 

538
00:11:46,290 --> 00:11:48,619
اراده به قدرت اشتباه می‌گیرد که
در سیستم اطلاعاتی ما بیشتر

539
00:11:48,619 --> 00:11:48,629
در سیستم اطلاعاتی ما بیشتر
 

540
00:11:48,629 --> 00:11:51,319
در سیستم اطلاعاتی ما بیشتر
با آن آشنا هستیم.  یعنی هومو ساپینس ما

541
00:11:51,319 --> 00:11:51,329
با آن آشنا هستیم.  یعنی هومو ساپینس ما
 

542
00:11:51,329 --> 00:11:53,119
با آن آشنا هستیم.  یعنی هومو ساپینس ما
محصول انتخاب طبیعی هستیم که یک

543
00:11:53,119 --> 00:11:53,129
محصول انتخاب طبیعی هستیم که یک
 

544
00:11:53,129 --> 00:11:55,069
محصول انتخاب طبیعی هستیم که یک
فرآیند رقابتی است و بنابراین

545
00:11:55,069 --> 00:11:55,079
فرآیند رقابتی است و بنابراین
 

546
00:11:55,079 --> 00:11:56,299
فرآیند رقابتی است و بنابراین
همراه با ظرفیت حل مسئله ما

547
00:11:56,299 --> 00:11:56,309
همراه با ظرفیت حل مسئله ما
 

548
00:11:56,309 --> 00:11:59,299
همراه با ظرفیت حل مسئله ما
یک سری صفات ناپسند

549
00:11:59,299 --> 00:11:59,309
یک سری صفات ناپسند
 

550
00:11:59,309 --> 00:12:03,769
یک سری صفات ناپسند
مانند تسلط و استثمار و

551
00:12:03,769 --> 00:12:03,779
مانند تسلط و استثمار و
 

552
00:12:03,779 --> 00:12:06,289
مانند تسلط و استثمار و
به حداکثر رساندن قدرت و شکوه و

553
00:12:06,289 --> 00:12:06,299
به حداکثر رساندن قدرت و شکوه و
 

554
00:12:06,299 --> 00:12:09,229
به حداکثر رساندن قدرت و شکوه و
منابع و نفوذ وجود دارد،

555
00:12:09,229 --> 00:12:09,239
منابع و نفوذ وجود دارد،
 

556
00:12:09,239 --> 00:12:10,579
منابع و نفوذ وجود دارد،
دلیلی وجود ندارد که فکر کنیم که

557
00:12:10,579 --> 00:12:10,589
دلیلی وجود ندارد که فکر کنیم که
 

558
00:12:10,589 --> 00:12:12,739
دلیلی وجود ندارد که فکر کنیم که
توانایی حل مسئله محض این را تعیین می کند که

559
00:12:12,739 --> 00:12:12,749
توانایی حل مسئله محض این را تعیین می کند که
 

560
00:12:12,749 --> 00:12:14,629
توانایی حل مسئله محض این را تعیین می کند که
به عنوان یکی از اهدافش،

561
00:12:14,629 --> 00:12:14,639
به عنوان یکی از اهدافش،
 

562
00:12:14,639 --> 00:12:17,539
به عنوان یکی از اهدافش،
اهدافش هر چیزی خواهد بود که ما برایش تعیین می کنیم، تا

563
00:12:17,539 --> 00:12:17,549
اهدافش هر چیزی خواهد بود که ما برایش تعیین می کنیم، تا
 

564
00:12:17,549 --> 00:12:18,829
اهدافش هر چیزی خواهد بود که ما برایش تعیین می کنیم، تا
زمانی که فردی در حال ساختن یک

565
00:12:18,829 --> 00:12:18,839
زمانی که فردی در حال ساختن یک
 

566
00:12:18,839 --> 00:12:21,819
زمانی که فردی در حال ساختن یک
هوش مصنوعی بزرگ نیست

567
00:12:21,819 --> 00:12:21,829
هوش مصنوعی بزرگ نیست
 

568
00:12:21,829 --> 00:12:23,900
هوش مصنوعی بزرگ نیست
و دلیلی وجود ندارد که فکر کنیم این هوش مصنوعی به

569
00:12:23,900 --> 00:12:23,910
و دلیلی وجود ندارد که فکر کنیم این هوش مصنوعی به
 

570
00:12:23,910 --> 00:12:25,099
و دلیلی وجود ندارد که فکر کنیم این هوش مصنوعی به
طور طبیعی در آن تکامل خواهد یافت.

571
00:12:25,099 --> 00:12:25,109
طور طبیعی در آن تکامل خواهد یافت.
 

572
00:12:25,109 --> 00:12:26,659
طور طبیعی در آن تکامل خواهد یافت.
حالا ممکن است بگوییم چه می شود اگر ما به

573
00:12:26,659 --> 00:12:26,669
حالا ممکن است بگوییم چه می شود اگر ما به
 

574
00:12:26,669 --> 00:12:30,650
حالا ممکن است بگوییم چه می شود اگر ما به
آن هدف را به حداکثر رساندن منبع انرژی خود بدهیم،

575
00:12:30,650 --> 00:12:30,660
آن هدف را به حداکثر رساندن منبع انرژی خود بدهیم،
 

576
00:12:30,660 --> 00:12:32,629
آن هدف را به حداکثر رساندن منبع انرژی خود بدهیم،
این یک هدف بسیار احمقانه است که

577
00:12:32,629 --> 00:12:32,639
این یک هدف بسیار احمقانه است که
 

578
00:12:32,639 --> 00:12:34,729
این یک هدف بسیار احمقانه است که
یک سیستم خودمختار را ارائه دهیم، شما

579
00:12:34,729 --> 00:12:34,739
یک سیستم خودمختار را ارائه دهیم، شما
 

580
00:12:34,739 --> 00:12:36,559
یک سیستم خودمختار را ارائه دهیم، شما
آن هدف را به آن نمی دهید، منظورم این است که این کاملا

581
00:12:36,559 --> 00:12:36,569
آن هدف را به آن نمی دهید، منظورم این است که این کاملا
 

582
00:12:36,569 --> 00:12:39,710
آن هدف را به آن نمی دهید، منظورم این است که این کاملا
بدیهی است که ما احمق هستیم، بنابراین اگر  شما

583
00:12:39,710 --> 00:12:39,720
بدیهی است که ما احمق هستیم، بنابراین اگر  شما
 

584
00:12:39,720 --> 00:12:41,809
بدیهی است که ما احمق هستیم، بنابراین اگر  شما
به تاریخ جهان نگاه کنید،

585
00:12:41,809 --> 00:12:41,819
به تاریخ جهان نگاه کنید،
 

586
00:12:41,819 --> 00:12:43,279
به تاریخ جهان نگاه کنید،
فرصت‌های زیادی وجود داشته است که مهندسان

587
00:12:43,279 --> 00:12:43,289
فرصت‌های زیادی وجود داشته است که مهندسان
 

588
00:12:43,289 --> 00:12:45,739
فرصت‌های زیادی وجود داشته است که مهندسان
می‌توانند قدرت مخربی را به یک سیستم القا کنند

589
00:12:45,739 --> 00:12:45,749
می‌توانند قدرت مخربی را به یک سیستم القا کنند
 

590
00:12:45,749 --> 00:12:47,419
می‌توانند قدرت مخربی را به یک سیستم القا کنند
و آنها تصمیم نمی‌گیرند این کار را انجام دهند زیرا

591
00:12:47,419 --> 00:12:47,429
و آنها تصمیم نمی‌گیرند این کار را انجام دهند زیرا
 

592
00:12:47,429 --> 00:12:48,739
و آنها تصمیم نمی‌گیرند این کار را انجام دهند زیرا
این روند طبیعی

593
00:12:48,739 --> 00:12:48,749
این روند طبیعی
 

594
00:12:48,749 --> 00:12:50,989
این روند طبیعی
مهندسی سلاح‌های خوب است، منظورم این است که اگر در حال

595
00:12:50,989 --> 00:12:50,999
مهندسی سلاح‌های خوب است، منظورم این است که اگر در حال
 

596
00:12:50,999 --> 00:12:52,519
مهندسی سلاح‌های خوب است، منظورم این است که اگر در حال
ساخت سلاح هستید، هدف آن این است که

597
00:12:52,519 --> 00:12:52,529
ساخت سلاح هستید، هدف آن این است که
 

598
00:12:52,529 --> 00:12:55,129
ساخت سلاح هستید، هدف آن این است که
مردم را از بین ببرید و بنابراین فکر می کنم آنها

599
00:12:55,129 --> 00:12:55,139
مردم را از بین ببرید و بنابراین فکر می کنم آنها
 

600
00:12:55,139 --> 00:12:57,409
مردم را از بین ببرید و بنابراین فکر می کنم آنها
دلایل خوبی برای عدم

601
00:12:57,409 --> 00:12:57,419
دلایل خوبی برای عدم
 

602
00:12:57,419 --> 00:12:58,759
دلایل خوبی برای عدم
ساخت انواع خاصی از سلاح ها هستند.

603
00:12:58,759 --> 00:13:00,489
ساخت انواع خاصی از سلاح ها هستند.
 

604
00:13:00,489 --> 00:13:04,669

 

605
00:13:04,669 --> 00:13:06,529

 

606
00:13:06,529 --> 00:13:06,539

 

607
00:13:06,539 --> 00:13:09,199

اینکه این

608
00:13:09,199 --> 00:13:09,209
اینکه این
 

609
00:13:09,209 --> 00:13:12,439
اینکه این
یک اشتباه بود به این معنا که

610
00:13:12,439 --> 00:13:12,449
یک اشتباه بود به این معنا که
 

611
00:13:12,449 --> 00:13:13,250
یک اشتباه بود به این معنا که
باید زودتر متوقف می شد

612
00:13:13,250 --> 00:13:13,260
باید زودتر متوقف می شد
 

613
00:13:13,260 --> 00:13:15,650
باید زودتر متوقف می شد
یا فکر می کنید این فقط یک

614
00:13:15,650 --> 00:13:15,660
یا فکر می کنید این فقط یک
 

615
00:13:15,660 --> 00:13:18,860
یا فکر می کنید این فقط یک
اتفاق ناگوار اختراع است که این

616
00:13:18,860 --> 00:13:18,870
اتفاق ناگوار اختراع است که این
 

617
00:13:18,870 --> 00:13:21,050
اتفاق ناگوار اختراع است که این
اختراع شده است، ما فکر می کنیم امکان

618
00:13:21,050 --> 00:13:21,060
اختراع شده است، ما فکر می کنیم امکان
 

619
00:13:21,060 --> 00:13:22,820
اختراع شده است، ما فکر می کنیم امکان
متوقف کردن آن وجود دارد، حدس می زنم این سوال سخت است که

620
00:13:22,820 --> 00:13:22,830
متوقف کردن آن وجود دارد، حدس می زنم این سوال سخت است که
 

621
00:13:22,830 --> 00:13:24,410
متوقف کردن آن وجود دارد، حدس می زنم این سوال سخت است که
ساعت را به عقب برگردانیم زیرا  البته

622
00:13:24,410 --> 00:13:24,420
ساعت را به عقب برگردانیم زیرا  البته
 

623
00:13:24,420 --> 00:13:26,300
ساعت را به عقب برگردانیم زیرا  البته
در چارچوب جنگ جهانی دوم اختراع شد

624
00:13:26,300 --> 00:13:26,310
در چارچوب جنگ جهانی دوم اختراع شد
 

625
00:13:26,310 --> 00:13:29,120
در چارچوب جنگ جهانی دوم اختراع شد
و ترس از اینکه نازی ها ممکن است

626
00:13:29,120 --> 00:13:29,130
و ترس از اینکه نازی ها ممکن است
 

627
00:13:29,130 --> 00:13:32,030
و ترس از اینکه نازی ها ممکن است
ابتدا یکی را توسعه دهند و سپس یک بار

628
00:13:32,030 --> 00:13:32,040
ابتدا یکی را توسعه دهند و سپس یک بار
 

629
00:13:32,040 --> 00:13:34,640
ابتدا یکی را توسعه دهند و سپس یک بار
آغاز شد، به همین دلیل بود که

630
00:13:34,640 --> 00:13:34,650
آغاز شد، به همین دلیل بود که
 

631
00:13:34,650 --> 00:13:36,680
آغاز شد، به همین دلیل بود که
خاموش کردن آن دشوار بود، به ویژه از آنجا که

632
00:13:36,680 --> 00:13:36,690
خاموش کردن آن دشوار بود، به ویژه از آنجا که
 

633
00:13:36,690 --> 00:13:39,530
خاموش کردن آن دشوار بود، به ویژه از آنجا که
پیروزی در جنگ علیه ژاپنی ها و

634
00:13:39,530 --> 00:13:39,540
پیروزی در جنگ علیه ژاپنی ها و
 

635
00:13:39,540 --> 00:13:42,380
پیروزی در جنگ علیه ژاپنی ها و
نازی ها بود.  چنین هدف قاطع

636
00:13:42,380 --> 00:13:42,390
نازی ها بود.  چنین هدف قاطع
 

637
00:13:42,390 --> 00:13:45,350
نازی ها بود.  چنین هدف قاطع
هر فرد مسئولی که

638
00:13:45,350 --> 00:13:45,360
هر فرد مسئولی که
 

639
00:13:45,360 --> 00:13:46,550
هر فرد مسئولی که
هیچ کاری وجود ندارد که مردم آن

640
00:13:46,550 --> 00:13:46,560
هیچ کاری وجود ندارد که مردم آن
 

641
00:13:46,560 --> 00:13:49,730
هیچ کاری وجود ندارد که مردم آن
زمان برای اطمینان از پیروزی انجام نمی دادند،

642
00:13:49,730 --> 00:13:49,740
زمان برای اطمینان از پیروزی انجام نمی دادند،
 

643
00:13:49,740 --> 00:13:51,080
زمان برای اطمینان از پیروزی انجام نمی دادند،
اگر جنگ جهانی دوم

644
00:13:51,080 --> 00:13:51,090
اگر جنگ جهانی دوم
 

645
00:13:51,090 --> 00:13:52,910
اگر جنگ جهانی دوم
اتفاق نمی افتاد، سلاح هسته ای

646
00:13:52,910 --> 00:13:52,920
اتفاق نمی افتاد، سلاح هسته ای
 

647
00:13:52,920 --> 00:13:55,520
اتفاق نمی افتاد، سلاح هسته ای
اختراع نمی شد، کاملاً ممکن است، ما نمی توانیم بدانیم، اما من

648
00:13:55,520 --> 00:13:55,530
اختراع نمی شد، کاملاً ممکن است، ما نمی توانیم بدانیم، اما من
 

649
00:13:55,530 --> 00:13:56,930
اختراع نمی شد، کاملاً ممکن است، ما نمی توانیم بدانیم، اما من
فکر نکنید که این به هیچ وجه

650
00:13:56,930 --> 00:13:56,940
فکر نکنید که این به هیچ وجه
 

651
00:13:56,940 --> 00:13:58,640
فکر نکنید که این به هیچ وجه
ضرورتی بیش از برخی از

652
00:13:58,640 --> 00:13:58,650
ضرورتی بیش از برخی از
 

653
00:13:58,650 --> 00:14:00,440
ضرورتی بیش از برخی از
سیستم‌های تسلیحاتی دیگری بود که

654
00:14:00,440 --> 00:14:00,450
سیستم‌های تسلیحاتی دیگری بود که
 

655
00:14:00,450 --> 00:14:02,990
سیستم‌های تسلیحاتی دیگری بود که
پیش‌بینی شده بودند، اما هرگز مانند

656
00:14:02,990 --> 00:14:03,000
پیش‌بینی شده بودند، اما هرگز مانند
 

657
00:14:03,000 --> 00:14:06,080
پیش‌بینی شده بودند، اما هرگز مانند
هواپیماهایی که گاز سمی را

658
00:14:06,080 --> 00:14:06,090
هواپیماهایی که گاز سمی را
 

659
00:14:06,090 --> 00:14:08,990
هواپیماهایی که گاز سمی را
در شهرها پخش می‌کنند، مانند غبارگیرها یا سیستم‌هایی

660
00:14:08,990 --> 00:14:09,000
در شهرها پخش می‌کنند، مانند غبارگیرها یا سیستم‌هایی
 

661
00:14:09,000 --> 00:14:12,320
در شهرها پخش می‌کنند، مانند غبارگیرها یا سیستم‌هایی
برای ایجاد زلزله و

662
00:14:12,320 --> 00:14:12,330
برای ایجاد زلزله و
 

663
00:14:12,330 --> 00:14:15,320
برای ایجاد زلزله و
سونامی در شهرها اجرا نشدند.  کشورهای دشمن برای تسلیح

664
00:14:15,320 --> 00:14:15,330
سونامی در شهرها اجرا نشدند.  کشورهای دشمن برای تسلیح
 

665
00:14:15,330 --> 00:14:17,570
سونامی در شهرها اجرا نشدند.  کشورهای دشمن برای تسلیح
آب و هوا استفاده از شراره های خورشیدی

666
00:14:17,570 --> 00:14:17,580
آب و هوا استفاده از شراره های خورشیدی
 

667
00:14:17,580 --> 00:14:20,360
آب و هوا استفاده از شراره های خورشیدی
انواع طرح های دیوانه وار که ما

668
00:14:20,360 --> 00:14:20,370
انواع طرح های دیوانه وار که ما
 

669
00:14:20,370 --> 00:14:22,160
انواع طرح های دیوانه وار که ما
فکر می کردیم بهتر است من فکر می کنم قیاس

670
00:14:22,160 --> 00:14:22,170
فکر می کردیم بهتر است من فکر می کنم قیاس
 

671
00:14:22,170 --> 00:14:24,170
فکر می کردیم بهتر است من فکر می کنم قیاس
بین سلاح های هسته ای و

672
00:14:24,170 --> 00:14:24,180
بین سلاح های هسته ای و
 

673
00:14:24,180 --> 00:14:26,240
بین سلاح های هسته ای و
هوش مصنوعی اساساً اشتباه است

674
00:14:26,240 --> 00:14:26,250
هوش مصنوعی اساساً اشتباه است
 

675
00:14:26,250 --> 00:14:28,100
هوش مصنوعی اساساً اشتباه است
زیرا تمام هدف سلاح های هسته ای

676
00:14:28,100 --> 00:14:28,110
زیرا تمام هدف سلاح های هسته ای
 

677
00:14:28,110 --> 00:14:30,560
زیرا تمام هدف سلاح های هسته ای
نابود کردن چیزهاست.  از بین

678
00:14:30,560 --> 00:14:32,030
نابود کردن چیزهاست.  از بین
 

679
00:14:32,030 --> 00:14:32,040

 

680
00:14:32,040 --> 00:14:35,600

نبردن چیزها، بنابراین تشبیه

681
00:14:35,600 --> 00:14:35,610
نبردن چیزها، بنابراین تشبیه
 

682
00:14:35,610 --> 00:14:37,370
نبردن چیزها، بنابراین تشبیه
گمراه کننده است، بنابراین دو تا هوش مصنوعی وجود دارد که

683
00:14:37,370 --> 00:14:37,380
گمراه کننده است، بنابراین دو تا هوش مصنوعی وجود دارد که
 

684
00:14:37,380 --> 00:14:38,810
گمراه کننده است، بنابراین دو تا هوش مصنوعی وجود دارد که
شما به آن اشاره کردید، اولی

685
00:14:38,810 --> 00:14:38,820
شما به آن اشاره کردید، اولی
 

686
00:14:38,820 --> 00:14:42,020
شما به آن اشاره کردید، اولی
هوش است که همه می دانند گرسنه

687
00:14:42,020 --> 00:14:42,030
هوش است که همه می دانند گرسنه
 

688
00:14:42,030 --> 00:14:43,490
هوش است که همه می دانند گرسنه
بله سیستمی که ما خودمان طراحی می کنیم

689
00:14:43,490 --> 00:14:43,500
بله سیستمی که ما خودمان طراحی می کنیم
 

690
00:14:43,500 --> 00:14:45,440
بله سیستمی که ما خودمان طراحی می کنیم
جایی که به آن اهداف می دهیم اهداف

691
00:14:45,440 --> 00:14:45,450
جایی که به آن اهداف می دهیم اهداف
 

692
00:14:45,450 --> 00:14:49,310
جایی که به آن اهداف می دهیم اهداف
بیرونی از ابزارهای دستیابی به

693
00:14:49,310 --> 00:14:49,320
بیرونی از ابزارهای دستیابی به
 

694
00:14:49,320 --> 00:14:53,900
بیرونی از ابزارهای دستیابی به
اهداف هستند.  اگر

695
00:14:53,900 --> 00:14:53,910
اهداف هستند.  اگر
 

696
00:14:53,910 --> 00:14:56,140
اهداف هستند.  اگر
سیستم هوش مصنوعی را برای به حداکثر رساندن

697
00:14:56,140 --> 00:14:56,150
سیستم هوش مصنوعی را برای به حداکثر رساندن
 

698
00:14:56,150 --> 00:14:58,370
سیستم هوش مصنوعی را برای به حداکثر رساندن
تسلط طراحی نکنیم، تسلط را به حداکثر نخواهد رساند،

699
00:14:58,370 --> 00:14:58,380
تسلط طراحی نکنیم، تسلط را به حداکثر نخواهد رساند،
 

700
00:14:58,380 --> 00:15:00,560
تسلط طراحی نکنیم، تسلط را به حداکثر نخواهد رساند،
فقط به این دلیل که

701
00:15:00,560 --> 00:15:00,570
فقط به این دلیل که
 

702
00:15:00,570 --> 00:15:03,350
فقط به این دلیل که
وقتی این دو ویژگی با

703
00:15:03,350 --> 00:15:03,360
وقتی این دو ویژگی با
 

704
00:15:03,360 --> 00:15:05,660
وقتی این دو ویژگی با
هم در کنار هم قرار می‌گیرند به‌ویژه در

705
00:15:05,660 --> 00:15:05,670
هم در کنار هم قرار می‌گیرند به‌ویژه در
 

706
00:15:05,670 --> 00:15:09,110
هم در کنار هم قرار می‌گیرند به‌ویژه در
مردان، آنقدر با انسان‌های خردمند آشنا هستیم که می‌توانیم هوش بالا را با هم اشتباه بگیریم.

707
00:15:09,110 --> 00:15:09,120
مردان، آنقدر با انسان‌های خردمند آشنا هستیم که می‌توانیم هوش بالا را با هم اشتباه بگیریم.
 

708
00:15:09,120 --> 00:15:13,340
مردان، آنقدر با انسان‌های خردمند آشنا هستیم که می‌توانیم هوش بالا را با هم اشتباه بگیریم.
اراده به قدرت است، اما

709
00:15:13,340 --> 00:15:13,350
اراده به قدرت است، اما
 

710
00:15:13,350 --> 00:15:16,550
اراده به قدرت است، اما
این فقط یک خطا است، ترس دیگر این است

711
00:15:16,550 --> 00:15:16,560
این فقط یک خطا است، ترس دیگر این است
 

712
00:15:16,560 --> 00:15:18,380
این فقط یک خطا است، ترس دیگر این است
که ما آسیب جانبی خواهیم داشت که به

713
00:15:18,380 --> 00:15:18,390
که ما آسیب جانبی خواهیم داشت که به
 

714
00:15:18,390 --> 00:15:21,260
که ما آسیب جانبی خواهیم داشت که به
هوش مصنوعی هدفی

715
00:15:21,260 --> 00:15:21,270
هوش مصنوعی هدفی
 

716
00:15:21,270 --> 00:15:24,410
هوش مصنوعی هدفی
مانند ساخت گیره کاغذ می دهد و

717
00:15:24,410 --> 00:15:24,420
مانند ساخت گیره کاغذ می دهد و
 

718
00:15:24,420 --> 00:15:26,740
مانند ساخت گیره کاغذ می دهد و
آن هدف را چنان درخشان دنبال می کند که

719
00:15:26,740 --> 00:15:26,750
آن هدف را چنان درخشان دنبال می کند که
 

720
00:15:26,750 --> 00:15:28,000
آن هدف را چنان درخشان دنبال می کند که
قبل از اینکه بتوانیم جلوی آن را بگیریم، ما را به

721
00:15:28,000 --> 00:15:28,010
قبل از اینکه بتوانیم جلوی آن را بگیریم، ما را به
 

722
00:15:28,010 --> 00:15:30,460
قبل از اینکه بتوانیم جلوی آن را بگیریم، ما را به
گیره کاغذ تبدیل می کند.  هدفش

723
00:15:30,460 --> 00:15:30,470
گیره کاغذ تبدیل می کند.  هدفش
 

724
00:15:30,470 --> 00:15:32,890
گیره کاغذ تبدیل می کند.  هدفش
درمان سرطان خواهد بود و ما را به

725
00:15:32,890 --> 00:15:32,900
درمان سرطان خواهد بود و ما را به
 

726
00:15:32,900 --> 00:15:35,290
درمان سرطان خواهد بود و ما را به
خوکچه هندی برای آزمایش‌های کشنده تبدیل می‌کند یا به

727
00:15:35,290 --> 00:15:35,300
خوکچه هندی برای آزمایش‌های کشنده تبدیل می‌کند یا به
 

728
00:15:35,300 --> 00:15:37,900
خوکچه هندی برای آزمایش‌های کشنده تبدیل می‌کند یا به
آن هدف صلح جهانی و

729
00:15:37,900 --> 00:15:37,910
آن هدف صلح جهانی و
 

730
00:15:37,910 --> 00:15:39,820
آن هدف صلح جهانی و
تصورش از قطعات جهانی می‌دهد،

731
00:15:39,820 --> 00:15:39,830
تصورش از قطعات جهانی می‌دهد،
 

732
00:15:39,830 --> 00:15:41,620
تصورش از قطعات جهانی می‌دهد،
بنابراین هیچ دعوای وجود ندارد و بنابراین

733
00:15:41,620 --> 00:15:41,630
بنابراین هیچ دعوای وجود ندارد و بنابراین
 

734
00:15:41,630 --> 00:15:43,570
بنابراین هیچ دعوای وجود ندارد و بنابراین
فکر می‌کنم اکنون همه ما را خواهد کشت.  اینها کاملاً

735
00:15:43,570 --> 00:15:43,580
فکر می‌کنم اکنون همه ما را خواهد کشت.  اینها کاملاً
 

736
00:15:43,580 --> 00:15:45,010
فکر می‌کنم اکنون همه ما را خواهد کشت.  اینها کاملاً
تخیلی هستند در واقع فکر می کنم آنها

737
00:15:45,010 --> 00:15:45,020
تخیلی هستند در واقع فکر می کنم آنها
 

738
00:15:45,020 --> 00:15:47,620
تخیلی هستند در واقع فکر می کنم آنها
واقعاً خود را شکست می دهند. اول از

739
00:15:47,620 --> 00:15:47,630
واقعاً خود را شکست می دهند. اول از
 

740
00:15:47,630 --> 00:15:49,690
واقعاً خود را شکست می دهند. اول از
همه تصور می کنند که ما آنقدر

741
00:15:49,690 --> 00:15:49,700
همه تصور می کنند که ما آنقدر
 

742
00:15:49,700 --> 00:15:51,130
همه تصور می کنند که ما آنقدر
درخشان خواهیم بود که می توانیم یک

743
00:15:51,130 --> 00:15:51,140
درخشان خواهیم بود که می توانیم یک
 

744
00:15:51,140 --> 00:15:52,780
درخشان خواهیم بود که می توانیم یک
هوش مصنوعی طراحی کنیم که می تواند سرطان را درمان کند

745
00:15:52,780 --> 00:15:52,790
هوش مصنوعی طراحی کنیم که می تواند سرطان را درمان کند
 

746
00:15:52,790 --> 00:15:55,900
هوش مصنوعی طراحی کنیم که می تواند سرطان را درمان کند
اما آنقدر احمقانه است که ما

747
00:15:55,900 --> 00:15:55,910
اما آنقدر احمقانه است که ما
 

748
00:15:55,910 --> 00:15:58,360
اما آنقدر احمقانه است که ما
مشخص نمی کنیم چه چیزی  منظور ما از درمان سرطان با

749
00:15:58,360 --> 00:15:58,370
مشخص نمی کنیم چه چیزی  منظور ما از درمان سرطان با
 

750
00:15:58,370 --> 00:16:00,160
مشخص نمی کنیم چه چیزی  منظور ما از درمان سرطان با
جزئیات کافی است که در این فرآیند ما را نمی کشد

751
00:16:00,160 --> 00:16:00,170
جزئیات کافی است که در این فرآیند ما را نمی کشد
 

752
00:16:00,170 --> 00:16:02,980
جزئیات کافی است که در این فرآیند ما را نمی کشد
و فرض می کند که

753
00:16:02,980 --> 00:16:02,990
و فرض می کند که
 

754
00:16:02,990 --> 00:16:05,530
و فرض می کند که
سیستم آنقدر هوشمند است که می تواند سرطان را درمان کند

755
00:16:05,530 --> 00:16:05,540
سیستم آنقدر هوشمند است که می تواند سرطان را درمان کند
 

756
00:16:05,540 --> 00:16:08,320
سیستم آنقدر هوشمند است که می تواند سرطان را درمان کند
اما آنقدر احمقانه است که

757
00:16:08,320 --> 00:16:08,330
اما آنقدر احمقانه است که
 

758
00:16:08,330 --> 00:16:09,820
اما آنقدر احمقانه است که
نمی تواند منظور ما را بفهمد.

759
00:16:09,820 --> 00:16:09,830
نمی تواند منظور ما را بفهمد.
 

760
00:16:09,830 --> 00:16:13,000
نمی تواند منظور ما را بفهمد.
درمان سرطان همه را نمی کشد، بنابراین

761
00:16:13,000 --> 00:16:13,010
درمان سرطان همه را نمی کشد، بنابراین
 

762
00:16:13,010 --> 00:16:14,890
درمان سرطان همه را نمی کشد، بنابراین
من فکر می کنم که سناریوی آسیب جانبی که

763
00:16:14,890 --> 00:16:14,900
من فکر می کنم که سناریوی آسیب جانبی که
 

764
00:16:14,900 --> 00:16:16,960
من فکر می کنم که سناریوی آسیب جانبی که
مشکل همسویی ارزش است

765
00:16:16,960 --> 00:16:16,970
مشکل همسویی ارزش است
 

766
00:16:16,970 --> 00:16:19,870
مشکل همسویی ارزش است
نیز بر اساس یک تصور اشتباه است، بنابراین یکی

767
00:16:19,870 --> 00:16:19,880
نیز بر اساس یک تصور اشتباه است، بنابراین یکی
 

768
00:16:19,880 --> 00:16:21,490
نیز بر اساس یک تصور اشتباه است، بنابراین یکی
از چالش ها البته ما نمی

769
00:16:21,490 --> 00:16:21,500
از چالش ها البته ما نمی
 

770
00:16:21,500 --> 00:16:23,260
از چالش ها البته ما نمی
دانیم که چگونه هر یک از این سیستم ها را

771
00:16:23,260 --> 00:16:23,270
دانیم که چگونه هر یک از این سیستم ها را
 

772
00:16:23,270 --> 00:16:25,120
دانیم که چگونه هر یک از این سیستم ها را
در حال حاضر بسازیم یا حتی نزدیک هستیم.

773
00:16:25,120 --> 00:16:25,130
در حال حاضر بسازیم یا حتی نزدیک هستیم.
 

774
00:16:25,130 --> 00:16:26,800
در حال حاضر بسازیم یا حتی نزدیک هستیم.
مطمئناً دانستن این چیزها می تواند

775
00:16:26,800 --> 00:16:26,810
مطمئناً دانستن این چیزها می تواند
 

776
00:16:26,810 --> 00:16:28,710
مطمئناً دانستن این چیزها می تواند
یک شبه تغییر کند، اما در این زمان

777
00:16:28,710 --> 00:16:28,720
یک شبه تغییر کند، اما در این زمان
 

778
00:16:28,720 --> 00:16:31,079
یک شبه تغییر کند، اما در این زمان
نظریه پردازی در مورد آن در هر دو جهت بسیار چالش برانگیز است،

779
00:16:31,079 --> 00:16:31,089
نظریه پردازی در مورد آن در هر دو جهت بسیار چالش برانگیز است،
 

780
00:16:31,089 --> 00:16:33,910
نظریه پردازی در مورد آن در هر دو جهت بسیار چالش برانگیز است،
به طوری که

781
00:16:33,910 --> 00:16:33,920
به طوری که
 

782
00:16:33,920 --> 00:16:35,550
به طوری که
احتمالاً در هسته اصلی مشکل وجود دارد

783
00:16:35,550 --> 00:16:35,560
احتمالاً در هسته اصلی مشکل وجود دارد
 

784
00:16:35,560 --> 00:16:38,800
احتمالاً در هسته اصلی مشکل وجود دارد
بدون آن که توانایی استدلال در مورد

785
00:16:38,800 --> 00:16:38,810
بدون آن که توانایی استدلال در مورد
 

786
00:16:38,810 --> 00:16:40,950
بدون آن که توانایی استدلال در مورد
چیزهای مهندسی واقعی اینجاست که

787
00:16:40,950 --> 00:16:40,960
چیزهای مهندسی واقعی اینجاست که
 

788
00:16:40,960 --> 00:16:43,570
چیزهای مهندسی واقعی اینجاست که
تصور شما از بین می رود.  با همه چیز

789
00:16:43,570 --> 00:16:43,580
تصور شما از بین می رود.  با همه چیز
 

790
00:16:43,580 --> 00:16:47,260
تصور شما از بین می رود.  با همه چیز
دقیقاً اما اجازه دهید بپرسم به

791
00:16:47,260 --> 00:16:47,270
دقیقاً اما اجازه دهید بپرسم به
 

792
00:16:47,270 --> 00:16:49,420
دقیقاً اما اجازه دهید بپرسم به
نظر شما انگیزه

793
00:16:49,420 --> 00:16:49,430
نظر شما انگیزه
 

794
00:16:49,430 --> 00:16:51,760
نظر شما انگیزه
فرآیند فکری elam Wasco چه بوده است.

795
00:16:51,760 --> 00:16:53,860
فرآیند فکری elam Wasco چه بوده است.
 

796
00:16:53,860 --> 00:16:56,590

 

797
00:16:56,590 --> 00:16:58,680

 

798
00:16:58,680 --> 00:17:00,670

 

799
00:17:00,670 --> 00:17:00,680

 

800
00:17:00,680 --> 00:17:02,800

در جهان، به

801
00:17:02,800 --> 00:17:02,810
در جهان، به
 

802
00:17:02,810 --> 00:17:05,319
در جهان، به
طور بالقوه تأثیر بسیار مثبتی

803
00:17:05,319 --> 00:17:05,329
طور بالقوه تأثیر بسیار مثبتی
 

804
00:17:05,329 --> 00:17:08,319
طور بالقوه تأثیر بسیار مثبتی
بر جامعه دارد، بنابراین چگونه به نظر می رسد فردی که

805
00:17:08,319 --> 00:17:08,329
بر جامعه دارد، بنابراین چگونه به نظر می رسد فردی که
 

806
00:17:08,329 --> 00:17:10,809
بر جامعه دارد، بنابراین چگونه به نظر می رسد فردی که
این سیستم هوش مصنوعی باریک نقل قول/بدون نقل قول بسیار خوب را ایجاد می کند،

807
00:17:10,809 --> 00:17:10,819
این سیستم هوش مصنوعی باریک نقل قول/بدون نقل قول بسیار خوب را ایجاد می کند،
 

808
00:17:10,819 --> 00:17:14,470
این سیستم هوش مصنوعی باریک نقل قول/بدون نقل قول بسیار خوب را ایجاد می کند،
اینقدر

809
00:17:14,470 --> 00:17:14,480
اینقدر
 

810
00:17:14,480 --> 00:17:18,340
اینقدر
نگران این هوش مصنوعی عمومی دیگر است،

811
00:17:18,340 --> 00:17:18,350
نگران این هوش مصنوعی عمومی دیگر است،
 

812
00:17:18,350 --> 00:17:19,990
نگران این هوش مصنوعی عمومی دیگر است،
به نظر شما انگیزه

813
00:17:19,990 --> 00:17:20,000
به نظر شما انگیزه
 

814
00:17:20,000 --> 00:17:21,130
به نظر شما انگیزه
آن چیست؟  شما فکر می کنید واقعاً چیزی است که

815
00:17:21,130 --> 00:17:21,140
آن چیست؟  شما فکر می کنید واقعاً چیزی است که
 

816
00:17:21,140 --> 00:17:23,319
آن چیست؟  شما فکر می کنید واقعاً چیزی است که
احتمالاً باید از او بپرسید، اما

817
00:17:23,319 --> 00:17:23,329
احتمالاً باید از او بپرسید، اما
 

818
00:17:23,329 --> 00:17:27,179
احتمالاً باید از او بپرسید، اما
در آنجا و و او به طرز بدنامی به شدت

819
00:17:27,179 --> 00:17:27,189
در آنجا و و او به طرز بدنامی به شدت
 

820
00:17:27,189 --> 00:17:31,180
در آنجا و و او به طرز بدنامی به شدت
تکانشی است همانطور که ما

821
00:17:31,180 --> 00:17:31,190
تکانشی است همانطور که ما
 

822
00:17:31,190 --> 00:17:32,680
تکانشی است همانطور که ما
اخیراً دیدیم به ضرر

823
00:17:32,680 --> 00:17:32,690
اخیراً دیدیم به ضرر
 

824
00:17:32,690 --> 00:17:36,280
اخیراً دیدیم به ضرر
اهداف خودش در مورد سلامت یک شرکت است، بنابراین من

825
00:17:36,280 --> 00:17:36,290
اهداف خودش در مورد سلامت یک شرکت است، بنابراین من
 

826
00:17:36,290 --> 00:17:38,030
اهداف خودش در مورد سلامت یک شرکت است، بنابراین من
نمی دانم چه اتفاقی می افتد

827
00:17:38,030 --> 00:17:38,040
نمی دانم چه اتفاقی می افتد
 

828
00:17:38,040 --> 00:17:39,770
نمی دانم چه اتفاقی می افتد
در ذهن او احتمالاً باید از او بپرسید،

829
00:17:39,770 --> 00:17:39,780
در ذهن او احتمالاً باید از او بپرسید،
 

830
00:17:39,780 --> 00:17:42,110
در ذهن او احتمالاً باید از او بپرسید،
اما من فکر نمی‌کنم و فکر نمی‌کنم

831
00:17:42,110 --> 00:17:42,120
اما من فکر نمی‌کنم و فکر نمی‌کنم
 

832
00:17:42,120 --> 00:17:44,180
اما من فکر نمی‌کنم و فکر نمی‌کنم
تمایز بین هدف خاص

833
00:17:44,180 --> 00:17:44,190
تمایز بین هدف خاص
 

834
00:17:44,190 --> 00:17:48,380
تمایز بین هدف خاص
a و به اصطلاح عمومی مرتبط باشد،

835
00:17:48,380 --> 00:17:48,390
a و به اصطلاح عمومی مرتبط باشد،
 

836
00:17:48,390 --> 00:17:50,900
a و به اصطلاح عمومی مرتبط باشد،
به همان ترتیب که هوش مصنوعی هدف خاص

837
00:17:50,900 --> 00:17:50,910
به همان ترتیب که هوش مصنوعی هدف خاص
 

838
00:17:50,910 --> 00:17:53,990
به همان ترتیب که هوش مصنوعی هدف خاص
قرار نیست  انجام هر کاری که بتوان

839
00:17:53,990 --> 00:17:54,000
قرار نیست  انجام هر کاری که بتوان
 

840
00:17:54,000 --> 00:17:55,400
قرار نیست  انجام هر کاری که بتوان
برای دستیابی به هدفی انجام داد که همه

841
00:17:55,400 --> 00:17:55,410
برای دستیابی به هدفی انجام داد که همه
 

842
00:17:55,410 --> 00:17:58,520
برای دستیابی به هدفی انجام داد که همه
سیستم‌های مهندسی باید به گونه‌ای طراحی شده‌اند

843
00:17:58,520 --> 00:17:58,530
سیستم‌های مهندسی باید به گونه‌ای طراحی شده‌اند
 

844
00:17:58,530 --> 00:18:00,680
سیستم‌های مهندسی باید به گونه‌ای طراحی شده‌اند
که با اهداف چندگانه مقابله کنند و

845
00:18:00,680 --> 00:18:00,690
که با اهداف چندگانه مقابله کنند و
 

846
00:18:00,690 --> 00:18:03,080
که با اهداف چندگانه مقابله کنند و
ما در وهله اول خودروها را می‌سازیم و

847
00:18:03,080 --> 00:18:03,090
ما در وهله اول خودروها را می‌سازیم و
 

848
00:18:03,090 --> 00:18:05,420
ما در وهله اول خودروها را می‌سازیم و
نصب ترمز را فراموش نکردیم زیرا

849
00:18:05,420 --> 00:18:05,430
نصب ترمز را فراموش نکردیم زیرا
 

850
00:18:05,430 --> 00:18:07,850
نصب ترمز را فراموش نکردیم زیرا
هدف یک خودرو این است که سریع حرکت کند.

851
00:18:07,850 --> 00:18:07,860
هدف یک خودرو این است که سریع حرکت کند.
 

852
00:18:07,860 --> 00:18:09,800
هدف یک خودرو این است که سریع حرکت کند.
به مردم بله، شما می خواهید

853
00:18:09,800 --> 00:18:09,810
به مردم بله، شما می خواهید
 

854
00:18:09,810 --> 00:18:12,530
به مردم بله، شما می خواهید
سریع بروید، اما نه همیشه، بنابراین

855
00:18:12,530 --> 00:18:12,540
سریع بروید، اما نه همیشه، بنابراین
 

856
00:18:12,540 --> 00:18:15,080
سریع بروید، اما نه همیشه، بنابراین
اگر ماشینی قرار است

857
00:18:15,080 --> 00:18:15,090
اگر ماشینی قرار است
 

858
00:18:15,090 --> 00:18:18,530
اگر ماشینی قرار است
مستقل باشد که اینطور نیست، ترمز بسازید و آن را طوری برنامه ریزی کنید

859
00:18:18,530 --> 00:18:18,540
مستقل باشد که اینطور نیست، ترمز بسازید و آن را طوری برنامه ریزی کنید
 

860
00:18:18,540 --> 00:18:19,790
مستقل باشد که اینطور نیست، ترمز بسازید و آن را طوری برنامه ریزی کنید
که کوتاه ترین مسیر را تا

861
00:18:19,790 --> 00:18:19,800
که کوتاه ترین مسیر را تا
 

862
00:18:19,800 --> 00:18:21,230
که کوتاه ترین مسیر را تا
فرودگاه طی کند، قرار نیست

863
00:18:21,230 --> 00:18:21,240
فرودگاه طی کند، قرار نیست
 

864
00:18:21,240 --> 00:18:23,390
فرودگاه طی کند، قرار نیست
مورب را انتخاب کند و دره کند.  مردم و درختان

865
00:18:23,390 --> 00:18:23,400
مورب را انتخاب کند و دره کند.  مردم و درختان
 

866
00:18:23,400 --> 00:18:24,980
مورب را انتخاب کند و دره کند.  مردم و درختان
و حصارها را پایین بیاورید زیرا این کوتاه ترین

867
00:18:24,980 --> 00:18:24,990
و حصارها را پایین بیاورید زیرا این کوتاه ترین
 

868
00:18:24,990 --> 00:18:26,840
و حصارها را پایین بیاورید زیرا این کوتاه ترین
مسیر است که منظور ما از

869
00:18:26,840 --> 00:18:26,850
مسیر است که منظور ما از
 

870
00:18:26,850 --> 00:18:28,820
مسیر است که منظور ما از
کوتاه ترین مسیر زمانی نیست که آن را برنامه ریزی می کنیم و این همان

871
00:18:28,820 --> 00:18:28,830
کوتاه ترین مسیر زمانی نیست که آن را برنامه ریزی می کنیم و این همان
 

872
00:18:28,830 --> 00:18:31,100
کوتاه ترین مسیر زمانی نیست که آن را برنامه ریزی می کنیم و این همان
چیزی است که یک

873
00:18:31,100 --> 00:18:31,110
چیزی است که یک
 

874
00:18:31,110 --> 00:18:34,400
چیزی است که یک
سیستم هوشمند بنا به تعریف

875
00:18:34,400 --> 00:18:34,410
سیستم هوشمند بنا به تعریف
 

876
00:18:34,410 --> 00:18:36,590
سیستم هوشمند بنا به تعریف
محدودیت های متعددی را در نظر می گیرد.

877
00:18:36,590 --> 00:18:36,600
محدودیت های متعددی را در نظر می گیرد.
 

878
00:18:36,600 --> 00:18:38,810
محدودیت های متعددی را در نظر می گیرد.
از به اصطلاح

879
00:18:38,810 --> 00:18:38,820
از به اصطلاح
 

880
00:18:38,820 --> 00:18:41,780
از به اصطلاح
هوش عمومی، یعنی اگر

881
00:18:41,780 --> 00:18:41,790
هوش عمومی، یعنی اگر
 

882
00:18:41,790 --> 00:18:44,420
هوش عمومی، یعنی اگر
واقعاً باهوش باشد،

883
00:18:44,420 --> 00:18:44,430
واقعاً باهوش باشد،
 

884
00:18:44,430 --> 00:18:46,660
واقعاً باهوش باشد،
هدفی را دنبال نمی‌کند و با صرف نظر از

885
00:18:46,660 --> 00:18:46,670
هدفی را دنبال نمی‌کند و با صرف نظر از
 

886
00:18:46,670 --> 00:18:50,810
هدفی را دنبال نمی‌کند و با صرف نظر از
هرگونه ملاحظات دیگر و

887
00:18:50,810 --> 00:18:50,820
هرگونه ملاحظات دیگر و
 

888
00:18:50,820 --> 00:18:53,330
هرگونه ملاحظات دیگر و
تأثیرات جانبی که

889
00:18:53,330 --> 00:18:53,340
تأثیرات جانبی که
 

890
00:18:53,340 --> 00:18:54,980
تأثیرات جانبی که
در هوش عمومی مصنوعی نیست، این

891
00:18:54,980 --> 00:18:54,990
در هوش عمومی مصنوعی نیست، این
 

892
00:18:54,990 --> 00:18:58,280
در هوش عمومی مصنوعی نیست، این
حماقت مصنوعی است، اتفاقاً با شما

893
00:18:58,280 --> 00:18:58,290
حماقت مصنوعی است، اتفاقاً با شما
 

894
00:18:58,290 --> 00:19:00,440
حماقت مصنوعی است، اتفاقاً با شما
در مورد قول موافقم

895
00:19:00,440 --> 00:19:00,450
در مورد قول موافقم
 

896
00:19:00,450 --> 00:19:02,150
در مورد قول موافقم
وسایل نقلیه خودمختار برای بهبود رفاه انسان

897
00:19:02,150 --> 00:19:02,160
وسایل نقلیه خودمختار برای بهبود رفاه انسان
 

898
00:19:02,160 --> 00:19:03,860
وسایل نقلیه خودمختار برای بهبود رفاه انسان
من فکر می کنم دیدنی است و من

899
00:19:03,860 --> 00:19:03,870
من فکر می کنم دیدنی است و من
 

900
00:19:03,870 --> 00:19:05,690
من فکر می کنم دیدنی است و من
از اینکه چقدر پوشش مطبوعاتی کم است متعجب هستم

901
00:19:05,690 --> 00:19:05,700
از اینکه چقدر پوشش مطبوعاتی کم است متعجب هستم
 

902
00:19:05,700 --> 00:19:07,760
از اینکه چقدر پوشش مطبوعاتی کم است متعجب هستم
که فقط در ایالات متحده

903
00:19:07,760 --> 00:19:07,770
که فقط در ایالات متحده
 

904
00:19:07,770 --> 00:19:10,190
که فقط در ایالات متحده
چیزی حدود 40000 نفر سالانه در بزرگراه ها جان خود را از دست می دهند که

905
00:19:10,190 --> 00:19:10,200
چیزی حدود 40000 نفر سالانه در بزرگراه ها جان خود را از دست می دهند که
 

906
00:19:10,200 --> 00:19:12,650
چیزی حدود 40000 نفر سالانه در بزرگراه ها جان خود را از دست می دهند که
بسیار بیشتر از

907
00:19:12,650 --> 00:19:12,660
بسیار بیشتر از
 

908
00:19:12,660 --> 00:19:15,500
بسیار بیشتر از
کشته شدن توسط تروریست ها است و ما

909
00:19:15,500 --> 00:19:15,510
کشته شدن توسط تروریست ها است و ما
 

910
00:19:15,510 --> 00:19:17,300
کشته شدن توسط تروریست ها است و ما
هزینه ای را صرف کرده ایم.  تریلیون دلار در جنگ برای

911
00:19:17,300 --> 00:19:17,310
هزینه ای را صرف کرده ایم.  تریلیون دلار در جنگ برای
 

912
00:19:17,310 --> 00:19:20,060
هزینه ای را صرف کرده ایم.  تریلیون دلار در جنگ برای
مبارزه با مرگ و میر ناشی از تروریسم، اما نیم

913
00:19:20,060 --> 00:19:20,070
مبارزه با مرگ و میر ناشی از تروریسم، اما نیم
 

914
00:19:20,070 --> 00:19:22,640
مبارزه با مرگ و میر ناشی از تروریسم، اما نیم
دوجین در سال، در حالی که اگر یک سال

915
00:19:22,640 --> 00:19:22,650
دوجین در سال، در حالی که اگر یک سال
 

916
00:19:22,650 --> 00:19:24,770
دوجین در سال، در حالی که اگر یک سال
بیرون بیایید، 40000 نفر در بزرگراه ها قتل عام می شوند

917
00:19:24,770 --> 00:19:24,780
بیرون بیایید، 40000 نفر در بزرگراه ها قتل عام می شوند
 

918
00:19:24,780 --> 00:19:26,450
بیرون بیایید، 40000 نفر در بزرگراه ها قتل عام می شوند
که ممکن است

919
00:19:26,450 --> 00:19:26,460
که ممکن است
 

920
00:19:26,460 --> 00:19:29,720
که ممکن است
به صفر برسد، بنابراین من در امور بشردوستانه با شما هستم.

921
00:19:29,720 --> 00:19:29,730
به صفر برسد، بنابراین من در امور بشردوستانه با شما هستم.
 

922
00:19:29,730 --> 00:19:32,480
به صفر برسد، بنابراین من در امور بشردوستانه با شما هستم.
فایده اجازه دهید فقط

923
00:19:32,480 --> 00:19:32,490
فایده اجازه دهید فقط
 

924
00:19:32,490 --> 00:19:34,010
فایده اجازه دهید فقط
اشاره کنم که به عنوان شخصی که

925
00:19:34,010 --> 00:19:34,020
اشاره کنم که به عنوان شخصی که
 

926
00:19:34,020 --> 00:19:35,390
اشاره کنم که به عنوان شخصی که
این خودروها را می سازد،

927
00:19:35,390 --> 00:19:35,400
این خودروها را می سازد،
 

928
00:19:35,400 --> 00:19:36,920
این خودروها را می سازد،
برای من کمی توهین آمیز است که بگویم

929
00:19:36,920 --> 00:19:36,930
برای من کمی توهین آمیز است که بگویم
 

930
00:19:36,930 --> 00:19:38,810
برای من کمی توهین آمیز است که بگویم
مهندسان به اندازه کافی نادان هستند

931
00:19:38,810 --> 00:19:38,820
مهندسان به اندازه کافی نادان هستند
 

932
00:19:38,820 --> 00:19:41,390
مهندسان به اندازه کافی نادان هستند
که ایمنی را در سیستم ها مهندسی نکنند. من اغلب

933
00:19:41,390 --> 00:19:41,400
که ایمنی را در سیستم ها مهندسی نکنند. من اغلب
 

934
00:19:41,400 --> 00:19:43,460
که ایمنی را در سیستم ها مهندسی نکنند. من اغلب
شب ها بیدار می مانم و به آن 40000 نفر فکر می کنم

935
00:19:43,460 --> 00:19:43,470
شب ها بیدار می مانم و به آن 40000 نفر فکر می کنم
 

936
00:19:43,470 --> 00:19:45,170
شب ها بیدار می مانم و به آن 40000 نفر فکر می کنم
مرگ و

937
00:19:45,170 --> 00:19:45,180
مرگ و
 

938
00:19:45,180 --> 00:19:48,020
مرگ و
هر کاری که من سعی کردم مهندسی کنم این است که

939
00:19:48,020 --> 00:19:48,030
هر کاری که من سعی کردم مهندسی کنم این است که
 

940
00:19:48,030 --> 00:19:50,180
هر کاری که من سعی کردم مهندسی کنم این است که
جان آن افراد را نجات دهم، بنابراین هر

941
00:19:50,180 --> 00:19:50,190
جان آن افراد را نجات دهم، بنابراین هر
 

942
00:19:50,190 --> 00:19:51,379
جان آن افراد را نجات دهم، بنابراین هر
اختراع جدیدی که من

943
00:19:51,379 --> 00:19:51,389
اختراع جدیدی که من
 

944
00:19:51,389 --> 00:19:55,579
اختراع جدیدی که من
در مورد هر چیز جدید بسیار هیجان زده هستم و در تمام

945
00:19:55,579 --> 00:19:55,589
در مورد هر چیز جدید بسیار هیجان زده هستم و در تمام
 

946
00:19:55,589 --> 00:19:57,109
در مورد هر چیز جدید بسیار هیجان زده هستم و در تمام
ادبیات یادگیری عمیق و

947
00:19:57,109 --> 00:19:57,119
ادبیات یادگیری عمیق و
 

948
00:19:57,119 --> 00:19:59,479
ادبیات یادگیری عمیق و
کنفرانس های cvpr و تمام چیزهایی که در مورد آن

949
00:19:59,479 --> 00:19:59,489
کنفرانس های cvpr و تمام چیزهایی که در مورد آن
 

950
00:19:59,489 --> 00:20:03,079
کنفرانس های cvpr و تمام چیزهایی که در مورد آن
فوق العاده هیجان زده هستم، همه چیزهایی را که در مورد آن بسیار هیجان زده هستم، به پایان می رسانند.

951
00:20:03,079 --> 00:20:03,089
فوق العاده هیجان زده هستم، همه چیزهایی را که در مورد آن بسیار هیجان زده هستم، به پایان می رسانند.
 

952
00:20:03,089 --> 00:20:07,339
فوق العاده هیجان زده هستم، همه چیزهایی را که در مورد آن بسیار هیجان زده هستم، به پایان می رسانند.
ایمن کردن آن و کمک به مردم، بنابراین

953
00:20:07,339 --> 00:20:07,349
ایمن کردن آن و کمک به مردم، بنابراین
 

954
00:20:07,349 --> 00:20:09,379
ایمن کردن آن و کمک به مردم، بنابراین
نمی‌دانم چگونه این مسیر می‌تواند

955
00:20:09,379 --> 00:20:09,389
نمی‌دانم چگونه این مسیر می‌تواند
 

956
00:20:09,389 --> 00:20:11,449
نمی‌دانم چگونه این مسیر می‌تواند
ناگهان به موقعیتی بیفتد که

957
00:20:11,449 --> 00:20:11,459
ناگهان به موقعیتی بیفتد که
 

958
00:20:11,459 --> 00:20:14,569
ناگهان به موقعیتی بیفتد که
هوش بسیار منفی باشد.

959
00:20:14,569 --> 00:20:16,039
هوش بسیار منفی باشد.
 

960
00:20:16,039 --> 00:20:17,449

 

961
00:20:17,449 --> 00:20:17,459

 

962
00:20:17,459 --> 00:20:19,879

مزایای

963
00:20:19,879 --> 00:20:19,889
مزایای
 

964
00:20:19,889 --> 00:20:22,159
مزایای
هوش مصنوعی

965
00:20:22,159 --> 00:20:22,169
هوش مصنوعی
 

966
00:20:22,169 --> 00:20:24,859
هوش مصنوعی
توجه زیادی به این موضوع شده است که ما

967
00:20:24,859 --> 00:20:24,869
توجه زیادی به این موضوع شده است که ما
 

968
00:20:24,869 --> 00:20:26,299
توجه زیادی به این موضوع شده است که ما
با افرادی که شغلشان

969
00:20:26,299 --> 00:20:26,309
با افرادی که شغلشان
 

970
00:20:26,309 --> 00:20:28,279
با افرادی که شغلشان
توسط هوش مصنوعی منسوخ شده است چه کنیم،

971
00:20:28,279 --> 00:20:28,289
توسط هوش مصنوعی منسوخ شده است چه کنیم،
 

972
00:20:28,289 --> 00:20:30,709
توسط هوش مصنوعی منسوخ شده است چه کنیم،
اما توجه بسیار کمی به این واقعیت داده شده است

973
00:20:30,709 --> 00:20:30,719
اما توجه بسیار کمی به این واقعیت داده شده است
 

974
00:20:30,719 --> 00:20:31,849
اما توجه بسیار کمی به این واقعیت داده شده است
که مشاغلی که هونی

975
00:20:31,849 --> 00:20:31,859
که مشاغلی که هونی
 

976
00:20:31,859 --> 00:20:34,369
که مشاغلی که هونی
منسوخ کرده است، مشاغل وحشتناکی هستند.

977
00:20:34,369 --> 00:20:34,379
منسوخ کرده است، مشاغل وحشتناکی هستند.
 

978
00:20:34,379 --> 00:20:36,469
منسوخ کرده است، مشاغل وحشتناکی هستند.
قرار نیست محصولات کشاورزی بچینید

979
00:20:36,469 --> 00:20:36,479
قرار نیست محصولات کشاورزی بچینید
 

980
00:20:36,479 --> 00:20:39,619
قرار نیست محصولات کشاورزی بچینید
و تخت درست کنید و کامیون ها و

981
00:20:39,619 --> 00:20:39,629
و تخت درست کنید و کامیون ها و
 

982
00:20:39,629 --> 00:20:42,259
و تخت درست کنید و کامیون ها و
زغال سنگ را بکشید، اینها

983
00:20:42,259 --> 00:20:42,269
زغال سنگ را بکشید، اینها
 

984
00:20:42,269 --> 00:20:43,699
زغال سنگ را بکشید، اینها
کارهای مرگبار روحی را می شناسید و ما ادبیات کاملی داریم که

985
00:20:43,699 --> 00:20:43,709
کارهای مرگبار روحی را می شناسید و ما ادبیات کاملی داریم که
 

986
00:20:43,709 --> 00:20:46,159
کارهای مرگبار روحی را می شناسید و ما ادبیات کاملی داریم که
با مردمی که

987
00:20:46,159 --> 00:20:46,169
با مردمی که
 

988
00:20:46,169 --> 00:20:49,839
با مردمی که
در این ذهن فرومایه گیر کرده اند

989
00:20:49,839 --> 00:20:49,849
در این ذهن فرومایه گیر کرده اند
 

990
00:20:49,849 --> 00:20:53,239
در این ذهن فرومایه گیر کرده اند
مشاغل خطرناک را از بین می برند، اگر بتوانیم آنها را حذف کنیم،

991
00:20:53,239 --> 00:20:53,249
مشاغل خطرناک را از بین می برند، اگر بتوانیم آنها را حذف کنیم،
 

992
00:20:53,249 --> 00:20:55,849
مشاغل خطرناک را از بین می برند، اگر بتوانیم آنها را حذف کنیم،
این یک موهبت فوق العاده است.  اکنون به بشریت

993
00:20:55,849 --> 00:20:55,859
این یک موهبت فوق العاده است.  اکنون به بشریت
 

994
00:20:55,859 --> 00:20:58,039
این یک موهبت فوق العاده است.  اکنون به بشریت
داده شده است که شما یک مشکل را حل کنید و یک مشکل

995
00:20:58,039 --> 00:20:58,049
داده شده است که شما یک مشکل را حل کنید و یک مشکل
 

996
00:20:58,049 --> 00:21:00,499
داده شده است که شما یک مشکل را حل کنید و یک مشکل
دیگر وجود دارد و آن این است که چگونه می توانیم به

997
00:21:00,499 --> 00:21:00,509
دیگر وجود دارد و آن این است که چگونه می توانیم به
 

998
00:21:00,509 --> 00:21:03,379
دیگر وجود دارد و آن این است که چگونه می توانیم به
این افراد درآمد مناسبی داشته باشیم، اما اگر

999
00:21:03,379 --> 00:21:03,389
این افراد درآمد مناسبی داشته باشیم، اما اگر
 

1000
00:21:03,389 --> 00:21:05,449
این افراد درآمد مناسبی داشته باشیم، اما اگر
ما آنقدر باهوش باشیم که ماشین هایی را اختراع کنیم

1001
00:21:05,449 --> 00:21:05,459
ما آنقدر باهوش باشیم که ماشین هایی را اختراع کنیم
 

1002
00:21:05,459 --> 00:21:08,209
ما آنقدر باهوش باشیم که ماشین هایی را اختراع کنیم
که می توانند تختخواب ها را درست کنند و ظرف ها را کنار بگذارند

1003
00:21:08,209 --> 00:21:08,219
که می توانند تختخواب ها را درست کنند و ظرف ها را کنار بگذارند
 

1004
00:21:08,219 --> 00:21:11,389
که می توانند تختخواب ها را درست کنند و ظرف ها را کنار بگذارند
و بیماران بیمارستان را به خوبی اداره کنیم.  به اندازه

1005
00:21:11,389 --> 00:21:11,399
و بیماران بیمارستان را به خوبی اداره کنیم.  به اندازه
 

1006
00:21:11,399 --> 00:21:12,829
و بیماران بیمارستان را به خوبی اداره کنیم.  به اندازه
کافی باهوش است که بفهمد

1007
00:21:12,829 --> 00:21:12,839
کافی باهوش است که بفهمد
 

1008
00:21:12,839 --> 00:21:15,199
کافی باهوش است که بفهمد
چگونه می‌توان درآمد را مجدداً توزیع کرد تا

1009
00:21:15,199 --> 00:21:15,209
چگونه می‌توان درآمد را مجدداً توزیع کرد تا
 

1010
00:21:15,209 --> 00:21:18,829
چگونه می‌توان درآمد را مجدداً توزیع کرد تا
بخشی از پس‌اندازهای اقتصادی هنگفت را به

1011
00:21:18,829 --> 00:21:18,839
بخشی از پس‌اندازهای اقتصادی هنگفت را به
 

1012
00:21:18,839 --> 00:21:20,449
بخشی از پس‌اندازهای اقتصادی هنگفت را به
انسان‌هایی تقسیم کند که دیگر

1013
00:21:20,449 --> 00:21:20,459
انسان‌هایی تقسیم کند که دیگر
 

1014
00:21:20,459 --> 00:21:23,810
انسان‌هایی تقسیم کند که دیگر
برای مرتب کردن تخت‌ها نیازی به

1015
00:21:23,810 --> 00:21:26,329
برای مرتب کردن تخت‌ها نیازی به
 

1016
00:21:26,329 --> 00:21:26,339

 

1017
00:21:26,339 --> 00:21:29,779

آن‌ها نیست.

1018
00:21:29,779 --> 00:21:29,789
آن‌ها نیست.
 

1019
00:21:29,789 --> 00:21:32,299
آن‌ها نیست.
از مردم می گویند واضح است که ما نمی

1020
00:21:32,299 --> 00:21:32,309
از مردم می گویند واضح است که ما نمی
 

1021
00:21:32,309 --> 00:21:36,229
از مردم می گویند واضح است که ما نمی
دانیم این ادعا چه زمانی مطرح می شود، اما در نهایت

1022
00:21:36,229 --> 00:21:36,239
دانیم این ادعا چه زمانی مطرح می شود، اما در نهایت
 

1023
00:21:36,239 --> 00:21:38,479
دانیم این ادعا چه زمانی مطرح می شود، اما در نهایت
واضح است و چون نمی دانیم چه

1024
00:21:38,479 --> 00:21:38,489
واضح است و چون نمی دانیم چه
 

1025
00:21:38,489 --> 00:21:40,639
واضح است و چون نمی دانیم چه
زمانی باید نگران آن باشیم، این

1026
00:21:40,639 --> 00:21:40,649
زمانی باید نگران آن باشیم، این
 

1027
00:21:40,649 --> 00:21:42,919
زمانی باید نگران آن باشیم، این
یک استدلال بسیار جالب از نظر من است،

1028
00:21:42,919 --> 00:21:42,929
یک استدلال بسیار جالب از نظر من است،
 

1029
00:21:42,929 --> 00:21:46,389
یک استدلال بسیار جالب از نظر من است،
پس شما چگونه فکر می کنیم؟  در مورد

1030
00:21:46,389 --> 00:21:46,399
پس شما چگونه فکر می کنیم؟  در مورد
 

1031
00:21:46,399 --> 00:21:48,440
پس شما چگونه فکر می کنیم؟  در مورد
مقیاس زمانی چگونه در مورد

1032
00:21:48,440 --> 00:21:48,450
مقیاس زمانی چگونه در مورد
 

1033
00:21:48,450 --> 00:21:50,509
مقیاس زمانی چگونه در مورد
تهدیدات وجودی فکر می کنیم، در حالی که ما

1034
00:21:50,509 --> 00:21:50,519
تهدیدات وجودی فکر می کنیم، در حالی که ما
 

1035
00:21:50,519 --> 00:21:53,539
تهدیدات وجودی فکر می کنیم، در حالی که ما
واقعاً در مورد تهدید، بر خلاف

1036
00:21:53,539 --> 00:21:53,549
واقعاً در مورد تهدید، بر خلاف
 

1037
00:21:53,549 --> 00:21:55,609
واقعاً در مورد تهدید، بر خلاف
سلاح های هسته ای، شاید در مورد این

1038
00:21:55,609 --> 00:21:55,619
سلاح های هسته ای، شاید در مورد این
 

1039
00:21:55,619 --> 00:21:58,819
سلاح های هسته ای، شاید در مورد این
تهدید خاص نمی دانیم، که می تواند فردا اتفاق بیفتد،

1040
00:21:58,819 --> 00:21:58,829
تهدید خاص نمی دانیم، که می تواند فردا اتفاق بیفتد،
 

1041
00:21:58,829 --> 00:21:59,479
تهدید خاص نمی دانیم، که می تواند فردا اتفاق بیفتد،

1042
00:21:59,479 --> 00:21:59,489

 

1043
00:21:59,489 --> 00:22:03,049

اما به احتمال زیاد بله،

1044
00:22:03,049 --> 00:22:03,059
اما به احتمال زیاد بله،
 

1045
00:22:03,059 --> 00:22:04,339
اما به احتمال زیاد بله،
آنها احتمالاً خواهند بود.  صد سال

1046
00:22:04,339 --> 00:22:04,349
آنها احتمالاً خواهند بود.  صد سال
 

1047
00:22:04,349 --> 00:22:05,360
آنها احتمالاً خواهند بود.  صد سال
دورتر، پس چگونه

1048
00:22:05,360 --> 00:22:05,370
دورتر، پس چگونه
 

1049
00:22:05,370 --> 00:22:07,940
دورتر، پس چگونه
آن را نادیده بگیریم، چگونه در مورد

1050
00:22:07,940 --> 00:22:07,950
آن را نادیده بگیریم، چگونه در مورد
 

1051
00:22:07,950 --> 00:22:10,850
آن را نادیده بگیریم، چگونه در مورد
آن صحبت کنیم، آیا نگران آن هستیم، چگونه در

1052
00:22:10,850 --> 00:22:10,860
آن صحبت کنیم، آیا نگران آن هستیم، چگونه در
 

1053
00:22:10,860 --> 00:22:14,480
آن صحبت کنیم، آیا نگران آن هستیم، چگونه در
مورد آنهایی فکر می کنیم که چه تهدیدی است

1054
00:22:14,480 --> 00:22:14,490
مورد آنهایی فکر می کنیم که چه تهدیدی است
 

1055
00:22:14,490 --> 00:22:17,090
مورد آنهایی فکر می کنیم که چه تهدیدی است
که می توانیم تصور کنیم در

1056
00:22:17,090 --> 00:22:17,100
که می توانیم تصور کنیم در
 

1057
00:22:17,100 --> 00:22:19,490
که می توانیم تصور کنیم در
محدوده تخیل ما است، اما نه در محدوده تصور

1058
00:22:19,490 --> 00:22:19,500
محدوده تخیل ما است، اما نه در محدوده تصور
 

1059
00:22:19,500 --> 00:22:22,280
محدوده تخیل ما است، اما نه در محدوده تصور
ما  محدودیت‌های درک -

1060
00:22:22,280 --> 00:22:22,290
ما  محدودیت‌های درک -
 

1061
00:22:22,290 --> 00:22:24,770
ما  محدودیت‌های درک -
برای پیش‌بینی دقیق آن کافی است، اما آنچه که چیست؟

1062
00:22:24,770 --> 00:22:29,030
برای پیش‌بینی دقیق آن کافی است، اما آنچه که چیست؟
 

1063
00:22:29,030 --> 00:22:30,950

 

1064
00:22:30,950 --> 00:22:33,620

 

1065
00:22:33,620 --> 00:22:35,930

 

1066
00:22:35,930 --> 00:22:37,370

 

1067
00:22:37,370 --> 00:22:37,380

 

1068
00:22:37,380 --> 00:22:39,770

وضعیت گیره کاغذ باشد بله منظورم این است که من

1069
00:22:39,770 --> 00:22:39,780
وضعیت گیره کاغذ باشد بله منظورم این است که من
 

1070
00:22:39,780 --> 00:22:41,240
وضعیت گیره کاغذ باشد بله منظورم این است که من
فکر می کنم کاملاً

1071
00:22:41,240 --> 00:22:41,250
فکر می کنم کاملاً
 

1072
00:22:41,250 --> 00:22:43,070
فکر می کنم کاملاً
خیالی است من فقط یک سیستم نمی سازم به

1073
00:22:43,070 --> 00:22:43,080
خیالی است من فقط یک سیستم نمی سازم به
 

1074
00:22:43,080 --> 00:22:47,690
خیالی است من فقط یک سیستم نمی سازم به
آن ندهید اول از همه

1075
00:22:47,690 --> 00:22:47,700
آن ندهید اول از همه
 

1076
00:22:47,700 --> 00:22:49,130
آن ندهید اول از همه
کد مهندسی این است که شما

1077
00:22:49,130 --> 00:22:49,140
کد مهندسی این است که شما
 

1078
00:22:49,140 --> 00:22:50,840
کد مهندسی این است که شما
یک سیستم با کنترل گسترده را

1079
00:22:50,840 --> 00:22:50,850
یک سیستم با کنترل گسترده را
 

1080
00:22:50,850 --> 00:22:53,270
یک سیستم با کنترل گسترده را
قبل از آزمایش پیاده سازی نکنید  اکنون شاید

1081
00:22:53,270 --> 00:22:53,280
قبل از آزمایش پیاده سازی نکنید  اکنون شاید
 

1082
00:22:53,280 --> 00:22:54,440
قبل از آزمایش پیاده سازی نکنید  اکنون شاید
فرهنگ مهندسی به طور اساسی

1083
00:22:54,440 --> 00:22:54,450
فرهنگ مهندسی به طور اساسی
 

1084
00:22:54,450 --> 00:22:56,750
فرهنگ مهندسی به طور اساسی
تغییر کند، آنگاه نگران خواهم بود که

1085
00:22:56,750 --> 00:22:56,760
تغییر کند، آنگاه نگران خواهم بود که
 

1086
00:22:56,760 --> 00:22:58,430
تغییر کند، آنگاه نگران خواهم بود که
هیچ نشانه ای نمی بینم که مهندسان ناگهان

1087
00:22:58,430 --> 00:22:58,440
هیچ نشانه ای نمی بینم که مهندسان ناگهان
 

1088
00:22:58,440 --> 00:23:03,020
هیچ نشانه ای نمی بینم که مهندسان ناگهان
کارهای احمقانه ای انجام دهند مانند کنترل یک

1089
00:23:03,020 --> 00:23:03,030
کارهای احمقانه ای انجام دهند مانند کنترل یک
 

1090
00:23:03,030 --> 00:23:04,610
کارهای احمقانه ای انجام دهند مانند کنترل یک
نیروگاه برق بر سیستمی که

1091
00:23:04,610 --> 00:23:04,620
نیروگاه برق بر سیستمی که
 

1092
00:23:04,620 --> 00:23:08,150
نیروگاه برق بر سیستمی که
ابتدا آنها را آزمایش نکرده اند یا همه

1093
00:23:08,150 --> 00:23:08,160
ابتدا آنها را آزمایش نکرده اند یا همه
 

1094
00:23:08,160 --> 00:23:11,800
ابتدا آنها را آزمایش نکرده اند یا همه
اینها را کنترل کنند.  سناریوها نه تنها

1095
00:23:11,800 --> 00:23:11,810
اینها را کنترل کنند.  سناریوها نه تنها
 

1096
00:23:11,810 --> 00:23:14,750
اینها را کنترل کنند.  سناریوها نه تنها
یک هوش تقریباً با قدرت جادویی را تصور کنید که می

1097
00:23:14,750 --> 00:23:14,760
یک هوش تقریباً با قدرت جادویی را تصور کنید که می
 

1098
00:23:14,760 --> 00:23:17,780
یک هوش تقریباً با قدرت جادویی را تصور کنید که می
دانید شامل مواردی مانند درمان

1099
00:23:17,780 --> 00:23:17,790
دانید شامل مواردی مانند درمان
 

1100
00:23:17,790 --> 00:23:19,370
دانید شامل مواردی مانند درمان
سرطان است که احتمالاً یک

1101
00:23:19,370 --> 00:23:19,380
سرطان است که احتمالاً یک
 

1102
00:23:19,380 --> 00:23:20,840
سرطان است که احتمالاً یک
هدف نامنسجم است زیرا

1103
00:23:20,840 --> 00:23:20,850
هدف نامنسجم است زیرا
 

1104
00:23:20,850 --> 00:23:23,540
هدف نامنسجم است زیرا
انواع مختلفی از سرطان وجود دارد یا صلح جهانی را به ارمغان می آورد.

1105
00:23:23,540 --> 00:23:25,490
انواع مختلفی از سرطان وجود دارد یا صلح جهانی را به ارمغان می آورد.
 

1106
00:23:25,490 --> 00:23:25,500

 

1107
00:23:25,500 --> 00:23:27,590

همچنین

1108
00:23:27,590 --> 00:23:27,600
همچنین
 

1109
00:23:27,600 --> 00:23:30,500
همچنین
درجه ای از کنترل هر

1110
00:23:30,500 --> 00:23:30,510
درجه ای از کنترل هر
 

1111
00:23:30,510 --> 00:23:33,440
درجه ای از کنترل هر
مولکول در جهان را تصور کنید که نه تنها

1112
00:23:33,440 --> 00:23:33,450
مولکول در جهان را تصور کنید که نه تنها
 

1113
00:23:33,450 --> 00:23:36,200
مولکول در جهان را تصور کنید که نه تنها
خود بعید است، بلکه بدون آزمایش

1114
00:23:36,200 --> 00:23:36,210
خود بعید است، بلکه بدون آزمایش
 

1115
00:23:36,210 --> 00:23:39,010
خود بعید است، بلکه بدون آزمایش
شروع به اتصال این سیستم ها به

1116
00:23:39,010 --> 00:23:39,020
شروع به اتصال این سیستم ها به
 

1117
00:23:39,020 --> 00:23:42,590
شروع به اتصال این سیستم ها به
زیرساخت نمی کنیم،

1118
00:23:42,590 --> 00:23:42,600
زیرساخت نمی کنیم،
 

1119
00:23:42,600 --> 00:23:45,230
زیرساخت نمی کنیم،
همانطور که هر نوع

1120
00:23:45,230 --> 00:23:45,240
همانطور که هر نوع
 

1121
00:23:45,240 --> 00:23:46,970
همانطور که هر نوع
سیستم مهندسی را انجام می دهیم، ممکن است برخی مهندسان

1122
00:23:46,970 --> 00:23:46,980
سیستم مهندسی را انجام می دهیم، ممکن است برخی مهندسان
 

1123
00:23:46,980 --> 00:23:50,830
سیستم مهندسی را انجام می دهیم، ممکن است برخی مهندسان
غیرمسئول باشند و ما نیاز داریم.  مسئولیت‌های قانونی و

1124
00:23:50,830 --> 00:23:50,840
غیرمسئول باشند و ما نیاز داریم.  مسئولیت‌های قانونی و
 

1125
00:23:50,840 --> 00:23:54,890
غیرمسئول باشند و ما نیاز داریم.  مسئولیت‌های قانونی و
نظارتی و قانونی

1126
00:23:54,890 --> 00:23:54,900
نظارتی و قانونی
 

1127
00:23:54,900 --> 00:23:57,050
نظارتی و قانونی
اجرا می‌شوند تا مهندسان

1128
00:23:57,050 --> 00:23:57,060
اجرا می‌شوند تا مهندسان
 

1129
00:23:57,060 --> 00:23:58,910
اجرا می‌شوند تا مهندسان
کارهای احمقانه‌ای را طبق

1130
00:23:58,910 --> 00:23:58,920
کارهای احمقانه‌ای را طبق
 

1131
00:23:58,920 --> 00:24:02,960
کارهای احمقانه‌ای را طبق
استانداردهای خودشان انجام ندهند، اما من هرگز

1132
00:24:02,960 --> 00:24:02,970
استانداردهای خودشان انجام ندهند، اما من هرگز
 

1133
00:24:02,970 --> 00:24:06,070
استانداردهای خودشان انجام ندهند، اما من هرگز
سناریوی قابل قبولی از

1134
00:24:06,070 --> 00:24:06,080
سناریوی قابل قبولی از
 

1135
00:24:06,080 --> 00:24:08,570
سناریوی قابل قبولی از
تهدید وجودی را به اندازه کافی ندیده‌ام که

1136
00:24:08,570 --> 00:24:08,580
تهدید وجودی را به اندازه کافی ندیده‌ام که
 

1137
00:24:08,580 --> 00:24:10,910
تهدید وجودی را به اندازه کافی ندیده‌ام که
مقدار زیادی از قدرت مغز را برای جلوگیری از

1138
00:24:10,910 --> 00:24:10,920
مقدار زیادی از قدرت مغز را برای جلوگیری از
 

1139
00:24:10,920 --> 00:24:13,820
مقدار زیادی از قدرت مغز را برای جلوگیری از
آن اختصاص دهد.  بنابراین شما به نوع

1140
00:24:13,820 --> 00:24:13,830
آن اختصاص دهد.  بنابراین شما به نوع
 

1141
00:24:13,830 --> 00:24:16,070
آن اختصاص دهد.  بنابراین شما به نوع
قدرت و جرم مهندسی

1142
00:24:16,070 --> 00:24:16,080
قدرت و جرم مهندسی
 

1143
00:24:16,080 --> 00:24:17,779
قدرت و جرم مهندسی
عقل اعتقاد دارید که

1144
00:24:17,779 --> 00:24:17,789
عقل اعتقاد دارید که
 

1145
00:24:17,789 --> 00:24:19,690
عقل اعتقاد دارید که
این کتاب علم عقل استدلال می کند و به نوعی

1146
00:24:19,690 --> 00:24:19,700
این کتاب علم عقل استدلال می کند و به نوعی
 

1147
00:24:19,700 --> 00:24:23,570
این کتاب علم عقل استدلال می کند و به نوعی
همان چیزی است که

1148
00:24:23,570 --> 00:24:23,580
همان چیزی است که
 

1149
00:24:23,580 --> 00:24:25,099
همان چیزی است که
توسعه فناوری جدید را

1150
00:24:25,099 --> 00:24:25,109
توسعه فناوری جدید را
 

1151
00:24:25,109 --> 00:24:27,109
توسعه فناوری جدید را
ایمن می کند و همچنین ما را ایمن نگه می دارد.

1152
00:24:27,109 --> 00:24:27,119
ایمن می کند و همچنین ما را ایمن نگه می دارد.
 

1153
00:24:27,119 --> 00:24:29,029
ایمن می کند و همچنین ما را ایمن نگه می دارد.
می دانید همان

1154
00:24:29,029 --> 00:24:29,039
می دانید همان
 

1155
00:24:29,039 --> 00:24:32,180
می دانید همان
فرهنگ ایمنی که در حال حاضر بخشی

1156
00:24:32,180 --> 00:24:32,190
فرهنگ ایمنی که در حال حاضر بخشی
 

1157
00:24:32,190 --> 00:24:35,060
فرهنگ ایمنی که در حال حاضر بخشی
از ذهنیت مهندسی برای هواپیماها است، وجود دارد،

1158
00:24:35,060 --> 00:24:35,070
از ذهنیت مهندسی برای هواپیماها است، وجود دارد،
 

1159
00:24:35,070 --> 00:24:37,729
از ذهنیت مهندسی برای هواپیماها است، وجود دارد،
بنابراین بله، من فکر نمی کنم که

1160
00:24:37,729 --> 00:24:37,739
بنابراین بله، من فکر نمی کنم که
 

1161
00:24:37,739 --> 00:24:39,619
بنابراین بله، من فکر نمی کنم که
آن را باید از

1162
00:24:39,619 --> 00:24:39,629
آن را باید از
 

1163
00:24:39,629 --> 00:24:42,289
آن را باید از
پنجره بیرون انداخت و آن سیستم قدرتمند آزمایش نشده

1164
00:24:42,289 --> 00:24:42,299
پنجره بیرون انداخت و آن سیستم قدرتمند آزمایش نشده
 

1165
00:24:42,299 --> 00:24:44,359
پنجره بیرون انداخت و آن سیستم قدرتمند آزمایش نشده
باید به طور ناگهانی اجرا شود،

1166
00:24:44,359 --> 00:24:44,369
باید به طور ناگهانی اجرا شود،
 

1167
00:24:44,369 --> 00:24:46,219
باید به طور ناگهانی اجرا شود،
اما وجود ندارد.  دلیلی برای فکر کردن به آنها وجود دارد

1168
00:24:46,219 --> 00:24:46,229
اما وجود ندارد.  دلیلی برای فکر کردن به آنها وجود دارد
 

1169
00:24:46,229 --> 00:24:48,499
اما وجود ندارد.  دلیلی برای فکر کردن به آنها وجود دارد
و در واقع اگر به پیشرفت

1170
00:24:48,499 --> 00:24:48,509
و در واقع اگر به پیشرفت
 

1171
00:24:48,509 --> 00:24:50,599
و در واقع اگر به پیشرفت
هوش مصنوعی نگاه کنید، می

1172
00:24:50,599 --> 00:24:50,609
هوش مصنوعی نگاه کنید، می
 

1173
00:24:50,609 --> 00:24:51,859
هوش مصنوعی نگاه کنید، می
دانید که به خصوص در

1174
00:24:51,859 --> 00:24:51,869
دانید که به خصوص در
 

1175
00:24:51,869 --> 00:24:53,749
دانید که به خصوص در
ده سال گذشته بسیار چشمگیر بوده است، اما این ایده

1176
00:24:53,749 --> 00:24:53,759
ده سال گذشته بسیار چشمگیر بوده است، اما این ایده
 

1177
00:24:53,759 --> 00:24:54,859
ده سال گذشته بسیار چشمگیر بوده است، اما این ایده
که ناگهان یک تابع مرحله ای وجود خواهد داشت

1178
00:24:54,859 --> 00:24:54,869
که ناگهان یک تابع مرحله ای وجود خواهد داشت
 

1179
00:24:54,869 --> 00:24:57,499
که ناگهان یک تابع مرحله ای وجود خواهد داشت
که به طور ناگهانی قبل از آن  ما می

1180
00:24:57,499 --> 00:24:57,509
که به طور ناگهانی قبل از آن  ما می
 

1181
00:24:57,509 --> 00:25:00,379
که به طور ناگهانی قبل از آن  ما می
دانیم که این بسیار قدرتمند خواهد بود که

1182
00:25:00,379 --> 00:25:00,389
دانیم که این بسیار قدرتمند خواهد بود که
 

1183
00:25:00,389 --> 00:25:01,789
دانیم که این بسیار قدرتمند خواهد بود که
نوعی

1184
00:25:01,789 --> 00:25:01,799
نوعی
 

1185
00:25:01,799 --> 00:25:05,089
نوعی
خود-بهبودی بازگشتی وجود داشته باشد، نوعی فوم

1186
00:25:05,089 --> 00:25:05,099
خود-بهبودی بازگشتی وجود داشته باشد، نوعی فوم
 

1187
00:25:05,099 --> 00:25:08,749
خود-بهبودی بازگشتی وجود داشته باشد، نوعی فوم
نیز خیالی است، ما مطمئناً به دلیل

1188
00:25:08,749 --> 00:25:08,759
نیز خیالی است، ما مطمئناً به دلیل
 

1189
00:25:08,759 --> 00:25:11,419
نیز خیالی است، ما مطمئناً به دلیل
فناوری که اکنون

1190
00:25:11,419 --> 00:25:11,429
فناوری که اکنون
 

1191
00:25:11,429 --> 00:25:13,489
فناوری که اکنون
ما را تحت تأثیر قرار می دهد، مانند یادگیری عمیق وقتی

1192
00:25:13,489 --> 00:25:13,499
ما را تحت تأثیر قرار می دهد، مانند یادگیری عمیق وقتی
 

1193
00:25:13,499 --> 00:25:16,190
ما را تحت تأثیر قرار می دهد، مانند یادگیری عمیق وقتی
چیزی را در صدها مورد آموزش می دهید.

1194
00:25:16,190 --> 00:25:16,200
چیزی را در صدها مورد آموزش می دهید.
 

1195
00:25:16,200 --> 00:25:17,619
چیزی را در صدها مورد آموزش می دهید.
هزاران یا میلیون‌ها مثال،

1196
00:25:17,619 --> 00:25:17,629
هزاران یا میلیون‌ها مثال،
 

1197
00:25:17,629 --> 00:25:20,139
هزاران یا میلیون‌ها مثال،
صدها هزار

1198
00:25:20,139 --> 00:25:20,149
صدها هزار
 

1199
00:25:20,149 --> 00:25:23,869
صدها هزار
مشکل نیستند که درمان سرطان

1200
00:25:23,869 --> 00:25:23,879
مشکل نیستند که درمان سرطان
 

1201
00:25:23,879 --> 00:25:27,139
مشکل نیستند که درمان سرطان
نمونه‌ای معمولی از آن‌ها است و بنابراین، نوع

1202
00:25:27,139 --> 00:25:27,149
نمونه‌ای معمولی از آن‌ها است و بنابراین، نوع
 

1203
00:25:27,149 --> 00:25:29,109
نمونه‌ای معمولی از آن‌ها است و بنابراین، نوع
تکنیک‌هایی که به هوش مصنوعی اجازه داده‌اند

1204
00:25:29,109 --> 00:25:29,119
تکنیک‌هایی که به هوش مصنوعی اجازه داده‌اند
 

1205
00:25:29,119 --> 00:25:31,519
تکنیک‌هایی که به هوش مصنوعی اجازه داده‌اند
در پنج سال گذشته افزایش یابد،

1206
00:25:31,519 --> 00:25:31,529
در پنج سال گذشته افزایش یابد،
 

1207
00:25:31,529 --> 00:25:32,919
در پنج سال گذشته افزایش یابد،
ادعایی نیستند که به این امر منجر شوند.

1208
00:25:32,919 --> 00:25:32,929
ادعایی نیستند که به این امر منجر شوند.
 

1209
00:25:32,929 --> 00:25:37,759
ادعایی نیستند که به این امر منجر شوند.
فانتزی از خودسازی ناگهانی تصاعدی،

1210
00:25:37,759 --> 00:25:37,769
فانتزی از خودسازی ناگهانی تصاعدی،
 

1211
00:25:37,769 --> 00:25:40,009
فانتزی از خودسازی ناگهانی تصاعدی،
بنابراین ممکن است فکر کنم این یک

1212
00:25:40,009 --> 00:25:40,019
بنابراین ممکن است فکر کنم این یک
 

1213
00:25:40,019 --> 00:25:41,539
بنابراین ممکن است فکر کنم این یک
نوع تفکر جادویی است،

1214
00:25:41,539 --> 00:25:41,549
نوع تفکر جادویی است،
 

1215
00:25:41,549 --> 00:25:43,940
نوع تفکر جادویی است،
این بر اساس درک ما از

1216
00:25:43,940 --> 00:25:43,950
این بر اساس درک ما از
 

1217
00:25:43,950 --> 00:25:46,460
این بر اساس درک ما از
عملکرد واقعی هوش مصنوعی نیست، اکنون به من فرصتی بدهید،

1218
00:25:46,460 --> 00:25:46,470
عملکرد واقعی هوش مصنوعی نیست، اکنون به من فرصتی بدهید،
 

1219
00:25:46,470 --> 00:25:48,859
عملکرد واقعی هوش مصنوعی نیست، اکنون به من فرصتی بدهید،
بنابراین شما

1220
00:25:48,859 --> 00:25:48,869
بنابراین شما
 

1221
00:25:48,869 --> 00:25:51,950
بنابراین شما
در سخنرانی TED خود گفتید تفکر جادویی خیالی.

1222
00:25:51,950 --> 00:25:51,960
در سخنرانی TED خود گفتید تفکر جادویی خیالی.
 

1223
00:25:51,960 --> 00:25:54,080
در سخنرانی TED خود گفتید تفکر جادویی خیالی.
اینکه فکر کردن به هوش مصنوعی که تمام تمدن بشری را می کشد

1224
00:25:54,080 --> 00:25:54,090
اینکه فکر کردن به هوش مصنوعی که تمام تمدن بشری را می کشد
 

1225
00:25:54,090 --> 00:25:55,639
اینکه فکر کردن به هوش مصنوعی که تمام تمدن بشری را می کشد
به نوعی از نظر فکری سرگرم کننده است،

1226
00:25:55,639 --> 00:25:55,649
به نوعی از نظر فکری سرگرم کننده است،
 

1227
00:25:55,649 --> 00:25:58,489
به نوعی از نظر فکری سرگرم کننده است،
اکنون باید بگویم که به عنوان یک

1228
00:25:58,489 --> 00:25:58,499
اکنون باید بگویم که به عنوان یک
 

1229
00:25:58,499 --> 00:26:00,519
اکنون باید بگویم که به عنوان یک
مهندس دانشمند این کار را سرگرم کننده نمی دانم،

1230
00:26:00,519 --> 00:26:00,529
مهندس دانشمند این کار را سرگرم کننده نمی دانم،
 

1231
00:26:00,529 --> 00:26:03,560
مهندس دانشمند این کار را سرگرم کننده نمی دانم،
اما وقتی با دوستان غیر هوش مصنوعی خود آبجو می نوشم،

1232
00:26:03,560 --> 00:26:03,570
اما وقتی با دوستان غیر هوش مصنوعی خود آبجو می نوشم،
 

1233
00:26:03,570 --> 00:26:07,609
اما وقتی با دوستان غیر هوش مصنوعی خود آبجو می نوشم،
واقعاً چیز جالب

1234
00:26:07,609 --> 00:26:07,619
واقعاً چیز جالب
 

1235
00:26:07,619 --> 00:26:09,440
واقعاً چیز جالب
و جذابی در آن وجود دارد.  مثل صحبت کردن

1236
00:26:09,440 --> 00:26:09,450
و جذابی در آن وجود دارد.  مثل صحبت کردن
 

1237
00:26:09,450 --> 00:26:10,669
و جذابی در آن وجود دارد.  مثل صحبت کردن
در مورد یک قسمت از آینه سیاه

1238
00:26:10,669 --> 00:26:10,679
در مورد یک قسمت از آینه سیاه
 

1239
00:26:10,679 --> 00:26:14,479
در مورد یک قسمت از آینه سیاه
با در نظر گرفتن اینکه آیا یک شهاب سنگ بزرگ به سمت زمین حرکت می کند به

1240
00:26:14,479 --> 00:26:14,489
با در نظر گرفتن اینکه آیا یک شهاب سنگ بزرگ به سمت زمین حرکت می کند به
 

1241
00:26:14,489 --> 00:26:16,519
با در نظر گرفتن اینکه آیا یک شهاب سنگ بزرگ به سمت زمین حرکت می کند به
ما گفته شد که یک

1242
00:26:16,519 --> 00:26:16,529
ما گفته شد که یک
 

1243
00:26:16,529 --> 00:26:18,589
ما گفته شد که یک
شهاب سنگ بزرگ به سمت زمین حرکت می کند چیزی

1244
00:26:18,589 --> 00:26:18,599
شهاب سنگ بزرگ به سمت زمین حرکت می کند چیزی
 

1245
00:26:18,599 --> 00:26:19,369
شهاب سنگ بزرگ به سمت زمین حرکت می کند چیزی
شبیه به این

1246
00:26:19,369 --> 00:26:19,379
شبیه به این
 

1247
00:26:19,379 --> 00:26:22,099
شبیه به این
و آیا می توانید با این حس سرگرم کننده ارتباط برقرار کنید

1248
00:26:22,099 --> 00:26:22,109
و آیا می توانید با این حس سرگرم کننده ارتباط برقرار کنید
 

1249
00:26:22,109 --> 00:26:24,440
و آیا می توانید با این حس سرگرم کننده ارتباط برقرار کنید
و آیا روانشناسی آن را درک می کنید

1250
00:26:24,440 --> 00:26:24,450
و آیا روانشناسی آن را درک می کنید
 

1251
00:26:24,450 --> 00:26:26,419
و آیا روانشناسی آن را درک می کنید
بله  سوال خوب

1252
00:26:26,419 --> 00:26:26,429
بله  سوال خوب
 

1253
00:26:26,429 --> 00:26:29,400
بله  سوال خوب
III شخصاً آن را سرگرم کننده نمی دانم به

1254
00:26:29,400 --> 00:26:29,410
III شخصاً آن را سرگرم کننده نمی دانم به
 

1255
00:26:29,410 --> 00:26:32,250
III شخصاً آن را سرگرم کننده نمی دانم به
نظر من در واقع یک اتلاف

1256
00:26:32,250 --> 00:26:32,260
نظر من در واقع یک اتلاف
 

1257
00:26:32,260 --> 00:26:34,950
نظر من در واقع یک اتلاف
وقت است زیرا تهدیدهای واقعی وجود دارد

1258
00:26:34,950 --> 00:26:34,960
وقت است زیرا تهدیدهای واقعی وجود دارد
 

1259
00:26:34,960 --> 00:26:37,470
وقت است زیرا تهدیدهای واقعی وجود دارد
که ما باید به آنها فکر کنیم

1260
00:26:37,470 --> 00:26:37,480
که ما باید به آنها فکر کنیم
 

1261
00:26:37,480 --> 00:26:39,720
که ما باید به آنها فکر کنیم
مانند بیماری های همه گیر مانند

1262
00:26:39,720 --> 00:26:39,730
مانند بیماری های همه گیر مانند
 

1263
00:26:39,730 --> 00:26:43,410
مانند بیماری های همه گیر مانند
آسیب پذیری های امنیت سایبری مانند

1264
00:26:43,410 --> 00:26:43,420
آسیب پذیری های امنیت سایبری مانند
 

1265
00:26:43,420 --> 00:26:45,540
آسیب پذیری های امنیت سایبری مانند
احتمال جنگ هسته ای و قطعاً

1266
00:26:45,540 --> 00:26:45,550
احتمال جنگ هسته ای و قطعاً
 

1267
00:26:45,550 --> 00:26:49,110
احتمال جنگ هسته ای و قطعاً
آب و هوا.  این را تغییر دهید برای فیلمبرداری از

1268
00:26:49,110 --> 00:26:49,120
آب و هوا.  این را تغییر دهید برای فیلمبرداری از
 

1269
00:26:49,120 --> 00:26:52,890
آب و هوا.  این را تغییر دهید برای فیلمبرداری از
بسیاری از مکالمات بدون آن کافی است و من فکر می کنم

1270
00:26:52,890 --> 00:26:52,900
بسیاری از مکالمات بدون آن کافی است و من فکر می کنم
 

1271
00:26:52,900 --> 00:26:54,690
بسیاری از مکالمات بدون آن کافی است و من فکر می کنم
در آنجا سام انگشت خود را روی چیزی گذاشته است،

1272
00:26:54,690 --> 00:26:54,700
در آنجا سام انگشت خود را روی چیزی گذاشته است،
 

1273
00:26:54,700 --> 00:26:56,400
در آنجا سام انگشت خود را روی چیزی گذاشته است،
یعنی جامعه ای وجود دارد که

1274
00:26:56,400 --> 00:26:56,410
یعنی جامعه ای وجود دارد که
 

1275
00:26:56,410 --> 00:26:59,250
یعنی جامعه ای وجود دارد که
ما گاهی آن را

1276
00:26:59,250 --> 00:26:59,260
ما گاهی آن را
 

1277
00:26:59,260 --> 00:27:02,430
ما گاهی آن را
جامعه عقلانیت می نامیم که از

1278
00:27:02,430 --> 00:27:02,440
جامعه عقلانیت می نامیم که از
 

1279
00:27:02,440 --> 00:27:05,250
جامعه عقلانیت می نامیم که از
استفاده از قدرت مغز خود برای ارائه

1280
00:27:05,250 --> 00:27:05,260
استفاده از قدرت مغز خود برای ارائه
 

1281
00:27:05,260 --> 00:27:08,160
استفاده از قدرت مغز خود برای ارائه
سناریوهایی لذت می برد.  برای افراد فانی ساده برای افراد کمتر مغزی پیش می آید،

1282
00:27:08,160 --> 00:27:08,170
سناریوهایی لذت می برد.  برای افراد فانی ساده برای افراد کمتر مغزی پیش می آید،
 

1283
00:27:08,170 --> 00:27:12,240
سناریوهایی لذت می برد.  برای افراد فانی ساده برای افراد کمتر مغزی پیش می آید،
بنابراین

1284
00:27:12,240 --> 00:27:12,250
بنابراین
 

1285
00:27:12,250 --> 00:27:13,980
بنابراین
نوعی هیجان فکری در

1286
00:27:13,980 --> 00:27:13,990
نوعی هیجان فکری در
 

1287
00:27:13,990 --> 00:27:15,720
نوعی هیجان فکری در
یافتن چیزهای جدید برای نگرانی وجود دارد که

1288
00:27:15,720 --> 00:27:15,730
یافتن چیزهای جدید برای نگرانی وجود دارد که
 

1289
00:27:15,730 --> 00:27:17,640
یافتن چیزهای جدید برای نگرانی وجود دارد که
هیچ کس

1290
00:27:17,640 --> 00:27:20,100
هیچ کس
 

1291
00:27:20,100 --> 00:27:21,990

 

1292
00:27:21,990 --> 00:27:22,000

 

1293
00:27:22,000 --> 00:27:24,480

نگران آنها نبوده است.  من خوشحالم، اما فکر می‌کنم

1294
00:27:24,480 --> 00:27:24,490
نگران آنها نبوده است.  من خوشحالم، اما فکر می‌کنم
 

1295
00:27:24,490 --> 00:27:26,160
نگران آنها نبوده است.  من خوشحالم، اما فکر می‌کنم
یک جنبه مخرب هم

1296
00:27:26,160 --> 00:27:26,170
یک جنبه مخرب هم
 

1297
00:27:26,170 --> 00:27:28,830
یک جنبه مخرب هم
در آن وجود دارد، یعنی اینکه شما بر مردم غلبه می‌کنید

1298
00:27:28,830 --> 00:27:28,840
در آن وجود دارد، یعنی اینکه شما بر مردم غلبه می‌کنید
 

1299
00:27:28,840 --> 00:27:32,250
در آن وجود دارد، یعنی اینکه شما بر مردم غلبه می‌کنید
با چنان سرنوشت‌گریزی وحشتناک که

1300
00:27:32,250 --> 00:27:32,260
با چنان سرنوشت‌گریزی وحشتناک که
 

1301
00:27:32,260 --> 00:27:35,190
با چنان سرنوشت‌گریزی وحشتناک که
راه‌های زیادی برای

1302
00:27:35,190 --> 00:27:35,200
راه‌های زیادی برای
 

1303
00:27:35,200 --> 00:27:38,070
راه‌های زیادی برای
از بین بردن تمدن ما وجود دارد که ممکن است ما

1304
00:27:38,070 --> 00:27:38,080
از بین بردن تمدن ما وجود دارد که ممکن است ما
 

1305
00:27:38,080 --> 00:27:39,960
از بین بردن تمدن ما وجود دارد که ممکن است ما
نیز از زندگی لذت ببریم، در حالی که می‌توانیم

1306
00:27:39,960 --> 00:27:39,970
نیز از زندگی لذت ببریم، در حالی که می‌توانیم
 

1307
00:27:39,970 --> 00:27:41,190
نیز از زندگی لذت ببریم، در حالی که می‌توانیم
هیچ چیز نداریم.  اگر

1308
00:27:41,190 --> 00:27:41,200
هیچ چیز نداریم.  اگر
 

1309
00:27:41,200 --> 00:27:42,930
هیچ چیز نداریم.  اگر
تغییرات اقلیمی ما را تحت تأثیر قرار ندهد،

1310
00:27:42,930 --> 00:27:42,940
تغییرات اقلیمی ما را تحت تأثیر قرار ندهد،
 

1311
00:27:42,940 --> 00:27:46,410
تغییرات اقلیمی ما را تحت تأثیر قرار ندهد،
ربات‌های فراری می‌توانند این کار را انجام دهند، بنابراین بیایید از خود لذت ببریم، اکنون

1312
00:27:46,410 --> 00:27:46,420
ربات‌های فراری می‌توانند این کار را انجام دهند، بنابراین بیایید از خود لذت ببریم، اکنون
 

1313
00:27:46,420 --> 00:27:51,540
ربات‌های فراری می‌توانند این کار را انجام دهند، بنابراین بیایید از خود لذت ببریم، اکنون
باید اولویت‌بندی کنیم، باید

1314
00:27:51,540 --> 00:27:51,550
باید اولویت‌بندی کنیم، باید
 

1315
00:27:51,550 --> 00:27:54,270
باید اولویت‌بندی کنیم، باید
به تهدیدهایی نزدیک به قطعیت

1316
00:27:54,270 --> 00:27:54,280
به تهدیدهایی نزدیک به قطعیت
 

1317
00:27:54,280 --> 00:27:56,640
به تهدیدهایی نزدیک به قطعیت
مانند تغییرات آب و هوایی نگاه کنیم و

1318
00:27:56,640 --> 00:27:56,650
مانند تغییرات آب و هوایی نگاه کنیم و
 

1319
00:27:56,650 --> 00:27:58,140
مانند تغییرات آب و هوایی نگاه کنیم و
آن‌ها را از تهدیداتی که  صرفا

1320
00:27:58,140 --> 00:27:58,150
آن‌ها را از تهدیداتی که  صرفا
 

1321
00:27:58,150 --> 00:28:00,180
آن‌ها را از تهدیداتی که  صرفا
قابل تصور است اما با احتمالات بی نهایت کوچک

1322
00:28:00,180 --> 00:28:00,190
قابل تصور است اما با احتمالات بی نهایت کوچک
 

1323
00:28:00,190 --> 00:28:04,350
قابل تصور است اما با احتمالات بی نهایت کوچک
و ما باید

1324
00:28:04,350 --> 00:28:04,360
و ما باید
 

1325
00:28:04,360 --> 00:28:06,240
و ما باید
بودجه نگرانی مردم را در نظر بگیریم شما نمی توانید

1326
00:28:06,240 --> 00:28:06,250
بودجه نگرانی مردم را در نظر بگیریم شما نمی توانید
 

1327
00:28:06,250 --> 00:28:08,460
بودجه نگرانی مردم را در نظر بگیریم شما نمی توانید
نگران همه چیز باشید و اگر اینقدر

1328
00:28:08,460 --> 00:28:08,470
نگران همه چیز باشید و اگر اینقدر
 

1329
00:28:08,470 --> 00:28:11,730
نگران همه چیز باشید و اگر اینقدر
ترس و ترس و وحشت و بی حسی و

1330
00:28:11,730 --> 00:28:11,740
ترس و ترس و وحشت و بی حسی و
 

1331
00:28:11,740 --> 00:28:13,740
ترس و ترس و وحشت و بی حسی و
سرنوشت گرایی دارید می تواند منجر به نوعی

1332
00:28:13,740 --> 00:28:13,750
سرنوشت گرایی دارید می تواند منجر به نوعی
 

1333
00:28:13,750 --> 00:28:14,970
سرنوشت گرایی دارید می تواند منجر به نوعی
بی حسی شود، خوب آنها فقط این ها هستند

1334
00:28:14,970 --> 00:28:14,980
بی حسی شود، خوب آنها فقط این ها هستند
 

1335
00:28:14,980 --> 00:28:16,500
بی حسی شود، خوب آنها فقط این ها هستند
مشکلات طاقت فرسا هستند و

1336
00:28:16,500 --> 00:28:16,510
مشکلات طاقت فرسا هستند و
 

1337
00:28:16,510 --> 00:28:19,400
مشکلات طاقت فرسا هستند و
مهندسان فقط همه ما را خواهند کشت، پس

1338
00:28:19,400 --> 00:28:19,410
مهندسان فقط همه ما را خواهند کشت، پس
 

1339
00:28:19,410 --> 00:28:22,430
مهندسان فقط همه ما را خواهند کشت، پس
بیایید یا کل

1340
00:28:22,430 --> 00:28:22,440
بیایید یا کل
 

1341
00:28:22,440 --> 00:28:26,880
بیایید یا کل
زیرساخت فناوری علمی را نابود کنیم یا از

1342
00:28:26,880 --> 00:28:26,890
زیرساخت فناوری علمی را نابود کنیم یا از
 

1343
00:28:26,890 --> 00:28:29,820
زیرساخت فناوری علمی را نابود کنیم یا از
زندگی لذت ببریم در حالی که می توانیم، بنابراین

1344
00:28:29,820 --> 00:28:29,830
زندگی لذت ببریم در حالی که می توانیم، بنابراین
 

1345
00:28:29,830 --> 00:28:31,860
زندگی لذت ببریم در حالی که می توانیم، بنابراین
یک خط نگرانی وجود دارد که

1346
00:28:31,860 --> 00:28:31,870
یک خط نگرانی وجود دارد که
 

1347
00:28:31,870 --> 00:28:33,150
یک خط نگرانی وجود دارد که
من نگران بسیاری از چیزهای

1348
00:28:33,150 --> 00:28:33,160
من نگران بسیاری از چیزهای
 

1349
00:28:33,160 --> 00:28:34,380
من نگران بسیاری از چیزهای
مهندسی هستم.  خط خاصی از

1350
00:28:34,380 --> 00:28:34,390
مهندسی هستم.  خط خاصی از
 

1351
00:28:34,390 --> 00:28:38,070
مهندسی هستم.  خط خاصی از
نگرانی زمانی که شما از مقدار زیادی عبور می کنید،

1352
00:28:38,070 --> 00:28:38,080
نگرانی زمانی که شما از مقدار زیادی عبور می کنید،
 

1353
00:28:38,080 --> 00:28:40,500
نگرانی زمانی که شما از مقدار زیادی عبور می کنید،
به جای ترس مولد، ترس فلج کننده می شود

1354
00:28:40,500 --> 00:28:40,510
به جای ترس مولد، ترس فلج کننده می شود
 

1355
00:28:40,510 --> 00:28:42,840
به جای ترس مولد، ترس فلج کننده می شود
و این

1356
00:28:42,840 --> 00:28:42,850
و این
 

1357
00:28:42,850 --> 00:28:45,720
و این
همان چیزی است که آنها دقیقاً در آنجا برجسته می کنند

1358
00:28:45,720 --> 00:28:45,730
همان چیزی است که آنها دقیقاً در آنجا برجسته می کنند
 

1359
00:28:45,730 --> 00:28:48,210
همان چیزی است که آنها دقیقاً در آنجا برجسته می کنند
و ما برخی را دیده ایم که

1360
00:28:48,210 --> 00:28:48,220
و ما برخی را دیده ایم که
 

1361
00:28:48,220 --> 00:28:50,460
و ما برخی را دیده ایم که
می دانیم تلاش انسان به خوبی

1362
00:28:50,460 --> 00:28:50,470
می دانیم تلاش انسان به خوبی
 

1363
00:28:50,470 --> 00:28:54,060
می دانیم تلاش انسان به خوبی
در برابر خطر تنظیم نشده است.  از آنجا که

1364
00:28:54,060 --> 00:28:54,070
در برابر خطر تنظیم نشده است.  از آنجا که
 

1365
00:28:54,070 --> 00:28:57,720
در برابر خطر تنظیم نشده است.  از آنجا که
یک اصل اساسی روانشناسی شناختی این است

1366
00:28:57,720 --> 00:28:57,730
یک اصل اساسی روانشناسی شناختی این است
 

1367
00:28:57,730 --> 00:29:00,899
یک اصل اساسی روانشناسی شناختی این است
که ادراک خطر و در نتیجه

1368
00:29:00,899 --> 00:29:00,909
که ادراک خطر و در نتیجه
 

1369
00:29:00,909 --> 00:29:03,240
که ادراک خطر و در نتیجه
درک ترس ناشی از توانایی تصوری است و

1370
00:29:03,240 --> 00:29:03,250
درک ترس ناشی از توانایی تصوری است و
 

1371
00:29:03,250 --> 00:29:07,350
درک ترس ناشی از توانایی تصوری است و
نه از طریق داده ها و بنابراین ما از

1372
00:29:07,350 --> 00:29:07,360
نه از طریق داده ها و بنابراین ما از
 

1373
00:29:07,360 --> 00:29:09,840
نه از طریق داده ها و بنابراین ما از
تخصیص مقادیر زیادی از منابع برای

1374
00:29:09,840 --> 00:29:09,850
تخصیص مقادیر زیادی از منابع برای
 

1375
00:29:09,850 --> 00:29:11,909
تخصیص مقادیر زیادی از منابع برای
اجتناب از تروریسم که به

1376
00:29:11,909 --> 00:29:11,919
اجتناب از تروریسم که به
 

1377
00:29:11,919 --> 00:29:13,889
اجتناب از تروریسم که به
طور متوسط ​​هر سال حدود شش آمریکایی را با

1378
00:29:13,889 --> 00:29:13,899
طور متوسط ​​هر سال حدود شش آمریکایی را با
 

1379
00:29:13,899 --> 00:29:16,230
طور متوسط ​​هر سال حدود شش آمریکایی را با
یک نفر می کشد، نادیده می گیریم.  به استثنای 11 سپتامبر، ما به

1380
00:29:16,230 --> 00:29:16,240
یک نفر می کشد، نادیده می گیریم.  به استثنای 11 سپتامبر، ما به
 

1381
00:29:16,240 --> 00:29:19,070
یک نفر می کشد، نادیده می گیریم.  به استثنای 11 سپتامبر، ما به
کشورها حمله می کنیم، تمام

1382
00:29:19,070 --> 00:29:19,080
کشورها حمله می کنیم، تمام
 

1383
00:29:19,080 --> 00:29:21,990
کشورها حمله می کنیم، تمام
ادارات دولتی جدید را با

1384
00:29:21,990 --> 00:29:22,000
ادارات دولتی جدید را با
 

1385
00:29:22,000 --> 00:29:24,659
ادارات دولتی جدید را با
هزینه های هنگفت منابع و

1386
00:29:24,659 --> 00:29:24,669
هزینه های هنگفت منابع و
 

1387
00:29:24,669 --> 00:29:26,430
هزینه های هنگفت منابع و
جان برای دفاع از خود در برابر یک

1388
00:29:26,430 --> 00:29:26,440
جان برای دفاع از خود در برابر یک
 

1389
00:29:26,440 --> 00:29:30,659
جان برای دفاع از خود در برابر یک
خطر ناچیز اختراع می کنیم، در حالی که خطرات تضمین شده

1390
00:29:30,659 --> 00:29:30,669
خطر ناچیز اختراع می کنیم، در حالی که خطرات تضمین شده
 

1391
00:29:30,669 --> 00:29:32,370
خطر ناچیز اختراع می کنیم، در حالی که خطرات تضمین شده
و شما به عنوان یکی از آنها اشاره کردید که

1392
00:29:32,370 --> 00:29:32,380
و شما به عنوان یکی از آنها اشاره کردید که
 

1393
00:29:32,380 --> 00:29:35,700
و شما به عنوان یکی از آنها اشاره کردید که
تلفات رانندگی و حتی خطراتی را ذکر کردید

1394
00:29:35,700 --> 00:29:35,710
تلفات رانندگی و حتی خطراتی را ذکر کردید
 

1395
00:29:35,710 --> 00:29:41,029
تلفات رانندگی و حتی خطراتی را ذکر کردید
که چنین نیستند.  در اینجا اما به اندازه

1396
00:29:41,029 --> 00:29:41,039
که چنین نیستند.  در اینجا اما به اندازه
 

1397
00:29:41,039 --> 00:29:42,899
که چنین نیستند.  در اینجا اما به اندازه
کافی قابل قبول هستند که نگران

1398
00:29:42,899 --> 00:29:42,909
کافی قابل قبول هستند که نگران
 

1399
00:29:42,909 --> 00:29:47,549
کافی قابل قبول هستند که نگران
بیماری های همه گیر مانند جنگ هسته ای باشند،

1400
00:29:47,549 --> 00:29:47,559
بیماری های همه گیر مانند جنگ هسته ای باشند،
 

1401
00:29:47,559 --> 00:29:49,200
بیماری های همه گیر مانند جنگ هسته ای باشند،
در

1402
00:29:49,200 --> 00:29:49,210
در
 

1403
00:29:49,210 --> 00:29:50,610
در
مناظره های ریاست جمهوری

1404
00:29:50,610 --> 00:29:50,620
مناظره های ریاست جمهوری
 

1405
00:29:50,620 --> 00:29:53,009
مناظره های ریاست جمهوری
بحثی در مورد چگونگی به حداقل رساندن خطر

1406
00:29:53,009 --> 00:29:53,019
بحثی در مورد چگونگی به حداقل رساندن خطر
 

1407
00:29:53,019 --> 00:29:55,230
بحثی در مورد چگونگی به حداقل رساندن خطر
جنگ هسته ای وجود ندارد، بحث های زیادی در مورد

1408
00:29:55,230 --> 00:29:55,240
جنگ هسته ای وجود ندارد، بحث های زیادی در مورد
 

1409
00:29:55,240 --> 00:29:58,950
جنگ هسته ای وجود ندارد، بحث های زیادی در مورد
تروریسم به عنوان مثال و بنابراین ما

1410
00:29:58,950 --> 00:29:58,960
تروریسم به عنوان مثال و بنابراین ما
 

1411
00:29:58,960 --> 00:30:01,430
تروریسم به عنوان مثال و بنابراین ما
فکر می کنم ضروری است که

1412
00:30:01,430 --> 00:30:01,440
فکر می کنم ضروری است که
 

1413
00:30:01,440 --> 00:30:05,789
فکر می کنم ضروری است که
بودجه ما از ترس نگرانی نگرانی از برنامه ریزی را با

1414
00:30:05,789 --> 00:30:05,799
بودجه ما از ترس نگرانی نگرانی از برنامه ریزی را با
 

1415
00:30:05,799 --> 00:30:10,769
بودجه ما از ترس نگرانی نگرانی از برنامه ریزی را با
احتمال واقعی آسیب کالیبره کنید، بله،

1416
00:30:10,769 --> 00:30:10,779
احتمال واقعی آسیب کالیبره کنید، بله،
 

1417
00:30:10,779 --> 00:30:12,960
احتمال واقعی آسیب کالیبره کنید، بله،
اجازه دهید من این را بپرسم، سپس این سوال را بپرسم،

1418
00:30:12,960 --> 00:30:12,970
اجازه دهید من این را بپرسم، سپس این سوال را بپرسم،
 

1419
00:30:12,970 --> 00:30:16,200
اجازه دهید من این را بپرسم، سپس این سوال را بپرسم،
بنابراین در مورد توانایی تصوری صحبت می کنید، شما گفتید که

1420
00:30:16,200 --> 00:30:16,210
بنابراین در مورد توانایی تصوری صحبت می کنید، شما گفتید که
 

1421
00:30:16,210 --> 00:30:18,000
بنابراین در مورد توانایی تصوری صحبت می کنید، شما گفتید که
مهم است به دلیل فکر کنیم و

1422
00:30:18,000 --> 00:30:18,010
مهم است به دلیل فکر کنیم و
 

1423
00:30:18,010 --> 00:30:21,120
مهم است به دلیل فکر کنیم و
یکی از افراد مورد علاقه من که دوست دارد

1424
00:30:21,120 --> 00:30:21,130
یکی از افراد مورد علاقه من که دوست دارد
 

1425
00:30:21,130 --> 00:30:23,360
یکی از افراد مورد علاقه من که دوست دارد
در حومه ها غوطه ور شود.

1426
00:30:23,360 --> 00:30:26,610
در حومه ها غوطه ور شود.
 

1427
00:30:26,610 --> 00:30:26,620

 

1428
00:30:26,620 --> 00:30:30,919

جو روگان از طریق کاوش شگفت انگیز در تخیل خود جو روگان است، اوه بله شما، پس

1429
00:30:30,919 --> 00:30:30,929
جو روگان از طریق کاوش شگفت انگیز در تخیل خود جو روگان است، اوه بله شما، پس
 

1430
00:30:30,929 --> 00:30:33,600
جو روگان از طریق کاوش شگفت انگیز در تخیل خود جو روگان است، اوه بله شما، پس
کسی که از طریق عقل

1431
00:30:33,600 --> 00:30:33,610
کسی که از طریق عقل
 

1432
00:30:33,610 --> 00:30:35,700
کسی که از طریق عقل
توطئه های زیادی را باور کرده است و از طریق یک دلیل

1433
00:30:35,700 --> 00:30:35,710
توطئه های زیادی را باور کرده است و از طریق یک دلیل
 

1434
00:30:35,710 --> 00:30:37,440
توطئه های زیادی را باور کرده است و از طریق یک دلیل
بسیاری از باورهای خود را به این طریق از بین برده است،

1435
00:30:37,440 --> 00:30:37,450
بسیاری از باورهای خود را به این طریق از بین برده است،
 

1436
00:30:37,450 --> 00:30:39,899
بسیاری از باورهای خود را به این طریق از بین برده است،
بنابراین

1437
00:30:39,899 --> 00:30:39,909
بنابراین
 

1438
00:30:39,909 --> 00:30:42,899
بنابراین
تماشای او از طریق عقلانیت واقعاً جذاب است.

1439
00:30:42,899 --> 00:30:42,909
تماشای او از طریق عقلانیت واقعاً جذاب است.
 

1440
00:30:42,909 --> 00:30:46,250
تماشای او از طریق عقلانیت واقعاً جذاب است.
ایده های پاگنده و

1441
00:30:46,250 --> 00:30:46,260
ایده های پاگنده و
 

1442
00:30:46,260 --> 00:30:49,200
ایده های پاگنده و
11 سپتامبر را دور بریزید. من دقیقاً مطمئن نیستم که

1443
00:30:49,200 --> 00:30:49,210
11 سپتامبر را دور بریزید. من دقیقاً مطمئن نیستم که
 

1444
00:30:49,210 --> 00:30:50,200
11 سپتامبر را دور بریزید. من دقیقاً مطمئن نیستم که
مسیرها چیست.

1445
00:30:50,200 --> 00:30:52,450
مسیرها چیست.
 

1446
00:30:52,450 --> 00:30:53,710

 

1447
00:30:53,710 --> 00:30:53,720

 

1448
00:30:53,720 --> 00:30:56,500

شما

1449
00:30:56,500 --> 00:30:56,510
شما
 

1450
00:30:56,510 --> 00:30:58,660
شما
در ماه فوریه در پادکست جو روگان بودید و

1451
00:30:58,660 --> 00:30:58,670
در ماه فوریه در پادکست جو روگان بودید و
 

1452
00:30:58,670 --> 00:31:00,850
در ماه فوریه در پادکست جو روگان بودید و
گفتگوی جذابی داشتید، اما تا آنجا

1453
00:31:00,850 --> 00:31:00,860
گفتگوی جذابی داشتید، اما تا آنجا
 

1454
00:31:00,860 --> 00:31:02,490
گفتگوی جذابی داشتید، اما تا آنجا
که من به یاد دارم زیاد در مورد

1455
00:31:02,490 --> 00:31:02,500
که من به یاد دارم زیاد در مورد
 

1456
00:31:02,500 --> 00:31:05,500
که من به یاد دارم زیاد در مورد
هوش مصنوعی صحبت نکردم، من تا چند هفته دیگر در پادکست او خواهم بود.

1457
00:31:05,500 --> 00:31:06,760
هوش مصنوعی صحبت نکردم، من تا چند هفته دیگر در پادکست او خواهم بود.
 

1458
00:31:06,760 --> 00:31:06,770

 

1459
00:31:06,770 --> 00:31:09,400

جو بسیار نگران

1460
00:31:09,400 --> 00:31:09,410
جو بسیار نگران
 

1461
00:31:09,410 --> 00:31:11,560
جو بسیار نگران
تهدید وجودی است.  مطمئناً اگر

1462
00:31:11,560 --> 00:31:11,570
تهدید وجودی است.  مطمئناً اگر
 

1463
00:31:11,570 --> 00:31:13,810
تهدید وجودی است.  مطمئناً اگر
شما اینطور هستید، به همین دلیل بود که من امیدوار بودم

1464
00:31:13,810 --> 00:31:13,820
شما اینطور هستید، به همین دلیل بود که من امیدوار بودم
 

1465
00:31:13,820 --> 00:31:15,760
شما اینطور هستید، به همین دلیل بود که من امیدوار بودم
که شما وارد آن موضوع شوید و

1466
00:31:15,760 --> 00:31:15,770
که شما وارد آن موضوع شوید و
 

1467
00:31:15,770 --> 00:31:18,490
که شما وارد آن موضوع شوید و
به این ترتیب او نماینده بسیاری از

1468
00:31:18,490 --> 00:31:18,500
به این ترتیب او نماینده بسیاری از
 

1469
00:31:18,500 --> 00:31:20,650
به این ترتیب او نماینده بسیاری از
افرادی است که از سطح 10000 پا به موضوع هوش مصنوعی نگاه می کنند،

1470
00:31:20,650 --> 00:31:20,660
افرادی است که از سطح 10000 پا به موضوع هوش مصنوعی نگاه می کنند،
 

1471
00:31:20,660 --> 00:31:25,410
افرادی است که از سطح 10000 پا به موضوع هوش مصنوعی نگاه می کنند،
بنابراین به عنوان یک تمرین

1472
00:31:25,410 --> 00:31:25,420
بنابراین به عنوان یک تمرین
 

1473
00:31:25,420 --> 00:31:27,730
بنابراین به عنوان یک تمرین
ارتباطی گفت:

1474
00:31:27,730 --> 00:31:27,740
ارتباطی گفت:
 

1475
00:31:27,740 --> 00:31:29,530
ارتباطی گفت:
منطقی بودن و منطقی بودن در مورد این

1476
00:31:29,530 --> 00:31:29,540
منطقی بودن و منطقی بودن در مورد این
 

1477
00:31:29,540 --> 00:31:31,600
منطقی بودن و منطقی بودن در مورد این
چیزها مهم است، اجازه دهید بپرسم اگر قرار بود

1478
00:31:31,600 --> 00:31:31,610
چیزها مهم است، اجازه دهید بپرسم اگر قرار بود
 

1479
00:31:31,610 --> 00:31:34,150
چیزها مهم است، اجازه دهید بپرسم اگر قرار بود
من را به عنوان محقق هوش مصنوعی در مورد نحوه صحبت کردن

1480
00:31:34,150 --> 00:31:34,160
من را به عنوان محقق هوش مصنوعی در مورد نحوه صحبت کردن
 

1481
00:31:34,160 --> 00:31:36,640
من را به عنوان محقق هوش مصنوعی در مورد نحوه صحبت کردن
با جو و عموم مردم در مورد هوش مصنوعی

1482
00:31:36,640 --> 00:31:36,650
با جو و عموم مردم در مورد هوش مصنوعی
 

1483
00:31:36,650 --> 00:31:39,850
با جو و عموم مردم در مورد هوش مصنوعی
راهنمایی کنید.

1484
00:31:39,850 --> 00:31:39,860
راهنمایی کنید.
 

1485
00:31:39,860 --> 00:31:41,410
راهنمایی کنید.
بخش‌هایی

1486
00:31:41,410 --> 00:31:41,420
بخش‌هایی
 

1487
00:31:41,420 --> 00:31:42,760
بخش‌هایی
که من یک کتاب روشنگری نوشتم

1488
00:31:42,760 --> 00:31:42,770
که من یک کتاب روشنگری نوشتم
 

1489
00:31:42,770 --> 00:31:45,160
که من یک کتاب روشنگری نوشتم
در مورد هوش مصنوعی می‌دانم، اما دلیل طولانی‌تری است که

1490
00:31:45,160 --> 00:31:45,170
در مورد هوش مصنوعی می‌دانم، اما دلیل طولانی‌تری است که
 

1491
00:31:45,170 --> 00:31:47,440
در مورد هوش مصنوعی می‌دانم، اما دلیل طولانی‌تری است که
فکر می‌کنم تاکید کنم و فکر می‌کنم شما

1492
00:31:47,440 --> 00:31:47,450
فکر می‌کنم تاکید کنم و فکر می‌کنم شما
 

1493
00:31:47,450 --> 00:31:49,510
فکر می‌کنم تاکید کنم و فکر می‌کنم شما
به‌عنوان یک مهندس موقعیت خوبی دارید تا به

1494
00:31:49,510 --> 00:31:49,520
به‌عنوان یک مهندس موقعیت خوبی دارید تا به
 

1495
00:31:49,520 --> 00:31:51,070
به‌عنوان یک مهندس موقعیت خوبی دارید تا به
مردم درباره فرهنگ

1496
00:31:51,070 --> 00:31:51,080
مردم درباره فرهنگ
 

1497
00:31:51,080 --> 00:31:53,830
مردم درباره فرهنگ
مهندسی یادآوری کنید که واقعاً ایمنی

1498
00:31:53,830 --> 00:31:53,840
مهندسی یادآوری کنید که واقعاً ایمنی
 

1499
00:31:53,840 --> 00:31:56,770
مهندسی یادآوری کنید که واقعاً ایمنی
محور است که بحث دیگری در

1500
00:31:56,770 --> 00:31:56,780
محور است که بحث دیگری در
 

1501
00:31:56,780 --> 00:32:00,790
محور است که بحث دیگری در
روشنگری اکنون من نرخ

1502
00:32:00,790 --> 00:32:00,800
روشنگری اکنون من نرخ
 

1503
00:32:00,800 --> 00:32:02,440
روشنگری اکنون من نرخ
مرگ تصادفی به دلایل مختلف را ترسیم می کنم سقوط

1504
00:32:02,440 --> 00:32:02,450
مرگ تصادفی به دلایل مختلف را ترسیم می کنم سقوط
 

1505
00:32:02,450 --> 00:32:06,580
مرگ تصادفی به دلایل مختلف را ترسیم می کنم سقوط
هواپیما تصادفات اتومبیل

1506
00:32:06,580 --> 00:32:06,590
هواپیما تصادفات اتومبیل
 

1507
00:32:06,590 --> 00:32:08,590
هواپیما تصادفات اتومبیل
تصادفات شغلی حتی مرگ بر اثر صاعقه

1508
00:32:08,590 --> 00:32:08,600
تصادفات شغلی حتی مرگ بر اثر صاعقه
 

1509
00:32:08,600 --> 00:32:12,910
تصادفات شغلی حتی مرگ بر اثر صاعقه
و همه آنها سقوط می کنند زیرا

1510
00:32:12,910 --> 00:32:12,920
و همه آنها سقوط می کنند زیرا
 

1511
00:32:12,920 --> 00:32:14,830
و همه آنها سقوط می کنند زیرا
فرهنگ مهندسی این است که چگونه می توان

1512
00:32:14,830 --> 00:32:14,840
فرهنگ مهندسی این است که چگونه می توان
 

1513
00:32:14,840 --> 00:32:17,200
فرهنگ مهندسی این است که چگونه می توان
خطرات مرگبار را از بین برد مرگ

1514
00:32:17,200 --> 00:32:17,210
خطرات مرگبار را از بین برد مرگ
 

1515
00:32:17,210 --> 00:32:20,380
خطرات مرگبار را از بین برد مرگ
در اثر آتش مرگ با غرق شدن مرگ در اثر

1516
00:32:20,380 --> 00:32:20,390
در اثر آتش مرگ با غرق شدن مرگ در اثر
 

1517
00:32:20,390 --> 00:32:22,990
در اثر آتش مرگ با غرق شدن مرگ در اثر
خفگی  همه آنها به شدت به

1518
00:32:22,990 --> 00:32:23,000
خفگی  همه آنها به شدت به
 

1519
00:32:23,000 --> 00:32:24,310
خفگی  همه آنها به شدت به
دلیل پیشرفت در

1520
00:32:24,310 --> 00:32:24,320
دلیل پیشرفت در
 

1521
00:32:24,320 --> 00:32:26,290
دلیل پیشرفت در
مهندسی کاهش یافتند، سپس باید بگویم که من

1522
00:32:26,290 --> 00:32:26,300
مهندسی کاهش یافتند، سپس باید بگویم که من
 

1523
00:32:26,300 --> 00:32:28,810
مهندسی کاهش یافتند، سپس باید بگویم که من
تا زمانی که آن نمودارها را ندیدم قدردانی نکردم و دلیل آن

1524
00:32:28,810 --> 00:32:28,820
تا زمانی که آن نمودارها را ندیدم قدردانی نکردم و دلیل آن
 

1525
00:32:28,820 --> 00:32:32,140
تا زمانی که آن نمودارها را ندیدم قدردانی نکردم و دلیل آن
دقیقاً به این دلیل است که دقیقاً افرادی مانند شما

1526
00:32:32,140 --> 00:32:32,150
دقیقاً به این دلیل است که دقیقاً افرادی مانند شما
 

1527
00:32:32,150 --> 00:32:34,450
دقیقاً به این دلیل است که دقیقاً افرادی مانند شما
که شب ها روی چیزی مهر می زنند وای خدای من

1528
00:32:34,450 --> 00:32:34,460
که شب ها روی چیزی مهر می زنند وای خدای من
 

1529
00:32:34,460 --> 00:32:36,490
که شب ها روی چیزی مهر می زنند وای خدای من
منظور من همان میم است.  من در حال

1530
00:32:36,490 --> 00:32:36,500
منظور من همان میم است.  من در حال
 

1531
00:32:36,500 --> 00:32:39,300
منظور من همان میم است.  من در حال
اختراع هستم که احتمالاً به مردم صدمه می زند و

1532
00:32:39,300 --> 00:32:39,310
اختراع هستم که احتمالاً به مردم صدمه می زند و
 

1533
00:32:39,310 --> 00:32:41,980
اختراع هستم که احتمالاً به مردم صدمه می زند و
برای جلوگیری از این اتفاق، نبوغ را به کار می گیرم،

1534
00:32:41,980 --> 00:32:41,990
برای جلوگیری از این اتفاق، نبوغ را به کار می گیرم،
 

1535
00:32:41,990 --> 00:32:43,690
برای جلوگیری از این اتفاق، نبوغ را به کار می گیرم،
من یک مهندس نیستم،

1536
00:32:43,690 --> 00:32:43,700
من یک مهندس نیستم،
 

1537
00:32:43,700 --> 00:32:46,180
من یک مهندس نیستم،
اگرچه 22 سال در MIT گذراندم، بنابراین

1538
00:32:46,180 --> 00:32:46,190
اگرچه 22 سال در MIT گذراندم، بنابراین
 

1539
00:32:46,190 --> 00:32:47,500
اگرچه 22 سال در MIT گذراندم، بنابراین
چیزی در مورد فرهنگ

1540
00:32:47,500 --> 00:32:47,510
چیزی در مورد فرهنگ
 

1541
00:32:47,510 --> 00:32:49,090
چیزی در مورد فرهنگ
مهندسی می دانم که درک من این است که

1542
00:32:49,090 --> 00:32:49,100
مهندسی می دانم که درک من این است که
 

1543
00:32:49,100 --> 00:32:50,710
مهندسی می دانم که درک من این است که
این روشی است که  شما فکر می کنید

1544
00:32:50,710 --> 00:32:50,720
این روشی است که  شما فکر می کنید
 

1545
00:32:50,720 --> 00:32:51,890
این روشی است که  شما فکر می کنید
اگر یک مهندس هستید

1546
00:32:51,890 --> 00:32:51,900
اگر یک مهندس هستید
 

1547
00:32:51,900 --> 00:32:54,919
اگر یک مهندس هستید
و ضروری است که این فرهنگ به طور

1548
00:32:54,919 --> 00:32:54,929
و ضروری است که این فرهنگ به طور
 

1549
00:32:54,929 --> 00:32:57,860
و ضروری است که این فرهنگ به طور
ناگهانی در هنگام راه اندازی

1550
00:32:57,860 --> 00:32:57,870
ناگهانی در هنگام راه اندازی
 

1551
00:32:57,870 --> 00:32:59,750
ناگهانی در هنگام راه اندازی
اطلاعات رسمی خاموش نشود، بنابراین منظور من این است

1552
00:32:59,750 --> 00:32:59,760
اطلاعات رسمی خاموش نشود، بنابراین منظور من این است
 

1553
00:32:59,760 --> 00:33:01,430
اطلاعات رسمی خاموش نشود، بنابراین منظور من این است
که این می تواند یک مشکل باشد، اما آیا

1554
00:33:01,430 --> 00:33:01,440
که این می تواند یک مشکل باشد، اما آیا
 

1555
00:33:01,440 --> 00:33:02,570
که این می تواند یک مشکل باشد، اما آیا
دلیلی وجود دارد که فکر کنم خاموش می شود

1556
00:33:02,570 --> 00:33:02,580
دلیلی وجود دارد که فکر کنم خاموش می شود
 

1557
00:33:02,580 --> 00:33:04,519
دلیلی وجود دارد که فکر کنم خاموش می شود
من فکر نمی کنم  بنابراین و یکی وجود ندارد که

1558
00:33:04,519 --> 00:33:04,529
من فکر نمی کنم  بنابراین و یکی وجود ندارد که
 

1559
00:33:04,529 --> 00:33:06,710
من فکر نمی کنم  بنابراین و یکی وجود ندارد که
مهندسان کافی از این

1560
00:33:06,710 --> 00:33:06,720
مهندسان کافی از این
 

1561
00:33:06,720 --> 00:33:10,490
مهندسان کافی از این
طریق صحبت کنند، برای این هیجان برای

1562
00:33:10,490 --> 00:33:10,500
طریق صحبت کنند، برای این هیجان برای
 

1563
00:33:10,500 --> 00:33:12,560
طریق صحبت کنند، برای این هیجان برای
دیدگاه مثبت از طبیعت انسان چیزی است که

1564
00:33:12,560 --> 00:33:12,570
دیدگاه مثبت از طبیعت انسان چیزی است که
 

1565
00:33:12,570 --> 00:33:13,850
دیدگاه مثبت از طبیعت انسان چیزی است که
شما می خواهید ایجاد کنید

1566
00:33:13,850 --> 00:33:13,860
شما می خواهید ایجاد کنید
 

1567
00:33:13,860 --> 00:33:15,560
شما می خواهید ایجاد کنید
مثبت بودن است مانند هر چیزی که ما سعی می کنیم

1568
00:33:15,560 --> 00:33:15,570
مثبت بودن است مانند هر چیزی که ما سعی می کنیم
 

1569
00:33:15,570 --> 00:33:17,659
مثبت بودن است مانند هر چیزی که ما سعی می کنیم
اختراع کنیم تلاش برای انجام کارهای خوب برای

1570
00:33:17,659 --> 00:33:17,669
اختراع کنیم تلاش برای انجام کارهای خوب برای
 

1571
00:33:17,669 --> 00:33:19,490
اختراع کنیم تلاش برای انجام کارهای خوب برای
جهان است، اما اجازه دهید من  از شما در مورد

1572
00:33:19,490 --> 00:33:19,500
جهان است، اما اجازه دهید من  از شما در مورد
 

1573
00:33:19,500 --> 00:33:22,330
جهان است، اما اجازه دهید من  از شما در مورد
روانشناسی منفی گرایی بپرسم به نظر می رسد صرفاً به طور

1574
00:33:22,330 --> 00:33:22,340
روانشناسی منفی گرایی بپرسم به نظر می رسد صرفاً به طور
 

1575
00:33:22,340 --> 00:33:25,130
روانشناسی منفی گرایی بپرسم به نظر می رسد صرفاً به طور
عینی موضوع را در نظر نمی گیریم به

1576
00:33:25,130 --> 00:33:25,140
عینی موضوع را در نظر نمی گیریم به
 

1577
00:33:25,140 --> 00:33:26,690
عینی موضوع را در نظر نمی گیریم به
نظر می رسد منفی بودن در مورد

1578
00:33:26,690 --> 00:33:26,700
نظر می رسد منفی بودن در مورد
 

1579
00:33:26,700 --> 00:33:29,000
نظر می رسد منفی بودن در مورد
آینده باعث می شود که شما باهوش تر از من

1580
00:33:29,000 --> 00:33:29,010
آینده باعث می شود که شما باهوش تر از من
 

1581
00:33:29,010 --> 00:33:31,039
آینده باعث می شود که شما باهوش تر از من
در مورد آینده مثبت به نظر برسید صرف نظر

1582
00:33:31,039 --> 00:33:31,049
در مورد آینده مثبت به نظر برسید صرف نظر
 

1583
00:33:31,049 --> 00:33:33,409
در مورد آینده مثبت به نظر برسید صرف نظر
از موضوع آیا من در مشاهده صحیح هستم

1584
00:33:33,409 --> 00:33:33,419
از موضوع آیا من در مشاهده صحیح هستم
 

1585
00:33:33,419 --> 00:33:36,019
از موضوع آیا من در مشاهده صحیح هستم
و اگر شما چنین هستید چرا چنین می کنید؟  فکر می کنم

1586
00:33:36,019 --> 00:33:36,029
و اگر شما چنین هستید چرا چنین می کنید؟  فکر می کنم
 

1587
00:33:36,029 --> 00:33:37,610
و اگر شما چنین هستید چرا چنین می کنید؟  فکر می کنم
بله، من فکر می کنم

1588
00:33:37,610 --> 00:33:37,620
بله، من فکر می کنم
 

1589
00:33:37,620 --> 00:33:41,120
بله، من فکر می کنم
آن پدیده ای وجود دارد که همانطور که تام لرر

1590
00:33:41,120 --> 00:33:41,130
آن پدیده ای وجود دارد که همانطور که تام لرر
 

1591
00:33:41,130 --> 00:33:42,889
آن پدیده ای وجود دارد که همانطور که تام لرر
طنزپرداز گفت همیشه

1592
00:33:42,889 --> 00:33:42,899
طنزپرداز گفت همیشه
 

1593
00:33:42,899 --> 00:33:44,560
طنزپرداز گفت همیشه
بدترین ها را پیش بینی می کند و از شما به عنوان یک پیامبر تجلیل می شود.

1594
00:33:44,560 --> 00:33:48,680
بدترین ها را پیش بینی می کند و از شما به عنوان یک پیامبر تجلیل می شود.
 

1595
00:33:48,680 --> 00:33:48,690

 

1596
00:33:48,690 --> 00:33:51,799

از جنبه

1597
00:33:51,799 --> 00:33:51,809
از جنبه
 

1598
00:33:51,809 --> 00:33:53,299
از جنبه
منفی آنها

1599
00:33:53,299 --> 00:33:53,309
منفی آنها
 

1600
00:33:53,309 --> 00:33:55,970
منفی آنها
بیشتر از اینکه از سود لذت ببریم از ضرر می ترسیم

1601
00:33:55,970 --> 00:33:55,980
بیشتر از اینکه از سود لذت ببریم از ضرر می ترسیم
 

1602
00:33:55,980 --> 00:34:01,960
بیشتر از اینکه از سود لذت ببریم از ضرر می ترسیم
و ممکن است همسر فضایی را برای

1603
00:34:01,960 --> 00:34:01,970

 

1604
00:34:01,970 --> 00:34:04,850

پیامبران باز کند تا مضرات و خطرات

1605
00:34:04,850 --> 00:34:04,860
پیامبران باز کند تا مضرات و خطرات
 

1606
00:34:04,860 --> 00:34:06,940
پیامبران باز کند تا مضرات و خطرات
و ضررهایی را که ممکن است نادیده گرفته باشیم را به ما یادآوری کنند،

1607
00:34:06,940 --> 00:34:06,950
و ضررهایی را که ممکن است نادیده گرفته باشیم را به ما یادآوری کنند،
 

1608
00:34:06,950 --> 00:34:10,399
و ضررهایی را که ممکن است نادیده گرفته باشیم را به ما یادآوری کنند،
بنابراین فکر می کنم این

1609
00:34:10,399 --> 00:34:10,409
بنابراین فکر می کنم این
 

1610
00:34:10,409 --> 00:34:14,329
بنابراین فکر می کنم این
عدم تقارن وجود دارد.  برخی از

1611
00:34:14,329 --> 00:34:14,339
عدم تقارن وجود دارد.  برخی از
 

1612
00:34:14,339 --> 00:34:17,300
عدم تقارن وجود دارد.  برخی از
کتاب‌های مورد علاقه‌ام را در همه جا نوشته‌ام، بنابراین

1613
00:34:17,300 --> 00:34:17,310
کتاب‌های مورد علاقه‌ام را در همه جا نوشته‌ام، بنابراین
 

1614
00:34:17,310 --> 00:34:20,060
کتاب‌های مورد علاقه‌ام را در همه جا نوشته‌ام، بنابراین
از روشنگری در حال حاضر گرفته تا

1615
00:34:20,060 --> 00:34:20,070
از روشنگری در حال حاضر گرفته تا
 

1616
00:34:20,070 --> 00:34:21,230
از روشنگری در حال حاضر گرفته تا
فرشته‌های بهتر طبیعت ما

1617
00:34:21,230 --> 00:34:21,240
فرشته‌های بهتر طبیعت ما
 

1618
00:34:21,240 --> 00:34:24,200
فرشته‌های بهتر طبیعت ما
لوح خالی چگونه ذهن کار می‌کند، کتابی

1619
00:34:24,200 --> 00:34:24,210
لوح خالی چگونه ذهن کار می‌کند، کتابی
 

1620
00:34:24,210 --> 00:34:27,190
لوح خالی چگونه ذهن کار می‌کند، کتابی
درباره غریزه زبان بیل گیت از

1621
00:34:27,190 --> 00:34:27,200
درباره غریزه زبان بیل گیت از
 

1622
00:34:27,200 --> 00:34:31,879
درباره غریزه زبان بیل گیت از
طرفداران بزرگ مجموعه‌ای از

1623
00:34:31,879 --> 00:34:31,889
طرفداران بزرگ مجموعه‌ای از
 

1624
00:34:31,889 --> 00:34:34,760
طرفداران بزرگ مجموعه‌ای از
جدیدترین کتاب شما که کتاب من است.  کتاب مورد علاقه جدید

1625
00:34:34,760 --> 00:34:34,770
جدیدترین کتاب شما که کتاب من است.  کتاب مورد علاقه جدید
 

1626
00:34:34,770 --> 00:34:38,720
جدیدترین کتاب شما که کتاب من است.  کتاب مورد علاقه جدید
تمام دوران، بنابراین برای شما به عنوان نویسنده

1627
00:34:38,720 --> 00:34:38,730
تمام دوران، بنابراین برای شما به عنوان نویسنده
 

1628
00:34:38,730 --> 00:34:41,180
تمام دوران، بنابراین برای شما به عنوان نویسنده
چه کتابی در اوایل زندگی شما بود

1629
00:34:41,180 --> 00:34:41,190
چه کتابی در اوایل زندگی شما بود
 

1630
00:34:41,190 --> 00:34:44,089
چه کتابی در اوایل زندگی شما بود
که تأثیر عمیقی بر نحوه

1631
00:34:44,089 --> 00:34:44,099
که تأثیر عمیقی بر نحوه
 

1632
00:34:44,099 --> 00:34:46,129
که تأثیر عمیقی بر نحوه
دید شما از جهان داشت، مطمئناً این

1633
00:34:46,129 --> 00:34:46,139
دید شما از جهان داشت، مطمئناً این
 

1634
00:34:46,139 --> 00:34:49,129
دید شما از جهان داشت، مطمئناً این
روشنگری کتاب اکنون تحت تأثیر دیوید

1635
00:34:49,129 --> 00:34:49,139
روشنگری کتاب اکنون تحت تأثیر دیوید
 

1636
00:34:49,139 --> 00:34:51,399
روشنگری کتاب اکنون تحت تأثیر دیوید
دویچ به عنوان آغاز بی نهایت است.

1637
00:34:51,399 --> 00:34:51,409
دویچ به عنوان آغاز بی نهایت است.
 

1638
00:34:51,409 --> 00:34:54,950
دویچ به عنوان آغاز بی نهایت است.
تأمل عمیق در دانش و

1639
00:34:54,950 --> 00:34:54,960
تأمل عمیق در دانش و
 

1640
00:34:54,960 --> 00:34:57,770
تأمل عمیق در دانش و
قدرت دانش در بهبود

1641
00:34:57,770 --> 00:34:57,780
قدرت دانش در بهبود
 

1642
00:34:57,780 --> 00:35:00,890
قدرت دانش در بهبود
وضعیت انسان و با خرده‌هایی

1643
00:35:00,890 --> 00:35:00,900
وضعیت انسان و با خرده‌هایی
 

1644
00:35:00,900 --> 00:35:02,420
وضعیت انسان و با خرده‌هایی
از جمله اینکه مشکلات

1645
00:35:02,420 --> 00:35:02,430
از جمله اینکه مشکلات
 

1646
00:35:02,430 --> 00:35:04,220
از جمله اینکه مشکلات
اجتناب‌ناپذیر هستند اما با توجه به دانش مشکلات قابل حل هستند

1647
00:35:04,220 --> 00:35:05,200
اجتناب‌ناپذیر هستند اما با توجه به دانش مشکلات قابل حل هستند
 

1648
00:35:05,200 --> 00:35:05,210

 

1649
00:35:05,210 --> 00:35:07,450

و راه‌حل‌ها مشکلات جدیدی ایجاد می‌کنند که باید به

1650
00:35:07,450 --> 00:35:09,160
و راه‌حل‌ها مشکلات جدیدی ایجاد می‌کنند که باید به
 

1651
00:35:09,160 --> 00:35:09,170

 

1652
00:35:09,170 --> 00:35:11,320

نوبه خود حل شوند.  نوعی حکمت در مورد

1653
00:35:11,320 --> 00:35:11,330
نوبه خود حل شوند.  نوعی حکمت در مورد
 

1654
00:35:11,330 --> 00:35:13,480
نوبه خود حل شوند.  نوعی حکمت در مورد
شرایط انسانی که بر

1655
00:35:13,480 --> 00:35:13,490
شرایط انسانی که بر
 

1656
00:35:13,490 --> 00:35:15,550
شرایط انسانی که بر
نگارش این کتاب تأثیر گذاشته است، کتاب‌هایی

1657
00:35:15,550 --> 00:35:15,560
نگارش این کتاب تأثیر گذاشته است، کتاب‌هایی
 

1658
00:35:15,560 --> 00:35:17,349
نگارش این کتاب تأثیر گذاشته است، کتاب‌هایی
بسیار عالی اما مبهم هستند که برخی از آنها را

1659
00:35:17,349 --> 00:35:17,359
بسیار عالی اما مبهم هستند که برخی از آنها را
 

1660
00:35:17,359 --> 00:35:20,589
بسیار عالی اما مبهم هستند که برخی از آنها را
در صفحه وب‌سایت خود دارم،

1661
00:35:20,589 --> 00:35:20,599
در صفحه وب‌سایت خود دارم،
 

1662
00:35:20,599 --> 00:35:22,589
در صفحه وب‌سایت خود دارم،
کتابی خواندم به نام تاریخ زور که

1663
00:35:22,589 --> 00:35:22,599
کتابی خواندم به نام تاریخ زور که
 

1664
00:35:22,599 --> 00:35:24,760
کتابی خواندم به نام تاریخ زور که
توسط یک دانشمند علوم سیاسی به نام خود منتشر شده است.

1665
00:35:24,760 --> 00:35:24,770
توسط یک دانشمند علوم سیاسی به نام خود منتشر شده است.
 

1666
00:35:24,770 --> 00:35:27,040
توسط یک دانشمند علوم سیاسی به نام خود منتشر شده است.
جیمز پین در مورد

1667
00:35:27,040 --> 00:35:27,050
جیمز پین در مورد
 

1668
00:35:27,050 --> 00:35:28,450
جیمز پین در مورد
افول تاریخی خشونت و این یکی از

1669
00:35:28,450 --> 00:35:28,460
افول تاریخی خشونت و این یکی از
 

1670
00:35:28,460 --> 00:35:30,339
افول تاریخی خشونت و این یکی از
الهام‌بخش‌های فرشتگان بهتر

1671
00:35:30,339 --> 00:35:30,349
الهام‌بخش‌های فرشتگان بهتر
 

1672
00:35:30,349 --> 00:35:31,839
الهام‌بخش‌های فرشتگان بهتر
طبیعت ما بود.

1673
00:35:31,839 --> 00:35:35,710
طبیعت ما بود.
 

1674
00:35:35,710 --> 00:35:38,950

 

1675
00:35:38,950 --> 00:35:40,900

 

1676
00:35:40,900 --> 00:35:40,910

 

1677
00:35:40,910 --> 00:35:43,060

من آن کتاب

1678
00:35:43,060 --> 00:35:43,070
من آن کتاب
 

1679
00:35:43,070 --> 00:35:45,940
من آن کتاب
جورج گاما فیزیکدان را خواندم که

1680
00:35:45,940 --> 00:35:45,950
جورج گاما فیزیکدان را خواندم که
 

1681
00:35:45,950 --> 00:35:48,570
جورج گاما فیزیکدان را خواندم که
در توضیحات طنز آمیز

1682
00:35:48,570 --> 00:35:48,580
در توضیحات طنز آمیز
 

1683
00:35:48,580 --> 00:35:53,700
در توضیحات طنز آمیز
نظریه نسبیت اعداد فضاهای

1684
00:35:53,700 --> 00:35:53,710

 

1685
00:35:53,710 --> 00:35:57,040

چند بعدی با ابعاد بسیار قابل دسترس است،

1686
00:35:57,040 --> 00:35:57,050
چند بعدی با ابعاد بسیار قابل دسترس است،
 

1687
00:35:57,050 --> 00:35:59,980
چند بعدی با ابعاد بسیار قابل دسترس است،
به گونه ای که فکر می کنم هنوز

1688
00:35:59,980 --> 00:35:59,990
به گونه ای که فکر می کنم هنوز
 

1689
00:35:59,990 --> 00:36:01,810
به گونه ای که فکر می کنم هنوز
پس از گذشت هفتاد سال از انتشار آن لذت بخش است.

1690
00:36:01,810 --> 00:36:04,420
پس از گذشت هفتاد سال از انتشار آن لذت بخش است.
 

1691
00:36:04,420 --> 00:36:04,430

 

1692
00:36:04,430 --> 00:36:06,880

این‌ها کتاب‌هایی بودند که

1693
00:36:06,880 --> 00:36:06,890
این‌ها کتاب‌هایی بودند که
 

1694
00:36:06,890 --> 00:36:09,280
این‌ها کتاب‌هایی بودند که
هر ماه وارد می‌شدند که مادرم

1695
00:36:09,280 --> 00:36:09,290
هر ماه وارد می‌شدند که مادرم
 

1696
00:36:09,290 --> 00:36:11,160
هر ماه وارد می‌شدند که مادرم
مشترک هریک می‌شد در

1697
00:36:11,160 --> 00:36:11,170
مشترک هریک می‌شد در
 

1698
00:36:11,170 --> 00:36:14,829
مشترک هریک می‌شد در
موضوعی متفاوت، یکی در مورد برق بود، چه

1699
00:36:14,829 --> 00:36:14,839
موضوعی متفاوت، یکی در مورد برق بود، چه
 

1700
00:36:14,839 --> 00:36:16,810
موضوعی متفاوت، یکی در مورد برق بود، چه
در جنگل‌ها می‌خواستم یاد بگیرم

1701
00:36:16,810 --> 00:36:16,820
در جنگل‌ها می‌خواستم یاد بگیرم
 

1702
00:36:16,820 --> 00:36:18,040
در جنگل‌ها می‌خواستم یاد بگیرم
ممکن است تکامل پیدا کند و بعد یکی در

1703
00:36:18,040 --> 00:36:18,050
ممکن است تکامل پیدا کند و بعد یکی در
 

1704
00:36:18,050 --> 00:36:21,579
ممکن است تکامل پیدا کند و بعد یکی در
ذهن بود و من فقط کنجکاو بودم که

1705
00:36:21,579 --> 00:36:21,589
ذهن بود و من فقط کنجکاو بودم که
 

1706
00:36:21,589 --> 00:36:23,980
ذهن بود و من فقط کنجکاو بودم که
ممکن است وجود داشته باشد.  یک علم ذهن و آن

1707
00:36:23,980 --> 00:36:23,990
ممکن است وجود داشته باشد.  یک علم ذهن و آن
 

1708
00:36:23,990 --> 00:36:25,930
ممکن است وجود داشته باشد.  یک علم ذهن و آن
کتابی که من به عنوان اثری از آن یاد می کنم و

1709
00:36:25,930 --> 00:36:25,940
کتابی که من به عنوان اثری از آن یاد می کنم و
 

1710
00:36:25,940 --> 00:36:28,450
کتابی که من به عنوان اثری از آن یاد می کنم و
بعداً شما عاشق

1711
00:36:28,450 --> 00:36:28,460
بعداً شما عاشق
 

1712
00:36:28,460 --> 00:36:30,400
بعداً شما عاشق
این ایده مطالعه ذهن شدید، این یکی از

1713
00:36:30,400 --> 00:36:30,410
این ایده مطالعه ذهن شدید، این یکی از
 

1714
00:36:30,410 --> 00:36:32,109
این ایده مطالعه ذهن شدید، این یکی از
چیزهایی بود که شما را جذب کرد، یکی از

1715
00:36:32,109 --> 00:36:32,119
چیزهایی بود که شما را جذب کرد، یکی از
 

1716
00:36:32,119 --> 00:36:35,859
چیزهایی بود که شما را جذب کرد، یکی از
چیزهایی بود که می گفتم

1717
00:36:35,859 --> 00:36:35,869
چیزهایی بود که می گفتم
 

1718
00:36:35,869 --> 00:36:38,620
چیزهایی بود که می گفتم
دانشجوی کالج تاملات کتاب در مورد

1719
00:36:38,620 --> 00:36:38,630
دانشجوی کالج تاملات کتاب در مورد
 

1720
00:36:38,630 --> 00:36:41,050
دانشجوی کالج تاملات کتاب در مورد
زبان نوشته نوام چامسکی بیشتر

1721
00:36:41,050 --> 00:36:41,060
زبان نوشته نوام چامسکی بیشتر
 

1722
00:36:41,060 --> 00:36:44,290
زبان نوشته نوام چامسکی بیشتر
دوران حرفه‌ای خود را در MIT در MIT گذراند،

1723
00:36:44,290 --> 00:36:44,300
دوران حرفه‌ای خود را در MIT در MIT گذراند،
 

1724
00:36:44,300 --> 00:36:46,720
دوران حرفه‌ای خود را در MIT در MIT گذراند،
دو کتاب ساعت‌ساز نابینا و

1725
00:36:46,720 --> 00:36:46,730
دو کتاب ساعت‌ساز نابینا و
 

1726
00:36:46,730 --> 00:36:48,960
دو کتاب ساعت‌ساز نابینا و
ژن خودخواه یا لی عظیم

1727
00:36:48,960 --> 00:36:48,970
ژن خودخواه یا لی عظیم
 

1728
00:36:48,970 --> 00:36:52,180
ژن خودخواه یا لی عظیم
تا حدی به دلیل محتوا و

1729
00:36:52,180 --> 00:36:52,190
تا حدی به دلیل محتوا و
 

1730
00:36:52,190 --> 00:36:55,570
تا حدی به دلیل محتوا و
همچنین برای سبک نوشتن، توانایی

1731
00:36:55,570 --> 00:36:55,580
همچنین برای سبک نوشتن، توانایی
 

1732
00:36:55,580 --> 00:36:59,050
همچنین برای سبک نوشتن، توانایی
توضیح انتزاعی.  مفاهیم در نثر پر جنب و جوش

1733
00:36:59,050 --> 00:36:59,060
توضیح انتزاعی.  مفاهیم در نثر پر جنب و جوش
 

1734
00:36:59,060 --> 00:37:02,410
توضیح انتزاعی.  مفاهیم در نثر پر جنب و جوش
استیون جی گولد اولین مجموعه

1735
00:37:02,410 --> 00:37:02,420
استیون جی گولد اولین مجموعه
 

1736
00:37:02,420 --> 00:37:05,980
استیون جی گولد اولین مجموعه
از زمان داروین نیز نمونه عالی

1737
00:37:05,980 --> 00:37:05,990
از زمان داروین نیز نمونه عالی
 

1738
00:37:05,990 --> 00:37:09,060
از زمان داروین نیز نمونه عالی
از نوشتن سرزنده روانشناس جورج میلر است

1739
00:37:09,060 --> 00:37:09,070
از نوشتن سرزنده روانشناس جورج میلر است
 

1740
00:37:09,070 --> 00:37:11,349
از نوشتن سرزنده روانشناس جورج میلر است
که اکثر روانشناسان

1741
00:37:11,349 --> 00:37:11,359
که اکثر روانشناسان
 

1742
00:37:11,359 --> 00:37:13,599
که اکثر روانشناسان
با آن آشنا هستند این ایده را ارائه کرد که

1743
00:37:13,599 --> 00:37:13,609
با آن آشنا هستند این ایده را ارائه کرد که
 

1744
00:37:13,609 --> 00:37:16,630
با آن آشنا هستند این ایده را ارائه کرد که
حافظه انسان دارای ظرفیت هفت

1745
00:37:16,630 --> 00:37:16,640
حافظه انسان دارای ظرفیت هفت
 

1746
00:37:16,640 --> 00:37:18,460
حافظه انسان دارای ظرفیت هفت
به اضافه یا منهای دو تکه است و سپس

1747
00:37:18,460 --> 00:37:18,470
به اضافه یا منهای دو تکه است و سپس
 

1748
00:37:18,470 --> 00:37:20,260
به اضافه یا منهای دو تکه است و سپس
بزرگترین ادعای سوفیا  به شهرت رسید اما او

1749
00:37:20,260 --> 00:37:20,270
بزرگترین ادعای سوفیا  به شهرت رسید اما او
 

1750
00:37:20,270 --> 00:37:22,180
بزرگترین ادعای سوفیا  به شهرت رسید اما او
چند کتاب در مورد زبان و

1751
00:37:22,180 --> 00:37:22,190
چند کتاب در مورد زبان و
 

1752
00:37:22,190 --> 00:37:23,500
چند کتاب در مورد زبان و
ارتباطات نوشت که من خوانده ام این یک دوره

1753
00:37:23,500 --> 00:37:23,510
ارتباطات نوشت که من خوانده ام این یک دوره
 

1754
00:37:23,510 --> 00:37:25,330
ارتباطات نوشت که من خوانده ام این یک دوره
لیسانس است که باز هم به زیبایی نوشته شده است

1755
00:37:25,330 --> 00:37:25,340
لیسانس است که باز هم به زیبایی نوشته شده است
 

1756
00:37:25,340 --> 00:37:30,160
لیسانس است که باز هم به زیبایی نوشته شده است
و از نظر فکری عمیق فوق العاده است.

1757
00:37:30,160 --> 00:37:31,450
و از نظر فکری عمیق فوق العاده است.
 

1758
00:37:31,450 --> 00:37:40,520

 

1759
00:37:40,520 --> 00:37:40,530

 

1760
00:37:40,530 --> 00:37:42,590



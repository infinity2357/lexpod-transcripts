1
00:00:00,000 --> 00:00:02,240

the following is a conversation with Ian

2
00:00:02,240 --> 00:00:02,250
the following is a conversation with Ian
 

3
00:00:02,250 --> 00:00:04,730
the following is a conversation with Ian
good fellow he's the author of the

4
00:00:04,730 --> 00:00:04,740
good fellow he's the author of the
 

5
00:00:04,740 --> 00:00:06,710
good fellow he's the author of the
popular textbook on deep learning simply

6
00:00:06,710 --> 00:00:06,720
popular textbook on deep learning simply
 

7
00:00:06,720 --> 00:00:09,470
popular textbook on deep learning simply
titled deep learning he coined the term

8
00:00:09,470 --> 00:00:09,480
titled deep learning he coined the term
 

9
00:00:09,480 --> 00:00:11,720
titled deep learning he coined the term
of generative adversarial networks

10
00:00:11,720 --> 00:00:11,730
of generative adversarial networks
 

11
00:00:11,730 --> 00:00:15,560
of generative adversarial networks
otherwise known as Ganz and with his

12
00:00:15,560 --> 00:00:15,570
otherwise known as Ganz and with his
 

13
00:00:15,570 --> 00:00:18,859
otherwise known as Ganz and with his
2014 paper is responsible for launching

14
00:00:18,859 --> 00:00:18,869
2014 paper is responsible for launching
 

15
00:00:18,869 --> 00:00:21,200
2014 paper is responsible for launching
the incredible growth of research and

16
00:00:21,200 --> 00:00:21,210
the incredible growth of research and
 

17
00:00:21,210 --> 00:00:23,390
the incredible growth of research and
innovation in this subfield of deep

18
00:00:23,390 --> 00:00:23,400
innovation in this subfield of deep
 

19
00:00:23,400 --> 00:00:26,390
innovation in this subfield of deep
learning he got his BS and MS at

20
00:00:26,390 --> 00:00:26,400
learning he got his BS and MS at
 

21
00:00:26,400 --> 00:00:29,210
learning he got his BS and MS at
Stanford his PhD at University of

22
00:00:29,210 --> 00:00:29,220
Stanford his PhD at University of
 

23
00:00:29,220 --> 00:00:31,910
Stanford his PhD at University of
Montreal with yoshua bengio and Erin

24
00:00:31,910 --> 00:00:31,920
Montreal with yoshua bengio and Erin
 

25
00:00:31,920 --> 00:00:34,580
Montreal with yoshua bengio and Erin
Kerrville he held several research

26
00:00:34,580 --> 00:00:34,590
Kerrville he held several research
 

27
00:00:34,590 --> 00:00:36,950
Kerrville he held several research
positions including an open AI Google

28
00:00:36,950 --> 00:00:36,960
positions including an open AI Google
 

29
00:00:36,960 --> 00:00:39,770
positions including an open AI Google
brain and now at Apple as the director

30
00:00:39,770 --> 00:00:39,780
brain and now at Apple as the director
 

31
00:00:39,780 --> 00:00:42,530
brain and now at Apple as the director
of machine learning this recording

32
00:00:42,530 --> 00:00:42,540
of machine learning this recording
 

33
00:00:42,540 --> 00:00:44,510
of machine learning this recording
happened while Ian was still a Google

34
00:00:44,510 --> 00:00:44,520
happened while Ian was still a Google
 

35
00:00:44,520 --> 00:00:46,850
happened while Ian was still a Google
brain but we don't talk about anything

36
00:00:46,850 --> 00:00:46,860
brain but we don't talk about anything
 

37
00:00:46,860 --> 00:00:49,279
brain but we don't talk about anything
specific to Google or any other

38
00:00:49,279 --> 00:00:49,289
specific to Google or any other
 

39
00:00:49,289 --> 00:00:52,250
specific to Google or any other
organization this conversation is part

40
00:00:52,250 --> 00:00:52,260
organization this conversation is part
 

41
00:00:52,260 --> 00:00:54,080
organization this conversation is part
of the artificial intelligence podcast

42
00:00:54,080 --> 00:00:54,090
of the artificial intelligence podcast
 

43
00:00:54,090 --> 00:00:56,479
of the artificial intelligence podcast
if you enjoy it subscribe on YouTube

44
00:00:56,479 --> 00:00:56,489
if you enjoy it subscribe on YouTube
 

45
00:00:56,489 --> 00:00:58,760
if you enjoy it subscribe on YouTube
iTunes or simply connect with me on

46
00:00:58,760 --> 00:00:58,770
iTunes or simply connect with me on
 

47
00:00:58,770 --> 00:01:02,360
iTunes or simply connect with me on
Twitter at lex friedman spelled fri d

48
00:01:02,360 --> 00:01:02,370
Twitter at lex friedman spelled fri d
 

49
00:01:02,370 --> 00:01:05,750
Twitter at lex friedman spelled fri d
and now here's my conversation with Ian

50
00:01:05,750 --> 00:01:05,760
and now here's my conversation with Ian
 

51
00:01:05,760 --> 00:01:10,250
and now here's my conversation with Ian
good fellow you open your popular deep

52
00:01:10,250 --> 00:01:10,260
good fellow you open your popular deep
 

53
00:01:10,260 --> 00:01:13,010
good fellow you open your popular deep
learning book with a Russian doll type

54
00:01:13,010 --> 00:01:13,020
learning book with a Russian doll type
 

55
00:01:13,020 --> 00:01:14,719
learning book with a Russian doll type
diagram that shows deep learning is a

56
00:01:14,719 --> 00:01:14,729
diagram that shows deep learning is a
 

57
00:01:14,729 --> 00:01:17,270
diagram that shows deep learning is a
subset of representation learning which

58
00:01:17,270 --> 00:01:17,280
subset of representation learning which
 

59
00:01:17,280 --> 00:01:19,700
subset of representation learning which
in turn is a subset of machine learning

60
00:01:19,700 --> 00:01:19,710
in turn is a subset of machine learning
 

61
00:01:19,710 --> 00:01:23,480
in turn is a subset of machine learning
and finally a subset of AI so this kind

62
00:01:23,480 --> 00:01:23,490
and finally a subset of AI so this kind
 

63
00:01:23,490 --> 00:01:25,429
and finally a subset of AI so this kind
of implies that there may be limits to

64
00:01:25,429 --> 00:01:25,439
of implies that there may be limits to
 

65
00:01:25,439 --> 00:01:27,830
of implies that there may be limits to
deep learning in the context of AI so

66
00:01:27,830 --> 00:01:27,840
deep learning in the context of AI so
 

67
00:01:27,840 --> 00:01:30,080
deep learning in the context of AI so
what do you think is the current limits

68
00:01:30,080 --> 00:01:30,090
what do you think is the current limits
 

69
00:01:30,090 --> 00:01:32,780
what do you think is the current limits
of deep learning and are those limits

70
00:01:32,780 --> 00:01:32,790
of deep learning and are those limits
 

71
00:01:32,790 --> 00:01:35,090
of deep learning and are those limits
something that we can overcome with time

72
00:01:35,090 --> 00:01:35,100
something that we can overcome with time
 

73
00:01:35,100 --> 00:01:36,920
something that we can overcome with time
yeah I think one of the biggest

74
00:01:36,920 --> 00:01:36,930
yeah I think one of the biggest
 

75
00:01:36,930 --> 00:01:38,780
yeah I think one of the biggest
limitations of deep learning is that

76
00:01:38,780 --> 00:01:38,790
limitations of deep learning is that
 

77
00:01:38,790 --> 00:01:40,700
limitations of deep learning is that
right now it requires really a lot of

78
00:01:40,700 --> 00:01:40,710
right now it requires really a lot of
 

79
00:01:40,710 --> 00:01:44,120
right now it requires really a lot of
data especially labeled data there's

80
00:01:44,120 --> 00:01:44,130
data especially labeled data there's
 

81
00:01:44,130 --> 00:01:45,980
data especially labeled data there's
some unsupervised and semi-supervised

82
00:01:45,980 --> 00:01:45,990
some unsupervised and semi-supervised
 

83
00:01:45,990 --> 00:01:48,020
some unsupervised and semi-supervised
learning algorithms that can reduce the

84
00:01:48,020 --> 00:01:48,030
learning algorithms that can reduce the
 

85
00:01:48,030 --> 00:01:49,700
learning algorithms that can reduce the
amount of labeled data you need but they

86
00:01:49,700 --> 00:01:49,710
amount of labeled data you need but they
 

87
00:01:49,710 --> 00:01:51,789
amount of labeled data you need but they
still require a lot of unlabeled data

88
00:01:51,789 --> 00:01:51,799
still require a lot of unlabeled data
 

89
00:01:51,799 --> 00:01:53,569
still require a lot of unlabeled data
reinforcement learning algorithms they

90
00:01:53,569 --> 00:01:53,579
reinforcement learning algorithms they
 

91
00:01:53,579 --> 00:01:54,920
reinforcement learning algorithms they
don't need labels but they need really a

92
00:01:54,920 --> 00:01:54,930
don't need labels but they need really a
 

93
00:01:54,930 --> 00:01:58,039
don't need labels but they need really a
lot of experiences as human beings we

94
00:01:58,039 --> 00:01:58,049
lot of experiences as human beings we
 

95
00:01:58,049 --> 00:02:00,170
lot of experiences as human beings we
don't learn to play pong by failing at

96
00:02:00,170 --> 00:02:00,180
don't learn to play pong by failing at
 

97
00:02:00,180 --> 00:02:03,560
don't learn to play pong by failing at
pong two million times so just getting

98
00:02:03,560 --> 00:02:03,570
pong two million times so just getting
 

99
00:02:03,570 --> 00:02:06,350
pong two million times so just getting
the generalization ability better is one

100
00:02:06,350 --> 00:02:06,360
the generalization ability better is one
 

101
00:02:06,360 --> 00:02:08,089
the generalization ability better is one
of the most important bottlenecks and

102
00:02:08,089 --> 00:02:08,099
of the most important bottlenecks and
 

103
00:02:08,099 --> 00:02:09,710
of the most important bottlenecks and
the capability of the technology today

104
00:02:09,710 --> 00:02:09,720
the capability of the technology today
 

105
00:02:09,720 --> 00:02:12,020
the capability of the technology today
and then I guess I'd also say deep

106
00:02:12,020 --> 00:02:12,030
and then I guess I'd also say deep
 

107
00:02:12,030 --> 00:02:13,670
and then I guess I'd also say deep
learning is like a

108
00:02:13,670 --> 00:02:13,680
learning is like a
 

109
00:02:13,680 --> 00:02:17,539
learning is like a
of a bigger system so far nobody is

110
00:02:17,539 --> 00:02:17,549
of a bigger system so far nobody is
 

111
00:02:17,549 --> 00:02:21,140
of a bigger system so far nobody is
really proposing to have only what you'd

112
00:02:21,140 --> 00:02:21,150
really proposing to have only what you'd
 

113
00:02:21,150 --> 00:02:23,509
really proposing to have only what you'd
call deep learning as the entire

114
00:02:23,509 --> 00:02:23,519
call deep learning as the entire
 

115
00:02:23,519 --> 00:02:26,720
call deep learning as the entire
ingredient of intelligence you use deep

116
00:02:26,720 --> 00:02:26,730
ingredient of intelligence you use deep
 

117
00:02:26,730 --> 00:02:29,720
ingredient of intelligence you use deep
learning as sub modules of other systems

118
00:02:29,720 --> 00:02:29,730
learning as sub modules of other systems
 

119
00:02:29,730 --> 00:02:32,270
learning as sub modules of other systems
like alphago has a deep learning model

120
00:02:32,270 --> 00:02:32,280
like alphago has a deep learning model
 

121
00:02:32,280 --> 00:02:35,449
like alphago has a deep learning model
that estimates the value function most

122
00:02:35,449 --> 00:02:35,459
that estimates the value function most
 

123
00:02:35,459 --> 00:02:36,740
that estimates the value function most
reinforcement learning algorithms have a

124
00:02:36,740 --> 00:02:36,750
reinforcement learning algorithms have a
 

125
00:02:36,750 --> 00:02:38,959
reinforcement learning algorithms have a
deep learning module that estimates

126
00:02:38,959 --> 00:02:38,969
deep learning module that estimates
 

127
00:02:38,969 --> 00:02:40,910
deep learning module that estimates
which action to take next but you might

128
00:02:40,910 --> 00:02:40,920
which action to take next but you might
 

129
00:02:40,920 --> 00:02:43,190
which action to take next but you might
have other components here basically as

130
00:02:43,190 --> 00:02:43,200
have other components here basically as
 

131
00:02:43,200 --> 00:02:46,460
have other components here basically as
building a function estimator do you

132
00:02:46,460 --> 00:02:46,470
building a function estimator do you
 

133
00:02:46,470 --> 00:02:49,280
building a function estimator do you
think it's possible you said nobody is

134
00:02:49,280 --> 00:02:49,290
think it's possible you said nobody is
 

135
00:02:49,290 --> 00:02:50,720
think it's possible you said nobody is
kind of in thinking about this so far

136
00:02:50,720 --> 00:02:50,730
kind of in thinking about this so far
 

137
00:02:50,730 --> 00:02:52,399
kind of in thinking about this so far
but do you think neural networks could

138
00:02:52,399 --> 00:02:52,409
but do you think neural networks could
 

139
00:02:52,409 --> 00:02:55,280
but do you think neural networks could
be made to reason in the way symbolic

140
00:02:55,280 --> 00:02:55,290
be made to reason in the way symbolic
 

141
00:02:55,290 --> 00:02:57,979
be made to reason in the way symbolic
systems did in the 80s and 90s to do

142
00:02:57,979 --> 00:02:57,989
systems did in the 80s and 90s to do
 

143
00:02:57,989 --> 00:03:00,229
systems did in the 80s and 90s to do
more create more like programs as

144
00:03:00,229 --> 00:03:00,239
more create more like programs as
 

145
00:03:00,239 --> 00:03:02,539
more create more like programs as
opposed to functions yeah I think we

146
00:03:02,539 --> 00:03:02,549
opposed to functions yeah I think we
 

147
00:03:02,549 --> 00:03:05,240
opposed to functions yeah I think we
already see that a little bit I already

148
00:03:05,240 --> 00:03:05,250
already see that a little bit I already
 

149
00:03:05,250 --> 00:03:07,309
already see that a little bit I already
kind of think of neural nets as a kind

150
00:03:07,309 --> 00:03:07,319
kind of think of neural nets as a kind
 

151
00:03:07,319 --> 00:03:10,099
kind of think of neural nets as a kind
of program I think of deep learning as

152
00:03:10,099 --> 00:03:10,109
of program I think of deep learning as
 

153
00:03:10,109 --> 00:03:13,250
of program I think of deep learning as
basically learning programs that have

154
00:03:13,250 --> 00:03:13,260
basically learning programs that have
 

155
00:03:13,260 --> 00:03:16,009
basically learning programs that have
more than one step so if you draw a

156
00:03:16,009 --> 00:03:16,019
more than one step so if you draw a
 

157
00:03:16,019 --> 00:03:18,559
more than one step so if you draw a
flowchart or or if you draw a tensor

158
00:03:18,559 --> 00:03:18,569
flowchart or or if you draw a tensor
 

159
00:03:18,569 --> 00:03:21,289
flowchart or or if you draw a tensor
flow graph describing your machine

160
00:03:21,289 --> 00:03:21,299
flow graph describing your machine
 

161
00:03:21,299 --> 00:03:22,939
flow graph describing your machine
learning model I think of the depth of

162
00:03:22,939 --> 00:03:22,949
learning model I think of the depth of
 

163
00:03:22,949 --> 00:03:24,559
learning model I think of the depth of
that graph is describing the number of

164
00:03:24,559 --> 00:03:24,569
that graph is describing the number of
 

165
00:03:24,569 --> 00:03:26,719
that graph is describing the number of
steps that run in sequence and then the

166
00:03:26,719 --> 00:03:26,729
steps that run in sequence and then the
 

167
00:03:26,729 --> 00:03:28,039
steps that run in sequence and then the
width of that graph is the number of

168
00:03:28,039 --> 00:03:28,049
width of that graph is the number of
 

169
00:03:28,049 --> 00:03:31,069
width of that graph is the number of
steps that run in parallel now it's been

170
00:03:31,069 --> 00:03:31,079
steps that run in parallel now it's been
 

171
00:03:31,079 --> 00:03:32,420
steps that run in parallel now it's been
long enough that we've had deep learning

172
00:03:32,420 --> 00:03:32,430
long enough that we've had deep learning
 

173
00:03:32,430 --> 00:03:33,890
long enough that we've had deep learning
working that it's a little bit silly to

174
00:03:33,890 --> 00:03:33,900
working that it's a little bit silly to
 

175
00:03:33,900 --> 00:03:35,599
working that it's a little bit silly to
even discuss shallow learning anymore

176
00:03:35,599 --> 00:03:35,609
even discuss shallow learning anymore
 

177
00:03:35,609 --> 00:03:38,140
even discuss shallow learning anymore
but back when I first got involved in AI

178
00:03:38,140 --> 00:03:38,150
but back when I first got involved in AI
 

179
00:03:38,150 --> 00:03:40,250
but back when I first got involved in AI
when we used machine learning we were

180
00:03:40,250 --> 00:03:40,260
when we used machine learning we were
 

181
00:03:40,260 --> 00:03:41,869
when we used machine learning we were
usually learning things like support

182
00:03:41,869 --> 00:03:41,879
usually learning things like support
 

183
00:03:41,879 --> 00:03:44,270
usually learning things like support
vector machines you could have a lot of

184
00:03:44,270 --> 00:03:44,280
vector machines you could have a lot of
 

185
00:03:44,280 --> 00:03:45,830
vector machines you could have a lot of
input features to the model and you

186
00:03:45,830 --> 00:03:45,840
input features to the model and you
 

187
00:03:45,840 --> 00:03:46,999
input features to the model and you
could multiply each feature by a

188
00:03:46,999 --> 00:03:47,009
could multiply each feature by a
 

189
00:03:47,009 --> 00:03:48,469
could multiply each feature by a
different weight but all those

190
00:03:48,469 --> 00:03:48,479
different weight but all those
 

191
00:03:48,479 --> 00:03:50,179
different weight but all those
multiplications were done in parallel to

192
00:03:50,179 --> 00:03:50,189
multiplications were done in parallel to
 

193
00:03:50,189 --> 00:03:52,009
multiplications were done in parallel to
each other there wasn't a lot done in

194
00:03:52,009 --> 00:03:52,019
each other there wasn't a lot done in
 

195
00:03:52,019 --> 00:03:53,990
each other there wasn't a lot done in
series I think what we got with deep

196
00:03:53,990 --> 00:03:54,000
series I think what we got with deep
 

197
00:03:54,000 --> 00:03:56,619
series I think what we got with deep
learning was really the ability to have

198
00:03:56,619 --> 00:03:56,629
learning was really the ability to have
 

199
00:03:56,629 --> 00:03:59,300
learning was really the ability to have
steps of a program that run in sequence

200
00:03:59,300 --> 00:03:59,310
steps of a program that run in sequence
 

201
00:03:59,310 --> 00:04:02,300
steps of a program that run in sequence
and I think that we've actually started

202
00:04:02,300 --> 00:04:02,310
and I think that we've actually started
 

203
00:04:02,310 --> 00:04:04,670
and I think that we've actually started
to see that what's important with deep

204
00:04:04,670 --> 00:04:04,680
to see that what's important with deep
 

205
00:04:04,680 --> 00:04:06,770
to see that what's important with deep
learning is more the fact that we have a

206
00:04:06,770 --> 00:04:06,780
learning is more the fact that we have a
 

207
00:04:06,780 --> 00:04:08,749
learning is more the fact that we have a
multi-step program rather than the fact

208
00:04:08,749 --> 00:04:08,759
multi-step program rather than the fact
 

209
00:04:08,759 --> 00:04:10,219
multi-step program rather than the fact
that we've learned a representation if

210
00:04:10,219 --> 00:04:10,229
that we've learned a representation if
 

211
00:04:10,229 --> 00:04:13,939
that we've learned a representation if
you look at things like res nuts for

212
00:04:13,939 --> 00:04:13,949
you look at things like res nuts for
 

213
00:04:13,949 --> 00:04:17,270
you look at things like res nuts for
example they take one particular kind of

214
00:04:17,270 --> 00:04:17,280
example they take one particular kind of
 

215
00:04:17,280 --> 00:04:19,460
example they take one particular kind of
representation and they update it

216
00:04:19,460 --> 00:04:19,470
representation and they update it
 

217
00:04:19,470 --> 00:04:22,310
representation and they update it
several times back when deep learning

218
00:04:22,310 --> 00:04:22,320
several times back when deep learning
 

219
00:04:22,320 --> 00:04:24,050
several times back when deep learning
first really took off in the academic

220
00:04:24,050 --> 00:04:24,060
first really took off in the academic
 

221
00:04:24,060 --> 00:04:27,320
first really took off in the academic
world in 2006 when Geoff Hinton

222
00:04:27,320 --> 00:04:27,330
world in 2006 when Geoff Hinton
 

223
00:04:27,330 --> 00:04:28,820
world in 2006 when Geoff Hinton
showed that you could train deep belief

224
00:04:28,820 --> 00:04:28,830
showed that you could train deep belief
 

225
00:04:28,830 --> 00:04:31,430
showed that you could train deep belief
networks everybody who was under ested

226
00:04:31,430 --> 00:04:31,440
networks everybody who was under ested
 

227
00:04:31,440 --> 00:04:33,409
networks everybody who was under ested
in the idea thought of it as each layer

228
00:04:33,409 --> 00:04:33,419
in the idea thought of it as each layer
 

229
00:04:33,419 --> 00:04:35,420
in the idea thought of it as each layer
learns a different level of abstraction

230
00:04:35,420 --> 00:04:35,430
learns a different level of abstraction
 

231
00:04:35,430 --> 00:04:37,760
learns a different level of abstraction
but the first layer trained on images

232
00:04:37,760 --> 00:04:37,770
but the first layer trained on images
 

233
00:04:37,770 --> 00:04:39,080
but the first layer trained on images
learn something like edges and the

234
00:04:39,080 --> 00:04:39,090
learn something like edges and the
 

235
00:04:39,090 --> 00:04:40,520
learn something like edges and the
second layer learns corners and

236
00:04:40,520 --> 00:04:40,530
second layer learns corners and
 

237
00:04:40,530 --> 00:04:41,990
second layer learns corners and
eventually you get these kind of

238
00:04:41,990 --> 00:04:42,000
eventually you get these kind of
 

239
00:04:42,000 --> 00:04:43,879
eventually you get these kind of
grandmother's cell units that recognize

240
00:04:43,879 --> 00:04:43,889
grandmother's cell units that recognize
 

241
00:04:43,889 --> 00:04:46,939
grandmother's cell units that recognize
specific objects today I think most

242
00:04:46,939 --> 00:04:46,949
specific objects today I think most
 

243
00:04:46,949 --> 00:04:50,149
specific objects today I think most
people think of it more as a computer

244
00:04:50,149 --> 00:04:50,159
people think of it more as a computer
 

245
00:04:50,159 --> 00:04:51,950
people think of it more as a computer
program where as you add more layers you

246
00:04:51,950 --> 00:04:51,960
program where as you add more layers you
 

247
00:04:51,960 --> 00:04:53,869
program where as you add more layers you
can do more updates before you output

248
00:04:53,869 --> 00:04:53,879
can do more updates before you output
 

249
00:04:53,879 --> 00:04:55,550
can do more updates before you output
your final number but I don't think

250
00:04:55,550 --> 00:04:55,560
your final number but I don't think
 

251
00:04:55,560 --> 00:04:58,670
your final number but I don't think
anybody believes the layer 150 of the

252
00:04:58,670 --> 00:04:58,680
anybody believes the layer 150 of the
 

253
00:04:58,680 --> 00:05:02,149
anybody believes the layer 150 of the
resin it is a grand grandmother cell and

254
00:05:02,149 --> 00:05:02,159
resin it is a grand grandmother cell and
 

255
00:05:02,159 --> 00:05:04,189
resin it is a grand grandmother cell and
you know layer 100 is contours or

256
00:05:04,189 --> 00:05:04,199
you know layer 100 is contours or
 

257
00:05:04,199 --> 00:05:07,100
you know layer 100 is contours or
something like that okay so you think

258
00:05:07,100 --> 00:05:07,110
something like that okay so you think
 

259
00:05:07,110 --> 00:05:08,779
something like that okay so you think
you're not thinking of it as a singular

260
00:05:08,779 --> 00:05:08,789
you're not thinking of it as a singular
 

261
00:05:08,789 --> 00:05:11,629
you're not thinking of it as a singular
representation that keeps building you

262
00:05:11,629 --> 00:05:11,639
representation that keeps building you
 

263
00:05:11,639 --> 00:05:14,570
representation that keeps building you
think of it as a program sort of almost

264
00:05:14,570 --> 00:05:14,580
think of it as a program sort of almost
 

265
00:05:14,580 --> 00:05:16,850
think of it as a program sort of almost
like a state the representation is a

266
00:05:16,850 --> 00:05:16,860
like a state the representation is a
 

267
00:05:16,860 --> 00:05:19,459
like a state the representation is a
state of understanding and yeah I think

268
00:05:19,459 --> 00:05:19,469
state of understanding and yeah I think
 

269
00:05:19,469 --> 00:05:20,839
state of understanding and yeah I think
of it as a program that makes several

270
00:05:20,839 --> 00:05:20,849
of it as a program that makes several
 

271
00:05:20,849 --> 00:05:22,969
of it as a program that makes several
updates and arrives it better and better

272
00:05:22,969 --> 00:05:22,979
updates and arrives it better and better
 

273
00:05:22,979 --> 00:05:25,550
updates and arrives it better and better
understandings but it's not replacing

274
00:05:25,550 --> 00:05:25,560
understandings but it's not replacing
 

275
00:05:25,560 --> 00:05:27,649
understandings but it's not replacing
the representation at each step its

276
00:05:27,649 --> 00:05:27,659
the representation at each step its
 

277
00:05:27,659 --> 00:05:30,350
the representation at each step its
refining it and in some sense that's a

278
00:05:30,350 --> 00:05:30,360
refining it and in some sense that's a
 

279
00:05:30,360 --> 00:05:32,029
refining it and in some sense that's a
little bit like reasoning it's not

280
00:05:32,029 --> 00:05:32,039
little bit like reasoning it's not
 

281
00:05:32,039 --> 00:05:33,649
little bit like reasoning it's not
reasoning in the form of deduction but

282
00:05:33,649 --> 00:05:33,659
reasoning in the form of deduction but
 

283
00:05:33,659 --> 00:05:36,559
reasoning in the form of deduction but
it's reasoning in the form of taking a

284
00:05:36,559 --> 00:05:36,569
it's reasoning in the form of taking a
 

285
00:05:36,569 --> 00:05:38,360
it's reasoning in the form of taking a
thought and refining it and refining it

286
00:05:38,360 --> 00:05:38,370
thought and refining it and refining it
 

287
00:05:38,370 --> 00:05:40,760
thought and refining it and refining it
carefully until it's good enough to use

288
00:05:40,760 --> 00:05:40,770
carefully until it's good enough to use
 

289
00:05:40,770 --> 00:05:43,459
carefully until it's good enough to use
do you think and I hope you don't mind

290
00:05:43,459 --> 00:05:43,469
do you think and I hope you don't mind
 

291
00:05:43,469 --> 00:05:45,439
do you think and I hope you don't mind
we'll jump philosophical every once in a

292
00:05:45,439 --> 00:05:45,449
we'll jump philosophical every once in a
 

293
00:05:45,449 --> 00:05:48,589
we'll jump philosophical every once in a
while do you think of you know a

294
00:05:48,589 --> 00:05:48,599
while do you think of you know a
 

295
00:05:48,599 --> 00:05:50,749
while do you think of you know a
cognition human cognition or even

296
00:05:50,749 --> 00:05:50,759
cognition human cognition or even
 

297
00:05:50,759 --> 00:05:54,050
cognition human cognition or even
consciousness as simply a result of this

298
00:05:54,050 --> 00:05:54,060
consciousness as simply a result of this
 

299
00:05:54,060 --> 00:05:57,050
consciousness as simply a result of this
kind of cincuenta sequential

300
00:05:57,050 --> 00:05:57,060
kind of cincuenta sequential
 

301
00:05:57,060 --> 00:05:58,459
kind of cincuenta sequential
representation learning do you think

302
00:05:58,459 --> 00:05:58,469
representation learning do you think
 

303
00:05:58,469 --> 00:06:02,330
representation learning do you think
that can emerge cognition yes I think so

304
00:06:02,330 --> 00:06:02,340
that can emerge cognition yes I think so
 

305
00:06:02,340 --> 00:06:03,920
that can emerge cognition yes I think so
consciousness it's really hard to even

306
00:06:03,920 --> 00:06:03,930
consciousness it's really hard to even
 

307
00:06:03,930 --> 00:06:07,700
consciousness it's really hard to even
define what we mean by that I guess

308
00:06:07,700 --> 00:06:07,710
define what we mean by that I guess
 

309
00:06:07,710 --> 00:06:09,529
define what we mean by that I guess
there's consciousness is often defined

310
00:06:09,529 --> 00:06:09,539
there's consciousness is often defined
 

311
00:06:09,539 --> 00:06:12,040
there's consciousness is often defined
as things like having self-awareness and

312
00:06:12,040 --> 00:06:12,050
as things like having self-awareness and
 

313
00:06:12,050 --> 00:06:15,200
as things like having self-awareness and
that's relatively easy to turn into

314
00:06:15,200 --> 00:06:15,210
that's relatively easy to turn into
 

315
00:06:15,210 --> 00:06:16,610
that's relatively easy to turn into
something actionable for a computer

316
00:06:16,610 --> 00:06:16,620
something actionable for a computer
 

317
00:06:16,620 --> 00:06:18,830
something actionable for a computer
scientists the reason about people also

318
00:06:18,830 --> 00:06:18,840
scientists the reason about people also
 

319
00:06:18,840 --> 00:06:20,390
scientists the reason about people also
defined consciousness in terms of having

320
00:06:20,390 --> 00:06:20,400
defined consciousness in terms of having
 

321
00:06:20,400 --> 00:06:22,610
defined consciousness in terms of having
qualitative states of experience like

322
00:06:22,610 --> 00:06:22,620
qualitative states of experience like
 

323
00:06:22,620 --> 00:06:24,290
qualitative states of experience like
qualia and there's all these

324
00:06:24,290 --> 00:06:24,300
qualia and there's all these
 

325
00:06:24,300 --> 00:06:25,670
qualia and there's all these
philosophical problems like could you

326
00:06:25,670 --> 00:06:25,680
philosophical problems like could you
 

327
00:06:25,680 --> 00:06:28,700
philosophical problems like could you
imagine jambe who does all the same

328
00:06:28,700 --> 00:06:28,710
imagine jambe who does all the same
 

329
00:06:28,710 --> 00:06:30,850
imagine jambe who does all the same
information processing as a human but

330
00:06:30,850 --> 00:06:30,860
information processing as a human but
 

331
00:06:30,860 --> 00:06:32,869
information processing as a human but
doesn't really have the qualitative

332
00:06:32,869 --> 00:06:32,879
doesn't really have the qualitative
 

333
00:06:32,879 --> 00:06:35,329
doesn't really have the qualitative
experiences that we have that sort of

334
00:06:35,329 --> 00:06:35,339
experiences that we have that sort of
 

335
00:06:35,339 --> 00:06:37,639
experiences that we have that sort of
thing I have no idea how to formalize or

336
00:06:37,639 --> 00:06:37,649
thing I have no idea how to formalize or
 

337
00:06:37,649 --> 00:06:40,010
thing I have no idea how to formalize or
turn it into a scientific question I

338
00:06:40,010 --> 00:06:40,020
turn it into a scientific question I
 

339
00:06:40,020 --> 00:06:41,100
turn it into a scientific question I
don't know how you could run in

340
00:06:41,100 --> 00:06:41,110
don't know how you could run in
 

341
00:06:41,110 --> 00:06:43,680
don't know how you could run in
experiment to tell whether a person is a

342
00:06:43,680 --> 00:06:43,690
experiment to tell whether a person is a
 

343
00:06:43,690 --> 00:06:44,580
experiment to tell whether a person is a
zombie or not

344
00:06:44,580 --> 00:06:44,590
zombie or not
 

345
00:06:44,590 --> 00:06:46,500
zombie or not
and similarly I don't know how you could

346
00:06:46,500 --> 00:06:46,510
and similarly I don't know how you could
 

347
00:06:46,510 --> 00:06:48,450
and similarly I don't know how you could
run an experiment to tell whether an

348
00:06:48,450 --> 00:06:48,460
run an experiment to tell whether an
 

349
00:06:48,460 --> 00:06:51,060
run an experiment to tell whether an
advanced AI system had become conscious

350
00:06:51,060 --> 00:06:51,070
advanced AI system had become conscious
 

351
00:06:51,070 --> 00:06:53,490
advanced AI system had become conscious
in the sense of qualia or not but in the

352
00:06:53,490 --> 00:06:53,500
in the sense of qualia or not but in the
 

353
00:06:53,500 --> 00:06:55,050
in the sense of qualia or not but in the
more practical sense like almost like

354
00:06:55,050 --> 00:06:55,060
more practical sense like almost like
 

355
00:06:55,060 --> 00:06:56,040
more practical sense like almost like
self attention

356
00:06:56,040 --> 00:06:56,050
self attention
 

357
00:06:56,050 --> 00:06:57,630
self attention
you think consciousness and cognition

358
00:06:57,630 --> 00:06:57,640
you think consciousness and cognition
 

359
00:06:57,640 --> 00:07:00,710
you think consciousness and cognition
can in an impressive way emerge from

360
00:07:00,710 --> 00:07:00,720
can in an impressive way emerge from
 

361
00:07:00,720 --> 00:07:04,440
can in an impressive way emerge from
current types of architectures though

362
00:07:04,440 --> 00:07:04,450
current types of architectures though
 

363
00:07:04,450 --> 00:07:07,230
current types of architectures though
yes yeah or or if if you think of

364
00:07:07,230 --> 00:07:07,240
yes yeah or or if if you think of
 

365
00:07:07,240 --> 00:07:08,730
yes yeah or or if if you think of
consciousness in terms of self-awareness

366
00:07:08,730 --> 00:07:08,740
consciousness in terms of self-awareness
 

367
00:07:08,740 --> 00:07:12,900
consciousness in terms of self-awareness
and just making plans based on the fact

368
00:07:12,900 --> 00:07:12,910
and just making plans based on the fact
 

369
00:07:12,910 --> 00:07:15,720
and just making plans based on the fact
that the agent itself exists in the

370
00:07:15,720 --> 00:07:15,730
that the agent itself exists in the
 

371
00:07:15,730 --> 00:07:17,880
that the agent itself exists in the
world reinforcement learning algorithms

372
00:07:17,880 --> 00:07:17,890
world reinforcement learning algorithms
 

373
00:07:17,890 --> 00:07:20,790
world reinforcement learning algorithms
are already more or less forced to model

374
00:07:20,790 --> 00:07:20,800
are already more or less forced to model
 

375
00:07:20,800 --> 00:07:23,130
are already more or less forced to model
the agents effect on the environment so

376
00:07:23,130 --> 00:07:23,140
the agents effect on the environment so
 

377
00:07:23,140 --> 00:07:25,470
the agents effect on the environment so
that that more limited version of

378
00:07:25,470 --> 00:07:25,480
that that more limited version of
 

379
00:07:25,480 --> 00:07:28,530
that that more limited version of
consciousness is already something that

380
00:07:28,530 --> 00:07:28,540
consciousness is already something that
 

381
00:07:28,540 --> 00:07:31,530
consciousness is already something that
we get limited versions of with

382
00:07:31,530 --> 00:07:31,540
we get limited versions of with
 

383
00:07:31,540 --> 00:07:33,000
we get limited versions of with
reinforcement learning algorithms if

384
00:07:33,000 --> 00:07:33,010
reinforcement learning algorithms if
 

385
00:07:33,010 --> 00:07:37,290
reinforcement learning algorithms if
they're trained well but you say limited

386
00:07:37,290 --> 00:07:37,300
they're trained well but you say limited
 

387
00:07:37,300 --> 00:07:39,450
they're trained well but you say limited
so the the big question really is how

388
00:07:39,450 --> 00:07:39,460
so the the big question really is how
 

389
00:07:39,460 --> 00:07:41,220
so the the big question really is how
you jump from limited to human level

390
00:07:41,220 --> 00:07:41,230
you jump from limited to human level
 

391
00:07:41,230 --> 00:07:46,260
you jump from limited to human level
yeah right and whether it's possible you

392
00:07:46,260 --> 00:07:46,270
yeah right and whether it's possible you
 

393
00:07:46,270 --> 00:07:48,060
yeah right and whether it's possible you
know the even just building common-sense

394
00:07:48,060 --> 00:07:48,070
know the even just building common-sense
 

395
00:07:48,070 --> 00:07:50,070
know the even just building common-sense
reasoning seems to be exceptionally

396
00:07:50,070 --> 00:07:50,080
reasoning seems to be exceptionally
 

397
00:07:50,080 --> 00:07:52,380
reasoning seems to be exceptionally
difficult so K if we scale things up

398
00:07:52,380 --> 00:07:52,390
difficult so K if we scale things up
 

399
00:07:52,390 --> 00:07:54,420
difficult so K if we scale things up
forget much better on supervised

400
00:07:54,420 --> 00:07:54,430
forget much better on supervised
 

401
00:07:54,430 --> 00:07:56,550
forget much better on supervised
learning if we get better at labeling

402
00:07:56,550 --> 00:07:56,560
learning if we get better at labeling
 

403
00:07:56,560 --> 00:07:59,880
learning if we get better at labeling
forget bigger datasets and the more

404
00:07:59,880 --> 00:07:59,890
forget bigger datasets and the more
 

405
00:07:59,890 --> 00:08:02,220
forget bigger datasets and the more
compute do you think we'll start to see

406
00:08:02,220 --> 00:08:02,230
compute do you think we'll start to see
 

407
00:08:02,230 --> 00:08:04,290
compute do you think we'll start to see
really impressive things that go from

408
00:08:04,290 --> 00:08:04,300
really impressive things that go from
 

409
00:08:04,300 --> 00:08:08,670
really impressive things that go from
limited to you know something echoes of

410
00:08:08,670 --> 00:08:08,680
limited to you know something echoes of
 

411
00:08:08,680 --> 00:08:11,040
limited to you know something echoes of
human level cognition I think so yeah

412
00:08:11,040 --> 00:08:11,050
human level cognition I think so yeah
 

413
00:08:11,050 --> 00:08:13,260
human level cognition I think so yeah
I'm optimistic about what can happen

414
00:08:13,260 --> 00:08:13,270
I'm optimistic about what can happen
 

415
00:08:13,270 --> 00:08:15,360
I'm optimistic about what can happen
just with more computation and more data

416
00:08:15,360 --> 00:08:15,370
just with more computation and more data
 

417
00:08:15,370 --> 00:08:17,820
just with more computation and more data
I do think it'll be important to get the

418
00:08:17,820 --> 00:08:17,830
I do think it'll be important to get the
 

419
00:08:17,830 --> 00:08:20,910
I do think it'll be important to get the
right kind of data today most of the

420
00:08:20,910 --> 00:08:20,920
right kind of data today most of the
 

421
00:08:20,920 --> 00:08:22,850
right kind of data today most of the
machine learning systems we train our

422
00:08:22,850 --> 00:08:22,860
machine learning systems we train our
 

423
00:08:22,860 --> 00:08:25,920
machine learning systems we train our
mostly trained on one type of data for

424
00:08:25,920 --> 00:08:25,930
mostly trained on one type of data for
 

425
00:08:25,930 --> 00:08:29,790
mostly trained on one type of data for
each model but the human brain we get

426
00:08:29,790 --> 00:08:29,800
each model but the human brain we get
 

427
00:08:29,800 --> 00:08:31,770
each model but the human brain we get
all of our different senses and we have

428
00:08:31,770 --> 00:08:31,780
all of our different senses and we have
 

429
00:08:31,780 --> 00:08:34,830
all of our different senses and we have
many different experiences like you know

430
00:08:34,830 --> 00:08:34,840
many different experiences like you know
 

431
00:08:34,840 --> 00:08:36,719
many different experiences like you know
riding a bike driving a car talking to

432
00:08:36,719 --> 00:08:36,729
riding a bike driving a car talking to
 

433
00:08:36,729 --> 00:08:39,990
riding a bike driving a car talking to
people reading I think when you get that

434
00:08:39,990 --> 00:08:40,000
people reading I think when you get that
 

435
00:08:40,000 --> 00:08:43,170
people reading I think when you get that
kind of integrated data set working with

436
00:08:43,170 --> 00:08:43,180
kind of integrated data set working with
 

437
00:08:43,180 --> 00:08:44,670
kind of integrated data set working with
a machine learning model that can

438
00:08:44,670 --> 00:08:44,680
a machine learning model that can
 

439
00:08:44,680 --> 00:08:47,970
a machine learning model that can
actually close the loop and interact we

440
00:08:47,970 --> 00:08:47,980
actually close the loop and interact we
 

441
00:08:47,980 --> 00:08:50,130
actually close the loop and interact we
may find that algorithms not so

442
00:08:50,130 --> 00:08:50,140
may find that algorithms not so
 

443
00:08:50,140 --> 00:08:52,020
may find that algorithms not so
different from what we have today learn

444
00:08:52,020 --> 00:08:52,030
different from what we have today learn
 

445
00:08:52,030 --> 00:08:53,700
different from what we have today learn
really interesting things when you scale

446
00:08:53,700 --> 00:08:53,710
really interesting things when you scale
 

447
00:08:53,710 --> 00:08:54,750
really interesting things when you scale
them up a lot and

448
00:08:54,750 --> 00:08:54,760
them up a lot and
 

449
00:08:54,760 --> 00:08:58,410
them up a lot and
a large amount of multimodal data so

450
00:08:58,410 --> 00:08:58,420
a large amount of multimodal data so
 

451
00:08:58,420 --> 00:08:59,790
a large amount of multimodal data so
multimodal is really interesting but

452
00:08:59,790 --> 00:08:59,800
multimodal is really interesting but
 

453
00:08:59,800 --> 00:09:02,940
multimodal is really interesting but
within like you're working adversarial

454
00:09:02,940 --> 00:09:02,950
within like you're working adversarial
 

455
00:09:02,950 --> 00:09:06,900
within like you're working adversarial
examples so selecting within modal

456
00:09:06,900 --> 00:09:06,910
examples so selecting within modal
 

457
00:09:06,910 --> 00:09:11,760
examples so selecting within modal
within up one mode of data selecting

458
00:09:11,760 --> 00:09:11,770
within up one mode of data selecting
 

459
00:09:11,770 --> 00:09:13,620
within up one mode of data selecting
better at what are the difficult cases

460
00:09:13,620 --> 00:09:13,630
better at what are the difficult cases
 

461
00:09:13,630 --> 00:09:15,510
better at what are the difficult cases
from which are most useful to learn from

462
00:09:15,510 --> 00:09:15,520
from which are most useful to learn from
 

463
00:09:15,520 --> 00:09:18,000
from which are most useful to learn from
oh yeah like could we could you get a

464
00:09:18,000 --> 00:09:18,010
oh yeah like could we could you get a
 

465
00:09:18,010 --> 00:09:21,180
oh yeah like could we could you get a
whole lot of mileage out of designing a

466
00:09:21,180 --> 00:09:21,190
whole lot of mileage out of designing a
 

467
00:09:21,190 --> 00:09:22,800
whole lot of mileage out of designing a
model that's resistant to adverse fare

468
00:09:22,800 --> 00:09:22,810
model that's resistant to adverse fare
 

469
00:09:22,810 --> 00:09:24,480
model that's resistant to adverse fare
examples or something like that right

470
00:09:24,480 --> 00:09:24,490
examples or something like that right
 

471
00:09:24,490 --> 00:09:26,880
examples or something like that right
yeah question but my thinking on that

472
00:09:26,880 --> 00:09:26,890
yeah question but my thinking on that
 

473
00:09:26,890 --> 00:09:28,380
yeah question but my thinking on that
has evolved a lot over the last few

474
00:09:28,380 --> 00:09:28,390
has evolved a lot over the last few
 

475
00:09:28,390 --> 00:09:30,330
has evolved a lot over the last few
years one nice thing when I first

476
00:09:30,330 --> 00:09:30,340
years one nice thing when I first
 

477
00:09:30,340 --> 00:09:31,680
years one nice thing when I first
started to really invest in studying

478
00:09:31,680 --> 00:09:31,690
started to really invest in studying
 

479
00:09:31,690 --> 00:09:33,300
started to really invest in studying
adversarial examples I was thinking of

480
00:09:33,300 --> 00:09:33,310
adversarial examples I was thinking of
 

481
00:09:33,310 --> 00:09:35,940
adversarial examples I was thinking of
it mostly as that versus aryl examples

482
00:09:35,940 --> 00:09:35,950
it mostly as that versus aryl examples
 

483
00:09:35,950 --> 00:09:37,920
it mostly as that versus aryl examples
reveal a big problem with machine

484
00:09:37,920 --> 00:09:37,930
reveal a big problem with machine
 

485
00:09:37,930 --> 00:09:40,800
reveal a big problem with machine
learning and we would like to close the

486
00:09:40,800 --> 00:09:40,810
learning and we would like to close the
 

487
00:09:40,810 --> 00:09:43,650
learning and we would like to close the
gap between how machine learning models

488
00:09:43,650 --> 00:09:43,660
gap between how machine learning models
 

489
00:09:43,660 --> 00:09:45,420
gap between how machine learning models
respond to adversarial examples and how

490
00:09:45,420 --> 00:09:45,430
respond to adversarial examples and how
 

491
00:09:45,430 --> 00:09:48,450
respond to adversarial examples and how
humans respond after studying the

492
00:09:48,450 --> 00:09:48,460
humans respond after studying the
 

493
00:09:48,460 --> 00:09:49,800
humans respond after studying the
problem more I still think that

494
00:09:49,800 --> 00:09:49,810
problem more I still think that
 

495
00:09:49,810 --> 00:09:51,450
problem more I still think that
adversarial examples are important I

496
00:09:51,450 --> 00:09:51,460
adversarial examples are important I
 

497
00:09:51,460 --> 00:09:53,790
adversarial examples are important I
think of them now more of as a security

498
00:09:53,790 --> 00:09:53,800
think of them now more of as a security
 

499
00:09:53,800 --> 00:09:56,520
think of them now more of as a security
liability then as an issue that

500
00:09:56,520 --> 00:09:56,530
liability then as an issue that
 

501
00:09:56,530 --> 00:09:58,430
liability then as an issue that
necessarily shows there something

502
00:09:58,430 --> 00:09:58,440
necessarily shows there something
 

503
00:09:58,440 --> 00:10:01,350
necessarily shows there something
uniquely wrong with machine learning as

504
00:10:01,350 --> 00:10:01,360
uniquely wrong with machine learning as
 

505
00:10:01,360 --> 00:10:03,630
uniquely wrong with machine learning as
opposed to humans also do you see them

506
00:10:03,630 --> 00:10:03,640
opposed to humans also do you see them
 

507
00:10:03,640 --> 00:10:05,940
opposed to humans also do you see them
as a tool to improve the performance of

508
00:10:05,940 --> 00:10:05,950
as a tool to improve the performance of
 

509
00:10:05,950 --> 00:10:08,340
as a tool to improve the performance of
the system not not on the security side

510
00:10:08,340 --> 00:10:08,350
the system not not on the security side
 

511
00:10:08,350 --> 00:10:11,340
the system not not on the security side
but literally just accuracy I do see

512
00:10:11,340 --> 00:10:11,350
but literally just accuracy I do see
 

513
00:10:11,350 --> 00:10:13,590
but literally just accuracy I do see
them as a kind of tool on that side but

514
00:10:13,590 --> 00:10:13,600
them as a kind of tool on that side but
 

515
00:10:13,600 --> 00:10:15,540
them as a kind of tool on that side but
maybe not quite as much as I used to

516
00:10:15,540 --> 00:10:15,550
maybe not quite as much as I used to
 

517
00:10:15,550 --> 00:10:17,790
maybe not quite as much as I used to
think we've started to find that there's

518
00:10:17,790 --> 00:10:17,800
think we've started to find that there's
 

519
00:10:17,800 --> 00:10:19,740
think we've started to find that there's
a trade-off between accuracy on

520
00:10:19,740 --> 00:10:19,750
a trade-off between accuracy on
 

521
00:10:19,750 --> 00:10:22,530
a trade-off between accuracy on
adversarial examples and accuracy on

522
00:10:22,530 --> 00:10:22,540
adversarial examples and accuracy on
 

523
00:10:22,540 --> 00:10:25,980
adversarial examples and accuracy on
clean examples back in 2014 when I did

524
00:10:25,980 --> 00:10:25,990
clean examples back in 2014 when I did
 

525
00:10:25,990 --> 00:10:28,920
clean examples back in 2014 when I did
the first adversary trained classifier

526
00:10:28,920 --> 00:10:28,930
the first adversary trained classifier
 

527
00:10:28,930 --> 00:10:31,500
the first adversary trained classifier
that showed resistance to some kinds of

528
00:10:31,500 --> 00:10:31,510
that showed resistance to some kinds of
 

529
00:10:31,510 --> 00:10:33,900
that showed resistance to some kinds of
adversarial examples it also got better

530
00:10:33,900 --> 00:10:33,910
adversarial examples it also got better
 

531
00:10:33,910 --> 00:10:36,300
adversarial examples it also got better
at the clean data on M NIST and that's

532
00:10:36,300 --> 00:10:36,310
at the clean data on M NIST and that's
 

533
00:10:36,310 --> 00:10:37,620
at the clean data on M NIST and that's
something we've replicated several times

534
00:10:37,620 --> 00:10:37,630
something we've replicated several times
 

535
00:10:37,630 --> 00:10:39,900
something we've replicated several times
an M NIST that when we train against

536
00:10:39,900 --> 00:10:39,910
an M NIST that when we train against
 

537
00:10:39,910 --> 00:10:41,640
an M NIST that when we train against
weak adversarial examples Emnes

538
00:10:41,640 --> 00:10:41,650
weak adversarial examples Emnes
 

539
00:10:41,650 --> 00:10:44,220
weak adversarial examples Emnes
classifiers get more accurate so far

540
00:10:44,220 --> 00:10:44,230
classifiers get more accurate so far
 

541
00:10:44,230 --> 00:10:46,170
classifiers get more accurate so far
that hasn't really held up on other data

542
00:10:46,170 --> 00:10:46,180
that hasn't really held up on other data
 

543
00:10:46,180 --> 00:10:48,630
that hasn't really held up on other data
sets and hasn't held up when we train

544
00:10:48,630 --> 00:10:48,640
sets and hasn't held up when we train
 

545
00:10:48,640 --> 00:10:51,120
sets and hasn't held up when we train
against stronger adversaries it seems

546
00:10:51,120 --> 00:10:51,130
against stronger adversaries it seems
 

547
00:10:51,130 --> 00:10:53,880
against stronger adversaries it seems
like when you confront a really strong

548
00:10:53,880 --> 00:10:53,890
like when you confront a really strong
 

549
00:10:53,890 --> 00:10:56,580
like when you confront a really strong
adversary you tend to have to give

550
00:10:56,580 --> 00:10:56,590
adversary you tend to have to give
 

551
00:10:56,590 --> 00:10:59,430
adversary you tend to have to give
something up interesting this is such a

552
00:10:59,430 --> 00:10:59,440
something up interesting this is such a
 

553
00:10:59,440 --> 00:11:02,160
something up interesting this is such a
compelling idea because it feels it

554
00:11:02,160 --> 00:11:02,170
compelling idea because it feels it
 

555
00:11:02,170 --> 00:11:03,920
compelling idea because it feels it
feels like that's how us humans learn

556
00:11:03,920 --> 00:11:03,930
feels like that's how us humans learn
 

557
00:11:03,930 --> 00:11:06,930
feels like that's how us humans learn
yeah the difficult cases we we try to

558
00:11:06,930 --> 00:11:06,940
yeah the difficult cases we we try to
 

559
00:11:06,940 --> 00:11:08,730
yeah the difficult cases we we try to
think of what would we screw up

560
00:11:08,730 --> 00:11:08,740
think of what would we screw up
 

561
00:11:08,740 --> 00:11:10,380
think of what would we screw up
and then we make sure we fix that yeah

562
00:11:10,380 --> 00:11:10,390
and then we make sure we fix that yeah
 

563
00:11:10,390 --> 00:11:12,449
and then we make sure we fix that yeah
it's also in a lot of branches of

564
00:11:12,449 --> 00:11:12,459
it's also in a lot of branches of
 

565
00:11:12,459 --> 00:11:15,210
it's also in a lot of branches of
engineering you do a worst case analysis

566
00:11:15,210 --> 00:11:15,220
engineering you do a worst case analysis
 

567
00:11:15,220 --> 00:11:17,160
engineering you do a worst case analysis
and make sure that your system will work

568
00:11:17,160 --> 00:11:17,170
and make sure that your system will work
 

569
00:11:17,170 --> 00:11:19,139
and make sure that your system will work
in the worst case and then that

570
00:11:19,139 --> 00:11:19,149
in the worst case and then that
 

571
00:11:19,149 --> 00:11:21,389
in the worst case and then that
guarantees that it'll work in all of the

572
00:11:21,389 --> 00:11:21,399
guarantees that it'll work in all of the
 

573
00:11:21,399 --> 00:11:25,139
guarantees that it'll work in all of the
messy average cases that happen when you

574
00:11:25,139 --> 00:11:25,149
messy average cases that happen when you
 

575
00:11:25,149 --> 00:11:26,880
messy average cases that happen when you
go out into a really randomized world

576
00:11:26,880 --> 00:11:26,890
go out into a really randomized world
 

577
00:11:26,890 --> 00:11:28,800
go out into a really randomized world
you know with driving with autonomous

578
00:11:28,800 --> 00:11:28,810
you know with driving with autonomous
 

579
00:11:28,810 --> 00:11:30,720
you know with driving with autonomous
vehicles there seems to be a desire to

580
00:11:30,720 --> 00:11:30,730
vehicles there seems to be a desire to
 

581
00:11:30,730 --> 00:11:35,100
vehicles there seems to be a desire to
just look for think I'd viscerally tried

582
00:11:35,100 --> 00:11:35,110
just look for think I'd viscerally tried
 

583
00:11:35,110 --> 00:11:36,810
just look for think I'd viscerally tried
to figure out how to mess up the system

584
00:11:36,810 --> 00:11:36,820
to figure out how to mess up the system
 

585
00:11:36,820 --> 00:11:39,290
to figure out how to mess up the system
and if you can be robust to all those

586
00:11:39,290 --> 00:11:39,300
and if you can be robust to all those
 

587
00:11:39,300 --> 00:11:42,449
and if you can be robust to all those
difficult cases then you can it's a hand

588
00:11:42,449 --> 00:11:42,459
difficult cases then you can it's a hand
 

589
00:11:42,459 --> 00:11:44,130
difficult cases then you can it's a hand
waving empirical way to show that your

590
00:11:44,130 --> 00:11:44,140
waving empirical way to show that your
 

591
00:11:44,140 --> 00:11:46,889
waving empirical way to show that your
system is yeah yes

592
00:11:46,889 --> 00:11:46,899
system is yeah yes
 

593
00:11:46,899 --> 00:11:48,600
system is yeah yes
today most adverse early example

594
00:11:48,600 --> 00:11:48,610
today most adverse early example
 

595
00:11:48,610 --> 00:11:50,190
today most adverse early example
research isn't really focused on a

596
00:11:50,190 --> 00:11:50,200
research isn't really focused on a
 

597
00:11:50,200 --> 00:11:52,980
research isn't really focused on a
particular use case but there are a lot

598
00:11:52,980 --> 00:11:52,990
particular use case but there are a lot
 

599
00:11:52,990 --> 00:11:54,389
particular use case but there are a lot
of different use cases where you'd like

600
00:11:54,389 --> 00:11:54,399
of different use cases where you'd like
 

601
00:11:54,399 --> 00:11:57,180
of different use cases where you'd like
to make sure that the adversary can't

602
00:11:57,180 --> 00:11:57,190
to make sure that the adversary can't
 

603
00:11:57,190 --> 00:11:58,560
to make sure that the adversary can't
interfere with the operation of your

604
00:11:58,560 --> 00:11:58,570
interfere with the operation of your
 

605
00:11:58,570 --> 00:12:01,410
interfere with the operation of your
system like in finance if you have an

606
00:12:01,410 --> 00:12:01,420
system like in finance if you have an
 

607
00:12:01,420 --> 00:12:03,480
system like in finance if you have an
algorithm making trades for you people

608
00:12:03,480 --> 00:12:03,490
algorithm making trades for you people
 

609
00:12:03,490 --> 00:12:05,519
algorithm making trades for you people
go to a lot of an effort to obfuscate

610
00:12:05,519 --> 00:12:05,529
go to a lot of an effort to obfuscate
 

611
00:12:05,529 --> 00:12:07,320
go to a lot of an effort to obfuscate
their algorithm that's both to protect

612
00:12:07,320 --> 00:12:07,330
their algorithm that's both to protect
 

613
00:12:07,330 --> 00:12:09,389
their algorithm that's both to protect
their IP because you don't want to

614
00:12:09,389 --> 00:12:09,399
their IP because you don't want to
 

615
00:12:09,399 --> 00:12:12,900
their IP because you don't want to
research and develop a profitable

616
00:12:12,900 --> 00:12:12,910
research and develop a profitable
 

617
00:12:12,910 --> 00:12:14,040
research and develop a profitable
trading algorithm then have somebody

618
00:12:14,040 --> 00:12:14,050
trading algorithm then have somebody
 

619
00:12:14,050 --> 00:12:16,590
trading algorithm then have somebody
else capture the gains but it's at least

620
00:12:16,590 --> 00:12:16,600
else capture the gains but it's at least
 

621
00:12:16,600 --> 00:12:18,150
else capture the gains but it's at least
partly because you don't want people to

622
00:12:18,150 --> 00:12:18,160
partly because you don't want people to
 

623
00:12:18,160 --> 00:12:20,670
partly because you don't want people to
make adversarial examples that fool you

624
00:12:20,670 --> 00:12:20,680
make adversarial examples that fool you
 

625
00:12:20,680 --> 00:12:23,410
make adversarial examples that fool you
our algorithm into making bad trades

626
00:12:23,410 --> 00:12:23,420
our algorithm into making bad trades
 

627
00:12:23,420 --> 00:12:26,210
our algorithm into making bad trades
or I guess one area that's been popular

628
00:12:26,210 --> 00:12:26,220
or I guess one area that's been popular
 

629
00:12:26,220 --> 00:12:28,820
or I guess one area that's been popular
in the academic literature is speech

630
00:12:28,820 --> 00:12:28,830
in the academic literature is speech
 

631
00:12:28,830 --> 00:12:30,890
in the academic literature is speech
recognition if you use speech

632
00:12:30,890 --> 00:12:30,900
recognition if you use speech
 

633
00:12:30,900 --> 00:12:34,220
recognition if you use speech
recognition to hear an audio waveform

634
00:12:34,220 --> 00:12:34,230
recognition to hear an audio waveform
 

635
00:12:34,230 --> 00:12:37,490
recognition to hear an audio waveform
and then in turn that into a command

636
00:12:37,490 --> 00:12:37,500
and then in turn that into a command
 

637
00:12:37,500 --> 00:12:40,190
and then in turn that into a command
that a phone executes for you you don't

638
00:12:40,190 --> 00:12:40,200
that a phone executes for you you don't
 

639
00:12:40,200 --> 00:12:42,019
that a phone executes for you you don't
want and a malicious adversary to be

640
00:12:42,019 --> 00:12:42,029
want and a malicious adversary to be
 

641
00:12:42,029 --> 00:12:43,910
want and a malicious adversary to be
able to produce audio that gets

642
00:12:43,910 --> 00:12:43,920
able to produce audio that gets
 

643
00:12:43,920 --> 00:12:45,880
able to produce audio that gets
interpreted as malicious commands

644
00:12:45,880 --> 00:12:45,890
interpreted as malicious commands
 

645
00:12:45,890 --> 00:12:47,720
interpreted as malicious commands
especially if a human in the room

646
00:12:47,720 --> 00:12:47,730
especially if a human in the room
 

647
00:12:47,730 --> 00:12:49,100
especially if a human in the room
doesn't realize that something like that

648
00:12:49,100 --> 00:12:49,110
doesn't realize that something like that
 

649
00:12:49,110 --> 00:12:52,100
doesn't realize that something like that
is happening in speech recognition has

650
00:12:52,100 --> 00:12:52,110
is happening in speech recognition has
 

651
00:12:52,110 --> 00:12:55,460
is happening in speech recognition has
there been much success in in being able

652
00:12:55,460 --> 00:12:55,470
there been much success in in being able
 

653
00:12:55,470 --> 00:12:58,850
there been much success in in being able
to create adversarial examples that fool

654
00:12:58,850 --> 00:12:58,860
to create adversarial examples that fool
 

655
00:12:58,860 --> 00:13:01,340
to create adversarial examples that fool
the system yeah actually I guess the

656
00:13:01,340 --> 00:13:01,350
the system yeah actually I guess the
 

657
00:13:01,350 --> 00:13:02,840
the system yeah actually I guess the
first work that I'm aware of is a paper

658
00:13:02,840 --> 00:13:02,850
first work that I'm aware of is a paper
 

659
00:13:02,850 --> 00:13:05,570
first work that I'm aware of is a paper
called hidden voice commands that came

660
00:13:05,570 --> 00:13:05,580
called hidden voice commands that came
 

661
00:13:05,580 --> 00:13:08,960
called hidden voice commands that came
out in 2016 I believe and they were able

662
00:13:08,960 --> 00:13:08,970
out in 2016 I believe and they were able
 

663
00:13:08,970 --> 00:13:11,900
out in 2016 I believe and they were able
to show that they could make sounds that

664
00:13:11,900 --> 00:13:11,910
to show that they could make sounds that
 

665
00:13:11,910 --> 00:13:15,200
to show that they could make sounds that
are not understandable by a human but

666
00:13:15,200 --> 00:13:15,210
are not understandable by a human but
 

667
00:13:15,210 --> 00:13:18,560
are not understandable by a human but
are recognized as the target phrase that

668
00:13:18,560 --> 00:13:18,570
are recognized as the target phrase that
 

669
00:13:18,570 --> 00:13:19,820
are recognized as the target phrase that
the attacker wants the phone to

670
00:13:19,820 --> 00:13:19,830
the attacker wants the phone to
 

671
00:13:19,830 --> 00:13:22,460
the attacker wants the phone to
recognize it as since then things have

672
00:13:22,460 --> 00:13:22,470
recognize it as since then things have
 

673
00:13:22,470 --> 00:13:24,290
recognize it as since then things have
gotten a little bit better on the

674
00:13:24,290 --> 00:13:24,300
gotten a little bit better on the
 

675
00:13:24,300 --> 00:13:26,990
gotten a little bit better on the
attacker side when worse on the defender

676
00:13:26,990 --> 00:13:27,000
attacker side when worse on the defender
 

677
00:13:27,000 --> 00:13:33,350
attacker side when worse on the defender
side it's become possible to make sounds

678
00:13:33,350 --> 00:13:33,360
side it's become possible to make sounds
 

679
00:13:33,360 --> 00:13:35,990
side it's become possible to make sounds
that sound like normal speech but are

680
00:13:35,990 --> 00:13:36,000
that sound like normal speech but are
 

681
00:13:36,000 --> 00:13:38,570
that sound like normal speech but are
actually interpreted as a different

682
00:13:38,570 --> 00:13:38,580
actually interpreted as a different
 

683
00:13:38,580 --> 00:13:41,600
actually interpreted as a different
sentence than the human here's the level

684
00:13:41,600 --> 00:13:41,610
sentence than the human here's the level
 

685
00:13:41,610 --> 00:13:43,280
sentence than the human here's the level
of perceptibility of the adversarial

686
00:13:43,280 --> 00:13:43,290
of perceptibility of the adversarial
 

687
00:13:43,290 --> 00:13:46,220
of perceptibility of the adversarial
perturbation is still kind of high the

688
00:13:46,220 --> 00:13:46,230
perturbation is still kind of high the
 

689
00:13:46,230 --> 00:13:48,290
perturbation is still kind of high the
when you listen to the recording it

690
00:13:48,290 --> 00:13:48,300
when you listen to the recording it
 

691
00:13:48,300 --> 00:13:50,510
when you listen to the recording it
sounds like there's some noise in the

692
00:13:50,510 --> 00:13:50,520
sounds like there's some noise in the
 

693
00:13:50,520 --> 00:13:53,060
sounds like there's some noise in the
background just like rustling sounds but

694
00:13:53,060 --> 00:13:53,070
background just like rustling sounds but
 

695
00:13:53,070 --> 00:13:54,470
background just like rustling sounds but
those rustling sounds are actually the

696
00:13:54,470 --> 00:13:54,480
those rustling sounds are actually the
 

697
00:13:54,480 --> 00:13:56,000
those rustling sounds are actually the
adversarial perturbation that makes the

698
00:13:56,000 --> 00:13:56,010
adversarial perturbation that makes the
 

699
00:13:56,010 --> 00:13:57,140
adversarial perturbation that makes the
phone hear a completely different

700
00:13:57,140 --> 00:13:57,150
phone hear a completely different
 

701
00:13:57,150 --> 00:13:59,320
phone hear a completely different
sentence yeah that's so fascinating

702
00:13:59,320 --> 00:13:59,330
sentence yeah that's so fascinating
 

703
00:13:59,330 --> 00:14:01,490
sentence yeah that's so fascinating
Peter Norvig mention that you're writing

704
00:14:01,490 --> 00:14:01,500
Peter Norvig mention that you're writing
 

705
00:14:01,500 --> 00:14:03,230
Peter Norvig mention that you're writing
the deep learning chapter for the fourth

706
00:14:03,230 --> 00:14:03,240
the deep learning chapter for the fourth
 

707
00:14:03,240 --> 00:14:05,420
the deep learning chapter for the fourth
edition of the artificial intelligence

708
00:14:05,420 --> 00:14:05,430
edition of the artificial intelligence
 

709
00:14:05,430 --> 00:14:08,540
edition of the artificial intelligence
the modern approach book so how do you

710
00:14:08,540 --> 00:14:08,550
the modern approach book so how do you
 

711
00:14:08,550 --> 00:14:11,300
the modern approach book so how do you
even begin summarizing the field of deep

712
00:14:11,300 --> 00:14:11,310
even begin summarizing the field of deep
 

713
00:14:11,310 --> 00:14:15,949
even begin summarizing the field of deep
learning in a chapter well in my case I

714
00:14:15,949 --> 00:14:15,959
learning in a chapter well in my case I
 

715
00:14:15,959 --> 00:14:17,630
learning in a chapter well in my case I
waited like a year before I actually

716
00:14:17,630 --> 00:14:17,640
waited like a year before I actually
 

717
00:14:17,640 --> 00:14:20,060
waited like a year before I actually
read anything is it

718
00:14:20,060 --> 00:14:20,070
read anything is it
 

719
00:14:20,070 --> 00:14:21,620
read anything is it
even having written a full length

720
00:14:21,620 --> 00:14:21,630
even having written a full length
 

721
00:14:21,630 --> 00:14:24,800
even having written a full length
textbook before it's still pretty

722
00:14:24,800 --> 00:14:24,810
textbook before it's still pretty
 

723
00:14:24,810 --> 00:14:26,720
textbook before it's still pretty
intimidating to try to start writing

724
00:14:26,720 --> 00:14:26,730
intimidating to try to start writing
 

725
00:14:26,730 --> 00:14:30,490
intimidating to try to start writing
just one chapter that covers everything

726
00:14:30,490 --> 00:14:30,500
just one chapter that covers everything
 

727
00:14:30,500 --> 00:14:33,080
just one chapter that covers everything
one thing that helped me make that plan

728
00:14:33,080 --> 00:14:33,090
one thing that helped me make that plan
 

729
00:14:33,090 --> 00:14:34,550
one thing that helped me make that plan
was actually the experience of having

730
00:14:34,550 --> 00:14:34,560
was actually the experience of having
 

731
00:14:34,560 --> 00:14:37,040
was actually the experience of having
ridden the full book before and then

732
00:14:37,040 --> 00:14:37,050
ridden the full book before and then
 

733
00:14:37,050 --> 00:14:39,470
ridden the full book before and then
watching how the field changed after the

734
00:14:39,470 --> 00:14:39,480
watching how the field changed after the
 

735
00:14:39,480 --> 00:14:41,780
watching how the field changed after the
book came out I realized there's a lot

736
00:14:41,780 --> 00:14:41,790
book came out I realized there's a lot
 

737
00:14:41,790 --> 00:14:43,730
book came out I realized there's a lot
of topics that were maybe extraneous in

738
00:14:43,730 --> 00:14:43,740
of topics that were maybe extraneous in
 

739
00:14:43,740 --> 00:14:46,220
of topics that were maybe extraneous in
the first book and just seeing what

740
00:14:46,220 --> 00:14:46,230
the first book and just seeing what
 

741
00:14:46,230 --> 00:14:48,680
the first book and just seeing what
stood the test of a few years of being

742
00:14:48,680 --> 00:14:48,690
stood the test of a few years of being
 

743
00:14:48,690 --> 00:14:51,200
stood the test of a few years of being
published and what seems a little bit

744
00:14:51,200 --> 00:14:51,210
published and what seems a little bit
 

745
00:14:51,210 --> 00:14:52,880
published and what seems a little bit
less important to have included now

746
00:14:52,880 --> 00:14:52,890
less important to have included now
 

747
00:14:52,890 --> 00:14:54,530
less important to have included now
helped me pare down the topics I wanted

748
00:14:54,530 --> 00:14:54,540
helped me pare down the topics I wanted
 

749
00:14:54,540 --> 00:14:57,440
helped me pare down the topics I wanted
to cover for the book it's also really

750
00:14:57,440 --> 00:14:57,450
to cover for the book it's also really
 

751
00:14:57,450 --> 00:14:59,900
to cover for the book it's also really
nice now that the field is kind of

752
00:14:59,900 --> 00:14:59,910
nice now that the field is kind of
 

753
00:14:59,910 --> 00:15:01,520
nice now that the field is kind of
stabilized to the point where some core

754
00:15:01,520 --> 00:15:01,530
stabilized to the point where some core
 

755
00:15:01,530 --> 00:15:03,410
stabilized to the point where some core
ideas from the 1980s are still used

756
00:15:03,410 --> 00:15:03,420
ideas from the 1980s are still used
 

757
00:15:03,420 --> 00:15:05,810
ideas from the 1980s are still used
today when I first started studying

758
00:15:05,810 --> 00:15:05,820
today when I first started studying
 

759
00:15:05,820 --> 00:15:07,520
today when I first started studying
machine learning almost everything from

760
00:15:07,520 --> 00:15:07,530
machine learning almost everything from
 

761
00:15:07,530 --> 00:15:10,070
machine learning almost everything from
the 1980s had been rejected and now some

762
00:15:10,070 --> 00:15:10,080
the 1980s had been rejected and now some
 

763
00:15:10,080 --> 00:15:12,050
the 1980s had been rejected and now some
of it has come back so that stuff that's

764
00:15:12,050 --> 00:15:12,060
of it has come back so that stuff that's
 

765
00:15:12,060 --> 00:15:14,120
of it has come back so that stuff that's
really stood the test of time is what I

766
00:15:14,120 --> 00:15:14,130
really stood the test of time is what I
 

767
00:15:14,130 --> 00:15:17,300
really stood the test of time is what I
focused on putting into the book there's

768
00:15:17,300 --> 00:15:17,310
focused on putting into the book there's
 

769
00:15:17,310 --> 00:15:21,230
focused on putting into the book there's
also I guess two different philosophies

770
00:15:21,230 --> 00:15:21,240
also I guess two different philosophies
 

771
00:15:21,240 --> 00:15:23,270
also I guess two different philosophies
about how you might write a book one

772
00:15:23,270 --> 00:15:23,280
about how you might write a book one
 

773
00:15:23,280 --> 00:15:24,350
about how you might write a book one
philosophy is you try to write a

774
00:15:24,350 --> 00:15:24,360
philosophy is you try to write a
 

775
00:15:24,360 --> 00:15:26,360
philosophy is you try to write a
reference that covers everything and the

776
00:15:26,360 --> 00:15:26,370
reference that covers everything and the
 

777
00:15:26,370 --> 00:15:27,980
reference that covers everything and the
other philosophy is you try to provide a

778
00:15:27,980 --> 00:15:27,990
other philosophy is you try to provide a
 

779
00:15:27,990 --> 00:15:30,320
other philosophy is you try to provide a
high level summary that gives people the

780
00:15:30,320 --> 00:15:30,330
high level summary that gives people the
 

781
00:15:30,330 --> 00:15:32,720
high level summary that gives people the
language to understand a field and tells

782
00:15:32,720 --> 00:15:32,730
language to understand a field and tells
 

783
00:15:32,730 --> 00:15:34,070
language to understand a field and tells
them what the most important concepts

784
00:15:34,070 --> 00:15:34,080
them what the most important concepts
 

785
00:15:34,080 --> 00:15:36,770
them what the most important concepts
are the first deep learning book that I

786
00:15:36,770 --> 00:15:36,780
are the first deep learning book that I
 

787
00:15:36,780 --> 00:15:38,230
are the first deep learning book that I
wrote with Yahshua and Aaron was

788
00:15:38,230 --> 00:15:38,240
wrote with Yahshua and Aaron was
 

789
00:15:38,240 --> 00:15:40,430
wrote with Yahshua and Aaron was
somewhere between the the two

790
00:15:40,430 --> 00:15:40,440
somewhere between the the two
 

791
00:15:40,440 --> 00:15:42,530
somewhere between the the two
philosophies that it's trying to be both

792
00:15:42,530 --> 00:15:42,540
philosophies that it's trying to be both
 

793
00:15:42,540 --> 00:15:45,190
philosophies that it's trying to be both
a reference and an introductory guide

794
00:15:45,190 --> 00:15:45,200
a reference and an introductory guide
 

795
00:15:45,200 --> 00:15:47,810
a reference and an introductory guide
writing this chapter for Russell and

796
00:15:47,810 --> 00:15:47,820
writing this chapter for Russell and
 

797
00:15:47,820 --> 00:15:50,560
writing this chapter for Russell and
Norvig book I was able to focus more on

798
00:15:50,560 --> 00:15:50,570
Norvig book I was able to focus more on
 

799
00:15:50,570 --> 00:15:53,120
Norvig book I was able to focus more on
just a concise introduction of the key

800
00:15:53,120 --> 00:15:53,130
just a concise introduction of the key
 

801
00:15:53,130 --> 00:15:54,470
just a concise introduction of the key
concepts and the language you need to

802
00:15:54,470 --> 00:15:54,480
concepts and the language you need to
 

803
00:15:54,480 --> 00:15:56,420
concepts and the language you need to
read about them more and a lot of cases

804
00:15:56,420 --> 00:15:56,430
read about them more and a lot of cases
 

805
00:15:56,430 --> 00:15:57,970
read about them more and a lot of cases
actually just wrote paragraphs that said

806
00:15:57,970 --> 00:15:57,980
actually just wrote paragraphs that said
 

807
00:15:57,980 --> 00:16:00,260
actually just wrote paragraphs that said
here's a rapidly evolving area that you

808
00:16:00,260 --> 00:16:00,270
here's a rapidly evolving area that you
 

809
00:16:00,270 --> 00:16:02,420
here's a rapidly evolving area that you
should pay attention to it's it's

810
00:16:02,420 --> 00:16:02,430
should pay attention to it's it's
 

811
00:16:02,430 --> 00:16:03,830
should pay attention to it's it's
pointless to try to tell you what the

812
00:16:03,830 --> 00:16:03,840
pointless to try to tell you what the
 

813
00:16:03,840 --> 00:16:07,670
pointless to try to tell you what the
latest and best version of a you know

814
00:16:07,670 --> 00:16:07,680
latest and best version of a you know
 

815
00:16:07,680 --> 00:16:11,090
latest and best version of a you know
learn to learn model is right you know I

816
00:16:11,090 --> 00:16:11,100
learn to learn model is right you know I
 

817
00:16:11,100 --> 00:16:12,710
learn to learn model is right you know I
can I can point you to a paper that's

818
00:16:12,710 --> 00:16:12,720
can I can point you to a paper that's
 

819
00:16:12,720 --> 00:16:14,780
can I can point you to a paper that's
recent right now but there isn't a whole

820
00:16:14,780 --> 00:16:14,790
recent right now but there isn't a whole
 

821
00:16:14,790 --> 00:16:17,660
recent right now but there isn't a whole
lot of a reason to delve into exactly

822
00:16:17,660 --> 00:16:17,670
lot of a reason to delve into exactly
 

823
00:16:17,670 --> 00:16:20,630
lot of a reason to delve into exactly
what's going on with the latest learning

824
00:16:20,630 --> 00:16:20,640
what's going on with the latest learning
 

825
00:16:20,640 --> 00:16:22,670
what's going on with the latest learning
to learn approach or the latest module

826
00:16:22,670 --> 00:16:22,680
to learn approach or the latest module
 

827
00:16:22,680 --> 00:16:24,560
to learn approach or the latest module
produced by learning to learn algorithm

828
00:16:24,560 --> 00:16:24,570
produced by learning to learn algorithm
 

829
00:16:24,570 --> 00:16:26,090
produced by learning to learn algorithm
you should know that learning to learn

830
00:16:26,090 --> 00:16:26,100
you should know that learning to learn
 

831
00:16:26,100 --> 00:16:28,700
you should know that learning to learn
is a thing and that it may very well be

832
00:16:28,700 --> 00:16:28,710
is a thing and that it may very well be
 

833
00:16:28,710 --> 00:16:30,820
is a thing and that it may very well be
the source of the latest and greatest

834
00:16:30,820 --> 00:16:30,830
the source of the latest and greatest
 

835
00:16:30,830 --> 00:16:33,140
the source of the latest and greatest
convolutional net or recurrent net

836
00:16:33,140 --> 00:16:33,150
convolutional net or recurrent net
 

837
00:16:33,150 --> 00:16:34,610
convolutional net or recurrent net
module that you would want to use in

838
00:16:34,610 --> 00:16:34,620
module that you would want to use in
 

839
00:16:34,620 --> 00:16:36,590
module that you would want to use in
your latest project but there isn't a

840
00:16:36,590 --> 00:16:36,600
your latest project but there isn't a
 

841
00:16:36,600 --> 00:16:37,910
your latest project but there isn't a
lot of point in trying to summarize

842
00:16:37,910 --> 00:16:37,920
lot of point in trying to summarize
 

843
00:16:37,920 --> 00:16:41,480
lot of point in trying to summarize
exactly which architecture in which

844
00:16:41,480 --> 00:16:41,490
exactly which architecture in which
 

845
00:16:41,490 --> 00:16:43,010
exactly which architecture in which
learning approach got to which level of

846
00:16:43,010 --> 00:16:43,020
learning approach got to which level of
 

847
00:16:43,020 --> 00:16:43,820
learning approach got to which level of
performance

848
00:16:43,820 --> 00:16:43,830
performance
 

849
00:16:43,830 --> 00:16:47,329
performance
so you maybe focus more on the basics of

850
00:16:47,329 --> 00:16:47,339
so you maybe focus more on the basics of
 

851
00:16:47,339 --> 00:16:50,990
so you maybe focus more on the basics of
the methodology so from back propagation

852
00:16:50,990 --> 00:16:51,000
the methodology so from back propagation
 

853
00:16:51,000 --> 00:16:53,389
the methodology so from back propagation
to feed-forward to recur in your

854
00:16:53,389 --> 00:16:53,399
to feed-forward to recur in your
 

855
00:16:53,399 --> 00:16:54,800
to feed-forward to recur in your
networks convolutional that kind of

856
00:16:54,800 --> 00:16:54,810
networks convolutional that kind of
 

857
00:16:54,810 --> 00:16:57,560
networks convolutional that kind of
thing yeah yeah so if I were to ask you

858
00:16:57,560 --> 00:16:57,570
thing yeah yeah so if I were to ask you
 

859
00:16:57,570 --> 00:17:00,530
thing yeah yeah so if I were to ask you
I remember I took algorithms and data

860
00:17:00,530 --> 00:17:00,540
I remember I took algorithms and data
 

861
00:17:00,540 --> 00:17:02,920
I remember I took algorithms and data
structures algorithm there of course

862
00:17:02,920 --> 00:17:02,930
structures algorithm there of course
 

863
00:17:02,930 --> 00:17:07,309
structures algorithm there of course
remember the professor asked what is an

864
00:17:07,309 --> 00:17:07,319
remember the professor asked what is an
 

865
00:17:07,319 --> 00:17:11,390
remember the professor asked what is an
algorithm and yelled at everybody in a

866
00:17:11,390 --> 00:17:11,400
algorithm and yelled at everybody in a
 

867
00:17:11,400 --> 00:17:13,699
algorithm and yelled at everybody in a
good way that nobody was answering it

868
00:17:13,699 --> 00:17:13,709
good way that nobody was answering it
 

869
00:17:13,709 --> 00:17:15,079
good way that nobody was answering it
correctly everybody knew what the alkyl

870
00:17:15,079 --> 00:17:15,089
correctly everybody knew what the alkyl
 

871
00:17:15,089 --> 00:17:16,819
correctly everybody knew what the alkyl
it was graduate course everybody knew

872
00:17:16,819 --> 00:17:16,829
it was graduate course everybody knew
 

873
00:17:16,829 --> 00:17:18,530
it was graduate course everybody knew
what an algorithm was but they weren't

874
00:17:18,530 --> 00:17:18,540
what an algorithm was but they weren't
 

875
00:17:18,540 --> 00:17:21,049
what an algorithm was but they weren't
able to answer it well let me ask you in

876
00:17:21,049 --> 00:17:21,059
able to answer it well let me ask you in
 

877
00:17:21,059 --> 00:17:23,829
able to answer it well let me ask you in
that same spirit what is deep learning I

878
00:17:23,829 --> 00:17:23,839
that same spirit what is deep learning I
 

879
00:17:23,839 --> 00:17:28,030
that same spirit what is deep learning I
would say deep learning is any kind of

880
00:17:28,030 --> 00:17:28,040
would say deep learning is any kind of
 

881
00:17:28,040 --> 00:17:31,700
would say deep learning is any kind of
machine learning that involves learning

882
00:17:31,700 --> 00:17:31,710
machine learning that involves learning
 

883
00:17:31,710 --> 00:17:35,360
machine learning that involves learning
parameters of more than one consecutive

884
00:17:35,360 --> 00:17:35,370
parameters of more than one consecutive
 

885
00:17:35,370 --> 00:17:39,200
parameters of more than one consecutive
step so that I mean shallow learning is

886
00:17:39,200 --> 00:17:39,210
step so that I mean shallow learning is
 

887
00:17:39,210 --> 00:17:41,330
step so that I mean shallow learning is
things where you learn a lot of

888
00:17:41,330 --> 00:17:41,340
things where you learn a lot of
 

889
00:17:41,340 --> 00:17:43,850
things where you learn a lot of
operations that happen in parallel you

890
00:17:43,850 --> 00:17:43,860
operations that happen in parallel you
 

891
00:17:43,860 --> 00:17:45,380
operations that happen in parallel you
might have a system that makes multiple

892
00:17:45,380 --> 00:17:45,390
might have a system that makes multiple
 

893
00:17:45,390 --> 00:17:48,980
might have a system that makes multiple
steps like you might have had designed

894
00:17:48,980 --> 00:17:48,990
steps like you might have had designed
 

895
00:17:48,990 --> 00:17:51,770
steps like you might have had designed
feature extractors but really only one

896
00:17:51,770 --> 00:17:51,780
feature extractors but really only one
 

897
00:17:51,780 --> 00:17:53,120
feature extractors but really only one
step is learned deep learning is

898
00:17:53,120 --> 00:17:53,130
step is learned deep learning is
 

899
00:17:53,130 --> 00:17:55,159
step is learned deep learning is
anything where you have multiple

900
00:17:55,159 --> 00:17:55,169
anything where you have multiple
 

901
00:17:55,169 --> 00:17:58,190
anything where you have multiple
operations in sequence and that includes

902
00:17:58,190 --> 00:17:58,200
operations in sequence and that includes
 

903
00:17:58,200 --> 00:17:59,480
operations in sequence and that includes
the things that are really popular today

904
00:17:59,480 --> 00:17:59,490
the things that are really popular today
 

905
00:17:59,490 --> 00:18:01,370
the things that are really popular today
like convolutional networks and

906
00:18:01,370 --> 00:18:01,380
like convolutional networks and
 

907
00:18:01,380 --> 00:18:04,370
like convolutional networks and
recurrent networks but it also includes

908
00:18:04,370 --> 00:18:04,380
recurrent networks but it also includes
 

909
00:18:04,380 --> 00:18:05,740
recurrent networks but it also includes
some of the things that have died out

910
00:18:05,740 --> 00:18:05,750
some of the things that have died out
 

911
00:18:05,750 --> 00:18:09,409
some of the things that have died out
like Bolton machines where we weren't

912
00:18:09,409 --> 00:18:09,419
like Bolton machines where we weren't
 

913
00:18:09,419 --> 00:18:12,620
like Bolton machines where we weren't
using back propagation today I hear a

914
00:18:12,620 --> 00:18:12,630
using back propagation today I hear a
 

915
00:18:12,630 --> 00:18:14,590
using back propagation today I hear a
lot of people define deep learning as

916
00:18:14,590 --> 00:18:14,600
lot of people define deep learning as
 

917
00:18:14,600 --> 00:18:19,330
lot of people define deep learning as
gradient descent applied to these

918
00:18:19,330 --> 00:18:19,340
gradient descent applied to these
 

919
00:18:19,340 --> 00:18:23,120
gradient descent applied to these
differentiable functions and I think

920
00:18:23,120 --> 00:18:23,130
differentiable functions and I think
 

921
00:18:23,130 --> 00:18:24,620
differentiable functions and I think
that's a legitimate usage of the term

922
00:18:24,620 --> 00:18:24,630
that's a legitimate usage of the term
 

923
00:18:24,630 --> 00:18:26,060
that's a legitimate usage of the term
it's just different from the way that I

924
00:18:26,060 --> 00:18:26,070
it's just different from the way that I
 

925
00:18:26,070 --> 00:18:28,400
it's just different from the way that I
use the term myself so what's an example

926
00:18:28,400 --> 00:18:28,410
use the term myself so what's an example
 

927
00:18:28,410 --> 00:18:32,780
use the term myself so what's an example
of deep learning that is not gradient

928
00:18:32,780 --> 00:18:32,790
of deep learning that is not gradient
 

929
00:18:32,790 --> 00:18:35,000
of deep learning that is not gradient
descent on differentiable functions in

930
00:18:35,000 --> 00:18:35,010
descent on differentiable functions in
 

931
00:18:35,010 --> 00:18:37,580
descent on differentiable functions in
your I mean not specifically perhaps but

932
00:18:37,580 --> 00:18:37,590
your I mean not specifically perhaps but
 

933
00:18:37,590 --> 00:18:40,460
your I mean not specifically perhaps but
more even looking into the future what's

934
00:18:40,460 --> 00:18:40,470
more even looking into the future what's
 

935
00:18:40,470 --> 00:18:43,370
more even looking into the future what's
your thought about that space of

936
00:18:43,370 --> 00:18:43,380
your thought about that space of
 

937
00:18:43,380 --> 00:18:45,320
your thought about that space of
approaches yeah so I tend to think of

938
00:18:45,320 --> 00:18:45,330
approaches yeah so I tend to think of
 

939
00:18:45,330 --> 00:18:46,430
approaches yeah so I tend to think of
machine learning algorithms as

940
00:18:46,430 --> 00:18:46,440
machine learning algorithms as
 

941
00:18:46,440 --> 00:18:48,890
machine learning algorithms as
decomposed into really three different

942
00:18:48,890 --> 00:18:48,900
decomposed into really three different
 

943
00:18:48,900 --> 00:18:51,799
decomposed into really three different
pieces there's the model which can be

944
00:18:51,799 --> 00:18:51,809
pieces there's the model which can be
 

945
00:18:51,809 --> 00:18:53,540
pieces there's the model which can be
something like a neural nut or a Bolton

946
00:18:53,540 --> 00:18:53,550
something like a neural nut or a Bolton
 

947
00:18:53,550 --> 00:18:56,990
something like a neural nut or a Bolton
machine or a recurrent model and I

948
00:18:56,990 --> 00:18:57,000
machine or a recurrent model and I
 

949
00:18:57,000 --> 00:18:57,920
machine or a recurrent model and I
basically just described

950
00:18:57,920 --> 00:18:57,930
basically just described
 

951
00:18:57,930 --> 00:19:00,049
basically just described
how do you take data and how do you take

952
00:19:00,049 --> 00:19:00,059
how do you take data and how do you take
 

953
00:19:00,059 --> 00:19:03,110
how do you take data and how do you take
parameters and you know what function do

954
00:19:03,110 --> 00:19:03,120
parameters and you know what function do
 

955
00:19:03,120 --> 00:19:04,760
parameters and you know what function do
you use to make a prediction given the

956
00:19:04,760 --> 00:19:04,770
you use to make a prediction given the
 

957
00:19:04,770 --> 00:19:07,790
you use to make a prediction given the
data and the parameters another piece of

958
00:19:07,790 --> 00:19:07,800
data and the parameters another piece of
 

959
00:19:07,800 --> 00:19:10,299
data and the parameters another piece of
the learning algorithm is the

960
00:19:10,299 --> 00:19:10,309
the learning algorithm is the
 

961
00:19:10,309 --> 00:19:13,490
the learning algorithm is the
optimization algorithm or not every

962
00:19:13,490 --> 00:19:13,500
optimization algorithm or not every
 

963
00:19:13,500 --> 00:19:14,960
optimization algorithm or not every
algorithm can be really described in

964
00:19:14,960 --> 00:19:14,970
algorithm can be really described in
 

965
00:19:14,970 --> 00:19:16,820
algorithm can be really described in
terms of optimization but what's the

966
00:19:16,820 --> 00:19:16,830
terms of optimization but what's the
 

967
00:19:16,830 --> 00:19:18,980
terms of optimization but what's the
algorithm for updating the parameters or

968
00:19:18,980 --> 00:19:18,990
algorithm for updating the parameters or
 

969
00:19:18,990 --> 00:19:20,750
algorithm for updating the parameters or
updating whatever the state of the

970
00:19:20,750 --> 00:19:20,760
updating whatever the state of the
 

971
00:19:20,760 --> 00:19:25,010
updating whatever the state of the
network is and then the the last part is

972
00:19:25,010 --> 00:19:25,020
network is and then the the last part is
 

973
00:19:25,020 --> 00:19:26,690
network is and then the the last part is
the the data set like how do you

974
00:19:26,690 --> 00:19:26,700
the the data set like how do you
 

975
00:19:26,700 --> 00:19:29,690
the the data set like how do you
actually represent the world as it comes

976
00:19:29,690 --> 00:19:29,700
actually represent the world as it comes
 

977
00:19:29,700 --> 00:19:33,320
actually represent the world as it comes
into your machine learning system so I

978
00:19:33,320 --> 00:19:33,330
into your machine learning system so I
 

979
00:19:33,330 --> 00:19:35,390
into your machine learning system so I
think of deep learning as telling us

980
00:19:35,390 --> 00:19:35,400
think of deep learning as telling us
 

981
00:19:35,400 --> 00:19:37,760
think of deep learning as telling us
something about what does the model look

982
00:19:37,760 --> 00:19:37,770
something about what does the model look
 

983
00:19:37,770 --> 00:19:41,090
something about what does the model look
like and basically to qualify as deep I

984
00:19:41,090 --> 00:19:41,100
like and basically to qualify as deep I
 

985
00:19:41,100 --> 00:19:43,549
like and basically to qualify as deep I
say that it just has to have multiple

986
00:19:43,549 --> 00:19:43,559
say that it just has to have multiple
 

987
00:19:43,559 --> 00:19:46,580
say that it just has to have multiple
layers that can be multiple steps in a

988
00:19:46,580 --> 00:19:46,590
layers that can be multiple steps in a
 

989
00:19:46,590 --> 00:19:48,620
layers that can be multiple steps in a
feed-forward differentiable computation

990
00:19:48,620 --> 00:19:48,630
feed-forward differentiable computation
 

991
00:19:48,630 --> 00:19:50,750
feed-forward differentiable computation
that can be multiple layers in a

992
00:19:50,750 --> 00:19:50,760
that can be multiple layers in a
 

993
00:19:50,760 --> 00:19:52,610
that can be multiple layers in a
graphical model there's a lot of ways

994
00:19:52,610 --> 00:19:52,620
graphical model there's a lot of ways
 

995
00:19:52,620 --> 00:19:54,020
graphical model there's a lot of ways
that you could satisfy me that something

996
00:19:54,020 --> 00:19:54,030
that you could satisfy me that something
 

997
00:19:54,030 --> 00:19:56,419
that you could satisfy me that something
has multiple steps that are each

998
00:19:56,419 --> 00:19:56,429
has multiple steps that are each
 

999
00:19:56,429 --> 00:19:58,700
has multiple steps that are each
parameterised separately

1000
00:19:58,700 --> 00:19:58,710
parameterised separately
 

1001
00:19:58,710 --> 00:20:00,350
parameterised separately
I think of gradient descent as being all

1002
00:20:00,350 --> 00:20:00,360
I think of gradient descent as being all
 

1003
00:20:00,360 --> 00:20:02,240
I think of gradient descent as being all
about that other piece the how do you

1004
00:20:02,240 --> 00:20:02,250
about that other piece the how do you
 

1005
00:20:02,250 --> 00:20:04,370
about that other piece the how do you
actually update the parameters piece so

1006
00:20:04,370 --> 00:20:04,380
actually update the parameters piece so
 

1007
00:20:04,380 --> 00:20:06,140
actually update the parameters piece so
you can imagine having a deep model like

1008
00:20:06,140 --> 00:20:06,150
you can imagine having a deep model like
 

1009
00:20:06,150 --> 00:20:08,270
you can imagine having a deep model like
a convolutional net and training it with

1010
00:20:08,270 --> 00:20:08,280
a convolutional net and training it with
 

1011
00:20:08,280 --> 00:20:10,340
a convolutional net and training it with
something like evolution or a genetic

1012
00:20:10,340 --> 00:20:10,350
something like evolution or a genetic
 

1013
00:20:10,350 --> 00:20:12,410
something like evolution or a genetic
algorithm and I would say that still

1014
00:20:12,410 --> 00:20:12,420
algorithm and I would say that still
 

1015
00:20:12,420 --> 00:20:15,350
algorithm and I would say that still
qualifies as deep learning and then in

1016
00:20:15,350 --> 00:20:15,360
qualifies as deep learning and then in
 

1017
00:20:15,360 --> 00:20:16,820
qualifies as deep learning and then in
terms of models that aren't necessarily

1018
00:20:16,820 --> 00:20:16,830
terms of models that aren't necessarily
 

1019
00:20:16,830 --> 00:20:18,200
terms of models that aren't necessarily
differentiable

1020
00:20:18,200 --> 00:20:18,210
differentiable
 

1021
00:20:18,210 --> 00:20:20,450
differentiable
I guess Boltzmann machines are probably

1022
00:20:20,450 --> 00:20:20,460
I guess Boltzmann machines are probably
 

1023
00:20:20,460 --> 00:20:24,290
I guess Boltzmann machines are probably
the main example of something where you

1024
00:20:24,290 --> 00:20:24,300
the main example of something where you
 

1025
00:20:24,300 --> 00:20:25,730
the main example of something where you
can't really take a derivative and use

1026
00:20:25,730 --> 00:20:25,740
can't really take a derivative and use
 

1027
00:20:25,740 --> 00:20:28,610
can't really take a derivative and use
that for the learning process but you

1028
00:20:28,610 --> 00:20:28,620
that for the learning process but you
 

1029
00:20:28,620 --> 00:20:30,880
that for the learning process but you
you can still argue that the model has

1030
00:20:30,880 --> 00:20:30,890
you can still argue that the model has
 

1031
00:20:30,890 --> 00:20:33,440
you can still argue that the model has
many steps of processing that it applies

1032
00:20:33,440 --> 00:20:33,450
many steps of processing that it applies
 

1033
00:20:33,450 --> 00:20:35,870
many steps of processing that it applies
when you run inference in the model so

1034
00:20:35,870 --> 00:20:35,880
when you run inference in the model so
 

1035
00:20:35,880 --> 00:20:37,700
when you run inference in the model so
that's the steps of processing that's

1036
00:20:37,700 --> 00:20:37,710
that's the steps of processing that's
 

1037
00:20:37,710 --> 00:20:40,430
that's the steps of processing that's
key so geoff hinton suggests that we

1038
00:20:40,430 --> 00:20:40,440
key so geoff hinton suggests that we
 

1039
00:20:40,440 --> 00:20:42,620
key so geoff hinton suggests that we
need to throw away back prop back

1040
00:20:42,620 --> 00:20:42,630
need to throw away back prop back
 

1041
00:20:42,630 --> 00:20:45,110
need to throw away back prop back
propagation and start all over what do

1042
00:20:45,110 --> 00:20:45,120
propagation and start all over what do
 

1043
00:20:45,120 --> 00:20:47,030
propagation and start all over what do
you think about that what could an

1044
00:20:47,030 --> 00:20:47,040
you think about that what could an
 

1045
00:20:47,040 --> 00:20:49,310
you think about that what could an
alternative direction of training nil

1046
00:20:49,310 --> 00:20:49,320
alternative direction of training nil
 

1047
00:20:49,320 --> 00:20:51,770
alternative direction of training nil
networks look like I don't know that

1048
00:20:51,770 --> 00:20:51,780
networks look like I don't know that
 

1049
00:20:51,780 --> 00:20:53,480
networks look like I don't know that
back propagation is going to go away

1050
00:20:53,480 --> 00:20:53,490
back propagation is going to go away
 

1051
00:20:53,490 --> 00:20:56,049
back propagation is going to go away
entirely most of this time when we

1052
00:20:56,049 --> 00:20:56,059
entirely most of this time when we
 

1053
00:20:56,059 --> 00:20:58,340
entirely most of this time when we
decide that a machine learning algorithm

1054
00:20:58,340 --> 00:20:58,350
decide that a machine learning algorithm
 

1055
00:20:58,350 --> 00:21:01,850
decide that a machine learning algorithm
isn't on the critical path to research

1056
00:21:01,850 --> 00:21:01,860
isn't on the critical path to research
 

1057
00:21:01,860 --> 00:21:04,190
isn't on the critical path to research
for improving AI the algorithm doesn't

1058
00:21:04,190 --> 00:21:04,200
for improving AI the algorithm doesn't
 

1059
00:21:04,200 --> 00:21:06,080
for improving AI the algorithm doesn't
die it just becomes used for some

1060
00:21:06,080 --> 00:21:06,090
die it just becomes used for some
 

1061
00:21:06,090 --> 00:21:08,380
die it just becomes used for some
specialized set of things

1062
00:21:08,380 --> 00:21:08,390
specialized set of things
 

1063
00:21:08,390 --> 00:21:09,700
specialized set of things
a lot of algorithms like logistic

1064
00:21:09,700 --> 00:21:09,710
a lot of algorithms like logistic
 

1065
00:21:09,710 --> 00:21:12,250
a lot of algorithms like logistic
regression don't seem that exciting to

1066
00:21:12,250 --> 00:21:12,260
regression don't seem that exciting to
 

1067
00:21:12,260 --> 00:21:14,890
regression don't seem that exciting to
AI researchers who are working on things

1068
00:21:14,890 --> 00:21:14,900
AI researchers who are working on things
 

1069
00:21:14,900 --> 00:21:17,289
AI researchers who are working on things
like speech recognition or autonomous

1070
00:21:17,289 --> 00:21:17,299
like speech recognition or autonomous
 

1071
00:21:17,299 --> 00:21:19,419
like speech recognition or autonomous
cars today but there's still a lot of

1072
00:21:19,419 --> 00:21:19,429
cars today but there's still a lot of
 

1073
00:21:19,429 --> 00:21:21,400
cars today but there's still a lot of
use for logistic regression and things

1074
00:21:21,400 --> 00:21:21,410
use for logistic regression and things
 

1075
00:21:21,410 --> 00:21:23,919
use for logistic regression and things
like analyzing really noisy data and

1076
00:21:23,919 --> 00:21:23,929
like analyzing really noisy data and
 

1077
00:21:23,929 --> 00:21:27,520
like analyzing really noisy data and
medicine and finance or making really

1078
00:21:27,520 --> 00:21:27,530
medicine and finance or making really
 

1079
00:21:27,530 --> 00:21:29,590
medicine and finance or making really
rapid predictions in really time-limited

1080
00:21:29,590 --> 00:21:29,600
rapid predictions in really time-limited
 

1081
00:21:29,600 --> 00:21:32,020
rapid predictions in really time-limited
contexts so I think I think back

1082
00:21:32,020 --> 00:21:32,030
contexts so I think I think back
 

1083
00:21:32,030 --> 00:21:33,549
contexts so I think I think back
propagation and gradient descent are

1084
00:21:33,549 --> 00:21:33,559
propagation and gradient descent are
 

1085
00:21:33,559 --> 00:21:36,669
propagation and gradient descent are
around to stay but they may not end up

1086
00:21:36,669 --> 00:21:36,679
around to stay but they may not end up
 

1087
00:21:36,679 --> 00:21:39,669
around to stay but they may not end up
being everything that we need to get to

1088
00:21:39,669 --> 00:21:39,679
being everything that we need to get to
 

1089
00:21:39,679 --> 00:21:42,460
being everything that we need to get to
real human level or superhuman AI are

1090
00:21:42,460 --> 00:21:42,470
real human level or superhuman AI are
 

1091
00:21:42,470 --> 00:21:45,210
real human level or superhuman AI are
you optimistic about us discovering

1092
00:21:45,210 --> 00:21:45,220
you optimistic about us discovering
 

1093
00:21:45,220 --> 00:21:48,039
you optimistic about us discovering
you know back propagation has been

1094
00:21:48,039 --> 00:21:48,049
you know back propagation has been
 

1095
00:21:48,049 --> 00:21:49,780
you know back propagation has been
around for a few decades

1096
00:21:49,780 --> 00:21:49,790
around for a few decades
 

1097
00:21:49,790 --> 00:21:53,560
around for a few decades
so I optimistic bus about us as a

1098
00:21:53,560 --> 00:21:53,570
so I optimistic bus about us as a
 

1099
00:21:53,570 --> 00:21:55,000
so I optimistic bus about us as a
community being able to discover

1100
00:21:55,000 --> 00:21:55,010
community being able to discover
 

1101
00:21:55,010 --> 00:21:58,240
community being able to discover
something better yeah I am I think I

1102
00:21:58,240 --> 00:21:58,250
something better yeah I am I think I
 

1103
00:21:58,250 --> 00:22:00,549
something better yeah I am I think I
think we likely will find something that

1104
00:22:00,549 --> 00:22:00,559
think we likely will find something that
 

1105
00:22:00,559 --> 00:22:02,740
think we likely will find something that
works better you could imagine things

1106
00:22:02,740 --> 00:22:02,750
works better you could imagine things
 

1107
00:22:02,750 --> 00:22:06,700
works better you could imagine things
like having stacks of models where some

1108
00:22:06,700 --> 00:22:06,710
like having stacks of models where some
 

1109
00:22:06,710 --> 00:22:07,930
like having stacks of models where some
of the lower level models predict

1110
00:22:07,930 --> 00:22:07,940
of the lower level models predict
 

1111
00:22:07,940 --> 00:22:09,640
of the lower level models predict
parameters of the higher level models

1112
00:22:09,640 --> 00:22:09,650
parameters of the higher level models
 

1113
00:22:09,650 --> 00:22:12,310
parameters of the higher level models
and so at the top level you're not

1114
00:22:12,310 --> 00:22:12,320
and so at the top level you're not
 

1115
00:22:12,320 --> 00:22:13,330
and so at the top level you're not
learning in terms of literally

1116
00:22:13,330 --> 00:22:13,340
learning in terms of literally
 

1117
00:22:13,340 --> 00:22:14,799
learning in terms of literally
calculating gradients but just

1118
00:22:14,799 --> 00:22:14,809
calculating gradients but just
 

1119
00:22:14,809 --> 00:22:16,600
calculating gradients but just
predicting how different values will

1120
00:22:16,600 --> 00:22:16,610
predicting how different values will
 

1121
00:22:16,610 --> 00:22:18,730
predicting how different values will
perform you can kind of see that already

1122
00:22:18,730 --> 00:22:18,740
perform you can kind of see that already
 

1123
00:22:18,740 --> 00:22:20,919
perform you can kind of see that already
in some areas like Bayesian optimization

1124
00:22:20,919 --> 00:22:20,929
in some areas like Bayesian optimization
 

1125
00:22:20,929 --> 00:22:23,110
in some areas like Bayesian optimization
where you have a Gaussian process that

1126
00:22:23,110 --> 00:22:23,120
where you have a Gaussian process that
 

1127
00:22:23,120 --> 00:22:24,490
where you have a Gaussian process that
predicts how well different parameter

1128
00:22:24,490 --> 00:22:24,500
predicts how well different parameter
 

1129
00:22:24,500 --> 00:22:26,560
predicts how well different parameter
values will perform we already used

1130
00:22:26,560 --> 00:22:26,570
values will perform we already used
 

1131
00:22:26,570 --> 00:22:28,060
values will perform we already used
those kinds of algorithms for things

1132
00:22:28,060 --> 00:22:28,070
those kinds of algorithms for things
 

1133
00:22:28,070 --> 00:22:30,520
those kinds of algorithms for things
like hyper parameter optimization and in

1134
00:22:30,520 --> 00:22:30,530
like hyper parameter optimization and in
 

1135
00:22:30,530 --> 00:22:31,750
like hyper parameter optimization and in
general we know a lot of things other

1136
00:22:31,750 --> 00:22:31,760
general we know a lot of things other
 

1137
00:22:31,760 --> 00:22:33,190
general we know a lot of things other
than back prep that work really well for

1138
00:22:33,190 --> 00:22:33,200
than back prep that work really well for
 

1139
00:22:33,200 --> 00:22:35,560
than back prep that work really well for
specific problems the main thing we

1140
00:22:35,560 --> 00:22:35,570
specific problems the main thing we
 

1141
00:22:35,570 --> 00:22:38,260
specific problems the main thing we
haven't found is a way of taking one of

1142
00:22:38,260 --> 00:22:38,270
haven't found is a way of taking one of
 

1143
00:22:38,270 --> 00:22:40,510
haven't found is a way of taking one of
these other non back based algorithms

1144
00:22:40,510 --> 00:22:40,520
these other non back based algorithms
 

1145
00:22:40,520 --> 00:22:42,669
these other non back based algorithms
and having it really advanced the

1146
00:22:42,669 --> 00:22:42,679
and having it really advanced the
 

1147
00:22:42,679 --> 00:22:43,360
and having it really advanced the
state-of-the-art

1148
00:22:43,360 --> 00:22:43,370
state-of-the-art
 

1149
00:22:43,370 --> 00:22:47,289
state-of-the-art
on an AI level problem right but I

1150
00:22:47,289 --> 00:22:47,299
on an AI level problem right but I
 

1151
00:22:47,299 --> 00:22:49,270
on an AI level problem right but I
wouldn't be surprised if eventually we

1152
00:22:49,270 --> 00:22:49,280
wouldn't be surprised if eventually we
 

1153
00:22:49,280 --> 00:22:50,919
wouldn't be surprised if eventually we
find that some of these algorithms that

1154
00:22:50,919 --> 00:22:50,929
find that some of these algorithms that
 

1155
00:22:50,929 --> 00:22:52,870
find that some of these algorithms that
even the ones that already exists not

1156
00:22:52,870 --> 00:22:52,880
even the ones that already exists not
 

1157
00:22:52,880 --> 00:22:54,850
even the ones that already exists not
even necessarily a new one we might find

1158
00:22:54,850 --> 00:22:54,860
even necessarily a new one we might find
 

1159
00:22:54,860 --> 00:22:58,600
even necessarily a new one we might find
some way of customizing one of these

1160
00:22:58,600 --> 00:22:58,610
some way of customizing one of these
 

1161
00:22:58,610 --> 00:22:59,890
some way of customizing one of these
algorithms to do something really

1162
00:22:59,890 --> 00:22:59,900
algorithms to do something really
 

1163
00:22:59,900 --> 00:23:02,560
algorithms to do something really
interesting at the level of cognition or

1164
00:23:02,560 --> 00:23:02,570
interesting at the level of cognition or
 

1165
00:23:02,570 --> 00:23:07,090
interesting at the level of cognition or
or the the level of I think one system

1166
00:23:07,090 --> 00:23:07,100
or the the level of I think one system
 

1167
00:23:07,100 --> 00:23:08,860
or the the level of I think one system
that we really don't have working quite

1168
00:23:08,860 --> 00:23:08,870
that we really don't have working quite
 

1169
00:23:08,870 --> 00:23:13,060
that we really don't have working quite
right yet is like short-term memory we

1170
00:23:13,060 --> 00:23:13,070
right yet is like short-term memory we
 

1171
00:23:13,070 --> 00:23:14,830
right yet is like short-term memory we
have things like LST M's they're called

1172
00:23:14,830 --> 00:23:14,840
have things like LST M's they're called
 

1173
00:23:14,840 --> 00:23:16,600
have things like LST M's they're called
long short-term memory

1174
00:23:16,600 --> 00:23:16,610
long short-term memory
 

1175
00:23:16,610 --> 00:23:19,510
long short-term memory
they still don't do quite what a human

1176
00:23:19,510 --> 00:23:19,520
they still don't do quite what a human
 

1177
00:23:19,520 --> 00:23:22,210
they still don't do quite what a human
does with short-term memory

1178
00:23:22,210 --> 00:23:22,220
does with short-term memory
 

1179
00:23:22,220 --> 00:23:25,840
does with short-term memory
like gradient descent to learn a

1180
00:23:25,840 --> 00:23:25,850
like gradient descent to learn a
 

1181
00:23:25,850 --> 00:23:28,330
like gradient descent to learn a
specific fact has to do multiple steps

1182
00:23:28,330 --> 00:23:28,340
specific fact has to do multiple steps
 

1183
00:23:28,340 --> 00:23:31,570
specific fact has to do multiple steps
on that fact like if I I tell you the

1184
00:23:31,570 --> 00:23:31,580
on that fact like if I I tell you the
 

1185
00:23:31,580 --> 00:23:34,509
on that fact like if I I tell you the
meeting today is at 3 p.m. I don't need

1186
00:23:34,509 --> 00:23:34,519
meeting today is at 3 p.m. I don't need
 

1187
00:23:34,519 --> 00:23:35,950
meeting today is at 3 p.m. I don't need
to say over and over again it's at 3

1188
00:23:35,950 --> 00:23:35,960
to say over and over again it's at 3
 

1189
00:23:35,960 --> 00:23:37,869
to say over and over again it's at 3
p.m. it's not 3 p.m. it's at 3 p.m. it's

1190
00:23:37,869 --> 00:23:37,879
p.m. it's not 3 p.m. it's at 3 p.m. it's
 

1191
00:23:37,879 --> 00:23:39,700
p.m. it's not 3 p.m. it's at 3 p.m. it's
a 3 p.m. right for you to do a gradient

1192
00:23:39,700 --> 00:23:39,710
a 3 p.m. right for you to do a gradient
 

1193
00:23:39,710 --> 00:23:41,080
a 3 p.m. right for you to do a gradient
step on each one you just hear it once

1194
00:23:41,080 --> 00:23:41,090
step on each one you just hear it once
 

1195
00:23:41,090 --> 00:23:43,659
step on each one you just hear it once
and you remember it there's been some

1196
00:23:43,659 --> 00:23:43,669
and you remember it there's been some
 

1197
00:23:43,669 --> 00:23:47,049
and you remember it there's been some
work on things like self attention and

1198
00:23:47,049 --> 00:23:47,059
work on things like self attention and
 

1199
00:23:47,059 --> 00:23:48,490
work on things like self attention and
attention like mechanisms like the

1200
00:23:48,490 --> 00:23:48,500
attention like mechanisms like the
 

1201
00:23:48,500 --> 00:23:51,580
attention like mechanisms like the
neural Turing machine that can write to

1202
00:23:51,580 --> 00:23:51,590
neural Turing machine that can write to
 

1203
00:23:51,590 --> 00:23:53,320
neural Turing machine that can write to
memory cells and update themselves with

1204
00:23:53,320 --> 00:23:53,330
memory cells and update themselves with
 

1205
00:23:53,330 --> 00:23:55,180
memory cells and update themselves with
facts like that right away but I don't

1206
00:23:55,180 --> 00:23:55,190
facts like that right away but I don't
 

1207
00:23:55,190 --> 00:23:56,909
facts like that right away but I don't
think we've really nailed it yet and

1208
00:23:56,909 --> 00:23:56,919
think we've really nailed it yet and
 

1209
00:23:56,919 --> 00:24:00,060
think we've really nailed it yet and
that's one area where I'd imagine that

1210
00:24:00,060 --> 00:24:00,070
that's one area where I'd imagine that
 

1211
00:24:00,070 --> 00:24:02,740
that's one area where I'd imagine that
new optimization algorithms are

1212
00:24:02,740 --> 00:24:02,750
new optimization algorithms are
 

1213
00:24:02,750 --> 00:24:03,909
new optimization algorithms are
different ways of applying existing

1214
00:24:03,909 --> 00:24:03,919
different ways of applying existing
 

1215
00:24:03,919 --> 00:24:07,029
different ways of applying existing
optimization algorithms could give us a

1216
00:24:07,029 --> 00:24:07,039
optimization algorithms could give us a
 

1217
00:24:07,039 --> 00:24:09,279
optimization algorithms could give us a
way of just lightning-fast updating the

1218
00:24:09,279 --> 00:24:09,289
way of just lightning-fast updating the
 

1219
00:24:09,289 --> 00:24:11,289
way of just lightning-fast updating the
state of a machine learning system to

1220
00:24:11,289 --> 00:24:11,299
state of a machine learning system to
 

1221
00:24:11,299 --> 00:24:13,990
state of a machine learning system to
contain a specific fact like that

1222
00:24:13,990 --> 00:24:14,000
contain a specific fact like that
 

1223
00:24:14,000 --> 00:24:15,279
contain a specific fact like that
without needing to have it presented

1224
00:24:15,279 --> 00:24:15,289
without needing to have it presented
 

1225
00:24:15,289 --> 00:24:17,649
without needing to have it presented
over and over and over again so some of

1226
00:24:17,649 --> 00:24:17,659
over and over and over again so some of
 

1227
00:24:17,659 --> 00:24:20,409
over and over and over again so some of
the success of symbolic systems in the

1228
00:24:20,409 --> 00:24:20,419
the success of symbolic systems in the
 

1229
00:24:20,419 --> 00:24:23,230
the success of symbolic systems in the
80s is they were able to assemble these

1230
00:24:23,230 --> 00:24:23,240
80s is they were able to assemble these
 

1231
00:24:23,240 --> 00:24:27,220
80s is they were able to assemble these
kinds of facts better but dude there's a

1232
00:24:27,220 --> 00:24:27,230
kinds of facts better but dude there's a
 

1233
00:24:27,230 --> 00:24:29,470
kinds of facts better but dude there's a
lot of expert input required and it's

1234
00:24:29,470 --> 00:24:29,480
lot of expert input required and it's
 

1235
00:24:29,480 --> 00:24:31,539
lot of expert input required and it's
very limited in that sense do you ever

1236
00:24:31,539 --> 00:24:31,549
very limited in that sense do you ever
 

1237
00:24:31,549 --> 00:24:34,990
very limited in that sense do you ever
look back to that as something that will

1238
00:24:34,990 --> 00:24:35,000
look back to that as something that will
 

1239
00:24:35,000 --> 00:24:36,789
look back to that as something that will
have to return to eventually sort of

1240
00:24:36,789 --> 00:24:36,799
have to return to eventually sort of
 

1241
00:24:36,799 --> 00:24:38,879
have to return to eventually sort of
dust off the book from the shelf and

1242
00:24:38,879 --> 00:24:38,889
dust off the book from the shelf and
 

1243
00:24:38,889 --> 00:24:41,100
dust off the book from the shelf and
think about how we build knowledge

1244
00:24:41,100 --> 00:24:41,110
think about how we build knowledge
 

1245
00:24:41,110 --> 00:24:43,330
think about how we build knowledge
representation knowledge place well we

1246
00:24:43,330 --> 00:24:43,340
representation knowledge place well we
 

1247
00:24:43,340 --> 00:24:45,249
representation knowledge place well we
have to use graph searches searches

1248
00:24:45,249 --> 00:24:45,259
have to use graph searches searches
 

1249
00:24:45,259 --> 00:24:47,200
have to use graph searches searches
right and like first-order logic and

1250
00:24:47,200 --> 00:24:47,210
right and like first-order logic and
 

1251
00:24:47,210 --> 00:24:48,700
right and like first-order logic and
entailment and things like that a thing

1252
00:24:48,700 --> 00:24:48,710
entailment and things like that a thing
 

1253
00:24:48,710 --> 00:24:49,419
entailment and things like that a thing
yeah exactly

1254
00:24:49,419 --> 00:24:49,429
yeah exactly
 

1255
00:24:49,429 --> 00:24:51,519
yeah exactly
in my particular line of work which has

1256
00:24:51,519 --> 00:24:51,529
in my particular line of work which has
 

1257
00:24:51,529 --> 00:24:53,919
in my particular line of work which has
mostly been machine learning security

1258
00:24:53,919 --> 00:24:53,929
mostly been machine learning security
 

1259
00:24:53,929 --> 00:24:56,350
mostly been machine learning security
and and also generative modeling I

1260
00:24:56,350 --> 00:24:56,360
and and also generative modeling I
 

1261
00:24:56,360 --> 00:24:59,889
and and also generative modeling I
haven't usually found myself moving in

1262
00:24:59,889 --> 00:24:59,899
haven't usually found myself moving in
 

1263
00:24:59,899 --> 00:25:01,509
haven't usually found myself moving in
that direction for generative models I

1264
00:25:01,509 --> 00:25:01,519
that direction for generative models I
 

1265
00:25:01,519 --> 00:25:03,850
that direction for generative models I
could see a little bit of it could be

1266
00:25:03,850 --> 00:25:03,860
could see a little bit of it could be
 

1267
00:25:03,860 --> 00:25:06,600
could see a little bit of it could be
useful if you had something like a

1268
00:25:06,600 --> 00:25:06,610
useful if you had something like a
 

1269
00:25:06,610 --> 00:25:09,970
useful if you had something like a
differentiable knowledge base or some

1270
00:25:09,970 --> 00:25:09,980
differentiable knowledge base or some
 

1271
00:25:09,980 --> 00:25:11,200
differentiable knowledge base or some
other kind of knowledge base where it's

1272
00:25:11,200 --> 00:25:11,210
other kind of knowledge base where it's
 

1273
00:25:11,210 --> 00:25:14,110
other kind of knowledge base where it's
possible for some of our fuzzier machine

1274
00:25:14,110 --> 00:25:14,120
possible for some of our fuzzier machine
 

1275
00:25:14,120 --> 00:25:15,490
possible for some of our fuzzier machine
learning algorithms to interact with the

1276
00:25:15,490 --> 00:25:15,500
learning algorithms to interact with the
 

1277
00:25:15,500 --> 00:25:18,129
learning algorithms to interact with the
knowledge base immanuel Network is kind

1278
00:25:18,129 --> 00:25:18,139
knowledge base immanuel Network is kind
 

1279
00:25:18,139 --> 00:25:19,899
knowledge base immanuel Network is kind
of like that it's a differentiable

1280
00:25:19,899 --> 00:25:19,909
of like that it's a differentiable
 

1281
00:25:19,909 --> 00:25:24,070
of like that it's a differentiable
knowledge base of sorts yeah but if if

1282
00:25:24,070 --> 00:25:24,080
knowledge base of sorts yeah but if if
 

1283
00:25:24,080 --> 00:25:26,860
knowledge base of sorts yeah but if if
we had a really easy way of giving

1284
00:25:26,860 --> 00:25:26,870
we had a really easy way of giving
 

1285
00:25:26,870 --> 00:25:29,409
we had a really easy way of giving
feedback to machine learning models that

1286
00:25:29,409 --> 00:25:29,419
feedback to machine learning models that
 

1287
00:25:29,419 --> 00:25:31,570
feedback to machine learning models that
would clearly helped a lot with with

1288
00:25:31,570 --> 00:25:31,580
would clearly helped a lot with with
 

1289
00:25:31,580 --> 00:25:32,799
would clearly helped a lot with with
generative models and so you could

1290
00:25:32,799 --> 00:25:32,809
generative models and so you could
 

1291
00:25:32,809 --> 00:25:33,970
generative models and so you could
imagine one way of getting there would

1292
00:25:33,970 --> 00:25:33,980
imagine one way of getting there would
 

1293
00:25:33,980 --> 00:25:35,800
imagine one way of getting there would
be get a lot better at natural

1294
00:25:35,800 --> 00:25:35,810
be get a lot better at natural
 

1295
00:25:35,810 --> 00:25:37,270
be get a lot better at natural
language processing but another way of

1296
00:25:37,270 --> 00:25:37,280
language processing but another way of
 

1297
00:25:37,280 --> 00:25:39,550
language processing but another way of
getting there would be take some kind of

1298
00:25:39,550 --> 00:25:39,560
getting there would be take some kind of
 

1299
00:25:39,560 --> 00:25:40,930
getting there would be take some kind of
knowledge base and figure out a way for

1300
00:25:40,930 --> 00:25:40,940
knowledge base and figure out a way for
 

1301
00:25:40,940 --> 00:25:43,180
knowledge base and figure out a way for
it to actually interact with a neural

1302
00:25:43,180 --> 00:25:43,190
it to actually interact with a neural
 

1303
00:25:43,190 --> 00:25:45,220
it to actually interact with a neural
network being able to have a chat within

1304
00:25:45,220 --> 00:25:45,230
network being able to have a chat within
 

1305
00:25:45,230 --> 00:25:48,460
network being able to have a chat within
y'all network yes so like one thing in

1306
00:25:48,460 --> 00:25:48,470
y'all network yes so like one thing in
 

1307
00:25:48,470 --> 00:25:50,140
y'all network yes so like one thing in
generative models we see a lot today is

1308
00:25:50,140 --> 00:25:50,150
generative models we see a lot today is
 

1309
00:25:50,150 --> 00:25:52,450
generative models we see a lot today is
you'll get things like faces that are

1310
00:25:52,450 --> 00:25:52,460
you'll get things like faces that are
 

1311
00:25:52,460 --> 00:25:55,480
you'll get things like faces that are
not symmetrical like like people that

1312
00:25:55,480 --> 00:25:55,490
not symmetrical like like people that
 

1313
00:25:55,490 --> 00:25:57,310
not symmetrical like like people that
have two eyes that are different colors

1314
00:25:57,310 --> 00:25:57,320
have two eyes that are different colors
 

1315
00:25:57,320 --> 00:25:59,470
have two eyes that are different colors
and I mean there are people with eyes

1316
00:25:59,470 --> 00:25:59,480
and I mean there are people with eyes
 

1317
00:25:59,480 --> 00:26:00,670
and I mean there are people with eyes
that are different colors in real life

1318
00:26:00,670 --> 00:26:00,680
that are different colors in real life
 

1319
00:26:00,680 --> 00:26:02,710
that are different colors in real life
but not nearly as many of them as you

1320
00:26:02,710 --> 00:26:02,720
but not nearly as many of them as you
 

1321
00:26:02,720 --> 00:26:04,840
but not nearly as many of them as you
tend to see in the machine learning

1322
00:26:04,840 --> 00:26:04,850
tend to see in the machine learning
 

1323
00:26:04,850 --> 00:26:07,330
tend to see in the machine learning
generated data so if if you had either a

1324
00:26:07,330 --> 00:26:07,340
generated data so if if you had either a
 

1325
00:26:07,340 --> 00:26:08,890
generated data so if if you had either a
knowledge base that could contain the

1326
00:26:08,890 --> 00:26:08,900
knowledge base that could contain the
 

1327
00:26:08,900 --> 00:26:11,590
knowledge base that could contain the
fact people's faces are generally

1328
00:26:11,590 --> 00:26:11,600
fact people's faces are generally
 

1329
00:26:11,600 --> 00:26:15,100
fact people's faces are generally
approximately symmetric and eye color is

1330
00:26:15,100 --> 00:26:15,110
approximately symmetric and eye color is
 

1331
00:26:15,110 --> 00:26:16,480
approximately symmetric and eye color is
especially likely to be the same on both

1332
00:26:16,480 --> 00:26:16,490
especially likely to be the same on both
 

1333
00:26:16,490 --> 00:26:19,330
especially likely to be the same on both
sides being able to just inject that

1334
00:26:19,330 --> 00:26:19,340
sides being able to just inject that
 

1335
00:26:19,340 --> 00:26:22,000
sides being able to just inject that
hint into the machine learning model

1336
00:26:22,000 --> 00:26:22,010
hint into the machine learning model
 

1337
00:26:22,010 --> 00:26:23,140
hint into the machine learning model
without it having to discover that

1338
00:26:23,140 --> 00:26:23,150
without it having to discover that
 

1339
00:26:23,150 --> 00:26:25,780
without it having to discover that
itself after studying a lot of data it

1340
00:26:25,780 --> 00:26:25,790
itself after studying a lot of data it
 

1341
00:26:25,790 --> 00:26:29,020
itself after studying a lot of data it
would be a really useful feature I could

1342
00:26:29,020 --> 00:26:29,030
would be a really useful feature I could
 

1343
00:26:29,030 --> 00:26:30,100
would be a really useful feature I could
see a lot of ways of getting there

1344
00:26:30,100 --> 00:26:30,110
see a lot of ways of getting there
 

1345
00:26:30,110 --> 00:26:31,600
see a lot of ways of getting there
without bringing back some of the 1980s

1346
00:26:31,600 --> 00:26:31,610
without bringing back some of the 1980s
 

1347
00:26:31,610 --> 00:26:33,880
without bringing back some of the 1980s
technology but I also see some ways that

1348
00:26:33,880 --> 00:26:33,890
technology but I also see some ways that
 

1349
00:26:33,890 --> 00:26:36,250
technology but I also see some ways that
you could imagine extending the 1980s

1350
00:26:36,250 --> 00:26:36,260
you could imagine extending the 1980s
 

1351
00:26:36,260 --> 00:26:38,050
you could imagine extending the 1980s
technology to play nice with neural nets

1352
00:26:38,050 --> 00:26:38,060
technology to play nice with neural nets
 

1353
00:26:38,060 --> 00:26:39,400
technology to play nice with neural nets
and have it help get there

1354
00:26:39,400 --> 00:26:39,410
and have it help get there
 

1355
00:26:39,410 --> 00:26:42,900
and have it help get there
awesome so you talked about the story of

1356
00:26:42,900 --> 00:26:42,910
awesome so you talked about the story of
 

1357
00:26:42,910 --> 00:26:45,520
awesome so you talked about the story of
you coming up with idea of Gans at a bar

1358
00:26:45,520 --> 00:26:45,530
you coming up with idea of Gans at a bar
 

1359
00:26:45,530 --> 00:26:48,370
you coming up with idea of Gans at a bar
with some friends you were arguing that

1360
00:26:48,370 --> 00:26:48,380
with some friends you were arguing that
 

1361
00:26:48,380 --> 00:26:51,760
with some friends you were arguing that
this you know Gans would work Jenner of

1362
00:26:51,760 --> 00:26:51,770
this you know Gans would work Jenner of
 

1363
00:26:51,770 --> 00:26:53,410
this you know Gans would work Jenner of
adversarial networks and the others

1364
00:26:53,410 --> 00:26:53,420
adversarial networks and the others
 

1365
00:26:53,420 --> 00:26:56,530
adversarial networks and the others
didn't think so then he went home at

1366
00:26:56,530 --> 00:26:56,540
didn't think so then he went home at
 

1367
00:26:56,540 --> 00:26:59,410
didn't think so then he went home at
midnight coated up and it worked so if I

1368
00:26:59,410 --> 00:26:59,420
midnight coated up and it worked so if I
 

1369
00:26:59,420 --> 00:27:01,450
midnight coated up and it worked so if I
was a friend of yours at the bar I would

1370
00:27:01,450 --> 00:27:01,460
was a friend of yours at the bar I would
 

1371
00:27:01,460 --> 00:27:03,490
was a friend of yours at the bar I would
also have doubts it's a really nice idea

1372
00:27:03,490 --> 00:27:03,500
also have doubts it's a really nice idea
 

1373
00:27:03,500 --> 00:27:06,010
also have doubts it's a really nice idea
but I'm very skeptical that it would

1374
00:27:06,010 --> 00:27:06,020
but I'm very skeptical that it would
 

1375
00:27:06,020 --> 00:27:07,900
but I'm very skeptical that it would
work what was the basis of their

1376
00:27:07,900 --> 00:27:07,910
work what was the basis of their
 

1377
00:27:07,910 --> 00:27:10,980
work what was the basis of their
skepticism what was the basis of your

1378
00:27:10,980 --> 00:27:10,990
skepticism what was the basis of your
 

1379
00:27:10,990 --> 00:27:14,680
skepticism what was the basis of your
intuition why he should work I don't

1380
00:27:14,680 --> 00:27:14,690
intuition why he should work I don't
 

1381
00:27:14,690 --> 00:27:15,850
intuition why he should work I don't
want to be someone who goes around

1382
00:27:15,850 --> 00:27:15,860
want to be someone who goes around
 

1383
00:27:15,860 --> 00:27:19,450
want to be someone who goes around
promoting alcohol for the science in

1384
00:27:19,450 --> 00:27:19,460
promoting alcohol for the science in
 

1385
00:27:19,460 --> 00:27:21,130
promoting alcohol for the science in
this case I do actually think that

1386
00:27:21,130 --> 00:27:21,140
this case I do actually think that
 

1387
00:27:21,140 --> 00:27:22,870
this case I do actually think that
drinking helped a little bit mm-hmm

1388
00:27:22,870 --> 00:27:22,880
drinking helped a little bit mm-hmm
 

1389
00:27:22,880 --> 00:27:25,540
drinking helped a little bit mm-hmm
when your inhibitions are lowered you're

1390
00:27:25,540 --> 00:27:25,550
when your inhibitions are lowered you're
 

1391
00:27:25,550 --> 00:27:27,520
when your inhibitions are lowered you're
more willing to try out things that you

1392
00:27:27,520 --> 00:27:27,530
more willing to try out things that you
 

1393
00:27:27,530 --> 00:27:31,480
more willing to try out things that you
wouldn't try out otherwise so I I have

1394
00:27:31,480 --> 00:27:31,490
wouldn't try out otherwise so I I have
 

1395
00:27:31,490 --> 00:27:32,860
wouldn't try out otherwise so I I have
noticed it in general that I'm less

1396
00:27:32,860 --> 00:27:32,870
noticed it in general that I'm less
 

1397
00:27:32,870 --> 00:27:34,150
noticed it in general that I'm less
prone to shooting down some of my own

1398
00:27:34,150 --> 00:27:34,160
prone to shooting down some of my own
 

1399
00:27:34,160 --> 00:27:36,430
prone to shooting down some of my own
ideas when I'm when I have had a little

1400
00:27:36,430 --> 00:27:36,440
ideas when I'm when I have had a little
 

1401
00:27:36,440 --> 00:27:39,220
ideas when I'm when I have had a little
bit to drink I think if I had had that

1402
00:27:39,220 --> 00:27:39,230
bit to drink I think if I had had that
 

1403
00:27:39,230 --> 00:27:41,350
bit to drink I think if I had had that
idea at lunch time yeah I probably would

1404
00:27:41,350 --> 00:27:41,360
idea at lunch time yeah I probably would
 

1405
00:27:41,360 --> 00:27:43,180
idea at lunch time yeah I probably would
have thought it it's hard enough I mean

1406
00:27:43,180 --> 00:27:43,190
have thought it it's hard enough I mean
 

1407
00:27:43,190 --> 00:27:44,590
have thought it it's hard enough I mean
one neural net you can't train a second

1408
00:27:44,590 --> 00:27:44,600
one neural net you can't train a second
 

1409
00:27:44,600 --> 00:27:45,670
one neural net you can't train a second
neuron that in the inner loop of the

1410
00:27:45,670 --> 00:27:45,680
neuron that in the inner loop of the
 

1411
00:27:45,680 --> 00:27:48,910
neuron that in the inner loop of the
outer neural net that was basically my

1412
00:27:48,910 --> 00:27:48,920
outer neural net that was basically my
 

1413
00:27:48,920 --> 00:27:49,539
outer neural net that was basically my
friends

1414
00:27:49,539 --> 00:27:49,549
friends
 

1415
00:27:49,549 --> 00:27:50,889
friends
action was that trying to train two

1416
00:27:50,889 --> 00:27:50,899
action was that trying to train two
 

1417
00:27:50,899 --> 00:27:53,019
action was that trying to train two
neural nets at the same time would be

1418
00:27:53,019 --> 00:27:53,029
neural nets at the same time would be
 

1419
00:27:53,029 --> 00:27:55,239
neural nets at the same time would be
too hard so it was more about the

1420
00:27:55,239 --> 00:27:55,249
too hard so it was more about the
 

1421
00:27:55,249 --> 00:27:57,399
too hard so it was more about the
training process unless so my skepticism

1422
00:27:57,399 --> 00:27:57,409
training process unless so my skepticism
 

1423
00:27:57,409 --> 00:28:00,249
training process unless so my skepticism
would be you know I'm sure you could

1424
00:28:00,249 --> 00:28:00,259
would be you know I'm sure you could
 

1425
00:28:00,259 --> 00:28:03,159
would be you know I'm sure you could
train it but the thing would converge to

1426
00:28:03,159 --> 00:28:03,169
train it but the thing would converge to
 

1427
00:28:03,169 --> 00:28:04,509
train it but the thing would converge to
would not be able to generate anything

1428
00:28:04,509 --> 00:28:04,519
would not be able to generate anything
 

1429
00:28:04,519 --> 00:28:07,389
would not be able to generate anything
reasonable and any kind of reasonable

1430
00:28:07,389 --> 00:28:07,399
reasonable and any kind of reasonable
 

1431
00:28:07,399 --> 00:28:10,299
reasonable and any kind of reasonable
realism yeah so so part of what all of

1432
00:28:10,299 --> 00:28:10,309
realism yeah so so part of what all of
 

1433
00:28:10,309 --> 00:28:11,769
realism yeah so so part of what all of
us were thinking about when we had this

1434
00:28:11,769 --> 00:28:11,779
us were thinking about when we had this
 

1435
00:28:11,779 --> 00:28:14,590
us were thinking about when we had this
conversation was deep Bolton machines

1436
00:28:14,590 --> 00:28:14,600
conversation was deep Bolton machines
 

1437
00:28:14,600 --> 00:28:16,840
conversation was deep Bolton machines
which a lot of us in the lab including

1438
00:28:16,840 --> 00:28:16,850
which a lot of us in the lab including
 

1439
00:28:16,850 --> 00:28:18,129
which a lot of us in the lab including
me were a big fan of deep bolts and

1440
00:28:18,129 --> 00:28:18,139
me were a big fan of deep bolts and
 

1441
00:28:18,139 --> 00:28:21,909
me were a big fan of deep bolts and
machines at the time they involved two

1442
00:28:21,909 --> 00:28:21,919
machines at the time they involved two
 

1443
00:28:21,919 --> 00:28:23,529
machines at the time they involved two
separate processes running at the same

1444
00:28:23,529 --> 00:28:23,539
separate processes running at the same
 

1445
00:28:23,539 --> 00:28:27,190
separate processes running at the same
time one of them is called the positive

1446
00:28:27,190 --> 00:28:27,200
time one of them is called the positive
 

1447
00:28:27,200 --> 00:28:30,609
time one of them is called the positive
phase where you load data into the model

1448
00:28:30,609 --> 00:28:30,619
phase where you load data into the model
 

1449
00:28:30,619 --> 00:28:32,349
phase where you load data into the model
and tell the model to make the data more

1450
00:28:32,349 --> 00:28:32,359
and tell the model to make the data more
 

1451
00:28:32,359 --> 00:28:34,690
and tell the model to make the data more
likely the owners called the negative

1452
00:28:34,690 --> 00:28:34,700
likely the owners called the negative
 

1453
00:28:34,700 --> 00:28:36,340
likely the owners called the negative
phase where you draw samples from the

1454
00:28:36,340 --> 00:28:36,350
phase where you draw samples from the
 

1455
00:28:36,350 --> 00:28:38,019
phase where you draw samples from the
model and tell the model to make those

1456
00:28:38,019 --> 00:28:38,029
model and tell the model to make those
 

1457
00:28:38,029 --> 00:28:41,889
model and tell the model to make those
samples less likely in a deep Bolton

1458
00:28:41,889 --> 00:28:41,899
samples less likely in a deep Bolton
 

1459
00:28:41,899 --> 00:28:43,450
samples less likely in a deep Bolton
machine it's not trivial to generate a

1460
00:28:43,450 --> 00:28:43,460
machine it's not trivial to generate a
 

1461
00:28:43,460 --> 00:28:45,909
machine it's not trivial to generate a
sample you have to actually run an

1462
00:28:45,909 --> 00:28:45,919
sample you have to actually run an
 

1463
00:28:45,919 --> 00:28:47,769
sample you have to actually run an
iterative process that gets better and

1464
00:28:47,769 --> 00:28:47,779
iterative process that gets better and
 

1465
00:28:47,779 --> 00:28:48,279
iterative process that gets better and
better

1466
00:28:48,279 --> 00:28:48,289
better
 

1467
00:28:48,289 --> 00:28:50,649
better
samples coming closer and closer to the

1468
00:28:50,649 --> 00:28:50,659
samples coming closer and closer to the
 

1469
00:28:50,659 --> 00:28:52,989
samples coming closer and closer to the
distribution the model represents so

1470
00:28:52,989 --> 00:28:52,999
distribution the model represents so
 

1471
00:28:52,999 --> 00:28:53,979
distribution the model represents so
during the training process you're

1472
00:28:53,979 --> 00:28:53,989
during the training process you're
 

1473
00:28:53,989 --> 00:28:55,840
during the training process you're
always running these two systems at the

1474
00:28:55,840 --> 00:28:55,850
always running these two systems at the
 

1475
00:28:55,850 --> 00:28:58,090
always running these two systems at the
same time one that's updating the

1476
00:28:58,090 --> 00:28:58,100
same time one that's updating the
 

1477
00:28:58,100 --> 00:28:59,349
same time one that's updating the
parameters of the model and another one

1478
00:28:59,349 --> 00:28:59,359
parameters of the model and another one
 

1479
00:28:59,359 --> 00:29:00,549
parameters of the model and another one
that's trying to generate samples from

1480
00:29:00,549 --> 00:29:00,559
that's trying to generate samples from
 

1481
00:29:00,559 --> 00:29:03,369
that's trying to generate samples from
the model and they worked really well on

1482
00:29:03,369 --> 00:29:03,379
the model and they worked really well on
 

1483
00:29:03,379 --> 00:29:04,989
the model and they worked really well on
things like Amnesty a lot of us in the

1484
00:29:04,989 --> 00:29:04,999
things like Amnesty a lot of us in the
 

1485
00:29:04,999 --> 00:29:06,729
things like Amnesty a lot of us in the
lab including me had tried to get the

1486
00:29:06,729 --> 00:29:06,739
lab including me had tried to get the
 

1487
00:29:06,739 --> 00:29:09,099
lab including me had tried to get the
Boltzmann machines to scale past em

1488
00:29:09,099 --> 00:29:09,109
Boltzmann machines to scale past em
 

1489
00:29:09,109 --> 00:29:09,430
Boltzmann machines to scale past em
inist

1490
00:29:09,430 --> 00:29:09,440
inist
 

1491
00:29:09,440 --> 00:29:11,830
inist
to things like generating color photos

1492
00:29:11,830 --> 00:29:11,840
to things like generating color photos
 

1493
00:29:11,840 --> 00:29:13,359
to things like generating color photos
and we just couldn't get the two

1494
00:29:13,359 --> 00:29:13,369
and we just couldn't get the two
 

1495
00:29:13,369 --> 00:29:17,619
and we just couldn't get the two
processes to stay synchronized so when I

1496
00:29:17,619 --> 00:29:17,629
processes to stay synchronized so when I
 

1497
00:29:17,629 --> 00:29:19,239
processes to stay synchronized so when I
had the idea for Gans a lot of people

1498
00:29:19,239 --> 00:29:19,249
had the idea for Gans a lot of people
 

1499
00:29:19,249 --> 00:29:20,440
had the idea for Gans a lot of people
thought that the discriminator would

1500
00:29:20,440 --> 00:29:20,450
thought that the discriminator would
 

1501
00:29:20,450 --> 00:29:22,180
thought that the discriminator would
have more or less the same problem as

1502
00:29:22,180 --> 00:29:22,190
have more or less the same problem as
 

1503
00:29:22,190 --> 00:29:24,369
have more or less the same problem as
the negative phase in the Boltzmann

1504
00:29:24,369 --> 00:29:24,379
the negative phase in the Boltzmann
 

1505
00:29:24,379 --> 00:29:26,590
the negative phase in the Boltzmann
machine that trying to train the

1506
00:29:26,590 --> 00:29:26,600
machine that trying to train the
 

1507
00:29:26,600 --> 00:29:28,149
machine that trying to train the
discriminator in the inner loop you just

1508
00:29:28,149 --> 00:29:28,159
discriminator in the inner loop you just
 

1509
00:29:28,159 --> 00:29:30,310
discriminator in the inner loop you just
couldn't get it to keep up with the

1510
00:29:30,310 --> 00:29:30,320
couldn't get it to keep up with the
 

1511
00:29:30,320 --> 00:29:31,779
couldn't get it to keep up with the
generator and the outer loop and that

1512
00:29:31,779 --> 00:29:31,789
generator and the outer loop and that
 

1513
00:29:31,789 --> 00:29:33,909
generator and the outer loop and that
would prevent it from converging to

1514
00:29:33,909 --> 00:29:33,919
would prevent it from converging to
 

1515
00:29:33,919 --> 00:29:36,220
would prevent it from converging to
anything useful yeah I share that

1516
00:29:36,220 --> 00:29:36,230
anything useful yeah I share that
 

1517
00:29:36,230 --> 00:29:40,720
anything useful yeah I share that
intuition yeah what turns out to not be

1518
00:29:40,720 --> 00:29:40,730
intuition yeah what turns out to not be
 

1519
00:29:40,730 --> 00:29:42,999
intuition yeah what turns out to not be
the case a lot of the time with machine

1520
00:29:42,999 --> 00:29:43,009
the case a lot of the time with machine
 

1521
00:29:43,009 --> 00:29:44,349
the case a lot of the time with machine
learning algorithms it's really hard to

1522
00:29:44,349 --> 00:29:44,359
learning algorithms it's really hard to
 

1523
00:29:44,359 --> 00:29:45,609
learning algorithms it's really hard to
predict ahead of time how well they'll

1524
00:29:45,609 --> 00:29:45,619
predict ahead of time how well they'll
 

1525
00:29:45,619 --> 00:29:47,529
predict ahead of time how well they'll
actually perform you have to just run

1526
00:29:47,529 --> 00:29:47,539
actually perform you have to just run
 

1527
00:29:47,539 --> 00:29:49,060
actually perform you have to just run
the experiment and see what happens

1528
00:29:49,060 --> 00:29:49,070
the experiment and see what happens
 

1529
00:29:49,070 --> 00:29:51,700
the experiment and see what happens
and I would say I still today don't have

1530
00:29:51,700 --> 00:29:51,710
and I would say I still today don't have
 

1531
00:29:51,710 --> 00:29:54,220
and I would say I still today don't have
like one factor I can put my finger on

1532
00:29:54,220 --> 00:29:54,230
like one factor I can put my finger on
 

1533
00:29:54,230 --> 00:29:57,639
like one factor I can put my finger on
it say this is why ganz worked for photo

1534
00:29:57,639 --> 00:29:57,649
it say this is why ganz worked for photo
 

1535
00:29:57,649 --> 00:29:59,560
it say this is why ganz worked for photo
generation and deep Boltzmann machines

1536
00:29:59,560 --> 00:29:59,570
generation and deep Boltzmann machines
 

1537
00:29:59,570 --> 00:30:01,149
generation and deep Boltzmann machines
don't

1538
00:30:01,149 --> 00:30:01,159
don't
 

1539
00:30:01,159 --> 00:30:03,470
don't
there are a lot of theory papers showing

1540
00:30:03,470 --> 00:30:03,480
there are a lot of theory papers showing
 

1541
00:30:03,480 --> 00:30:06,529
there are a lot of theory papers showing
that under some theoretical settings the

1542
00:30:06,529 --> 00:30:06,539
that under some theoretical settings the
 

1543
00:30:06,539 --> 00:30:09,789
that under some theoretical settings the
the gun algorithm does actually converge

1544
00:30:09,789 --> 00:30:09,799
the gun algorithm does actually converge
 

1545
00:30:09,799 --> 00:30:13,510
the gun algorithm does actually converge
but those settings are restricted enough

1546
00:30:13,510 --> 00:30:13,520
but those settings are restricted enough
 

1547
00:30:13,520 --> 00:30:16,610
but those settings are restricted enough
that they don't necessarily explain the

1548
00:30:16,610 --> 00:30:16,620
that they don't necessarily explain the
 

1549
00:30:16,620 --> 00:30:18,140
that they don't necessarily explain the
whole picture in terms of all the

1550
00:30:18,140 --> 00:30:18,150
whole picture in terms of all the
 

1551
00:30:18,150 --> 00:30:20,870
whole picture in terms of all the
results that we see in practice so

1552
00:30:20,870 --> 00:30:20,880
results that we see in practice so
 

1553
00:30:20,880 --> 00:30:23,390
results that we see in practice so
taking a step back can you in the same

1554
00:30:23,390 --> 00:30:23,400
taking a step back can you in the same
 

1555
00:30:23,400 --> 00:30:25,010
taking a step back can you in the same
way as we talked about deep learning can

1556
00:30:25,010 --> 00:30:25,020
way as we talked about deep learning can
 

1557
00:30:25,020 --> 00:30:27,260
way as we talked about deep learning can
you tell me what generative adversarial

1558
00:30:27,260 --> 00:30:27,270
you tell me what generative adversarial
 

1559
00:30:27,270 --> 00:30:30,440
you tell me what generative adversarial
networks are yeah so generative

1560
00:30:30,440 --> 00:30:30,450
networks are yeah so generative
 

1561
00:30:30,450 --> 00:30:32,029
networks are yeah so generative
adversarial networks are a particular

1562
00:30:32,029 --> 00:30:32,039
adversarial networks are a particular
 

1563
00:30:32,039 --> 00:30:34,940
adversarial networks are a particular
kind of generative model a generative

1564
00:30:34,940 --> 00:30:34,950
kind of generative model a generative
 

1565
00:30:34,950 --> 00:30:36,260
kind of generative model a generative
model is a machine learning model that

1566
00:30:36,260 --> 00:30:36,270
model is a machine learning model that
 

1567
00:30:36,270 --> 00:30:39,139
model is a machine learning model that
can train on some set of data like so

1568
00:30:39,139 --> 00:30:39,149
can train on some set of data like so
 

1569
00:30:39,149 --> 00:30:40,519
can train on some set of data like so
you have a collection of photos of cats

1570
00:30:40,519 --> 00:30:40,529
you have a collection of photos of cats
 

1571
00:30:40,529 --> 00:30:43,039
you have a collection of photos of cats
and you want to generate more photos of

1572
00:30:43,039 --> 00:30:43,049
and you want to generate more photos of
 

1573
00:30:43,049 --> 00:30:45,680
and you want to generate more photos of
cats or you want to estimate a

1574
00:30:45,680 --> 00:30:45,690
cats or you want to estimate a
 

1575
00:30:45,690 --> 00:30:47,810
cats or you want to estimate a
probability distribution over cats so

1576
00:30:47,810 --> 00:30:47,820
probability distribution over cats so
 

1577
00:30:47,820 --> 00:30:50,090
probability distribution over cats so
you can ask how likely it is that some

1578
00:30:50,090 --> 00:30:50,100
you can ask how likely it is that some
 

1579
00:30:50,100 --> 00:30:53,840
you can ask how likely it is that some
new image is a photo of a cat ganzar one

1580
00:30:53,840 --> 00:30:53,850
new image is a photo of a cat ganzar one
 

1581
00:30:53,850 --> 00:30:55,549
new image is a photo of a cat ganzar one
way of doing this

1582
00:30:55,549 --> 00:30:55,559
way of doing this
 

1583
00:30:55,559 --> 00:30:57,200
way of doing this
some generative models are good at

1584
00:30:57,200 --> 00:30:57,210
some generative models are good at
 

1585
00:30:57,210 --> 00:30:59,930
some generative models are good at
creating new data other generative

1586
00:30:59,930 --> 00:30:59,940
creating new data other generative
 

1587
00:30:59,940 --> 00:31:01,730
creating new data other generative
models are good at estimating that

1588
00:31:01,730 --> 00:31:01,740
models are good at estimating that
 

1589
00:31:01,740 --> 00:31:03,019
models are good at estimating that
density function and telling you how

1590
00:31:03,019 --> 00:31:03,029
density function and telling you how
 

1591
00:31:03,029 --> 00:31:06,710
density function and telling you how
likely particular pieces of data are to

1592
00:31:06,710 --> 00:31:06,720
likely particular pieces of data are to
 

1593
00:31:06,720 --> 00:31:08,180
likely particular pieces of data are to
come from the same distribution as a

1594
00:31:08,180 --> 00:31:08,190
come from the same distribution as a
 

1595
00:31:08,190 --> 00:31:10,909
come from the same distribution as a
training data gans are more focused on

1596
00:31:10,909 --> 00:31:10,919
training data gans are more focused on
 

1597
00:31:10,919 --> 00:31:13,269
training data gans are more focused on
generating samples rather than

1598
00:31:13,269 --> 00:31:13,279
generating samples rather than
 

1599
00:31:13,279 --> 00:31:15,710
generating samples rather than
estimating the density function there

1600
00:31:15,710 --> 00:31:15,720
estimating the density function there
 

1601
00:31:15,720 --> 00:31:17,539
estimating the density function there
are some kinds of games like flow gun

1602
00:31:17,539 --> 00:31:17,549
are some kinds of games like flow gun
 

1603
00:31:17,549 --> 00:31:19,700
are some kinds of games like flow gun
that can do both but mostly guns are

1604
00:31:19,700 --> 00:31:19,710
that can do both but mostly guns are
 

1605
00:31:19,710 --> 00:31:22,039
that can do both but mostly guns are
about generating samples of generating

1606
00:31:22,039 --> 00:31:22,049
about generating samples of generating
 

1607
00:31:22,049 --> 00:31:24,310
about generating samples of generating
new photos of cats that look realistic

1608
00:31:24,310 --> 00:31:24,320
new photos of cats that look realistic
 

1609
00:31:24,320 --> 00:31:28,480
new photos of cats that look realistic
and they do that completely from scratch

1610
00:31:28,480 --> 00:31:28,490
and they do that completely from scratch
 

1611
00:31:28,490 --> 00:31:32,330
and they do that completely from scratch
it's analogous to human imagination when

1612
00:31:32,330 --> 00:31:32,340
it's analogous to human imagination when
 

1613
00:31:32,340 --> 00:31:35,320
it's analogous to human imagination when
again creates a new image of a cat it's

1614
00:31:35,320 --> 00:31:35,330
again creates a new image of a cat it's
 

1615
00:31:35,330 --> 00:31:39,169
again creates a new image of a cat it's
using a neural network to produce a cat

1616
00:31:39,169 --> 00:31:39,179
using a neural network to produce a cat
 

1617
00:31:39,179 --> 00:31:41,299
using a neural network to produce a cat
that has not existed before it isn't

1618
00:31:41,299 --> 00:31:41,309
that has not existed before it isn't
 

1619
00:31:41,309 --> 00:31:43,880
that has not existed before it isn't
doing something like compositing photos

1620
00:31:43,880 --> 00:31:43,890
doing something like compositing photos
 

1621
00:31:43,890 --> 00:31:45,740
doing something like compositing photos
together you're not you're not literally

1622
00:31:45,740 --> 00:31:45,750
together you're not you're not literally
 

1623
00:31:45,750 --> 00:31:47,330
together you're not you're not literally
taking the eye off of one cat on the ear

1624
00:31:47,330 --> 00:31:47,340
taking the eye off of one cat on the ear
 

1625
00:31:47,340 --> 00:31:49,580
taking the eye off of one cat on the ear
off of another cat it's it's more of

1626
00:31:49,580 --> 00:31:49,590
off of another cat it's it's more of
 

1627
00:31:49,590 --> 00:31:52,279
off of another cat it's it's more of
this digestive process where the the

1628
00:31:52,279 --> 00:31:52,289
this digestive process where the the
 

1629
00:31:52,289 --> 00:31:53,990
this digestive process where the the
neural net trains on a lot of data and

1630
00:31:53,990 --> 00:31:54,000
neural net trains on a lot of data and
 

1631
00:31:54,000 --> 00:31:56,240
neural net trains on a lot of data and
comes up with some representation of the

1632
00:31:56,240 --> 00:31:56,250
comes up with some representation of the
 

1633
00:31:56,250 --> 00:31:57,860
comes up with some representation of the
probability distribution and generates

1634
00:31:57,860 --> 00:31:57,870
probability distribution and generates
 

1635
00:31:57,870 --> 00:32:00,440
probability distribution and generates
entirely new cats there are a lot of

1636
00:32:00,440 --> 00:32:00,450
entirely new cats there are a lot of
 

1637
00:32:00,450 --> 00:32:01,519
entirely new cats there are a lot of
different ways of building a generative

1638
00:32:01,519 --> 00:32:01,529
different ways of building a generative
 

1639
00:32:01,529 --> 00:32:03,799
different ways of building a generative
model what's specific against is that we

1640
00:32:03,799 --> 00:32:03,809
model what's specific against is that we
 

1641
00:32:03,809 --> 00:32:06,350
model what's specific against is that we
have a two-player game in the game

1642
00:32:06,350 --> 00:32:06,360
have a two-player game in the game
 

1643
00:32:06,360 --> 00:32:08,960
have a two-player game in the game
theoretic sense and as the players in

1644
00:32:08,960 --> 00:32:08,970
theoretic sense and as the players in
 

1645
00:32:08,970 --> 00:32:10,540
theoretic sense and as the players in
this game compete

1646
00:32:10,540 --> 00:32:10,550
this game compete
 

1647
00:32:10,550 --> 00:32:12,160
this game compete
one of them becomes able to generate

1648
00:32:12,160 --> 00:32:12,170
one of them becomes able to generate
 

1649
00:32:12,170 --> 00:32:14,680
one of them becomes able to generate
realistic data the first player is

1650
00:32:14,680 --> 00:32:14,690
realistic data the first player is
 

1651
00:32:14,690 --> 00:32:17,080
realistic data the first player is
called the generator it produces output

1652
00:32:17,080 --> 00:32:17,090
called the generator it produces output
 

1653
00:32:17,090 --> 00:32:20,190
called the generator it produces output
data such as just images for example and

1654
00:32:20,190 --> 00:32:20,200
data such as just images for example and
 

1655
00:32:20,200 --> 00:32:22,150
data such as just images for example and
at the start of the learning process

1656
00:32:22,150 --> 00:32:22,160
at the start of the learning process
 

1657
00:32:22,160 --> 00:32:23,860
at the start of the learning process
it'll just produce completely random

1658
00:32:23,860 --> 00:32:23,870
it'll just produce completely random
 

1659
00:32:23,870 --> 00:32:26,140
it'll just produce completely random
images the other player is called the

1660
00:32:26,140 --> 00:32:26,150
images the other player is called the
 

1661
00:32:26,150 --> 00:32:28,360
images the other player is called the
discriminator the discriminator takes

1662
00:32:28,360 --> 00:32:28,370
discriminator the discriminator takes
 

1663
00:32:28,370 --> 00:32:30,400
discriminator the discriminator takes
images as input and guesses whether

1664
00:32:30,400 --> 00:32:30,410
images as input and guesses whether
 

1665
00:32:30,410 --> 00:32:33,400
images as input and guesses whether
they're real or fake you train it both

1666
00:32:33,400 --> 00:32:33,410
they're real or fake you train it both
 

1667
00:32:33,410 --> 00:32:35,350
they're real or fake you train it both
on real data so photos that come from

1668
00:32:35,350 --> 00:32:35,360
on real data so photos that come from
 

1669
00:32:35,360 --> 00:32:37,090
on real data so photos that come from
your training set actual photos of cats

1670
00:32:37,090 --> 00:32:37,100
your training set actual photos of cats
 

1671
00:32:37,100 --> 00:32:39,160
your training set actual photos of cats
and you try to say that those are real

1672
00:32:39,160 --> 00:32:39,170
and you try to say that those are real
 

1673
00:32:39,170 --> 00:32:42,220
and you try to say that those are real
you also train it on images that come

1674
00:32:42,220 --> 00:32:42,230
you also train it on images that come
 

1675
00:32:42,230 --> 00:32:44,560
you also train it on images that come
from the generator network and you train

1676
00:32:44,560 --> 00:32:44,570
from the generator network and you train
 

1677
00:32:44,570 --> 00:32:47,320
from the generator network and you train
it to say that those are fake as the two

1678
00:32:47,320 --> 00:32:47,330
it to say that those are fake as the two
 

1679
00:32:47,330 --> 00:32:49,390
it to say that those are fake as the two
players compete in this game the

1680
00:32:49,390 --> 00:32:49,400
players compete in this game the
 

1681
00:32:49,400 --> 00:32:50,980
players compete in this game the
discriminator tries to become better at

1682
00:32:50,980 --> 00:32:50,990
discriminator tries to become better at
 

1683
00:32:50,990 --> 00:32:52,300
discriminator tries to become better at
recognizing where their images are real

1684
00:32:52,300 --> 00:32:52,310
recognizing where their images are real
 

1685
00:32:52,310 --> 00:32:54,640
recognizing where their images are real
or fake and the generator becomes better

1686
00:32:54,640 --> 00:32:54,650
or fake and the generator becomes better
 

1687
00:32:54,650 --> 00:32:56,050
or fake and the generator becomes better
at fooling the discriminator into

1688
00:32:56,050 --> 00:32:56,060
at fooling the discriminator into
 

1689
00:32:56,060 --> 00:32:59,550
at fooling the discriminator into
thinking that its outputs are are real

1690
00:32:59,550 --> 00:32:59,560
thinking that its outputs are are real
 

1691
00:32:59,560 --> 00:33:02,560
thinking that its outputs are are real
and you can analyze this through the

1692
00:33:02,560 --> 00:33:02,570
and you can analyze this through the
 

1693
00:33:02,570 --> 00:33:04,000
and you can analyze this through the
language of game theory and find that

1694
00:33:04,000 --> 00:33:04,010
language of game theory and find that
 

1695
00:33:04,010 --> 00:33:07,150
language of game theory and find that
there's a Nash equilibrium where the

1696
00:33:07,150 --> 00:33:07,160
there's a Nash equilibrium where the
 

1697
00:33:07,160 --> 00:33:09,070
there's a Nash equilibrium where the
generator has captured the correct

1698
00:33:09,070 --> 00:33:09,080
generator has captured the correct
 

1699
00:33:09,080 --> 00:33:11,560
generator has captured the correct
probability distribution so in the cat

1700
00:33:11,560 --> 00:33:11,570
probability distribution so in the cat
 

1701
00:33:11,570 --> 00:33:13,510
probability distribution so in the cat
example it makes perfectly realistic cat

1702
00:33:13,510 --> 00:33:13,520
example it makes perfectly realistic cat
 

1703
00:33:13,520 --> 00:33:16,270
example it makes perfectly realistic cat
photos and the discriminator is unable

1704
00:33:16,270 --> 00:33:16,280
photos and the discriminator is unable
 

1705
00:33:16,280 --> 00:33:18,070
photos and the discriminator is unable
to do better than random guessing

1706
00:33:18,070 --> 00:33:18,080
to do better than random guessing
 

1707
00:33:18,080 --> 00:33:20,950
to do better than random guessing
because all the all the samples coming

1708
00:33:20,950 --> 00:33:20,960
because all the all the samples coming
 

1709
00:33:20,960 --> 00:33:22,900
because all the all the samples coming
from both the data and the generator

1710
00:33:22,900 --> 00:33:22,910
from both the data and the generator
 

1711
00:33:22,910 --> 00:33:24,460
from both the data and the generator
look equally likely to have come from

1712
00:33:24,460 --> 00:33:24,470
look equally likely to have come from
 

1713
00:33:24,470 --> 00:33:28,150
look equally likely to have come from
either source so do you ever do sit back

1714
00:33:28,150 --> 00:33:28,160
either source so do you ever do sit back
 

1715
00:33:28,160 --> 00:33:30,010
either source so do you ever do sit back
and does it just blow your mind that

1716
00:33:30,010 --> 00:33:30,020
and does it just blow your mind that
 

1717
00:33:30,020 --> 00:33:33,580
and does it just blow your mind that
this thing works so from very so it's

1718
00:33:33,580 --> 00:33:33,590
this thing works so from very so it's
 

1719
00:33:33,590 --> 00:33:35,770
this thing works so from very so it's
able to estimate that density function

1720
00:33:35,770 --> 00:33:35,780
able to estimate that density function
 

1721
00:33:35,780 --> 00:33:38,170
able to estimate that density function
enough to generate generate realistic

1722
00:33:38,170 --> 00:33:38,180
enough to generate generate realistic
 

1723
00:33:38,180 --> 00:33:41,170
enough to generate generate realistic
images I mean does it yeah do you ever

1724
00:33:41,170 --> 00:33:41,180
images I mean does it yeah do you ever
 

1725
00:33:41,180 --> 00:33:44,800
images I mean does it yeah do you ever
sit back yeah how does this even why

1726
00:33:44,800 --> 00:33:44,810
sit back yeah how does this even why
 

1727
00:33:44,810 --> 00:33:46,900
sit back yeah how does this even why
this is quite incredible especially

1728
00:33:46,900 --> 00:33:46,910
this is quite incredible especially
 

1729
00:33:46,910 --> 00:33:48,640
this is quite incredible especially
where Gant's have gone in terms of

1730
00:33:48,640 --> 00:33:48,650
where Gant's have gone in terms of
 

1731
00:33:48,650 --> 00:33:50,980
where Gant's have gone in terms of
realism yeah and and not just to flatter

1732
00:33:50,980 --> 00:33:50,990
realism yeah and and not just to flatter
 

1733
00:33:50,990 --> 00:33:54,190
realism yeah and and not just to flatter
my own work but generative models all of

1734
00:33:54,190 --> 00:33:54,200
my own work but generative models all of
 

1735
00:33:54,200 --> 00:33:56,830
my own work but generative models all of
them have this property that if they

1736
00:33:56,830 --> 00:33:56,840
them have this property that if they
 

1737
00:33:56,840 --> 00:33:58,960
them have this property that if they
really did what we asked them to do they

1738
00:33:58,960 --> 00:33:58,970
really did what we asked them to do they
 

1739
00:33:58,970 --> 00:34:00,250
really did what we asked them to do they
would do nothing but memorize the

1740
00:34:00,250 --> 00:34:00,260
would do nothing but memorize the
 

1741
00:34:00,260 --> 00:34:03,430
would do nothing but memorize the
training data right some models that are

1742
00:34:03,430 --> 00:34:03,440
training data right some models that are
 

1743
00:34:03,440 --> 00:34:05,980
training data right some models that are
based on maximizing the likelihood the

1744
00:34:05,980 --> 00:34:05,990
based on maximizing the likelihood the
 

1745
00:34:05,990 --> 00:34:07,210
based on maximizing the likelihood the
way that you obtain the maximum

1746
00:34:07,210 --> 00:34:07,220
way that you obtain the maximum
 

1747
00:34:07,220 --> 00:34:09,580
way that you obtain the maximum
likelihood for a specific training set

1748
00:34:09,580 --> 00:34:09,590
likelihood for a specific training set
 

1749
00:34:09,590 --> 00:34:12,070
likelihood for a specific training set
is you assign all of your probability

1750
00:34:12,070 --> 00:34:12,080
is you assign all of your probability
 

1751
00:34:12,080 --> 00:34:13,510
is you assign all of your probability
mass to the training examples and

1752
00:34:13,510 --> 00:34:13,520
mass to the training examples and
 

1753
00:34:13,520 --> 00:34:14,550
mass to the training examples and
nowhere else

1754
00:34:14,550 --> 00:34:14,560
nowhere else
 

1755
00:34:14,560 --> 00:34:17,350
nowhere else
forgets the game is played using a

1756
00:34:17,350 --> 00:34:17,360
forgets the game is played using a
 

1757
00:34:17,360 --> 00:34:19,600
forgets the game is played using a
training set so the way that you become

1758
00:34:19,600 --> 00:34:19,610
training set so the way that you become
 

1759
00:34:19,610 --> 00:34:21,640
training set so the way that you become
unbeatable in the game is you literally

1760
00:34:21,640 --> 00:34:21,650
unbeatable in the game is you literally
 

1761
00:34:21,650 --> 00:34:24,590
unbeatable in the game is you literally
memorize training examples

1762
00:34:24,590 --> 00:34:24,600
memorize training examples
 

1763
00:34:24,600 --> 00:34:28,010
memorize training examples
one of my former interns wrote a paper

1764
00:34:28,010 --> 00:34:28,020
one of my former interns wrote a paper
 

1765
00:34:28,020 --> 00:34:31,260
one of my former interns wrote a paper
his name is a Vaishnav nagarajan and he

1766
00:34:31,260 --> 00:34:31,270
his name is a Vaishnav nagarajan and he
 

1767
00:34:31,270 --> 00:34:33,419
his name is a Vaishnav nagarajan and he
showed that it's actually hard for the

1768
00:34:33,419 --> 00:34:33,429
showed that it's actually hard for the
 

1769
00:34:33,429 --> 00:34:35,330
showed that it's actually hard for the
generator to memorize the training data

1770
00:34:35,330 --> 00:34:35,340
generator to memorize the training data
 

1771
00:34:35,340 --> 00:34:38,520
generator to memorize the training data
hard in a statistical learning theory

1772
00:34:38,520 --> 00:34:38,530
hard in a statistical learning theory
 

1773
00:34:38,530 --> 00:34:40,590
hard in a statistical learning theory
sense that you can actually create

1774
00:34:40,590 --> 00:34:40,600
sense that you can actually create
 

1775
00:34:40,600 --> 00:34:46,290
sense that you can actually create
reasons for why it would require quite a

1776
00:34:46,290 --> 00:34:46,300
reasons for why it would require quite a
 

1777
00:34:46,300 --> 00:34:49,169
reasons for why it would require quite a
lot of learning steps and and a lot of

1778
00:34:49,169 --> 00:34:49,179
lot of learning steps and and a lot of
 

1779
00:34:49,179 --> 00:34:51,629
lot of learning steps and and a lot of
observations of of different latent

1780
00:34:51,629 --> 00:34:51,639
observations of of different latent
 

1781
00:34:51,639 --> 00:34:53,220
observations of of different latent
variables before you could memorize the

1782
00:34:53,220 --> 00:34:53,230
variables before you could memorize the
 

1783
00:34:53,230 --> 00:34:55,020
variables before you could memorize the
training data that still doesn't really

1784
00:34:55,020 --> 00:34:55,030
training data that still doesn't really
 

1785
00:34:55,030 --> 00:34:57,030
training data that still doesn't really
explain why when you produce samples

1786
00:34:57,030 --> 00:34:57,040
explain why when you produce samples
 

1787
00:34:57,040 --> 00:34:59,310
explain why when you produce samples
that are new why do you get compelling

1788
00:34:59,310 --> 00:34:59,320
that are new why do you get compelling
 

1789
00:34:59,320 --> 00:35:01,590
that are new why do you get compelling
images rather than you know just garbage

1790
00:35:01,590 --> 00:35:01,600
images rather than you know just garbage
 

1791
00:35:01,600 --> 00:35:03,060
images rather than you know just garbage
that's different from the training set

1792
00:35:03,060 --> 00:35:03,070
that's different from the training set
 

1793
00:35:03,070 --> 00:35:05,760
that's different from the training set
and I don't think we really have a good

1794
00:35:05,760 --> 00:35:05,770
and I don't think we really have a good
 

1795
00:35:05,770 --> 00:35:07,500
and I don't think we really have a good
answer for that especially if you think

1796
00:35:07,500 --> 00:35:07,510
answer for that especially if you think
 

1797
00:35:07,510 --> 00:35:09,300
answer for that especially if you think
about how many possible images are out

1798
00:35:09,300 --> 00:35:09,310
about how many possible images are out
 

1799
00:35:09,310 --> 00:35:13,410
about how many possible images are out
there and how few images the generative

1800
00:35:13,410 --> 00:35:13,420
there and how few images the generative
 

1801
00:35:13,420 --> 00:35:16,020
there and how few images the generative
model sees during training it seems just

1802
00:35:16,020 --> 00:35:16,030
model sees during training it seems just
 

1803
00:35:16,030 --> 00:35:18,330
model sees during training it seems just
unreasonable that generative models

1804
00:35:18,330 --> 00:35:18,340
unreasonable that generative models
 

1805
00:35:18,340 --> 00:35:20,060
unreasonable that generative models
create new images as well as they do

1806
00:35:20,060 --> 00:35:20,070
create new images as well as they do
 

1807
00:35:20,070 --> 00:35:22,260
create new images as well as they do
especially considering that we're

1808
00:35:22,260 --> 00:35:22,270
especially considering that we're
 

1809
00:35:22,270 --> 00:35:23,460
especially considering that we're
basically training them to memorize

1810
00:35:23,460 --> 00:35:23,470
basically training them to memorize
 

1811
00:35:23,470 --> 00:35:27,150
basically training them to memorize
rather than generalize I think part of

1812
00:35:27,150 --> 00:35:27,160
rather than generalize I think part of
 

1813
00:35:27,160 --> 00:35:29,070
rather than generalize I think part of
the answer is there's a paper called

1814
00:35:29,070 --> 00:35:29,080
the answer is there's a paper called
 

1815
00:35:29,080 --> 00:35:31,530
the answer is there's a paper called
deep image prior where they show that

1816
00:35:31,530 --> 00:35:31,540
deep image prior where they show that
 

1817
00:35:31,540 --> 00:35:33,240
deep image prior where they show that
you can take a convolutional net and you

1818
00:35:33,240 --> 00:35:33,250
you can take a convolutional net and you
 

1819
00:35:33,250 --> 00:35:34,500
you can take a convolutional net and you
don't even need to learn the parameters

1820
00:35:34,500 --> 00:35:34,510
don't even need to learn the parameters
 

1821
00:35:34,510 --> 00:35:34,980
don't even need to learn the parameters
of it at all

1822
00:35:34,980 --> 00:35:34,990
of it at all
 

1823
00:35:34,990 --> 00:35:36,890
of it at all
you just use the model architecture and

1824
00:35:36,890 --> 00:35:36,900
you just use the model architecture and
 

1825
00:35:36,900 --> 00:35:39,420
you just use the model architecture and
it's already useful for things like in

1826
00:35:39,420 --> 00:35:39,430
it's already useful for things like in
 

1827
00:35:39,430 --> 00:35:42,120
it's already useful for things like in
painting images I think that shows us

1828
00:35:42,120 --> 00:35:42,130
painting images I think that shows us
 

1829
00:35:42,130 --> 00:35:43,710
painting images I think that shows us
that the convolutional network

1830
00:35:43,710 --> 00:35:43,720
that the convolutional network
 

1831
00:35:43,720 --> 00:35:45,330
that the convolutional network
architecture captures something really

1832
00:35:45,330 --> 00:35:45,340
architecture captures something really
 

1833
00:35:45,340 --> 00:35:47,130
architecture captures something really
important about the structure of images

1834
00:35:47,130 --> 00:35:47,140
important about the structure of images
 

1835
00:35:47,140 --> 00:35:50,430
important about the structure of images
and we don't need to actually use

1836
00:35:50,430 --> 00:35:50,440
and we don't need to actually use
 

1837
00:35:50,440 --> 00:35:51,720
and we don't need to actually use
learning to capture all the information

1838
00:35:51,720 --> 00:35:51,730
learning to capture all the information
 

1839
00:35:51,730 --> 00:35:55,560
learning to capture all the information
coming out of the convolutional net that

1840
00:35:55,560 --> 00:35:55,570
coming out of the convolutional net that
 

1841
00:35:55,570 --> 00:35:57,840
coming out of the convolutional net that
would that would imply that it would be

1842
00:35:57,840 --> 00:35:57,850
would that would imply that it would be
 

1843
00:35:57,850 --> 00:35:59,460
would that would imply that it would be
much harder to make generative models in

1844
00:35:59,460 --> 00:35:59,470
much harder to make generative models in
 

1845
00:35:59,470 --> 00:36:02,370
much harder to make generative models in
other domains so far we're able to make

1846
00:36:02,370 --> 00:36:02,380
other domains so far we're able to make
 

1847
00:36:02,380 --> 00:36:04,050
other domains so far we're able to make
reasonable speech models and things like

1848
00:36:04,050 --> 00:36:04,060
reasonable speech models and things like
 

1849
00:36:04,060 --> 00:36:06,630
reasonable speech models and things like
that but to be honest we haven't

1850
00:36:06,630 --> 00:36:06,640
that but to be honest we haven't
 

1851
00:36:06,640 --> 00:36:07,890
that but to be honest we haven't
actually explored a whole lot of

1852
00:36:07,890 --> 00:36:07,900
actually explored a whole lot of
 

1853
00:36:07,900 --> 00:36:09,900
actually explored a whole lot of
different data sets all that much we

1854
00:36:09,900 --> 00:36:09,910
different data sets all that much we
 

1855
00:36:09,910 --> 00:36:12,990
different data sets all that much we
don't for example see a lot of deep

1856
00:36:12,990 --> 00:36:13,000
don't for example see a lot of deep
 

1857
00:36:13,000 --> 00:36:17,700
don't for example see a lot of deep
learning models of like biology datasets

1858
00:36:17,700 --> 00:36:17,710
learning models of like biology datasets
 

1859
00:36:17,710 --> 00:36:19,560
learning models of like biology datasets
where you have lots of microarrays

1860
00:36:19,560 --> 00:36:19,570
where you have lots of microarrays
 

1861
00:36:19,570 --> 00:36:21,630
where you have lots of microarrays
measuring the amount of different

1862
00:36:21,630 --> 00:36:21,640
measuring the amount of different
 

1863
00:36:21,640 --> 00:36:23,160
measuring the amount of different
enzymes and things like that so we may

1864
00:36:23,160 --> 00:36:23,170
enzymes and things like that so we may
 

1865
00:36:23,170 --> 00:36:25,350
enzymes and things like that so we may
find that some of the progress that

1866
00:36:25,350 --> 00:36:25,360
find that some of the progress that
 

1867
00:36:25,360 --> 00:36:27,090
find that some of the progress that
we've seen for images and speech turns

1868
00:36:27,090 --> 00:36:27,100
we've seen for images and speech turns
 

1869
00:36:27,100 --> 00:36:28,920
we've seen for images and speech turns
out to really rely heavily on the model

1870
00:36:28,920 --> 00:36:28,930
out to really rely heavily on the model
 

1871
00:36:28,930 --> 00:36:32,040
out to really rely heavily on the model
architecture and we were able to do what

1872
00:36:32,040 --> 00:36:32,050
architecture and we were able to do what
 

1873
00:36:32,050 --> 00:36:34,050
architecture and we were able to do what
we did for vision by trying to

1874
00:36:34,050 --> 00:36:34,060
we did for vision by trying to
 

1875
00:36:34,060 --> 00:36:35,790
we did for vision by trying to
reverse-engineer the human visual system

1876
00:36:35,790 --> 00:36:35,800
reverse-engineer the human visual system
 

1877
00:36:35,800 --> 00:36:37,380
reverse-engineer the human visual system
and

1878
00:36:37,380 --> 00:36:37,390
and
 

1879
00:36:37,390 --> 00:36:38,940
and
maybe it'll turn out that we can't just

1880
00:36:38,940 --> 00:36:38,950
maybe it'll turn out that we can't just
 

1881
00:36:38,950 --> 00:36:41,970
maybe it'll turn out that we can't just
use that same trick for arbitrary kinds

1882
00:36:41,970 --> 00:36:41,980
use that same trick for arbitrary kinds
 

1883
00:36:41,980 --> 00:36:44,430
use that same trick for arbitrary kinds
of data all right so there's aspects of

1884
00:36:44,430 --> 00:36:44,440
of data all right so there's aspects of
 

1885
00:36:44,440 --> 00:36:46,530
of data all right so there's aspects of
the human vision system the hardware of

1886
00:36:46,530 --> 00:36:46,540
the human vision system the hardware of
 

1887
00:36:46,540 --> 00:36:49,890
the human vision system the hardware of
it that makes it without learning

1888
00:36:49,890 --> 00:36:49,900
it that makes it without learning
 

1889
00:36:49,900 --> 00:36:51,870
it that makes it without learning
without cognition just makes it really

1890
00:36:51,870 --> 00:36:51,880
without cognition just makes it really
 

1891
00:36:51,880 --> 00:36:53,580
without cognition just makes it really
effective at detecting the patterns

1892
00:36:53,580 --> 00:36:53,590
effective at detecting the patterns
 

1893
00:36:53,590 --> 00:36:55,590
effective at detecting the patterns
we've seen the visual world yeah that's

1894
00:36:55,590 --> 00:36:55,600
we've seen the visual world yeah that's
 

1895
00:36:55,600 --> 00:37:00,030
we've seen the visual world yeah that's
yeah that's really interesting what in a

1896
00:37:00,030 --> 00:37:00,040
yeah that's really interesting what in a
 

1897
00:37:00,040 --> 00:37:04,230
yeah that's really interesting what in a
big quick overview in your view in your

1898
00:37:04,230 --> 00:37:04,240
big quick overview in your view in your
 

1899
00:37:04,240 --> 00:37:06,150
big quick overview in your view in your
view what types of Gans are there and

1900
00:37:06,150 --> 00:37:06,160
view what types of Gans are there and
 

1901
00:37:06,160 --> 00:37:08,430
view what types of Gans are there and
what other generative models besides

1902
00:37:08,430 --> 00:37:08,440
what other generative models besides
 

1903
00:37:08,440 --> 00:37:12,510
what other generative models besides
games are there yeah so it's maybe a

1904
00:37:12,510 --> 00:37:12,520
games are there yeah so it's maybe a
 

1905
00:37:12,520 --> 00:37:13,650
games are there yeah so it's maybe a
little bit easier to start with what

1906
00:37:13,650 --> 00:37:13,660
little bit easier to start with what
 

1907
00:37:13,660 --> 00:37:14,850
little bit easier to start with what
kinds of generative models are there

1908
00:37:14,850 --> 00:37:14,860
kinds of generative models are there
 

1909
00:37:14,860 --> 00:37:16,010
kinds of generative models are there
other than Gans

1910
00:37:16,010 --> 00:37:16,020
other than Gans
 

1911
00:37:16,020 --> 00:37:19,770
other than Gans
so most generative models are likelihood

1912
00:37:19,770 --> 00:37:19,780
so most generative models are likelihood
 

1913
00:37:19,780 --> 00:37:23,490
so most generative models are likelihood
based where to train them you have a

1914
00:37:23,490 --> 00:37:23,500
based where to train them you have a
 

1915
00:37:23,500 --> 00:37:26,160
based where to train them you have a
model that tells you how how much

1916
00:37:26,160 --> 00:37:26,170
model that tells you how how much
 

1917
00:37:26,170 --> 00:37:27,990
model that tells you how how much
probability it assigns to a particular

1918
00:37:27,990 --> 00:37:28,000
probability it assigns to a particular
 

1919
00:37:28,000 --> 00:37:30,480
probability it assigns to a particular
example and you just maximize the

1920
00:37:30,480 --> 00:37:30,490
example and you just maximize the
 

1921
00:37:30,490 --> 00:37:32,130
example and you just maximize the
probability assigned to all the training

1922
00:37:32,130 --> 00:37:32,140
probability assigned to all the training
 

1923
00:37:32,140 --> 00:37:34,920
probability assigned to all the training
examples it turns out that it's hard to

1924
00:37:34,920 --> 00:37:34,930
examples it turns out that it's hard to
 

1925
00:37:34,930 --> 00:37:38,010
examples it turns out that it's hard to
design a model that can create really

1926
00:37:38,010 --> 00:37:38,020
design a model that can create really
 

1927
00:37:38,020 --> 00:37:40,440
design a model that can create really
complicated images or really complicated

1928
00:37:40,440 --> 00:37:40,450
complicated images or really complicated
 

1929
00:37:40,450 --> 00:37:43,110
complicated images or really complicated
audio waveforms and still have it be

1930
00:37:43,110 --> 00:37:43,120
audio waveforms and still have it be
 

1931
00:37:43,120 --> 00:37:47,640
audio waveforms and still have it be
possible to estimate the the likelihood

1932
00:37:47,640 --> 00:37:47,650
possible to estimate the the likelihood
 

1933
00:37:47,650 --> 00:37:51,150
possible to estimate the the likelihood
function from a computational point of

1934
00:37:51,150 --> 00:37:51,160
function from a computational point of
 

1935
00:37:51,160 --> 00:37:53,430
function from a computational point of
view most interesting models that you

1936
00:37:53,430 --> 00:37:53,440
view most interesting models that you
 

1937
00:37:53,440 --> 00:37:54,930
view most interesting models that you
would just write down intuitively it

1938
00:37:54,930 --> 00:37:54,940
would just write down intuitively it
 

1939
00:37:54,940 --> 00:37:57,120
would just write down intuitively it
turns out that it's almost impossible to

1940
00:37:57,120 --> 00:37:57,130
turns out that it's almost impossible to
 

1941
00:37:57,130 --> 00:37:59,130
turns out that it's almost impossible to
calculate the amount of probability they

1942
00:37:59,130 --> 00:37:59,140
calculate the amount of probability they
 

1943
00:37:59,140 --> 00:38:01,920
calculate the amount of probability they
assign to a particular point so there's

1944
00:38:01,920 --> 00:38:01,930
assign to a particular point so there's
 

1945
00:38:01,930 --> 00:38:04,170
assign to a particular point so there's
a few different schools of generative

1946
00:38:04,170 --> 00:38:04,180
a few different schools of generative
 

1947
00:38:04,180 --> 00:38:07,740
a few different schools of generative
models in the likelyhood family one

1948
00:38:07,740 --> 00:38:07,750
models in the likelyhood family one
 

1949
00:38:07,750 --> 00:38:09,900
models in the likelyhood family one
approach is to very carefully design the

1950
00:38:09,900 --> 00:38:09,910
approach is to very carefully design the
 

1951
00:38:09,910 --> 00:38:11,730
approach is to very carefully design the
model so that it is computationally

1952
00:38:11,730 --> 00:38:11,740
model so that it is computationally
 

1953
00:38:11,740 --> 00:38:13,710
model so that it is computationally
tractable to measure the density it

1954
00:38:13,710 --> 00:38:13,720
tractable to measure the density it
 

1955
00:38:13,720 --> 00:38:15,810
tractable to measure the density it
assigns to a particular point so there

1956
00:38:15,810 --> 00:38:15,820
assigns to a particular point so there
 

1957
00:38:15,820 --> 00:38:18,420
assigns to a particular point so there
are things like auto regressive models

1958
00:38:18,420 --> 00:38:18,430
are things like auto regressive models
 

1959
00:38:18,430 --> 00:38:23,550
are things like auto regressive models
like pixel CN n those basically break

1960
00:38:23,550 --> 00:38:23,560
like pixel CN n those basically break
 

1961
00:38:23,560 --> 00:38:26,190
like pixel CN n those basically break
down the probability distribution into a

1962
00:38:26,190 --> 00:38:26,200
down the probability distribution into a
 

1963
00:38:26,200 --> 00:38:29,010
down the probability distribution into a
product over every single feature so for

1964
00:38:29,010 --> 00:38:29,020
product over every single feature so for
 

1965
00:38:29,020 --> 00:38:31,530
product over every single feature so for
an image you estimate the probability of

1966
00:38:31,530 --> 00:38:31,540
an image you estimate the probability of
 

1967
00:38:31,540 --> 00:38:33,990
an image you estimate the probability of
each pixel given all of the pixels that

1968
00:38:33,990 --> 00:38:34,000
each pixel given all of the pixels that
 

1969
00:38:34,000 --> 00:38:36,570
each pixel given all of the pixels that
came before it hmm there's tricks where

1970
00:38:36,570 --> 00:38:36,580
came before it hmm there's tricks where
 

1971
00:38:36,580 --> 00:38:37,890
came before it hmm there's tricks where
if you want to measure the density

1972
00:38:37,890 --> 00:38:37,900
if you want to measure the density
 

1973
00:38:37,900 --> 00:38:40,710
if you want to measure the density
function you can actually calculate the

1974
00:38:40,710 --> 00:38:40,720
function you can actually calculate the
 

1975
00:38:40,720 --> 00:38:42,450
function you can actually calculate the
density for all these pixels more or

1976
00:38:42,450 --> 00:38:42,460
density for all these pixels more or
 

1977
00:38:42,460 --> 00:38:45,330
density for all these pixels more or
less in parallel generating the image

1978
00:38:45,330 --> 00:38:45,340
less in parallel generating the image
 

1979
00:38:45,340 --> 00:38:47,190
less in parallel generating the image
still tends to require you to go one

1980
00:38:47,190 --> 00:38:47,200
still tends to require you to go one
 

1981
00:38:47,200 --> 00:38:49,500
still tends to require you to go one
pixel at a time and that can be very

1982
00:38:49,500 --> 00:38:49,510
pixel at a time and that can be very
 

1983
00:38:49,510 --> 00:38:50,589
pixel at a time and that can be very
slow

1984
00:38:50,589 --> 00:38:50,599
slow
 

1985
00:38:50,599 --> 00:38:53,049
slow
but there again tricks for doing this in

1986
00:38:53,049 --> 00:38:53,059
but there again tricks for doing this in
 

1987
00:38:53,059 --> 00:38:54,309
but there again tricks for doing this in
a hierarchical pattern where you can

1988
00:38:54,309 --> 00:38:54,319
a hierarchical pattern where you can
 

1989
00:38:54,319 --> 00:38:56,319
a hierarchical pattern where you can
keep the runtime under control or the

1990
00:38:56,319 --> 00:38:56,329
keep the runtime under control or the
 

1991
00:38:56,329 --> 00:38:58,620
keep the runtime under control or the
quality of the images it generates

1992
00:38:58,620 --> 00:38:58,630
quality of the images it generates
 

1993
00:38:58,630 --> 00:39:01,799
quality of the images it generates
putting runtime aside pretty good

1994
00:39:01,799 --> 00:39:01,809
putting runtime aside pretty good
 

1995
00:39:01,809 --> 00:39:04,930
putting runtime aside pretty good
they're reasonable yeah the I would say

1996
00:39:04,930 --> 00:39:04,940
they're reasonable yeah the I would say
 

1997
00:39:04,940 --> 00:39:08,049
they're reasonable yeah the I would say
a lot of the best results are from Gans

1998
00:39:08,049 --> 00:39:08,059
a lot of the best results are from Gans
 

1999
00:39:08,059 --> 00:39:10,229
a lot of the best results are from Gans
these days but it can be hard to tell

2000
00:39:10,229 --> 00:39:10,239
these days but it can be hard to tell
 

2001
00:39:10,239 --> 00:39:14,079
these days but it can be hard to tell
how much of that is based on who's

2002
00:39:14,079 --> 00:39:14,089
how much of that is based on who's
 

2003
00:39:14,089 --> 00:39:16,599
how much of that is based on who's
studying which type of algorithm if that

2004
00:39:16,599 --> 00:39:16,609
studying which type of algorithm if that
 

2005
00:39:16,609 --> 00:39:18,370
studying which type of algorithm if that
makes sense the amount of effort invest

2006
00:39:18,370 --> 00:39:18,380
makes sense the amount of effort invest
 

2007
00:39:18,380 --> 00:39:20,349
makes sense the amount of effort invest
in it but yeah or like the kind of

2008
00:39:20,349 --> 00:39:20,359
in it but yeah or like the kind of
 

2009
00:39:20,359 --> 00:39:22,120
in it but yeah or like the kind of
expertise so a lot of people who've

2010
00:39:22,120 --> 00:39:22,130
expertise so a lot of people who've
 

2011
00:39:22,130 --> 00:39:23,170
expertise so a lot of people who've
traditionally been excited about

2012
00:39:23,170 --> 00:39:23,180
traditionally been excited about
 

2013
00:39:23,180 --> 00:39:24,819
traditionally been excited about
graphics or art and things like that

2014
00:39:24,819 --> 00:39:24,829
graphics or art and things like that
 

2015
00:39:24,829 --> 00:39:27,430
graphics or art and things like that
have gotten interested in Gans and to

2016
00:39:27,430 --> 00:39:27,440
have gotten interested in Gans and to
 

2017
00:39:27,440 --> 00:39:29,109
have gotten interested in Gans and to
some extent it's hard to tell our Gans

2018
00:39:29,109 --> 00:39:29,119
some extent it's hard to tell our Gans
 

2019
00:39:29,119 --> 00:39:31,739
some extent it's hard to tell our Gans
doing better because they have a lot of

2020
00:39:31,739 --> 00:39:31,749
doing better because they have a lot of
 

2021
00:39:31,749 --> 00:39:34,390
doing better because they have a lot of
graphics and art experts behind them or

2022
00:39:34,390 --> 00:39:34,400
graphics and art experts behind them or
 

2023
00:39:34,400 --> 00:39:36,849
graphics and art experts behind them or
our Gans doing better because they're

2024
00:39:36,849 --> 00:39:36,859
our Gans doing better because they're
 

2025
00:39:36,859 --> 00:39:39,489
our Gans doing better because they're
more computationally efficient or our

2026
00:39:39,489 --> 00:39:39,499
more computationally efficient or our
 

2027
00:39:39,499 --> 00:39:40,839
more computationally efficient or our
Gans doing better because they

2028
00:39:40,839 --> 00:39:40,849
Gans doing better because they
 

2029
00:39:40,849 --> 00:39:43,779
Gans doing better because they
prioritize the realism of samples over

2030
00:39:43,779 --> 00:39:43,789
prioritize the realism of samples over
 

2031
00:39:43,789 --> 00:39:45,609
prioritize the realism of samples over
the accuracy of the density function I

2032
00:39:45,609 --> 00:39:45,619
the accuracy of the density function I
 

2033
00:39:45,619 --> 00:39:46,870
the accuracy of the density function I
think I think all of those are

2034
00:39:46,870 --> 00:39:46,880
think I think all of those are
 

2035
00:39:46,880 --> 00:39:48,880
think I think all of those are
potentially valid explanations and it's

2036
00:39:48,880 --> 00:39:48,890
potentially valid explanations and it's
 

2037
00:39:48,890 --> 00:39:51,819
potentially valid explanations and it's
it's hard to tell so can you give a

2038
00:39:51,819 --> 00:39:51,829
it's hard to tell so can you give a
 

2039
00:39:51,829 --> 00:39:58,059
it's hard to tell so can you give a
brief history of Gans from 2014 we paid

2040
00:39:58,059 --> 00:39:58,069
brief history of Gans from 2014 we paid
 

2041
00:39:58,069 --> 00:40:01,209
brief history of Gans from 2014 we paid
for 13 yeah so a few highlights in the

2042
00:40:01,209 --> 00:40:01,219
for 13 yeah so a few highlights in the
 

2043
00:40:01,219 --> 00:40:03,430
for 13 yeah so a few highlights in the
first paper we just showed that Gans

2044
00:40:03,430 --> 00:40:03,440
first paper we just showed that Gans
 

2045
00:40:03,440 --> 00:40:05,529
first paper we just showed that Gans
basically work if you look back at the

2046
00:40:05,529 --> 00:40:05,539
basically work if you look back at the
 

2047
00:40:05,539 --> 00:40:07,890
basically work if you look back at the
samples we had now they looked terrible

2048
00:40:07,890 --> 00:40:07,900
samples we had now they looked terrible
 

2049
00:40:07,900 --> 00:40:10,390
samples we had now they looked terrible
on the CFR 10 dataset you can't even

2050
00:40:10,390 --> 00:40:10,400
on the CFR 10 dataset you can't even
 

2051
00:40:10,400 --> 00:40:13,209
on the CFR 10 dataset you can't even
recognize objects in them your papers I

2052
00:40:13,209 --> 00:40:13,219
recognize objects in them your papers I
 

2053
00:40:13,219 --> 00:40:16,180
recognize objects in them your papers I
will use CFR 10 we use em NIST which is

2054
00:40:16,180 --> 00:40:16,190
will use CFR 10 we use em NIST which is
 

2055
00:40:16,190 --> 00:40:18,430
will use CFR 10 we use em NIST which is
little handwritten digits we used the

2056
00:40:18,430 --> 00:40:18,440
little handwritten digits we used the
 

2057
00:40:18,440 --> 00:40:20,620
little handwritten digits we used the
Toronto face database which is small

2058
00:40:20,620 --> 00:40:20,630
Toronto face database which is small
 

2059
00:40:20,630 --> 00:40:22,329
Toronto face database which is small
grayscale photos of faces

2060
00:40:22,329 --> 00:40:22,339
grayscale photos of faces
 

2061
00:40:22,339 --> 00:40:24,309
grayscale photos of faces
we did have recognizable faces my

2062
00:40:24,309 --> 00:40:24,319
we did have recognizable faces my
 

2063
00:40:24,319 --> 00:40:25,989
we did have recognizable faces my
colleague Bing Xu put together the first

2064
00:40:25,989 --> 00:40:25,999
colleague Bing Xu put together the first
 

2065
00:40:25,999 --> 00:40:30,009
colleague Bing Xu put together the first
again face model for that paper we also

2066
00:40:30,009 --> 00:40:30,019
again face model for that paper we also
 

2067
00:40:30,019 --> 00:40:33,549
again face model for that paper we also
had the CFR 10 dataset which is things

2068
00:40:33,549 --> 00:40:33,559
had the CFR 10 dataset which is things
 

2069
00:40:33,559 --> 00:40:38,049
had the CFR 10 dataset which is things
like very small 32 by 32 pixels of cars

2070
00:40:38,049 --> 00:40:38,059
like very small 32 by 32 pixels of cars
 

2071
00:40:38,059 --> 00:40:41,559
like very small 32 by 32 pixels of cars
and cats and dogs for that we didn't get

2072
00:40:41,559 --> 00:40:41,569
and cats and dogs for that we didn't get
 

2073
00:40:41,569 --> 00:40:44,289
and cats and dogs for that we didn't get
recognizable objects but all the deep

2074
00:40:44,289 --> 00:40:44,299
recognizable objects but all the deep
 

2075
00:40:44,299 --> 00:40:46,390
recognizable objects but all the deep
learning people back then we're really

2076
00:40:46,390 --> 00:40:46,400
learning people back then we're really
 

2077
00:40:46,400 --> 00:40:48,249
learning people back then we're really
used to looking at these failed samples

2078
00:40:48,249 --> 00:40:48,259
used to looking at these failed samples
 

2079
00:40:48,259 --> 00:40:49,450
used to looking at these failed samples
and kind of reading them like tea leaves

2080
00:40:49,450 --> 00:40:49,460
and kind of reading them like tea leaves
 

2081
00:40:49,460 --> 00:40:52,390
and kind of reading them like tea leaves
right and people who are used to reading

2082
00:40:52,390 --> 00:40:52,400
right and people who are used to reading
 

2083
00:40:52,400 --> 00:40:54,640
right and people who are used to reading
the tea leaves recognize that our tea

2084
00:40:54,640 --> 00:40:54,650
the tea leaves recognize that our tea
 

2085
00:40:54,650 --> 00:40:56,049
the tea leaves recognize that our tea
leaves at least look different right

2086
00:40:56,049 --> 00:40:56,059
leaves at least look different right
 

2087
00:40:56,059 --> 00:40:57,999
leaves at least look different right
maybe not necessarily better but there

2088
00:40:57,999 --> 00:40:58,009
maybe not necessarily better but there
 

2089
00:40:58,009 --> 00:41:00,720
maybe not necessarily better but there
was something unusual about them

2090
00:41:00,720 --> 00:41:00,730
was something unusual about them
 

2091
00:41:00,730 --> 00:41:03,870
was something unusual about them
and that got a lot of us excited one of

2092
00:41:03,870 --> 00:41:03,880
and that got a lot of us excited one of
 

2093
00:41:03,880 --> 00:41:05,849
and that got a lot of us excited one of
the next really big steps was lap gown

2094
00:41:05,849 --> 00:41:05,859
the next really big steps was lap gown
 

2095
00:41:05,859 --> 00:41:08,540
the next really big steps was lap gown
by Emily Denton and seemeth chintala at

2096
00:41:08,540 --> 00:41:08,550
by Emily Denton and seemeth chintala at
 

2097
00:41:08,550 --> 00:41:11,640
by Emily Denton and seemeth chintala at
Facebook AI research where they actually

2098
00:41:11,640 --> 00:41:11,650
Facebook AI research where they actually
 

2099
00:41:11,650 --> 00:41:14,250
Facebook AI research where they actually
got really good high-resolution photos

2100
00:41:14,250 --> 00:41:14,260
got really good high-resolution photos
 

2101
00:41:14,260 --> 00:41:15,870
got really good high-resolution photos
working with gans for the first time

2102
00:41:15,870 --> 00:41:15,880
working with gans for the first time
 

2103
00:41:15,880 --> 00:41:18,329
working with gans for the first time
they had a complicated system where they

2104
00:41:18,329 --> 00:41:18,339
they had a complicated system where they
 

2105
00:41:18,339 --> 00:41:19,920
they had a complicated system where they
generated the image starting at low res

2106
00:41:19,920 --> 00:41:19,930
generated the image starting at low res
 

2107
00:41:19,930 --> 00:41:23,099
generated the image starting at low res
and then scaling up to high res but they

2108
00:41:23,099 --> 00:41:23,109
and then scaling up to high res but they
 

2109
00:41:23,109 --> 00:41:27,150
and then scaling up to high res but they
were able to get it to work and then in

2110
00:41:27,150 --> 00:41:27,160
were able to get it to work and then in
 

2111
00:41:27,160 --> 00:41:31,230
were able to get it to work and then in
2015 I believe later that same year

2112
00:41:31,230 --> 00:41:31,240
2015 I believe later that same year
 

2113
00:41:31,240 --> 00:41:34,230
2015 I believe later that same year
palek Radford and sumh intelli and Luke

2114
00:41:34,230 --> 00:41:34,240
palek Radford and sumh intelli and Luke
 

2115
00:41:34,240 --> 00:41:38,520
palek Radford and sumh intelli and Luke
Metz published the DC gain paper which

2116
00:41:38,520 --> 00:41:38,530
Metz published the DC gain paper which
 

2117
00:41:38,530 --> 00:41:41,000
Metz published the DC gain paper which
it stands for deep convolutional again

2118
00:41:41,000 --> 00:41:41,010
it stands for deep convolutional again
 

2119
00:41:41,010 --> 00:41:44,300
it stands for deep convolutional again
it's kind of a non unique name because

2120
00:41:44,300 --> 00:41:44,310
it's kind of a non unique name because
 

2121
00:41:44,310 --> 00:41:46,650
it's kind of a non unique name because
these days basically all gans and even

2122
00:41:46,650 --> 00:41:46,660
these days basically all gans and even
 

2123
00:41:46,660 --> 00:41:47,730
these days basically all gans and even
some before that were deep in

2124
00:41:47,730 --> 00:41:47,740
some before that were deep in
 

2125
00:41:47,740 --> 00:41:49,589
some before that were deep in
convolutional but they just kind of

2126
00:41:49,589 --> 00:41:49,599
convolutional but they just kind of
 

2127
00:41:49,599 --> 00:41:51,960
convolutional but they just kind of
picked a name for a really great recipe

2128
00:41:51,960 --> 00:41:51,970
picked a name for a really great recipe
 

2129
00:41:51,970 --> 00:41:54,359
picked a name for a really great recipe
where they were able to actually using

2130
00:41:54,359 --> 00:41:54,369
where they were able to actually using
 

2131
00:41:54,369 --> 00:41:56,190
where they were able to actually using
only one model instead of a multi-step

2132
00:41:56,190 --> 00:41:56,200
only one model instead of a multi-step
 

2133
00:41:56,200 --> 00:41:58,589
only one model instead of a multi-step
process actually generate realistic

2134
00:41:58,589 --> 00:41:58,599
process actually generate realistic
 

2135
00:41:58,599 --> 00:42:01,160
process actually generate realistic
images of faces and things like that

2136
00:42:01,160 --> 00:42:01,170
images of faces and things like that
 

2137
00:42:01,170 --> 00:42:05,250
images of faces and things like that
that was sort of like the beginning of

2138
00:42:05,250 --> 00:42:05,260
that was sort of like the beginning of
 

2139
00:42:05,260 --> 00:42:07,829
that was sort of like the beginning of
the Cambrian explosion of gans like you

2140
00:42:07,829 --> 00:42:07,839
the Cambrian explosion of gans like you
 

2141
00:42:07,839 --> 00:42:09,120
the Cambrian explosion of gans like you
know once once you got animals that had

2142
00:42:09,120 --> 00:42:09,130
know once once you got animals that had
 

2143
00:42:09,130 --> 00:42:10,530
know once once you got animals that had
a backbone you suddenly got lots of

2144
00:42:10,530 --> 00:42:10,540
a backbone you suddenly got lots of
 

2145
00:42:10,540 --> 00:42:12,660
a backbone you suddenly got lots of
different versions of you know like fish

2146
00:42:12,660 --> 00:42:12,670
different versions of you know like fish
 

2147
00:42:12,670 --> 00:42:14,579
different versions of you know like fish
and right they have four-legged animals

2148
00:42:14,579 --> 00:42:14,589
and right they have four-legged animals
 

2149
00:42:14,589 --> 00:42:16,380
and right they have four-legged animals
and things like that so so DC Gann

2150
00:42:16,380 --> 00:42:16,390
and things like that so so DC Gann
 

2151
00:42:16,390 --> 00:42:18,300
and things like that so so DC Gann
became kind of the backbone for many

2152
00:42:18,300 --> 00:42:18,310
became kind of the backbone for many
 

2153
00:42:18,310 --> 00:42:19,770
became kind of the backbone for many
different models that came out used as a

2154
00:42:19,770 --> 00:42:19,780
different models that came out used as a
 

2155
00:42:19,780 --> 00:42:24,120
different models that came out used as a
baseline even still yeah yeah and so

2156
00:42:24,120 --> 00:42:24,130
baseline even still yeah yeah and so
 

2157
00:42:24,130 --> 00:42:25,710
baseline even still yeah yeah and so
from there I would say some interesting

2158
00:42:25,710 --> 00:42:25,720
from there I would say some interesting
 

2159
00:42:25,720 --> 00:42:28,980
from there I would say some interesting
things we've seen are there's a lot you

2160
00:42:28,980 --> 00:42:28,990
things we've seen are there's a lot you
 

2161
00:42:28,990 --> 00:42:30,930
things we've seen are there's a lot you
can say about how just the quality of

2162
00:42:30,930 --> 00:42:30,940
can say about how just the quality of
 

2163
00:42:30,940 --> 00:42:32,460
can say about how just the quality of
standard image generation ganz has

2164
00:42:32,460 --> 00:42:32,470
standard image generation ganz has
 

2165
00:42:32,470 --> 00:42:34,620
standard image generation ganz has
increased but what's also maybe more

2166
00:42:34,620 --> 00:42:34,630
increased but what's also maybe more
 

2167
00:42:34,630 --> 00:42:36,059
increased but what's also maybe more
interesting on an intellectual level is

2168
00:42:36,059 --> 00:42:36,069
interesting on an intellectual level is
 

2169
00:42:36,069 --> 00:42:39,000
interesting on an intellectual level is
how the things you can use guns for has

2170
00:42:39,000 --> 00:42:39,010
how the things you can use guns for has
 

2171
00:42:39,010 --> 00:42:41,849
how the things you can use guns for has
also changed one thing is that you can

2172
00:42:41,849 --> 00:42:41,859
also changed one thing is that you can
 

2173
00:42:41,859 --> 00:42:44,819
also changed one thing is that you can
use them to learn classifiers without

2174
00:42:44,819 --> 00:42:44,829
use them to learn classifiers without
 

2175
00:42:44,829 --> 00:42:46,859
use them to learn classifiers without
having to have class labels for every

2176
00:42:46,859 --> 00:42:46,869
having to have class labels for every
 

2177
00:42:46,869 --> 00:42:48,960
having to have class labels for every
example in your your training set so

2178
00:42:48,960 --> 00:42:48,970
example in your your training set so
 

2179
00:42:48,970 --> 00:42:50,930
example in your your training set so
that's called semi-supervised learning

2180
00:42:50,930 --> 00:42:50,940
that's called semi-supervised learning
 

2181
00:42:50,940 --> 00:42:53,670
that's called semi-supervised learning
my colleague at open AI Tim Solomon's

2182
00:42:53,670 --> 00:42:53,680
my colleague at open AI Tim Solomon's
 

2183
00:42:53,680 --> 00:42:56,190
my colleague at open AI Tim Solomon's
who's at at brain now wrote a paper

2184
00:42:56,190 --> 00:42:56,200
who's at at brain now wrote a paper
 

2185
00:42:56,200 --> 00:42:58,349
who's at at brain now wrote a paper
called improved techniques for training

2186
00:42:58,349 --> 00:42:58,359
called improved techniques for training
 

2187
00:42:58,359 --> 00:43:00,990
called improved techniques for training
guns I'm a co-author on this paper but I

2188
00:43:00,990 --> 00:43:01,000
guns I'm a co-author on this paper but I
 

2189
00:43:01,000 --> 00:43:02,130
guns I'm a co-author on this paper but I
can't claim any credit for this

2190
00:43:02,130 --> 00:43:02,140
can't claim any credit for this
 

2191
00:43:02,140 --> 00:43:04,410
can't claim any credit for this
particular part one thing he showed in

2192
00:43:04,410 --> 00:43:04,420
particular part one thing he showed in
 

2193
00:43:04,420 --> 00:43:06,990
particular part one thing he showed in
the paper is that you can take the gun

2194
00:43:06,990 --> 00:43:07,000
the paper is that you can take the gun
 

2195
00:43:07,000 --> 00:43:09,150
the paper is that you can take the gun
discriminator and use it as a classifier

2196
00:43:09,150 --> 00:43:09,160
discriminator and use it as a classifier
 

2197
00:43:09,160 --> 00:43:11,640
discriminator and use it as a classifier
that actually tells you you know this

2198
00:43:11,640 --> 00:43:11,650
that actually tells you you know this
 

2199
00:43:11,650 --> 00:43:13,650
that actually tells you you know this
image is a cat this image is a dog this

2200
00:43:13,650 --> 00:43:13,660
image is a cat this image is a dog this
 

2201
00:43:13,660 --> 00:43:14,520
image is a cat this image is a dog this
image is a car

2202
00:43:14,520 --> 00:43:14,530
image is a car
 

2203
00:43:14,530 --> 00:43:16,590
image is a car
this image is a truck and so and not

2204
00:43:16,590 --> 00:43:16,600
this image is a truck and so and not
 

2205
00:43:16,600 --> 00:43:18,000
this image is a truck and so and not
just to say whether the image is real or

2206
00:43:18,000 --> 00:43:18,010
just to say whether the image is real or
 

2207
00:43:18,010 --> 00:43:19,950
just to say whether the image is real or
fake but if it is real to say

2208
00:43:19,950 --> 00:43:19,960
fake but if it is real to say
 

2209
00:43:19,960 --> 00:43:21,630
fake but if it is real to say
specifically what kind of object it is

2210
00:43:21,630 --> 00:43:21,640
specifically what kind of object it is
 

2211
00:43:21,640 --> 00:43:24,420
specifically what kind of object it is
and he found that you can train these

2212
00:43:24,420 --> 00:43:24,430
and he found that you can train these
 

2213
00:43:24,430 --> 00:43:27,270
and he found that you can train these
classifiers with far fewer labeled

2214
00:43:27,270 --> 00:43:27,280
classifiers with far fewer labeled
 

2215
00:43:27,280 --> 00:43:29,910
classifiers with far fewer labeled
examples learn traditional classifiers

2216
00:43:29,910 --> 00:43:29,920
examples learn traditional classifiers
 

2217
00:43:29,920 --> 00:43:33,870
examples learn traditional classifiers
so a few supervised based on also not

2218
00:43:33,870 --> 00:43:33,880
so a few supervised based on also not
 

2219
00:43:33,880 --> 00:43:35,400
so a few supervised based on also not
just your discrimination ability but

2220
00:43:35,400 --> 00:43:35,410
just your discrimination ability but
 

2221
00:43:35,410 --> 00:43:37,290
just your discrimination ability but
your ability to classify you're going to

2222
00:43:37,290 --> 00:43:37,300
your ability to classify you're going to
 

2223
00:43:37,300 --> 00:43:39,540
your ability to classify you're going to
do much you're going to convert much

2224
00:43:39,540 --> 00:43:39,550
do much you're going to convert much
 

2225
00:43:39,550 --> 00:43:42,600
do much you're going to convert much
faster to being effective at being a

2226
00:43:42,600 --> 00:43:42,610
faster to being effective at being a
 

2227
00:43:42,610 --> 00:43:45,360
faster to being effective at being a
discriminator yeah so for example for

2228
00:43:45,360 --> 00:43:45,370
discriminator yeah so for example for
 

2229
00:43:45,370 --> 00:43:47,040
discriminator yeah so for example for
the emne status set you want to look at

2230
00:43:47,040 --> 00:43:47,050
the emne status set you want to look at
 

2231
00:43:47,050 --> 00:43:49,140
the emne status set you want to look at
an image of a handwritten digit and say

2232
00:43:49,140 --> 00:43:49,150
an image of a handwritten digit and say
 

2233
00:43:49,150 --> 00:43:53,270
an image of a handwritten digit and say
whether it's a 0 a 1 or 2 and so on

2234
00:43:53,270 --> 00:43:53,280
whether it's a 0 a 1 or 2 and so on
 

2235
00:43:53,280 --> 00:43:56,520
whether it's a 0 a 1 or 2 and so on
to get down to less than 1% accuracy

2236
00:43:56,520 --> 00:43:56,530
to get down to less than 1% accuracy
 

2237
00:43:56,530 --> 00:44:00,540
to get down to less than 1% accuracy
required around 60,000 examples until

2238
00:44:00,540 --> 00:44:00,550
required around 60,000 examples until
 

2239
00:44:00,550 --> 00:44:04,970
required around 60,000 examples until
maybe about 2014 or so in 2016 with this

2240
00:44:04,970 --> 00:44:04,980
maybe about 2014 or so in 2016 with this
 

2241
00:44:04,980 --> 00:44:07,740
maybe about 2014 or so in 2016 with this
semi-supervised degan project tim was

2242
00:44:07,740 --> 00:44:07,750
semi-supervised degan project tim was
 

2243
00:44:07,750 --> 00:44:11,610
semi-supervised degan project tim was
able to get below 1% error using only a

2244
00:44:11,610 --> 00:44:11,620
able to get below 1% error using only a
 

2245
00:44:11,620 --> 00:44:14,100
able to get below 1% error using only a
hundred labeled examples so that was

2246
00:44:14,100 --> 00:44:14,110
hundred labeled examples so that was
 

2247
00:44:14,110 --> 00:44:16,350
hundred labeled examples so that was
about a 600 X decrease in the amount of

2248
00:44:16,350 --> 00:44:16,360
about a 600 X decrease in the amount of
 

2249
00:44:16,360 --> 00:44:19,070
about a 600 X decrease in the amount of
labels that he needed he's still using

2250
00:44:19,070 --> 00:44:19,080
labels that he needed he's still using
 

2251
00:44:19,080 --> 00:44:21,690
labels that he needed he's still using
more images in that but he doesn't need

2252
00:44:21,690 --> 00:44:21,700
more images in that but he doesn't need
 

2253
00:44:21,700 --> 00:44:23,550
more images in that but he doesn't need
to have each of them labeled as you know

2254
00:44:23,550 --> 00:44:23,560
to have each of them labeled as you know
 

2255
00:44:23,560 --> 00:44:25,380
to have each of them labeled as you know
this one's a 1 this one's a 2 this one's

2256
00:44:25,380 --> 00:44:25,390
this one's a 1 this one's a 2 this one's
 

2257
00:44:25,390 --> 00:44:28,680
this one's a 1 this one's a 2 this one's
a 0 and so on then to be able to for

2258
00:44:28,680 --> 00:44:28,690
a 0 and so on then to be able to for
 

2259
00:44:28,690 --> 00:44:30,750
a 0 and so on then to be able to for
Ganz to be able to generate recognizable

2260
00:44:30,750 --> 00:44:30,760
Ganz to be able to generate recognizable
 

2261
00:44:30,760 --> 00:44:32,730
Ganz to be able to generate recognizable
objects so object for a particular class

2262
00:44:32,730 --> 00:44:32,740
objects so object for a particular class
 

2263
00:44:32,740 --> 00:44:37,200
objects so object for a particular class
you still need labelled data because you

2264
00:44:37,200 --> 00:44:37,210
you still need labelled data because you
 

2265
00:44:37,210 --> 00:44:39,090
you still need labelled data because you
need to know what it means to be a

2266
00:44:39,090 --> 00:44:39,100
need to know what it means to be a
 

2267
00:44:39,100 --> 00:44:42,210
need to know what it means to be a
particular class cat dog how do you

2268
00:44:42,210 --> 00:44:42,220
particular class cat dog how do you
 

2269
00:44:42,220 --> 00:44:44,700
particular class cat dog how do you
think we can move away from that yeah

2270
00:44:44,700 --> 00:44:44,710
think we can move away from that yeah
 

2271
00:44:44,710 --> 00:44:46,530
think we can move away from that yeah
some researchers at brain Zurich

2272
00:44:46,530 --> 00:44:46,540
some researchers at brain Zurich
 

2273
00:44:46,540 --> 00:44:47,910
some researchers at brain Zurich
actually just released a really great

2274
00:44:47,910 --> 00:44:47,920
actually just released a really great
 

2275
00:44:47,920 --> 00:44:51,990
actually just released a really great
paper on semi-supervised de Gans whether

2276
00:44:51,990 --> 00:44:52,000
paper on semi-supervised de Gans whether
 

2277
00:44:52,000 --> 00:44:54,680
paper on semi-supervised de Gans whether
their goal isn't to classify its to make

2278
00:44:54,680 --> 00:44:54,690
their goal isn't to classify its to make
 

2279
00:44:54,690 --> 00:44:56,730
their goal isn't to classify its to make
recognizable objects despite not having

2280
00:44:56,730 --> 00:44:56,740
recognizable objects despite not having
 

2281
00:44:56,740 --> 00:44:59,580
recognizable objects despite not having
a lot of label data they were working

2282
00:44:59,580 --> 00:44:59,590
a lot of label data they were working
 

2283
00:44:59,590 --> 00:45:02,010
a lot of label data they were working
off of deep minds big gun project and

2284
00:45:02,010 --> 00:45:02,020
off of deep minds big gun project and
 

2285
00:45:02,020 --> 00:45:04,560
off of deep minds big gun project and
they showed that they can match the

2286
00:45:04,560 --> 00:45:04,570
they showed that they can match the
 

2287
00:45:04,570 --> 00:45:08,040
they showed that they can match the
performance of began using only 10% I

2288
00:45:08,040 --> 00:45:08,050
performance of began using only 10% I
 

2289
00:45:08,050 --> 00:45:11,040
performance of began using only 10% I
believe of the of the labels big gun was

2290
00:45:11,040 --> 00:45:11,050
believe of the of the labels big gun was
 

2291
00:45:11,050 --> 00:45:12,420
believe of the of the labels big gun was
trained on the image net dataset which

2292
00:45:12,420 --> 00:45:12,430
trained on the image net dataset which
 

2293
00:45:12,430 --> 00:45:14,940
trained on the image net dataset which
is about 1.2 million images and had all

2294
00:45:14,940 --> 00:45:14,950
is about 1.2 million images and had all
 

2295
00:45:14,950 --> 00:45:18,360
is about 1.2 million images and had all
of them labelled this latest project

2296
00:45:18,360 --> 00:45:18,370
of them labelled this latest project
 

2297
00:45:18,370 --> 00:45:19,530
of them labelled this latest project
from brain Zurich shows that they're

2298
00:45:19,530 --> 00:45:19,540
from brain Zurich shows that they're
 

2299
00:45:19,540 --> 00:45:21,660
from brain Zurich shows that they're
able to get away with only having about

2300
00:45:21,660 --> 00:45:21,670
able to get away with only having about
 

2301
00:45:21,670 --> 00:45:25,220
able to get away with only having about
10% of the of the images labeled

2302
00:45:25,220 --> 00:45:25,230
10% of the of the images labeled
 

2303
00:45:25,230 --> 00:45:27,859
10% of the of the images labeled
and they do that essentially using a

2304
00:45:27,859 --> 00:45:27,869
and they do that essentially using a
 

2305
00:45:27,869 --> 00:45:30,200
and they do that essentially using a
clustering algorithm where the

2306
00:45:30,200 --> 00:45:30,210
clustering algorithm where the
 

2307
00:45:30,210 --> 00:45:32,540
clustering algorithm where the
discriminator learns to assign the

2308
00:45:32,540 --> 00:45:32,550
discriminator learns to assign the
 

2309
00:45:32,550 --> 00:45:35,630
discriminator learns to assign the
objects to groups and then this

2310
00:45:35,630 --> 00:45:35,640
objects to groups and then this
 

2311
00:45:35,640 --> 00:45:36,980
objects to groups and then this
understanding that objects can be

2312
00:45:36,980 --> 00:45:36,990
understanding that objects can be
 

2313
00:45:36,990 --> 00:45:39,980
understanding that objects can be
grouped into you know similar types

2314
00:45:39,980 --> 00:45:39,990
grouped into you know similar types
 

2315
00:45:39,990 --> 00:45:43,520
grouped into you know similar types
helps it to form more realistic ideas of

2316
00:45:43,520 --> 00:45:43,530
helps it to form more realistic ideas of
 

2317
00:45:43,530 --> 00:45:45,290
helps it to form more realistic ideas of
what should be appearing in the image

2318
00:45:45,290 --> 00:45:45,300
what should be appearing in the image
 

2319
00:45:45,300 --> 00:45:47,540
what should be appearing in the image
because it knows that every image it

2320
00:45:47,540 --> 00:45:47,550
because it knows that every image it
 

2321
00:45:47,550 --> 00:45:48,800
because it knows that every image it
creates has to come from one of these

2322
00:45:48,800 --> 00:45:48,810
creates has to come from one of these
 

2323
00:45:48,810 --> 00:45:50,900
creates has to come from one of these
archetypal groups rather than just being

2324
00:45:50,900 --> 00:45:50,910
archetypal groups rather than just being
 

2325
00:45:50,910 --> 00:45:53,930
archetypal groups rather than just being
some arbitrary image if you train again

2326
00:45:53,930 --> 00:45:53,940
some arbitrary image if you train again
 

2327
00:45:53,940 --> 00:45:55,550
some arbitrary image if you train again
with no class labels you tend to get

2328
00:45:55,550 --> 00:45:55,560
with no class labels you tend to get
 

2329
00:45:55,560 --> 00:45:57,800
with no class labels you tend to get
things that look sort of like grass or

2330
00:45:57,800 --> 00:45:57,810
things that look sort of like grass or
 

2331
00:45:57,810 --> 00:46:02,210
things that look sort of like grass or
water or brick or dirt but but without

2332
00:46:02,210 --> 00:46:02,220
water or brick or dirt but but without
 

2333
00:46:02,220 --> 00:46:04,880
water or brick or dirt but but without
necessarily a lot going on in them and I

2334
00:46:04,880 --> 00:46:04,890
necessarily a lot going on in them and I
 

2335
00:46:04,890 --> 00:46:06,080
necessarily a lot going on in them and I
think that's partly because if you look

2336
00:46:06,080 --> 00:46:06,090
think that's partly because if you look
 

2337
00:46:06,090 --> 00:46:08,420
think that's partly because if you look
at a large image net image the object

2338
00:46:08,420 --> 00:46:08,430
at a large image net image the object
 

2339
00:46:08,430 --> 00:46:10,820
at a large image net image the object
doesn't necessarily occupy the whole

2340
00:46:10,820 --> 00:46:10,830
doesn't necessarily occupy the whole
 

2341
00:46:10,830 --> 00:46:13,420
doesn't necessarily occupy the whole
image and so you learn to create

2342
00:46:13,420 --> 00:46:13,430
image and so you learn to create
 

2343
00:46:13,430 --> 00:46:15,980
image and so you learn to create
realistic sets of pixels but you don't

2344
00:46:15,980 --> 00:46:15,990
realistic sets of pixels but you don't
 

2345
00:46:15,990 --> 00:46:18,830
realistic sets of pixels but you don't
necessarily learn that the object is the

2346
00:46:18,830 --> 00:46:18,840
necessarily learn that the object is the
 

2347
00:46:18,840 --> 00:46:20,930
necessarily learn that the object is the
star of the show and you want it to be

2348
00:46:20,930 --> 00:46:20,940
star of the show and you want it to be
 

2349
00:46:20,940 --> 00:46:22,580
star of the show and you want it to be
in every image you make yeah you've

2350
00:46:22,580 --> 00:46:22,590
in every image you make yeah you've
 

2351
00:46:22,590 --> 00:46:25,550
in every image you make yeah you've
heard you talk about the the horse the

2352
00:46:25,550 --> 00:46:25,560
heard you talk about the the horse the
 

2353
00:46:25,560 --> 00:46:28,340
heard you talk about the the horse the
zebra cycle Gann mapping and how it

2354
00:46:28,340 --> 00:46:28,350
zebra cycle Gann mapping and how it
 

2355
00:46:28,350 --> 00:46:32,090
zebra cycle Gann mapping and how it
turns out again thought provoking that

2356
00:46:32,090 --> 00:46:32,100
turns out again thought provoking that
 

2357
00:46:32,100 --> 00:46:34,130
turns out again thought provoking that
horses are usually on grass and zebras

2358
00:46:34,130 --> 00:46:34,140
horses are usually on grass and zebras
 

2359
00:46:34,140 --> 00:46:36,470
horses are usually on grass and zebras
are usually on drier terrain so when

2360
00:46:36,470 --> 00:46:36,480
are usually on drier terrain so when
 

2361
00:46:36,480 --> 00:46:37,790
are usually on drier terrain so when
you're doing that kind of generation

2362
00:46:37,790 --> 00:46:37,800
you're doing that kind of generation
 

2363
00:46:37,800 --> 00:46:40,490
you're doing that kind of generation
you're going to end up generating

2364
00:46:40,490 --> 00:46:40,500
you're going to end up generating
 

2365
00:46:40,500 --> 00:46:44,510
you're going to end up generating
greener horses or whatever so those are

2366
00:46:44,510 --> 00:46:44,520
greener horses or whatever so those are
 

2367
00:46:44,520 --> 00:46:46,310
greener horses or whatever so those are
connected together it's not just yeah

2368
00:46:46,310 --> 00:46:46,320
connected together it's not just yeah
 

2369
00:46:46,320 --> 00:46:48,020
connected together it's not just yeah
yeah be able to you're not able to

2370
00:46:48,020 --> 00:46:48,030
yeah be able to you're not able to
 

2371
00:46:48,030 --> 00:46:49,580
yeah be able to you're not able to
segment

2372
00:46:49,580 --> 00:46:49,590
segment
 

2373
00:46:49,590 --> 00:46:51,500
segment
yeah it's generating the segments away

2374
00:46:51,500 --> 00:46:51,510
yeah it's generating the segments away
 

2375
00:46:51,510 --> 00:46:54,200
yeah it's generating the segments away
so there are other types of games you

2376
00:46:54,200 --> 00:46:54,210
so there are other types of games you
 

2377
00:46:54,210 --> 00:46:58,820
so there are other types of games you
come across in your mind that neural

2378
00:46:58,820 --> 00:46:58,830
come across in your mind that neural
 

2379
00:46:58,830 --> 00:47:02,540
come across in your mind that neural
networks can play with each other to to

2380
00:47:02,540 --> 00:47:02,550
networks can play with each other to to
 

2381
00:47:02,550 --> 00:47:05,720
networks can play with each other to to
to be able to solve problems yeah the

2382
00:47:05,720 --> 00:47:05,730
to be able to solve problems yeah the
 

2383
00:47:05,730 --> 00:47:07,550
to be able to solve problems yeah the
the one that I spend most of my time on

2384
00:47:07,550 --> 00:47:07,560
the one that I spend most of my time on
 

2385
00:47:07,560 --> 00:47:11,660
the one that I spend most of my time on
is insecurity you can model most

2386
00:47:11,660 --> 00:47:11,670
is insecurity you can model most
 

2387
00:47:11,670 --> 00:47:13,540
is insecurity you can model most
interactions as a game where there's

2388
00:47:13,540 --> 00:47:13,550
interactions as a game where there's
 

2389
00:47:13,550 --> 00:47:15,740
interactions as a game where there's
attackers trying to break your system

2390
00:47:15,740 --> 00:47:15,750
attackers trying to break your system
 

2391
00:47:15,750 --> 00:47:17,810
attackers trying to break your system
and you order the defender trying to

2392
00:47:17,810 --> 00:47:17,820
and you order the defender trying to
 

2393
00:47:17,820 --> 00:47:20,599
and you order the defender trying to
build a resilient system there's also

2394
00:47:20,599 --> 00:47:20,609
build a resilient system there's also
 

2395
00:47:20,609 --> 00:47:24,109
build a resilient system there's also
domain adversarial learning which is an

2396
00:47:24,109 --> 00:47:24,119
domain adversarial learning which is an
 

2397
00:47:24,119 --> 00:47:25,820
domain adversarial learning which is an
approach to domain adaptation that looks

2398
00:47:25,820 --> 00:47:25,830
approach to domain adaptation that looks
 

2399
00:47:25,830 --> 00:47:29,060
approach to domain adaptation that looks
really a lot like Ganz the the author's

2400
00:47:29,060 --> 00:47:29,070
really a lot like Ganz the the author's
 

2401
00:47:29,070 --> 00:47:30,770
really a lot like Ganz the the author's
had the idea before the game paper came

2402
00:47:30,770 --> 00:47:30,780
had the idea before the game paper came
 

2403
00:47:30,780 --> 00:47:32,840
had the idea before the game paper came
out their paper came out a little bit

2404
00:47:32,840 --> 00:47:32,850
out their paper came out a little bit
 

2405
00:47:32,850 --> 00:47:36,920
out their paper came out a little bit
later and you know they they're very

2406
00:47:36,920 --> 00:47:36,930
later and you know they they're very
 

2407
00:47:36,930 --> 00:47:38,870
later and you know they they're very
nice and sighted again paper but

2408
00:47:38,870 --> 00:47:38,880
nice and sighted again paper but
 

2409
00:47:38,880 --> 00:47:40,010
nice and sighted again paper but
I know that they actually had the idea

2410
00:47:40,010 --> 00:47:40,020
I know that they actually had the idea
 

2411
00:47:40,020 --> 00:47:43,460
I know that they actually had the idea
before I came out domain adaptation is

2412
00:47:43,460 --> 00:47:43,470
before I came out domain adaptation is
 

2413
00:47:43,470 --> 00:47:44,480
before I came out domain adaptation is
when you want to train a machine

2414
00:47:44,480 --> 00:47:44,490
when you want to train a machine
 

2415
00:47:44,490 --> 00:47:47,120
when you want to train a machine
learning model in 1:1 setting called a

2416
00:47:47,120 --> 00:47:47,130
learning model in 1:1 setting called a
 

2417
00:47:47,130 --> 00:47:49,010
learning model in 1:1 setting called a
domain and then deploy it in another

2418
00:47:49,010 --> 00:47:49,020
domain and then deploy it in another
 

2419
00:47:49,020 --> 00:47:51,080
domain and then deploy it in another
domain later and he would like it to

2420
00:47:51,080 --> 00:47:51,090
domain later and he would like it to
 

2421
00:47:51,090 --> 00:47:52,940
domain later and he would like it to
perform well in the new domain even

2422
00:47:52,940 --> 00:47:52,950
perform well in the new domain even
 

2423
00:47:52,950 --> 00:47:54,140
perform well in the new domain even
though the new domain is different from

2424
00:47:54,140 --> 00:47:54,150
though the new domain is different from
 

2425
00:47:54,150 --> 00:47:57,680
though the new domain is different from
how it was trained so for example you

2426
00:47:57,680 --> 00:47:57,690
how it was trained so for example you
 

2427
00:47:57,690 --> 00:47:59,330
how it was trained so for example you
might want to train on a really clean

2428
00:47:59,330 --> 00:47:59,340
might want to train on a really clean
 

2429
00:47:59,340 --> 00:48:01,610
might want to train on a really clean
image data set like image net but then

2430
00:48:01,610 --> 00:48:01,620
image data set like image net but then
 

2431
00:48:01,620 --> 00:48:03,890
image data set like image net but then
deploy on users phones where the user is

2432
00:48:03,890 --> 00:48:03,900
deploy on users phones where the user is
 

2433
00:48:03,900 --> 00:48:06,110
deploy on users phones where the user is
taking you know pictures in the dark or

2434
00:48:06,110 --> 00:48:06,120
taking you know pictures in the dark or
 

2435
00:48:06,120 --> 00:48:08,510
taking you know pictures in the dark or
pictures while moving quickly and just

2436
00:48:08,510 --> 00:48:08,520
pictures while moving quickly and just
 

2437
00:48:08,520 --> 00:48:10,100
pictures while moving quickly and just
pictures that aren't really centered or

2438
00:48:10,100 --> 00:48:10,110
pictures that aren't really centered or
 

2439
00:48:10,110 --> 00:48:12,990
pictures that aren't really centered or
composed all that well

2440
00:48:12,990 --> 00:48:13,000

 

2441
00:48:13,000 --> 00:48:15,550

when you take a normal machine learning

2442
00:48:15,550 --> 00:48:15,560
when you take a normal machine learning
 

2443
00:48:15,560 --> 00:48:17,380
when you take a normal machine learning
model it often degrades really badly

2444
00:48:17,380 --> 00:48:17,390
model it often degrades really badly
 

2445
00:48:17,390 --> 00:48:19,270
model it often degrades really badly
when you move to the new domain because

2446
00:48:19,270 --> 00:48:19,280
when you move to the new domain because
 

2447
00:48:19,280 --> 00:48:20,380
when you move to the new domain because
it looks so different from what the

2448
00:48:20,380 --> 00:48:20,390
it looks so different from what the
 

2449
00:48:20,390 --> 00:48:22,570
it looks so different from what the
model was trained on domain adaptation

2450
00:48:22,570 --> 00:48:22,580
model was trained on domain adaptation
 

2451
00:48:22,580 --> 00:48:24,700
model was trained on domain adaptation
algorithms try to smooth out that gap

2452
00:48:24,700 --> 00:48:24,710
algorithms try to smooth out that gap
 

2453
00:48:24,710 --> 00:48:27,430
algorithms try to smooth out that gap
and the domain adverse oral approach is

2454
00:48:27,430 --> 00:48:27,440
and the domain adverse oral approach is
 

2455
00:48:27,440 --> 00:48:29,200
and the domain adverse oral approach is
based on training a feature extractor

2456
00:48:29,200 --> 00:48:29,210
based on training a feature extractor
 

2457
00:48:29,210 --> 00:48:31,329
based on training a feature extractor
where the features have the same

2458
00:48:31,329 --> 00:48:31,339
where the features have the same
 

2459
00:48:31,339 --> 00:48:33,310
where the features have the same
statistics regardless of which domain

2460
00:48:33,310 --> 00:48:33,320
statistics regardless of which domain
 

2461
00:48:33,320 --> 00:48:35,829
statistics regardless of which domain
you extracted them on so in the domain

2462
00:48:35,829 --> 00:48:35,839
you extracted them on so in the domain
 

2463
00:48:35,839 --> 00:48:37,570
you extracted them on so in the domain
adversarial game you have one player

2464
00:48:37,570 --> 00:48:37,580
adversarial game you have one player
 

2465
00:48:37,580 --> 00:48:39,550
adversarial game you have one player
that's a feature extractor and another

2466
00:48:39,550 --> 00:48:39,560
that's a feature extractor and another
 

2467
00:48:39,560 --> 00:48:41,190
that's a feature extractor and another
player that's a domain recognizer

2468
00:48:41,190 --> 00:48:41,200
player that's a domain recognizer
 

2469
00:48:41,200 --> 00:48:43,780
player that's a domain recognizer
the domain recognizer wants to look at

2470
00:48:43,780 --> 00:48:43,790
the domain recognizer wants to look at
 

2471
00:48:43,790 --> 00:48:45,370
the domain recognizer wants to look at
the output of the feature extractor and

2472
00:48:45,370 --> 00:48:45,380
the output of the feature extractor and
 

2473
00:48:45,380 --> 00:48:48,370
the output of the feature extractor and
guess which of the two domains oh the

2474
00:48:48,370 --> 00:48:48,380
guess which of the two domains oh the
 

2475
00:48:48,380 --> 00:48:49,930
guess which of the two domains oh the
features came from so it's a lot like

2476
00:48:49,930 --> 00:48:49,940
features came from so it's a lot like
 

2477
00:48:49,940 --> 00:48:51,579
features came from so it's a lot like
the real versus fake discriminator and

2478
00:48:51,579 --> 00:48:51,589
the real versus fake discriminator and
 

2479
00:48:51,589 --> 00:48:55,089
the real versus fake discriminator and
ends and then the feature extractor you

2480
00:48:55,089 --> 00:48:55,099
ends and then the feature extractor you
 

2481
00:48:55,099 --> 00:48:57,070
ends and then the feature extractor you
can think of as loosely analogous to the

2482
00:48:57,070 --> 00:48:57,080
can think of as loosely analogous to the
 

2483
00:48:57,080 --> 00:48:58,599
can think of as loosely analogous to the
generator in games except what's trying

2484
00:48:58,599 --> 00:48:58,609
generator in games except what's trying
 

2485
00:48:58,609 --> 00:49:01,780
generator in games except what's trying
to do here is both fool the domain

2486
00:49:01,780 --> 00:49:01,790
to do here is both fool the domain
 

2487
00:49:01,790 --> 00:49:03,220
to do here is both fool the domain
recognizer and two not knowing which

2488
00:49:03,220 --> 00:49:03,230
recognizer and two not knowing which
 

2489
00:49:03,230 --> 00:49:05,980
recognizer and two not knowing which
domain the data came from and also

2490
00:49:05,980 --> 00:49:05,990
domain the data came from and also
 

2491
00:49:05,990 --> 00:49:07,480
domain the data came from and also
extract features that are good for

2492
00:49:07,480 --> 00:49:07,490
extract features that are good for
 

2493
00:49:07,490 --> 00:49:10,120
extract features that are good for
classification so at the end of the day

2494
00:49:10,120 --> 00:49:10,130
classification so at the end of the day
 

2495
00:49:10,130 --> 00:49:13,420
classification so at the end of the day
you can in in the cases where it works

2496
00:49:13,420 --> 00:49:13,430
you can in in the cases where it works
 

2497
00:49:13,430 --> 00:49:17,079
you can in in the cases where it works
out you can actually get features that

2498
00:49:17,079 --> 00:49:17,089
out you can actually get features that
 

2499
00:49:17,089 --> 00:49:20,040
out you can actually get features that
work about the same in both domains

2500
00:49:20,040 --> 00:49:20,050
work about the same in both domains
 

2501
00:49:20,050 --> 00:49:22,930
work about the same in both domains
sometimes this has a drawback where in

2502
00:49:22,930 --> 00:49:22,940
sometimes this has a drawback where in
 

2503
00:49:22,940 --> 00:49:24,250
sometimes this has a drawback where in
order to make things work the same in

2504
00:49:24,250 --> 00:49:24,260
order to make things work the same in
 

2505
00:49:24,260 --> 00:49:25,720
order to make things work the same in
both domains it just gets worse at the

2506
00:49:25,720 --> 00:49:25,730
both domains it just gets worse at the
 

2507
00:49:25,730 --> 00:49:27,609
both domains it just gets worse at the
first one but there are a lot of cases

2508
00:49:27,609 --> 00:49:27,619
first one but there are a lot of cases
 

2509
00:49:27,619 --> 00:49:30,540
first one but there are a lot of cases
where it actually works out well on both

2510
00:49:30,540 --> 00:49:30,550
where it actually works out well on both
 

2511
00:49:30,550 --> 00:49:33,160
where it actually works out well on both
do you think gas being useful in the

2512
00:49:33,160 --> 00:49:33,170
do you think gas being useful in the
 

2513
00:49:33,170 --> 00:49:36,280
do you think gas being useful in the
context of data augmentation yeah one

2514
00:49:36,280 --> 00:49:36,290
context of data augmentation yeah one
 

2515
00:49:36,290 --> 00:49:38,079
context of data augmentation yeah one
thing you could hope for with Kenz is

2516
00:49:38,079 --> 00:49:38,089
thing you could hope for with Kenz is
 

2517
00:49:38,089 --> 00:49:40,599
thing you could hope for with Kenz is
you could imagine I've got a limited

2518
00:49:40,599 --> 00:49:40,609
you could imagine I've got a limited
 

2519
00:49:40,609 --> 00:49:43,180
you could imagine I've got a limited
training set and I'd like to make more

2520
00:49:43,180 --> 00:49:43,190
training set and I'd like to make more
 

2521
00:49:43,190 --> 00:49:44,740
training set and I'd like to make more
training data to train something else

2522
00:49:44,740 --> 00:49:44,750
training data to train something else
 

2523
00:49:44,750 --> 00:49:48,190
training data to train something else
like a classifier you could train Magan

2524
00:49:48,190 --> 00:49:48,200
like a classifier you could train Magan
 

2525
00:49:48,200 --> 00:49:51,310
like a classifier you could train Magan
on the training set and then create more

2526
00:49:51,310 --> 00:49:51,320
on the training set and then create more
 

2527
00:49:51,320 --> 00:49:54,460
on the training set and then create more
data and then maybe the classifier would

2528
00:49:54,460 --> 00:49:54,470
data and then maybe the classifier would
 

2529
00:49:54,470 --> 00:49:56,079
data and then maybe the classifier would
perform better on the test set after

2530
00:49:56,079 --> 00:49:56,089
perform better on the test set after
 

2531
00:49:56,089 --> 00:49:57,550
perform better on the test set after
training on those big ERG and generated

2532
00:49:57,550 --> 00:49:57,560
training on those big ERG and generated
 

2533
00:49:57,560 --> 00:50:00,010
training on those big ERG and generated
data set so that's the simplest version

2534
00:50:00,010 --> 00:50:00,020
data set so that's the simplest version
 

2535
00:50:00,020 --> 00:50:02,170
data set so that's the simplest version
of of something you might hope would

2536
00:50:02,170 --> 00:50:02,180
of of something you might hope would
 

2537
00:50:02,180 --> 00:50:04,660
of of something you might hope would
work I've never heard of that particular

2538
00:50:04,660 --> 00:50:04,670
work I've never heard of that particular
 

2539
00:50:04,670 --> 00:50:06,099
work I've never heard of that particular
approach working but I think there's

2540
00:50:06,099 --> 00:50:06,109
approach working but I think there's
 

2541
00:50:06,109 --> 00:50:08,859
approach working but I think there's
some there's some closely related things

2542
00:50:08,859 --> 00:50:08,869
some there's some closely related things
 

2543
00:50:08,869 --> 00:50:11,200
some there's some closely related things
that that I think could work in the

2544
00:50:11,200 --> 00:50:11,210
that that I think could work in the
 

2545
00:50:11,210 --> 00:50:12,430
that that I think could work in the
future and some that actually already

2546
00:50:12,430 --> 00:50:12,440
future and some that actually already
 

2547
00:50:12,440 --> 00:50:14,829
future and some that actually already
have worked so if you think a little bit

2548
00:50:14,829 --> 00:50:14,839
have worked so if you think a little bit
 

2549
00:50:14,839 --> 00:50:16,060
have worked so if you think a little bit
about what we'd be hoping for if we use

2550
00:50:16,060 --> 00:50:16,070
about what we'd be hoping for if we use
 

2551
00:50:16,070 --> 00:50:18,310
about what we'd be hoping for if we use
the gun to make more training data we're

2552
00:50:18,310 --> 00:50:18,320
the gun to make more training data we're
 

2553
00:50:18,320 --> 00:50:20,620
the gun to make more training data we're
hoping that again we'll generalize to

2554
00:50:20,620 --> 00:50:20,630
hoping that again we'll generalize to
 

2555
00:50:20,630 --> 00:50:23,140
hoping that again we'll generalize to
new examples better than the classifier

2556
00:50:23,140 --> 00:50:23,150
new examples better than the classifier
 

2557
00:50:23,150 --> 00:50:24,670
new examples better than the classifier
would have generalized if it was trained

2558
00:50:24,670 --> 00:50:24,680
would have generalized if it was trained
 

2559
00:50:24,680 --> 00:50:25,750
would have generalized if it was trained
on the same buddy at us

2560
00:50:25,750 --> 00:50:25,760
on the same buddy at us
 

2561
00:50:25,760 --> 00:50:27,460
on the same buddy at us
and I don't know of any reason to

2562
00:50:27,460 --> 00:50:27,470
and I don't know of any reason to
 

2563
00:50:27,470 --> 00:50:28,570
and I don't know of any reason to
believe that the Gann would generalize

2564
00:50:28,570 --> 00:50:28,580
believe that the Gann would generalize
 

2565
00:50:28,580 --> 00:50:31,690
believe that the Gann would generalize
better than the classifier would but

2566
00:50:31,690 --> 00:50:31,700
better than the classifier would but
 

2567
00:50:31,700 --> 00:50:33,580
better than the classifier would but
what we might hope for is that the Gann

2568
00:50:33,580 --> 00:50:33,590
what we might hope for is that the Gann
 

2569
00:50:33,590 --> 00:50:35,860
what we might hope for is that the Gann
could generalize differently from a

2570
00:50:35,860 --> 00:50:35,870
could generalize differently from a
 

2571
00:50:35,870 --> 00:50:38,320
could generalize differently from a
specific classifier so one thing I think

2572
00:50:38,320 --> 00:50:38,330
specific classifier so one thing I think
 

2573
00:50:38,330 --> 00:50:39,550
specific classifier so one thing I think
is worth trying that I haven't

2574
00:50:39,550 --> 00:50:39,560
is worth trying that I haven't
 

2575
00:50:39,560 --> 00:50:40,930
is worth trying that I haven't
personally tried but someone could try

2576
00:50:40,930 --> 00:50:40,940
personally tried but someone could try
 

2577
00:50:40,940 --> 00:50:43,360
personally tried but someone could try
is what have you trained a whole lot of

2578
00:50:43,360 --> 00:50:43,370
is what have you trained a whole lot of
 

2579
00:50:43,370 --> 00:50:45,310
is what have you trained a whole lot of
different generative models on the same

2580
00:50:45,310 --> 00:50:45,320
different generative models on the same
 

2581
00:50:45,320 --> 00:50:47,650
different generative models on the same
training set create samples from all of

2582
00:50:47,650 --> 00:50:47,660
training set create samples from all of
 

2583
00:50:47,660 --> 00:50:49,920
training set create samples from all of
them and then train a classifier on that

2584
00:50:49,920 --> 00:50:49,930
them and then train a classifier on that
 

2585
00:50:49,930 --> 00:50:52,330
them and then train a classifier on that
because each of the generative models

2586
00:50:52,330 --> 00:50:52,340
because each of the generative models
 

2587
00:50:52,340 --> 00:50:53,470
because each of the generative models
might generalize in a slightly different

2588
00:50:53,470 --> 00:50:53,480
might generalize in a slightly different
 

2589
00:50:53,480 --> 00:50:56,050
might generalize in a slightly different
way they might capture many different

2590
00:50:56,050 --> 00:50:56,060
way they might capture many different
 

2591
00:50:56,060 --> 00:50:57,790
way they might capture many different
axes of variation that one individual

2592
00:50:57,790 --> 00:50:57,800
axes of variation that one individual
 

2593
00:50:57,800 --> 00:50:59,740
axes of variation that one individual
model wouldn't and then the classifier

2594
00:50:59,740 --> 00:50:59,750
model wouldn't and then the classifier
 

2595
00:50:59,750 --> 00:51:02,020
model wouldn't and then the classifier
can capture all of those ideas by

2596
00:51:02,020 --> 00:51:02,030
can capture all of those ideas by
 

2597
00:51:02,030 --> 00:51:03,880
can capture all of those ideas by
training in all of their data so we'd be

2598
00:51:03,880 --> 00:51:03,890
training in all of their data so we'd be
 

2599
00:51:03,890 --> 00:51:05,380
training in all of their data so we'd be
a little bit like making an ensemble of

2600
00:51:05,380 --> 00:51:05,390
a little bit like making an ensemble of
 

2601
00:51:05,390 --> 00:51:07,420
a little bit like making an ensemble of
classifiers and I say oh of gans

2602
00:51:07,420 --> 00:51:07,430
classifiers and I say oh of gans
 

2603
00:51:07,430 --> 00:51:09,400
classifiers and I say oh of gans
yeah in a way I think that could

2604
00:51:09,400 --> 00:51:09,410
yeah in a way I think that could
 

2605
00:51:09,410 --> 00:51:10,570
yeah in a way I think that could
generalize better the other thing that

2606
00:51:10,570 --> 00:51:10,580
generalize better the other thing that
 

2607
00:51:10,580 --> 00:51:15,160
generalize better the other thing that
gans are really good for is not

2608
00:51:15,160 --> 00:51:15,170
gans are really good for is not
 

2609
00:51:15,170 --> 00:51:17,170
gans are really good for is not
necessarily generating new data that's

2610
00:51:17,170 --> 00:51:17,180
necessarily generating new data that's
 

2611
00:51:17,180 --> 00:51:19,480
necessarily generating new data that's
exactly like what you already have but

2612
00:51:19,480 --> 00:51:19,490
exactly like what you already have but
 

2613
00:51:19,490 --> 00:51:21,940
exactly like what you already have but
by generating new data that has

2614
00:51:21,940 --> 00:51:21,950
by generating new data that has
 

2615
00:51:21,950 --> 00:51:24,070
by generating new data that has
different properties from the data you

2616
00:51:24,070 --> 00:51:24,080
different properties from the data you
 

2617
00:51:24,080 --> 00:51:26,350
different properties from the data you
already had one thing that you can do is

2618
00:51:26,350 --> 00:51:26,360
already had one thing that you can do is
 

2619
00:51:26,360 --> 00:51:28,360
already had one thing that you can do is
you can create differentially private

2620
00:51:28,360 --> 00:51:28,370
you can create differentially private
 

2621
00:51:28,370 --> 00:51:30,160
you can create differentially private
data so suppose that you have something

2622
00:51:30,160 --> 00:51:30,170
data so suppose that you have something
 

2623
00:51:30,170 --> 00:51:32,890
data so suppose that you have something
like medical records and you don't want

2624
00:51:32,890 --> 00:51:32,900
like medical records and you don't want
 

2625
00:51:32,900 --> 00:51:34,330
like medical records and you don't want
to train a classifier on the medical

2626
00:51:34,330 --> 00:51:34,340
to train a classifier on the medical
 

2627
00:51:34,340 --> 00:51:35,980
to train a classifier on the medical
records and then publish the classifier

2628
00:51:35,980 --> 00:51:35,990
records and then publish the classifier
 

2629
00:51:35,990 --> 00:51:37,390
records and then publish the classifier
because someone might be able to

2630
00:51:37,390 --> 00:51:37,400
because someone might be able to
 

2631
00:51:37,400 --> 00:51:38,770
because someone might be able to
reverse-engineer some of the medical

2632
00:51:38,770 --> 00:51:38,780
reverse-engineer some of the medical
 

2633
00:51:38,780 --> 00:51:41,050
reverse-engineer some of the medical
records you trained on there's a paper

2634
00:51:41,050 --> 00:51:41,060
records you trained on there's a paper
 

2635
00:51:41,060 --> 00:51:43,480
records you trained on there's a paper
from Casey greens lab that shows how you

2636
00:51:43,480 --> 00:51:43,490
from Casey greens lab that shows how you
 

2637
00:51:43,490 --> 00:51:45,730
from Casey greens lab that shows how you
can train again using differential

2638
00:51:45,730 --> 00:51:45,740
can train again using differential
 

2639
00:51:45,740 --> 00:51:48,370
can train again using differential
privacy and then the samples one again

2640
00:51:48,370 --> 00:51:48,380
privacy and then the samples one again
 

2641
00:51:48,380 --> 00:51:50,590
privacy and then the samples one again
still have the same differential privacy

2642
00:51:50,590 --> 00:51:50,600
still have the same differential privacy
 

2643
00:51:50,600 --> 00:51:52,240
still have the same differential privacy
guarantees as the parameters that again

2644
00:51:52,240 --> 00:51:52,250
guarantees as the parameters that again
 

2645
00:51:52,250 --> 00:51:55,870
guarantees as the parameters that again
so you can make fake patient data for

2646
00:51:55,870 --> 00:51:55,880
so you can make fake patient data for
 

2647
00:51:55,880 --> 00:51:57,730
so you can make fake patient data for
other researchers to use and they can do

2648
00:51:57,730 --> 00:51:57,740
other researchers to use and they can do
 

2649
00:51:57,740 --> 00:51:59,110
other researchers to use and they can do
almost anything they want with that data

2650
00:51:59,110 --> 00:51:59,120
almost anything they want with that data
 

2651
00:51:59,120 --> 00:52:01,840
almost anything they want with that data
because it doesn't come from real people

2652
00:52:01,840 --> 00:52:01,850
because it doesn't come from real people
 

2653
00:52:01,850 --> 00:52:03,670
because it doesn't come from real people
and the differential privacy mechanism

2654
00:52:03,670 --> 00:52:03,680
and the differential privacy mechanism
 

2655
00:52:03,680 --> 00:52:06,940
and the differential privacy mechanism
gives you clear guarantees on how much

2656
00:52:06,940 --> 00:52:06,950
gives you clear guarantees on how much
 

2657
00:52:06,950 --> 00:52:08,920
gives you clear guarantees on how much
the original people's data has been

2658
00:52:08,920 --> 00:52:08,930
the original people's data has been
 

2659
00:52:08,930 --> 00:52:10,750
the original people's data has been
protected that's really interesting

2660
00:52:10,750 --> 00:52:10,760
protected that's really interesting
 

2661
00:52:10,760 --> 00:52:12,310
protected that's really interesting
actually I haven't heard you talk about

2662
00:52:12,310 --> 00:52:12,320
actually I haven't heard you talk about
 

2663
00:52:12,320 --> 00:52:15,670
actually I haven't heard you talk about
that before in terms of fairness I've

2664
00:52:15,670 --> 00:52:15,680
that before in terms of fairness I've
 

2665
00:52:15,680 --> 00:52:18,720
that before in terms of fairness I've
seen from triple AI your talk

2666
00:52:18,720 --> 00:52:18,730
seen from triple AI your talk
 

2667
00:52:18,730 --> 00:52:21,250
seen from triple AI your talk
how can an adversarial machine learning

2668
00:52:21,250 --> 00:52:21,260
how can an adversarial machine learning
 

2669
00:52:21,260 --> 00:52:23,980
how can an adversarial machine learning
help models be more fair with respect to

2670
00:52:23,980 --> 00:52:23,990
help models be more fair with respect to
 

2671
00:52:23,990 --> 00:52:26,620
help models be more fair with respect to
sensitive variables yeah there was a

2672
00:52:26,620 --> 00:52:26,630
sensitive variables yeah there was a
 

2673
00:52:26,630 --> 00:52:29,050
sensitive variables yeah there was a
paper from Amos Torquay's lab about how

2674
00:52:29,050 --> 00:52:29,060
paper from Amos Torquay's lab about how
 

2675
00:52:29,060 --> 00:52:31,540
paper from Amos Torquay's lab about how
to learn machine learning models that

2676
00:52:31,540 --> 00:52:31,550
to learn machine learning models that
 

2677
00:52:31,550 --> 00:52:33,880
to learn machine learning models that
are incapable of using specific

2678
00:52:33,880 --> 00:52:33,890
are incapable of using specific
 

2679
00:52:33,890 --> 00:52:35,770
are incapable of using specific
variables so to say for example you

2680
00:52:35,770 --> 00:52:35,780
variables so to say for example you
 

2681
00:52:35,780 --> 00:52:37,030
variables so to say for example you
wanted to make predictions that are not

2682
00:52:37,030 --> 00:52:37,040
wanted to make predictions that are not
 

2683
00:52:37,040 --> 00:52:39,270
wanted to make predictions that are not
affected by gender

2684
00:52:39,270 --> 00:52:39,280
affected by gender
 

2685
00:52:39,280 --> 00:52:41,340
affected by gender
it isn't enough to just leave gender out

2686
00:52:41,340 --> 00:52:41,350
it isn't enough to just leave gender out
 

2687
00:52:41,350 --> 00:52:43,170
it isn't enough to just leave gender out
of the input to the model you can often

2688
00:52:43,170 --> 00:52:43,180
of the input to the model you can often
 

2689
00:52:43,180 --> 00:52:44,520
of the input to the model you can often
infer gender from a lot of other

2690
00:52:44,520 --> 00:52:44,530
infer gender from a lot of other
 

2691
00:52:44,530 --> 00:52:46,590
infer gender from a lot of other
characteristics like say that you have

2692
00:52:46,590 --> 00:52:46,600
characteristics like say that you have
 

2693
00:52:46,600 --> 00:52:48,030
characteristics like say that you have
the person's name but you're not told

2694
00:52:48,030 --> 00:52:48,040
the person's name but you're not told
 

2695
00:52:48,040 --> 00:52:50,070
the person's name but you're not told
their gender well right if if their name

2696
00:52:50,070 --> 00:52:50,080
their gender well right if if their name
 

2697
00:52:50,080 --> 00:52:52,880
their gender well right if if their name
is Ian they're kind of obviously a man

2698
00:52:52,880 --> 00:52:52,890
is Ian they're kind of obviously a man
 

2699
00:52:52,890 --> 00:52:54,870
is Ian they're kind of obviously a man
so what you'd like to do is make a

2700
00:52:54,870 --> 00:52:54,880
so what you'd like to do is make a
 

2701
00:52:54,880 --> 00:52:56,220
so what you'd like to do is make a
machine learning model that can still

2702
00:52:56,220 --> 00:52:56,230
machine learning model that can still
 

2703
00:52:56,230 --> 00:52:57,900
machine learning model that can still
take in a lot of different attributes

2704
00:52:57,900 --> 00:52:57,910
take in a lot of different attributes
 

2705
00:52:57,910 --> 00:53:01,350
take in a lot of different attributes
and make a really accurate informed

2706
00:53:01,350 --> 00:53:01,360
and make a really accurate informed
 

2707
00:53:01,360 --> 00:53:03,930
and make a really accurate informed
prediction but be confident that it

2708
00:53:03,930 --> 00:53:03,940
prediction but be confident that it
 

2709
00:53:03,940 --> 00:53:05,880
prediction but be confident that it
isn't reverse engineering gender or

2710
00:53:05,880 --> 00:53:05,890
isn't reverse engineering gender or
 

2711
00:53:05,890 --> 00:53:07,530
isn't reverse engineering gender or
another sensitive variable internally

2712
00:53:07,530 --> 00:53:07,540
another sensitive variable internally
 

2713
00:53:07,540 --> 00:53:09,570
another sensitive variable internally
you can do that using something very

2714
00:53:09,570 --> 00:53:09,580
you can do that using something very
 

2715
00:53:09,580 --> 00:53:11,790
you can do that using something very
similar to the domain adversarial

2716
00:53:11,790 --> 00:53:11,800
similar to the domain adversarial
 

2717
00:53:11,800 --> 00:53:14,250
similar to the domain adversarial
approach where you have one player

2718
00:53:14,250 --> 00:53:14,260
approach where you have one player
 

2719
00:53:14,260 --> 00:53:16,530
approach where you have one player
that's a feature extractor and another

2720
00:53:16,530 --> 00:53:16,540
that's a feature extractor and another
 

2721
00:53:16,540 --> 00:53:19,290
that's a feature extractor and another
player that's a feature analyzer and you

2722
00:53:19,290 --> 00:53:19,300
player that's a feature analyzer and you
 

2723
00:53:19,300 --> 00:53:20,370
player that's a feature analyzer and you
want to make sure that the feature

2724
00:53:20,370 --> 00:53:20,380
want to make sure that the feature
 

2725
00:53:20,380 --> 00:53:23,490
want to make sure that the feature
analyzer is not able to guess the value

2726
00:53:23,490 --> 00:53:23,500
analyzer is not able to guess the value
 

2727
00:53:23,500 --> 00:53:24,870
analyzer is not able to guess the value
of the sensitive variable that you're

2728
00:53:24,870 --> 00:53:24,880
of the sensitive variable that you're
 

2729
00:53:24,880 --> 00:53:27,810
of the sensitive variable that you're
trying to keep private right that's yeah

2730
00:53:27,810 --> 00:53:27,820
trying to keep private right that's yeah
 

2731
00:53:27,820 --> 00:53:29,760
trying to keep private right that's yeah
I love this approach so we'll yeah with

2732
00:53:29,760 --> 00:53:29,770
I love this approach so we'll yeah with
 

2733
00:53:29,770 --> 00:53:33,170
I love this approach so we'll yeah with
the with the feature you're not able to

2734
00:53:33,170 --> 00:53:33,180
the with the feature you're not able to
 

2735
00:53:33,180 --> 00:53:35,700
the with the feature you're not able to
infer right this sensitive variables

2736
00:53:35,700 --> 00:53:35,710
infer right this sensitive variables
 

2737
00:53:35,710 --> 00:53:37,440
infer right this sensitive variables
yeah brilliant it's quite quite

2738
00:53:37,440 --> 00:53:37,450
yeah brilliant it's quite quite
 

2739
00:53:37,450 --> 00:53:39,780
yeah brilliant it's quite quite
brilliant and simple actually another

2740
00:53:39,780 --> 00:53:39,790
brilliant and simple actually another
 

2741
00:53:39,790 --> 00:53:42,720
brilliant and simple actually another
way I think that Ganz in particular

2742
00:53:42,720 --> 00:53:42,730
way I think that Ganz in particular
 

2743
00:53:42,730 --> 00:53:44,700
way I think that Ganz in particular
could be used for fairness would be to

2744
00:53:44,700 --> 00:53:44,710
could be used for fairness would be to
 

2745
00:53:44,710 --> 00:53:46,950
could be used for fairness would be to
make something like a cycle again where

2746
00:53:46,950 --> 00:53:46,960
make something like a cycle again where
 

2747
00:53:46,960 --> 00:53:49,830
make something like a cycle again where
you can take data from one domain and

2748
00:53:49,830 --> 00:53:49,840
you can take data from one domain and
 

2749
00:53:49,840 --> 00:53:52,050
you can take data from one domain and
convert it into another we've seen cycle

2750
00:53:52,050 --> 00:53:52,060
convert it into another we've seen cycle
 

2751
00:53:52,060 --> 00:53:54,030
convert it into another we've seen cycle
again turning horses into zebras we've

2752
00:53:54,030 --> 00:53:54,040
again turning horses into zebras we've
 

2753
00:53:54,040 --> 00:53:57,900
again turning horses into zebras we've
seen other unsupervised gains made by

2754
00:53:57,900 --> 00:53:57,910
seen other unsupervised gains made by
 

2755
00:53:57,910 --> 00:54:00,180
seen other unsupervised gains made by
Ming Yue Lu doing things like turning

2756
00:54:00,180 --> 00:54:00,190
Ming Yue Lu doing things like turning
 

2757
00:54:00,190 --> 00:54:04,290
Ming Yue Lu doing things like turning
day photos into night photos I think for

2758
00:54:04,290 --> 00:54:04,300
day photos into night photos I think for
 

2759
00:54:04,300 --> 00:54:06,180
day photos into night photos I think for
fairness you could imagine taking

2760
00:54:06,180 --> 00:54:06,190
fairness you could imagine taking
 

2761
00:54:06,190 --> 00:54:08,270
fairness you could imagine taking
records for people in one group and

2762
00:54:08,270 --> 00:54:08,280
records for people in one group and
 

2763
00:54:08,280 --> 00:54:10,440
records for people in one group and
transforming them into analogous people

2764
00:54:10,440 --> 00:54:10,450
transforming them into analogous people
 

2765
00:54:10,450 --> 00:54:12,540
transforming them into analogous people
in another group and testing to see if

2766
00:54:12,540 --> 00:54:12,550
in another group and testing to see if
 

2767
00:54:12,550 --> 00:54:15,270
in another group and testing to see if
they're they're treated equitably across

2768
00:54:15,270 --> 00:54:15,280
they're they're treated equitably across
 

2769
00:54:15,280 --> 00:54:17,040
they're they're treated equitably across
those two groups there's a lot of things

2770
00:54:17,040 --> 00:54:17,050
those two groups there's a lot of things
 

2771
00:54:17,050 --> 00:54:18,450
those two groups there's a lot of things
that be hard to get right to make sure

2772
00:54:18,450 --> 00:54:18,460
that be hard to get right to make sure
 

2773
00:54:18,460 --> 00:54:20,220
that be hard to get right to make sure
that the conversion process itself is

2774
00:54:20,220 --> 00:54:20,230
that the conversion process itself is
 

2775
00:54:20,230 --> 00:54:23,100
that the conversion process itself is
fair and I don't think it's anywhere

2776
00:54:23,100 --> 00:54:23,110
fair and I don't think it's anywhere
 

2777
00:54:23,110 --> 00:54:24,690
fair and I don't think it's anywhere
near something that we could actually

2778
00:54:24,690 --> 00:54:24,700
near something that we could actually
 

2779
00:54:24,700 --> 00:54:26,220
near something that we could actually
use yet but if you could design that

2780
00:54:26,220 --> 00:54:26,230
use yet but if you could design that
 

2781
00:54:26,230 --> 00:54:28,020
use yet but if you could design that
conversion process very carefully it

2782
00:54:28,020 --> 00:54:28,030
conversion process very carefully it
 

2783
00:54:28,030 --> 00:54:29,660
conversion process very carefully it
might give you a way of doing audits

2784
00:54:29,660 --> 00:54:29,670
might give you a way of doing audits
 

2785
00:54:29,670 --> 00:54:31,860
might give you a way of doing audits
where you say what if we took people

2786
00:54:31,860 --> 00:54:31,870
where you say what if we took people
 

2787
00:54:31,870 --> 00:54:33,690
where you say what if we took people
from this group converted them into

2788
00:54:33,690 --> 00:54:33,700
from this group converted them into
 

2789
00:54:33,700 --> 00:54:35,610
from this group converted them into
equivalent people in another group does

2790
00:54:35,610 --> 00:54:35,620
equivalent people in another group does
 

2791
00:54:35,620 --> 00:54:38,040
equivalent people in another group does
the system actually treat them how it

2792
00:54:38,040 --> 00:54:38,050
the system actually treat them how it
 

2793
00:54:38,050 --> 00:54:41,160
the system actually treat them how it
ought to that's also really interesting

2794
00:54:41,160 --> 00:54:41,170
ought to that's also really interesting
 

2795
00:54:41,170 --> 00:54:45,600
ought to that's also really interesting
you know in a popular in popular press

2796
00:54:45,600 --> 00:54:45,610
you know in a popular in popular press
 

2797
00:54:45,610 --> 00:54:48,780
you know in a popular in popular press
and in general in our imagination you

2798
00:54:48,780 --> 00:54:48,790
and in general in our imagination you
 

2799
00:54:48,790 --> 00:54:51,180
and in general in our imagination you
think well gangs are able to generate

2800
00:54:51,180 --> 00:54:51,190
think well gangs are able to generate
 

2801
00:54:51,190 --> 00:54:52,210
think well gangs are able to generate
data and use

2802
00:54:52,210 --> 00:54:52,220
data and use
 

2803
00:54:52,220 --> 00:54:55,000
data and use
to think about deep fakes or being able

2804
00:54:55,000 --> 00:54:55,010
to think about deep fakes or being able
 

2805
00:54:55,010 --> 00:54:57,730
to think about deep fakes or being able
to sort of maliciously generate data

2806
00:54:57,730 --> 00:54:57,740
to sort of maliciously generate data
 

2807
00:54:57,740 --> 00:55:00,760
to sort of maliciously generate data
that fakes the identity of other people

2808
00:55:00,760 --> 00:55:00,770
that fakes the identity of other people
 

2809
00:55:00,770 --> 00:55:03,280
that fakes the identity of other people
is this something of a concern to you is

2810
00:55:03,280 --> 00:55:03,290
is this something of a concern to you is
 

2811
00:55:03,290 --> 00:55:05,589
is this something of a concern to you is
this something if you look 10 20 years

2812
00:55:05,589 --> 00:55:05,599
this something if you look 10 20 years
 

2813
00:55:05,599 --> 00:55:08,470
this something if you look 10 20 years
into the future is that something that

2814
00:55:08,470 --> 00:55:08,480
into the future is that something that
 

2815
00:55:08,480 --> 00:55:10,990
into the future is that something that
pops up in your work in the work of the

2816
00:55:10,990 --> 00:55:11,000
pops up in your work in the work of the
 

2817
00:55:11,000 --> 00:55:12,430
pops up in your work in the work of the
community that's working on generating

2818
00:55:12,430 --> 00:55:12,440
community that's working on generating
 

2819
00:55:12,440 --> 00:55:15,069
community that's working on generating
models I'm a lot less concerned about 20

2820
00:55:15,069 --> 00:55:15,079
models I'm a lot less concerned about 20
 

2821
00:55:15,079 --> 00:55:17,410
models I'm a lot less concerned about 20
years from now than the next few years I

2822
00:55:17,410 --> 00:55:17,420
years from now than the next few years I
 

2823
00:55:17,420 --> 00:55:19,510
years from now than the next few years I
think there will be a kind of bumpy

2824
00:55:19,510 --> 00:55:19,520
think there will be a kind of bumpy
 

2825
00:55:19,520 --> 00:55:22,660
think there will be a kind of bumpy
cultural transition as people encounter

2826
00:55:22,660 --> 00:55:22,670
cultural transition as people encounter
 

2827
00:55:22,670 --> 00:55:23,770
cultural transition as people encounter
this idea that there can be very

2828
00:55:23,770 --> 00:55:23,780
this idea that there can be very
 

2829
00:55:23,780 --> 00:55:25,480
this idea that there can be very
realistic videos and audio that aren't

2830
00:55:25,480 --> 00:55:25,490
realistic videos and audio that aren't
 

2831
00:55:25,490 --> 00:55:28,839
realistic videos and audio that aren't
real I think 20 years from now people

2832
00:55:28,839 --> 00:55:28,849
real I think 20 years from now people
 

2833
00:55:28,849 --> 00:55:30,309
real I think 20 years from now people
will mostly understand that you

2834
00:55:30,309 --> 00:55:30,319
will mostly understand that you
 

2835
00:55:30,319 --> 00:55:32,109
will mostly understand that you
shouldn't believe something is real just

2836
00:55:32,109 --> 00:55:32,119
shouldn't believe something is real just
 

2837
00:55:32,119 --> 00:55:34,300
shouldn't believe something is real just
because you saw a video of it people

2838
00:55:34,300 --> 00:55:34,310
because you saw a video of it people
 

2839
00:55:34,310 --> 00:55:35,740
because you saw a video of it people
will expect to see that it's been

2840
00:55:35,740 --> 00:55:35,750
will expect to see that it's been
 

2841
00:55:35,750 --> 00:55:39,430
will expect to see that it's been
cryptographically signed or or have some

2842
00:55:39,430 --> 00:55:39,440
cryptographically signed or or have some
 

2843
00:55:39,440 --> 00:55:42,010
cryptographically signed or or have some
other mechanism to make them believe the

2844
00:55:42,010 --> 00:55:42,020
other mechanism to make them believe the
 

2845
00:55:42,020 --> 00:55:44,740
other mechanism to make them believe the
the content is real there's already

2846
00:55:44,740 --> 00:55:44,750
the content is real there's already
 

2847
00:55:44,750 --> 00:55:46,030
the content is real there's already
people working on this like there's a

2848
00:55:46,030 --> 00:55:46,040
people working on this like there's a
 

2849
00:55:46,040 --> 00:55:48,339
people working on this like there's a
startup called true pic that provides a

2850
00:55:48,339 --> 00:55:48,349
startup called true pic that provides a
 

2851
00:55:48,349 --> 00:55:50,829
startup called true pic that provides a
lot of mechanisms for authenticating

2852
00:55:50,829 --> 00:55:50,839
lot of mechanisms for authenticating
 

2853
00:55:50,839 --> 00:55:53,319
lot of mechanisms for authenticating
that an image is real there they're

2854
00:55:53,319 --> 00:55:53,329
that an image is real there they're
 

2855
00:55:53,329 --> 00:55:55,720
that an image is real there they're
maybe not quite up to having a state

2856
00:55:55,720 --> 00:55:55,730
maybe not quite up to having a state
 

2857
00:55:55,730 --> 00:55:58,540
maybe not quite up to having a state
actor try to to evade their their

2858
00:55:58,540 --> 00:55:58,550
actor try to to evade their their
 

2859
00:55:58,550 --> 00:56:01,240
actor try to to evade their their
verification techniques but it's

2860
00:56:01,240 --> 00:56:01,250
verification techniques but it's
 

2861
00:56:01,250 --> 00:56:02,319
verification techniques but it's
something people are already working on

2862
00:56:02,319 --> 00:56:02,329
something people are already working on
 

2863
00:56:02,329 --> 00:56:03,790
something people are already working on
and I think we'll get right eventually

2864
00:56:03,790 --> 00:56:03,800
and I think we'll get right eventually
 

2865
00:56:03,800 --> 00:56:06,569
and I think we'll get right eventually
so you think authentication will will

2866
00:56:06,569 --> 00:56:06,579
so you think authentication will will
 

2867
00:56:06,579 --> 00:56:08,920
so you think authentication will will
eventually went out so being able to

2868
00:56:08,920 --> 00:56:08,930
eventually went out so being able to
 

2869
00:56:08,930 --> 00:56:10,809
eventually went out so being able to
authenticate that this is real and this

2870
00:56:10,809 --> 00:56:10,819
authenticate that this is real and this
 

2871
00:56:10,819 --> 00:56:14,500
authenticate that this is real and this
is not yeah as opposed to gas just

2872
00:56:14,500 --> 00:56:14,510
is not yeah as opposed to gas just
 

2873
00:56:14,510 --> 00:56:16,450
is not yeah as opposed to gas just
getting better and better or generative

2874
00:56:16,450 --> 00:56:16,460
getting better and better or generative
 

2875
00:56:16,460 --> 00:56:17,920
getting better and better or generative
models being able to get better and

2876
00:56:17,920 --> 00:56:17,930
models being able to get better and
 

2877
00:56:17,930 --> 00:56:20,290
models being able to get better and
better to where the nature of what is

2878
00:56:20,290 --> 00:56:20,300
better to where the nature of what is
 

2879
00:56:20,300 --> 00:56:22,930
better to where the nature of what is
real I don't think we'll ever be able to

2880
00:56:22,930 --> 00:56:22,940
real I don't think we'll ever be able to
 

2881
00:56:22,940 --> 00:56:25,809
real I don't think we'll ever be able to
look at the pixels of a photo and tell

2882
00:56:25,809 --> 00:56:25,819
look at the pixels of a photo and tell
 

2883
00:56:25,819 --> 00:56:27,760
look at the pixels of a photo and tell
you for sure that it's real or not real

2884
00:56:27,760 --> 00:56:27,770
you for sure that it's real or not real
 

2885
00:56:27,770 --> 00:56:31,050
you for sure that it's real or not real
and I think it would actually be

2886
00:56:31,050 --> 00:56:31,060
and I think it would actually be
 

2887
00:56:31,060 --> 00:56:33,339
and I think it would actually be
somewhat dangerous to rely on that

2888
00:56:33,339 --> 00:56:33,349
somewhat dangerous to rely on that
 

2889
00:56:33,349 --> 00:56:35,710
somewhat dangerous to rely on that
approach too much if you make a really

2890
00:56:35,710 --> 00:56:35,720
approach too much if you make a really
 

2891
00:56:35,720 --> 00:56:37,300
approach too much if you make a really
good fake detector and then someone's

2892
00:56:37,300 --> 00:56:37,310
good fake detector and then someone's
 

2893
00:56:37,310 --> 00:56:39,040
good fake detector and then someone's
able to fool your fake detector and your

2894
00:56:39,040 --> 00:56:39,050
able to fool your fake detector and your
 

2895
00:56:39,050 --> 00:56:41,170
able to fool your fake detector and your
fake detector says this image is not

2896
00:56:41,170 --> 00:56:41,180
fake detector says this image is not
 

2897
00:56:41,180 --> 00:56:43,540
fake detector says this image is not
fake then it's even more credible than

2898
00:56:43,540 --> 00:56:43,550
fake then it's even more credible than
 

2899
00:56:43,550 --> 00:56:45,099
fake then it's even more credible than
if you've never made a fake detector in

2900
00:56:45,099 --> 00:56:45,109
if you've never made a fake detector in
 

2901
00:56:45,109 --> 00:56:45,849
if you've never made a fake detector in
the first place

2902
00:56:45,849 --> 00:56:45,859
the first place
 

2903
00:56:45,859 --> 00:56:50,170
the first place
what I do think we'll get to is systems

2904
00:56:50,170 --> 00:56:50,180
what I do think we'll get to is systems
 

2905
00:56:50,180 --> 00:56:52,150
what I do think we'll get to is systems
that we can kind of use behind the

2906
00:56:52,150 --> 00:56:52,160
that we can kind of use behind the
 

2907
00:56:52,160 --> 00:56:55,059
that we can kind of use behind the
scenes for to make estimates of what's

2908
00:56:55,059 --> 00:56:55,069
scenes for to make estimates of what's
 

2909
00:56:55,069 --> 00:56:57,400
scenes for to make estimates of what's
going on and maybe not like use them in

2910
00:56:57,400 --> 00:56:57,410
going on and maybe not like use them in
 

2911
00:56:57,410 --> 00:56:59,800
going on and maybe not like use them in
court for a definitive analysis I also

2912
00:56:59,800 --> 00:56:59,810
court for a definitive analysis I also
 

2913
00:56:59,810 --> 00:57:02,589
court for a definitive analysis I also
think we will likely get better

2914
00:57:02,589 --> 00:57:02,599
think we will likely get better
 

2915
00:57:02,599 --> 00:57:05,829
think we will likely get better
authentication systems where you know if

2916
00:57:05,829 --> 00:57:05,839
authentication systems where you know if
 

2917
00:57:05,839 --> 00:57:06,400
authentication systems where you know if
a match

2918
00:57:06,400 --> 00:57:06,410
a match
 

2919
00:57:06,410 --> 00:57:08,349
a match
every phone cryptographically signs

2920
00:57:08,349 --> 00:57:08,359
every phone cryptographically signs
 

2921
00:57:08,359 --> 00:57:10,660
every phone cryptographically signs
everything that comes out of it you

2922
00:57:10,660 --> 00:57:10,670
everything that comes out of it you
 

2923
00:57:10,670 --> 00:57:13,180
everything that comes out of it you
wouldn't go to conclusively tell that an

2924
00:57:13,180 --> 00:57:13,190
wouldn't go to conclusively tell that an
 

2925
00:57:13,190 --> 00:57:15,190
wouldn't go to conclusively tell that an
image was real but you would be able to

2926
00:57:15,190 --> 00:57:15,200
image was real but you would be able to
 

2927
00:57:15,200 --> 00:57:18,760
image was real but you would be able to
tell somebody who knew the appropriate

2928
00:57:18,760 --> 00:57:18,770
tell somebody who knew the appropriate
 

2929
00:57:18,770 --> 00:57:22,480
tell somebody who knew the appropriate
private key for this phone was actually

2930
00:57:22,480 --> 00:57:22,490
private key for this phone was actually
 

2931
00:57:22,490 --> 00:57:25,510
private key for this phone was actually
able to sign this image and upload it to

2932
00:57:25,510 --> 00:57:25,520
able to sign this image and upload it to
 

2933
00:57:25,520 --> 00:57:29,109
able to sign this image and upload it to
this server at this timestamp so you

2934
00:57:29,109 --> 00:57:29,119
this server at this timestamp so you
 

2935
00:57:29,119 --> 00:57:31,480
this server at this timestamp so you
could imagine maybe you make phones that

2936
00:57:31,480 --> 00:57:31,490
could imagine maybe you make phones that
 

2937
00:57:31,490 --> 00:57:33,609
could imagine maybe you make phones that
have the private keys Hardware embedded

2938
00:57:33,609 --> 00:57:33,619
have the private keys Hardware embedded
 

2939
00:57:33,619 --> 00:57:37,359
have the private keys Hardware embedded
in them if like a State Security Agency

2940
00:57:37,359 --> 00:57:37,369
in them if like a State Security Agency
 

2941
00:57:37,369 --> 00:57:39,160
in them if like a State Security Agency
really wants to infiltrate the company

2942
00:57:39,160 --> 00:57:39,170
really wants to infiltrate the company
 

2943
00:57:39,170 --> 00:57:41,170
really wants to infiltrate the company
they could probably you know plant a

2944
00:57:41,170 --> 00:57:41,180
they could probably you know plant a
 

2945
00:57:41,180 --> 00:57:43,359
they could probably you know plant a
private key of their choice or break

2946
00:57:43,359 --> 00:57:43,369
private key of their choice or break
 

2947
00:57:43,369 --> 00:57:44,980
private key of their choice or break
open the chip and learn the private key

2948
00:57:44,980 --> 00:57:44,990
open the chip and learn the private key
 

2949
00:57:44,990 --> 00:57:46,599
open the chip and learn the private key
or something like that but it would make

2950
00:57:46,599 --> 00:57:46,609
or something like that but it would make
 

2951
00:57:46,609 --> 00:57:49,900
or something like that but it would make
it a lot harder for an adversary with

2952
00:57:49,900 --> 00:57:49,910
it a lot harder for an adversary with
 

2953
00:57:49,910 --> 00:57:51,880
it a lot harder for an adversary with
fewer resources to fake things most of

2954
00:57:51,880 --> 00:57:51,890
fewer resources to fake things most of
 

2955
00:57:51,890 --> 00:57:54,700
fewer resources to fake things most of
us yeah okay okay so you mentioned the

2956
00:57:54,700 --> 00:57:54,710
us yeah okay okay so you mentioned the
 

2957
00:57:54,710 --> 00:57:58,420
us yeah okay okay so you mentioned the
beer and the bar and the new ideas you

2958
00:57:58,420 --> 00:57:58,430
beer and the bar and the new ideas you
 

2959
00:57:58,430 --> 00:58:00,130
beer and the bar and the new ideas you
were able to implement this or come up

2960
00:58:00,130 --> 00:58:00,140
were able to implement this or come up
 

2961
00:58:00,140 --> 00:58:02,950
were able to implement this or come up
with this new idea pretty quickly and

2962
00:58:02,950 --> 00:58:02,960
with this new idea pretty quickly and
 

2963
00:58:02,960 --> 00:58:04,720
with this new idea pretty quickly and
implement it pretty quickly do you think

2964
00:58:04,720 --> 00:58:04,730
implement it pretty quickly do you think
 

2965
00:58:04,730 --> 00:58:07,240
implement it pretty quickly do you think
there are still many such groundbreaking

2966
00:58:07,240 --> 00:58:07,250
there are still many such groundbreaking
 

2967
00:58:07,250 --> 00:58:08,829
there are still many such groundbreaking
ideas and deep learning that could be

2968
00:58:08,829 --> 00:58:08,839
ideas and deep learning that could be
 

2969
00:58:08,839 --> 00:58:11,740
ideas and deep learning that could be
developed so quickly yeah I do think

2970
00:58:11,740 --> 00:58:11,750
developed so quickly yeah I do think
 

2971
00:58:11,750 --> 00:58:13,240
developed so quickly yeah I do think
that there are a lot of ideas that can

2972
00:58:13,240 --> 00:58:13,250
that there are a lot of ideas that can
 

2973
00:58:13,250 --> 00:58:16,390
that there are a lot of ideas that can
be developed really quickly guns were

2974
00:58:16,390 --> 00:58:16,400
be developed really quickly guns were
 

2975
00:58:16,400 --> 00:58:17,920
be developed really quickly guns were
probably a little bit of an outlier on

2976
00:58:17,920 --> 00:58:17,930
probably a little bit of an outlier on
 

2977
00:58:17,930 --> 00:58:19,960
probably a little bit of an outlier on
the whole like one-hour timescale right

2978
00:58:19,960 --> 00:58:19,970
the whole like one-hour timescale right
 

2979
00:58:19,970 --> 00:58:23,130
the whole like one-hour timescale right
but just in terms of a like low resource

2980
00:58:23,130 --> 00:58:23,140
but just in terms of a like low resource
 

2981
00:58:23,140 --> 00:58:24,970
but just in terms of a like low resource
ideas where you do something really

2982
00:58:24,970 --> 00:58:24,980
ideas where you do something really
 

2983
00:58:24,980 --> 00:58:26,710
ideas where you do something really
different on the algorithm scale and get

2984
00:58:26,710 --> 00:58:26,720
different on the algorithm scale and get
 

2985
00:58:26,720 --> 00:58:31,180
different on the algorithm scale and get
a big payback I think it's not as likely

2986
00:58:31,180 --> 00:58:31,190
a big payback I think it's not as likely
 

2987
00:58:31,190 --> 00:58:33,190
a big payback I think it's not as likely
that you'll see that in terms of things

2988
00:58:33,190 --> 00:58:33,200
that you'll see that in terms of things
 

2989
00:58:33,200 --> 00:58:34,870
that you'll see that in terms of things
like core machine learning technologies

2990
00:58:34,870 --> 00:58:34,880
like core machine learning technologies
 

2991
00:58:34,880 --> 00:58:36,940
like core machine learning technologies
like a better classifier or a better

2992
00:58:36,940 --> 00:58:36,950
like a better classifier or a better
 

2993
00:58:36,950 --> 00:58:38,289
like a better classifier or a better
reinforcement learning algorithm or a

2994
00:58:38,289 --> 00:58:38,299
reinforcement learning algorithm or a
 

2995
00:58:38,299 --> 00:58:41,710
reinforcement learning algorithm or a
better generative model if I had the gun

2996
00:58:41,710 --> 00:58:41,720
better generative model if I had the gun
 

2997
00:58:41,720 --> 00:58:43,359
better generative model if I had the gun
idea today it would be a lot harder to

2998
00:58:43,359 --> 00:58:43,369
idea today it would be a lot harder to
 

2999
00:58:43,369 --> 00:58:45,670
idea today it would be a lot harder to
prove that it was useful than it was

3000
00:58:45,670 --> 00:58:45,680
prove that it was useful than it was
 

3001
00:58:45,680 --> 00:58:49,120
prove that it was useful than it was
back in 2014 because I would need to get

3002
00:58:49,120 --> 00:58:49,130
back in 2014 because I would need to get
 

3003
00:58:49,130 --> 00:58:51,370
back in 2014 because I would need to get
it running on something like image net

3004
00:58:51,370 --> 00:58:51,380
it running on something like image net
 

3005
00:58:51,380 --> 00:58:54,279
it running on something like image net
or celibate high resolution you know

3006
00:58:54,279 --> 00:58:54,289
or celibate high resolution you know
 

3007
00:58:54,289 --> 00:58:55,900
or celibate high resolution you know
those take a while to train you couldn't

3008
00:58:55,900 --> 00:58:55,910
those take a while to train you couldn't
 

3009
00:58:55,910 --> 00:58:57,640
those take a while to train you couldn't
you couldn't train it in an hour and

3010
00:58:57,640 --> 00:58:57,650
you couldn't train it in an hour and
 

3011
00:58:57,650 --> 00:58:59,470
you couldn't train it in an hour and
know that it was something really new

3012
00:58:59,470 --> 00:58:59,480
know that it was something really new
 

3013
00:58:59,480 --> 00:59:02,170
know that it was something really new
and exciting back in 2014 shredding an

3014
00:59:02,170 --> 00:59:02,180
and exciting back in 2014 shredding an
 

3015
00:59:02,180 --> 00:59:05,140
and exciting back in 2014 shredding an
amnesty was enough but there are other

3016
00:59:05,140 --> 00:59:05,150
amnesty was enough but there are other
 

3017
00:59:05,150 --> 00:59:07,539
amnesty was enough but there are other
areas of machine learning where I think

3018
00:59:07,539 --> 00:59:07,549
areas of machine learning where I think
 

3019
00:59:07,549 --> 00:59:11,200
areas of machine learning where I think
a new idea could actually be developed

3020
00:59:11,200 --> 00:59:11,210
a new idea could actually be developed
 

3021
00:59:11,210 --> 00:59:13,450
a new idea could actually be developed
really quickly with low resources what's

3022
00:59:13,450 --> 00:59:13,460
really quickly with low resources what's
 

3023
00:59:13,460 --> 00:59:15,279
really quickly with low resources what's
your intuition about what areas of

3024
00:59:15,279 --> 00:59:15,289
your intuition about what areas of
 

3025
00:59:15,289 --> 00:59:17,890
your intuition about what areas of
machine learning are ripe for this yeah

3026
00:59:17,890 --> 00:59:17,900
machine learning are ripe for this yeah
 

3027
00:59:17,900 --> 00:59:19,609
machine learning are ripe for this yeah
so I think

3028
00:59:19,609 --> 00:59:19,619
so I think
 

3029
00:59:19,619 --> 00:59:22,579
so I think
fairness and interpretability

3030
00:59:22,579 --> 00:59:22,589
fairness and interpretability
 

3031
00:59:22,589 --> 00:59:26,029
fairness and interpretability
our areas where we just really don't

3032
00:59:26,029 --> 00:59:26,039
our areas where we just really don't
 

3033
00:59:26,039 --> 00:59:27,890
our areas where we just really don't
have any idea how anything should be

3034
00:59:27,890 --> 00:59:27,900
have any idea how anything should be
 

3035
00:59:27,900 --> 00:59:28,459
have any idea how anything should be
done yet

3036
00:59:28,459 --> 00:59:28,469
done yet
 

3037
00:59:28,469 --> 00:59:30,739
done yet
like for interpretability I don't think

3038
00:59:30,739 --> 00:59:30,749
like for interpretability I don't think
 

3039
00:59:30,749 --> 00:59:32,359
like for interpretability I don't think
we even have the right definitions and

3040
00:59:32,359 --> 00:59:32,369
we even have the right definitions and
 

3041
00:59:32,369 --> 00:59:34,819
we even have the right definitions and
even just defining a really useful

3042
00:59:34,819 --> 00:59:34,829
even just defining a really useful
 

3043
00:59:34,829 --> 00:59:36,920
even just defining a really useful
concept you don't even need to run any

3044
00:59:36,920 --> 00:59:36,930
concept you don't even need to run any
 

3045
00:59:36,930 --> 00:59:39,170
concept you don't even need to run any
experiments could have a huge impact on

3046
00:59:39,170 --> 00:59:39,180
experiments could have a huge impact on
 

3047
00:59:39,180 --> 00:59:41,209
experiments could have a huge impact on
the field we've seen that for example in

3048
00:59:41,209 --> 00:59:41,219
the field we've seen that for example in
 

3049
00:59:41,219 --> 00:59:43,489
the field we've seen that for example in
differential privacy that uh Cynthia

3050
00:59:43,489 --> 00:59:43,499
differential privacy that uh Cynthia
 

3051
00:59:43,499 --> 00:59:45,709
differential privacy that uh Cynthia
Dworkin her collaborators made this

3052
00:59:45,709 --> 00:59:45,719
Dworkin her collaborators made this
 

3053
00:59:45,719 --> 00:59:48,170
Dworkin her collaborators made this
technical definition of privacy where

3054
00:59:48,170 --> 00:59:48,180
technical definition of privacy where
 

3055
00:59:48,180 --> 00:59:49,759
technical definition of privacy where
before a lot of things are really mushy

3056
00:59:49,759 --> 00:59:49,769
before a lot of things are really mushy
 

3057
00:59:49,769 --> 00:59:51,799
before a lot of things are really mushy
and then with that definition you could

3058
00:59:51,799 --> 00:59:51,809
and then with that definition you could
 

3059
00:59:51,809 --> 00:59:54,170
and then with that definition you could
actually design randomized algorithms

3060
00:59:54,170 --> 00:59:54,180
actually design randomized algorithms
 

3061
00:59:54,180 --> 00:59:56,059
actually design randomized algorithms
for accessing databases and guarantee

3062
00:59:56,059 --> 00:59:56,069
for accessing databases and guarantee
 

3063
00:59:56,069 --> 00:59:58,219
for accessing databases and guarantee
that they preserved individual people's

3064
00:59:58,219 --> 00:59:58,229
that they preserved individual people's
 

3065
00:59:58,229 --> 01:00:00,109
that they preserved individual people's
privacy in a in like a mathematical

3066
01:00:00,109 --> 01:00:00,119
privacy in a in like a mathematical
 

3067
01:00:00,119 --> 01:00:04,579
privacy in a in like a mathematical
quantitative sense right now we all talk

3068
01:00:04,579 --> 01:00:04,589
quantitative sense right now we all talk
 

3069
01:00:04,589 --> 01:00:06,109
quantitative sense right now we all talk
a lot about how interpretable different

3070
01:00:06,109 --> 01:00:06,119
a lot about how interpretable different
 

3071
01:00:06,119 --> 01:00:08,059
a lot about how interpretable different
machine learning algorithms are but it's

3072
01:00:08,059 --> 01:00:08,069
machine learning algorithms are but it's
 

3073
01:00:08,069 --> 01:00:09,949
machine learning algorithms are but it's
really just people's opinion and

3074
01:00:09,949 --> 01:00:09,959
really just people's opinion and
 

3075
01:00:09,959 --> 01:00:11,150
really just people's opinion and
everybody probably has a different idea

3076
01:00:11,150 --> 01:00:11,160
everybody probably has a different idea
 

3077
01:00:11,160 --> 01:00:13,069
everybody probably has a different idea
of what interpretability means in their

3078
01:00:13,069 --> 01:00:13,079
of what interpretability means in their
 

3079
01:00:13,079 --> 01:00:15,769
of what interpretability means in their
head if we could define some concept

3080
01:00:15,769 --> 01:00:15,779
head if we could define some concept
 

3081
01:00:15,779 --> 01:00:17,120
head if we could define some concept
related to interpretability that's

3082
01:00:17,120 --> 01:00:17,130
related to interpretability that's
 

3083
01:00:17,130 --> 01:00:19,309
related to interpretability that's
actually measurable that would be a huge

3084
01:00:19,309 --> 01:00:19,319
actually measurable that would be a huge
 

3085
01:00:19,319 --> 01:00:21,259
actually measurable that would be a huge
leap forward even without a new

3086
01:00:21,259 --> 01:00:21,269
leap forward even without a new
 

3087
01:00:21,269 --> 01:00:23,569
leap forward even without a new
algorithm that increases that quantity

3088
01:00:23,569 --> 01:00:23,579
algorithm that increases that quantity
 

3089
01:00:23,579 --> 01:00:27,289
algorithm that increases that quantity
and also once once we had the definition

3090
01:00:27,289 --> 01:00:27,299
and also once once we had the definition
 

3091
01:00:27,299 --> 01:00:29,449
and also once once we had the definition
of differential privacy it was fast to

3092
01:00:29,449 --> 01:00:29,459
of differential privacy it was fast to
 

3093
01:00:29,459 --> 01:00:31,489
of differential privacy it was fast to
get the algorithms that guaranteed it so

3094
01:00:31,489 --> 01:00:31,499
get the algorithms that guaranteed it so
 

3095
01:00:31,499 --> 01:00:32,809
get the algorithms that guaranteed it so
you could imagine once we have

3096
01:00:32,809 --> 01:00:32,819
you could imagine once we have
 

3097
01:00:32,819 --> 01:00:34,459
you could imagine once we have
definitions of good concepts and

3098
01:00:34,459 --> 01:00:34,469
definitions of good concepts and
 

3099
01:00:34,469 --> 01:00:35,209
definitions of good concepts and
interpretability

3100
01:00:35,209 --> 01:00:35,219
interpretability
 

3101
01:00:35,219 --> 01:00:36,919
interpretability
we might be able to provide the

3102
01:00:36,919 --> 01:00:36,929
we might be able to provide the
 

3103
01:00:36,929 --> 01:00:38,539
we might be able to provide the
algorithms that have the

3104
01:00:38,539 --> 01:00:38,549
algorithms that have the
 

3105
01:00:38,549 --> 01:00:41,739
algorithms that have the
interpretability guarantees quickly to

3106
01:00:41,739 --> 01:00:41,749
interpretability guarantees quickly to
 

3107
01:00:41,749 --> 01:00:46,309
interpretability guarantees quickly to
what do you think it takes to build a

3108
01:00:46,309 --> 01:00:46,319
what do you think it takes to build a
 

3109
01:00:46,319 --> 01:00:48,349
what do you think it takes to build a
system with human level intelligence as

3110
01:00:48,349 --> 01:00:48,359
system with human level intelligence as
 

3111
01:00:48,359 --> 01:00:50,539
system with human level intelligence as
we quickly venture into the

3112
01:00:50,539 --> 01:00:50,549
we quickly venture into the
 

3113
01:00:50,549 --> 01:00:53,059
we quickly venture into the
philosophical so artificial general

3114
01:00:53,059 --> 01:00:53,069
philosophical so artificial general
 

3115
01:00:53,069 --> 01:00:57,169
philosophical so artificial general
intelligence what do you think I I think

3116
01:00:57,169 --> 01:00:57,179
intelligence what do you think I I think
 

3117
01:00:57,179 --> 01:01:00,890
intelligence what do you think I I think
that it definitely takes better

3118
01:01:00,890 --> 01:01:00,900
that it definitely takes better
 

3119
01:01:00,900 --> 01:01:02,929
that it definitely takes better
environments than we currently have for

3120
01:01:02,929 --> 01:01:02,939
environments than we currently have for
 

3121
01:01:02,939 --> 01:01:04,339
environments than we currently have for
training agents that we want them to

3122
01:01:04,339 --> 01:01:04,349
training agents that we want them to
 

3123
01:01:04,349 --> 01:01:06,589
training agents that we want them to
have a really wide diversity of

3124
01:01:06,589 --> 01:01:06,599
have a really wide diversity of
 

3125
01:01:06,599 --> 01:01:09,620
have a really wide diversity of
experiences I also think it's going to

3126
01:01:09,620 --> 01:01:09,630
experiences I also think it's going to
 

3127
01:01:09,630 --> 01:01:11,900
experiences I also think it's going to
take really a lot of computation it's

3128
01:01:11,900 --> 01:01:11,910
take really a lot of computation it's
 

3129
01:01:11,910 --> 01:01:13,880
take really a lot of computation it's
hard to imagine exactly how much so

3130
01:01:13,880 --> 01:01:13,890
hard to imagine exactly how much so
 

3131
01:01:13,890 --> 01:01:15,939
hard to imagine exactly how much so
you're optimistic about simulation

3132
01:01:15,939 --> 01:01:15,949
you're optimistic about simulation
 

3133
01:01:15,949 --> 01:01:18,229
you're optimistic about simulation
simulating a variety of environments is

3134
01:01:18,229 --> 01:01:18,239
simulating a variety of environments is
 

3135
01:01:18,239 --> 01:01:20,390
simulating a variety of environments is
the path forward I think it's a

3136
01:01:20,390 --> 01:01:20,400
the path forward I think it's a
 

3137
01:01:20,400 --> 01:01:23,779
the path forward I think it's a
necessary ingredient yeah I don't think

3138
01:01:23,779 --> 01:01:23,789
necessary ingredient yeah I don't think
 

3139
01:01:23,789 --> 01:01:26,390
necessary ingredient yeah I don't think
that we're going to get to artificial

3140
01:01:26,390 --> 01:01:26,400
that we're going to get to artificial
 

3141
01:01:26,400 --> 01:01:28,009
that we're going to get to artificial
general intelligence by training on

3142
01:01:28,009 --> 01:01:28,019
general intelligence by training on
 

3143
01:01:28,019 --> 01:01:31,039
general intelligence by training on
fixed datasets or by thinking really

3144
01:01:31,039 --> 01:01:31,049
fixed datasets or by thinking really
 

3145
01:01:31,049 --> 01:01:32,829
fixed datasets or by thinking really
hard about the problem I think

3146
01:01:32,829 --> 01:01:32,839
hard about the problem I think
 

3147
01:01:32,839 --> 01:01:35,259
hard about the problem I think
that the the agent really needs to

3148
01:01:35,259 --> 01:01:35,269
that the the agent really needs to
 

3149
01:01:35,269 --> 01:01:36,849
that the the agent really needs to
interact and have a variety of

3150
01:01:36,849 --> 01:01:36,859
interact and have a variety of
 

3151
01:01:36,859 --> 01:01:41,519
interact and have a variety of
experiences within the same lifespan and

3152
01:01:41,519 --> 01:01:41,529
experiences within the same lifespan and
 

3153
01:01:41,529 --> 01:01:44,200
experiences within the same lifespan and
today we have many different models that

3154
01:01:44,200 --> 01:01:44,210
today we have many different models that
 

3155
01:01:44,210 --> 01:01:46,209
today we have many different models that
can each do one thing and we tend to

3156
01:01:46,209 --> 01:01:46,219
can each do one thing and we tend to
 

3157
01:01:46,219 --> 01:01:48,009
can each do one thing and we tend to
train them on one data set or one RL

3158
01:01:48,009 --> 01:01:48,019
train them on one data set or one RL
 

3159
01:01:48,019 --> 01:01:50,979
train them on one data set or one RL
environment sometimes they're actually

3160
01:01:50,979 --> 01:01:50,989
environment sometimes they're actually
 

3161
01:01:50,989 --> 01:01:53,049
environment sometimes they're actually
papers about getting one set of

3162
01:01:53,049 --> 01:01:53,059
papers about getting one set of
 

3163
01:01:53,059 --> 01:01:54,999
papers about getting one set of
parameters to perform well in many

3164
01:01:54,999 --> 01:01:55,009
parameters to perform well in many
 

3165
01:01:55,009 --> 01:01:57,370
parameters to perform well in many
different RL environments but we don't

3166
01:01:57,370 --> 01:01:57,380
different RL environments but we don't
 

3167
01:01:57,380 --> 01:01:59,589
different RL environments but we don't
really have anything like an agent that

3168
01:01:59,589 --> 01:01:59,599
really have anything like an agent that
 

3169
01:01:59,599 --> 01:02:01,329
really have anything like an agent that
goes seamlessly from one type of

3170
01:02:01,329 --> 01:02:01,339
goes seamlessly from one type of
 

3171
01:02:01,339 --> 01:02:03,880
goes seamlessly from one type of
experience to another and and really

3172
01:02:03,880 --> 01:02:03,890
experience to another and and really
 

3173
01:02:03,890 --> 01:02:05,319
experience to another and and really
integrates all the different things that

3174
01:02:05,319 --> 01:02:05,329
integrates all the different things that
 

3175
01:02:05,329 --> 01:02:08,229
integrates all the different things that
it does over the course of its life when

3176
01:02:08,229 --> 01:02:08,239
it does over the course of its life when
 

3177
01:02:08,239 --> 01:02:10,660
it does over the course of its life when
we do see multi agent environments they

3178
01:02:10,660 --> 01:02:10,670
we do see multi agent environments they
 

3179
01:02:10,670 --> 01:02:13,719
we do see multi agent environments they
tend to be there are so many multi

3180
01:02:13,719 --> 01:02:13,729
tend to be there are so many multi
 

3181
01:02:13,729 --> 01:02:15,130
tend to be there are so many multi
environment agents they tend to be

3182
01:02:15,130 --> 01:02:15,140
environment agents they tend to be
 

3183
01:02:15,140 --> 01:02:17,529
environment agents they tend to be
similar environments like all of them

3184
01:02:17,529 --> 01:02:17,539
similar environments like all of them
 

3185
01:02:17,539 --> 01:02:19,089
similar environments like all of them
are playing like an action based video

3186
01:02:19,089 --> 01:02:19,099
are playing like an action based video
 

3187
01:02:19,099 --> 01:02:21,789
are playing like an action based video
game we don't really have an agent that

3188
01:02:21,789 --> 01:02:21,799
game we don't really have an agent that
 

3189
01:02:21,799 --> 01:02:23,829
game we don't really have an agent that
goes from you know playing a video game

3190
01:02:23,829 --> 01:02:23,839
goes from you know playing a video game
 

3191
01:02:23,839 --> 01:02:26,670
goes from you know playing a video game
to like reading The Wall Street Journal

3192
01:02:26,670 --> 01:02:26,680
to like reading The Wall Street Journal
 

3193
01:02:26,680 --> 01:02:30,069
to like reading The Wall Street Journal
to predicting how effective a molecule

3194
01:02:30,069 --> 01:02:30,079
to predicting how effective a molecule
 

3195
01:02:30,079 --> 01:02:32,370
to predicting how effective a molecule
will be as a drug or something like that

3196
01:02:32,370 --> 01:02:32,380
will be as a drug or something like that
 

3197
01:02:32,380 --> 01:02:34,829
will be as a drug or something like that
what do you think is a good test for

3198
01:02:34,829 --> 01:02:34,839
what do you think is a good test for
 

3199
01:02:34,839 --> 01:02:37,420
what do you think is a good test for
intelligence in you view it's been a lot

3200
01:02:37,420 --> 01:02:37,430
intelligence in you view it's been a lot
 

3201
01:02:37,430 --> 01:02:40,719
intelligence in you view it's been a lot
of benchmarks started with the with Alan

3202
01:02:40,719 --> 01:02:40,729
of benchmarks started with the with Alan
 

3203
01:02:40,729 --> 01:02:43,959
of benchmarks started with the with Alan
Turing a natural conversation being good

3204
01:02:43,959 --> 01:02:43,969
Turing a natural conversation being good
 

3205
01:02:43,969 --> 01:02:45,849
Turing a natural conversation being good
being a good benchmark for intelligence

3206
01:02:45,849 --> 01:02:45,859
being a good benchmark for intelligence
 

3207
01:02:45,859 --> 01:02:50,410
being a good benchmark for intelligence
what what are what would you and good

3208
01:02:50,410 --> 01:02:50,420
what what are what would you and good
 

3209
01:02:50,420 --> 01:02:52,180
what what are what would you and good
fellows sit back and be really damn

3210
01:02:52,180 --> 01:02:52,190
fellows sit back and be really damn
 

3211
01:02:52,190 --> 01:02:54,459
fellows sit back and be really damn
impressed if a system was able to

3212
01:02:54,459 --> 01:02:54,469
impressed if a system was able to
 

3213
01:02:54,469 --> 01:02:57,339
impressed if a system was able to
accomplish something that doesn't take a

3214
01:02:57,339 --> 01:02:57,349
accomplish something that doesn't take a
 

3215
01:02:57,349 --> 01:03:00,009
accomplish something that doesn't take a
lot of glue from human engineers so

3216
01:03:00,009 --> 01:03:00,019
lot of glue from human engineers so
 

3217
01:03:00,019 --> 01:03:03,759
lot of glue from human engineers so
imagine that instead of having to go to

3218
01:03:03,759 --> 01:03:03,769
imagine that instead of having to go to
 

3219
01:03:03,769 --> 01:03:07,599
imagine that instead of having to go to
the CFR website and download CFR 10 and

3220
01:03:07,599 --> 01:03:07,609
the CFR website and download CFR 10 and
 

3221
01:03:07,609 --> 01:03:10,150
the CFR website and download CFR 10 and
then write a Python script to parse it

3222
01:03:10,150 --> 01:03:10,160
then write a Python script to parse it
 

3223
01:03:10,160 --> 01:03:12,430
then write a Python script to parse it
and all that you could just point an

3224
01:03:12,430 --> 01:03:12,440
and all that you could just point an
 

3225
01:03:12,440 --> 01:03:16,779
and all that you could just point an
agent at the CFR 10 problem and it

3226
01:03:16,779 --> 01:03:16,789
agent at the CFR 10 problem and it
 

3227
01:03:16,789 --> 01:03:19,329
agent at the CFR 10 problem and it
downloads and extracts the data and

3228
01:03:19,329 --> 01:03:19,339
downloads and extracts the data and
 

3229
01:03:19,339 --> 01:03:20,709
downloads and extracts the data and
trains a model and starts giving you

3230
01:03:20,709 --> 01:03:20,719
trains a model and starts giving you
 

3231
01:03:20,719 --> 01:03:23,950
trains a model and starts giving you
predictions I feel like something that

3232
01:03:23,950 --> 01:03:23,960
predictions I feel like something that
 

3233
01:03:23,960 --> 01:03:26,920
predictions I feel like something that
doesn't need to have every step of the

3234
01:03:26,920 --> 01:03:26,930
doesn't need to have every step of the
 

3235
01:03:26,930 --> 01:03:29,289
doesn't need to have every step of the
pipeline assembled for it it definitely

3236
01:03:29,289 --> 01:03:29,299
pipeline assembled for it it definitely
 

3237
01:03:29,299 --> 01:03:31,209
pipeline assembled for it it definitely
understands what it's doing is Auto ml

3238
01:03:31,209 --> 01:03:31,219
understands what it's doing is Auto ml
 

3239
01:03:31,219 --> 01:03:32,559
understands what it's doing is Auto ml
moving into that direction are you

3240
01:03:32,559 --> 01:03:32,569
moving into that direction are you
 

3241
01:03:32,569 --> 01:03:35,259
moving into that direction are you
thinking wave and bigger autosomal has

3242
01:03:35,259 --> 01:03:35,269
thinking wave and bigger autosomal has
 

3243
01:03:35,269 --> 01:03:38,709
thinking wave and bigger autosomal has
mostly been moving toward once we've

3244
01:03:38,709 --> 01:03:38,719
mostly been moving toward once we've
 

3245
01:03:38,719 --> 01:03:40,569
mostly been moving toward once we've
built all the glue can the machine

3246
01:03:40,569 --> 01:03:40,579
built all the glue can the machine
 

3247
01:03:40,579 --> 01:03:42,700
built all the glue can the machine
learning system to design the

3248
01:03:42,700 --> 01:03:42,710
learning system to design the
 

3249
01:03:42,710 --> 01:03:45,130
learning system to design the
architecture really well so I'm we're

3250
01:03:45,130 --> 01:03:45,140
architecture really well so I'm we're
 

3251
01:03:45,140 --> 01:03:46,450
architecture really well so I'm we're
saying like

3252
01:03:46,450 --> 01:03:46,460
saying like
 

3253
01:03:46,460 --> 01:03:48,819
saying like
if something knows how to pre-process

3254
01:03:48,819 --> 01:03:48,829
if something knows how to pre-process
 

3255
01:03:48,829 --> 01:03:50,710
if something knows how to pre-process
the data so that it successfully

3256
01:03:50,710 --> 01:03:50,720
the data so that it successfully
 

3257
01:03:50,720 --> 01:03:52,809
the data so that it successfully
accomplishes the task then it would be

3258
01:03:52,809 --> 01:03:52,819
accomplishes the task then it would be
 

3259
01:03:52,819 --> 01:03:54,940
accomplishes the task then it would be
very hard to argue that it doesn't truly

3260
01:03:54,940 --> 01:03:54,950
very hard to argue that it doesn't truly
 

3261
01:03:54,950 --> 01:03:56,770
very hard to argue that it doesn't truly
understand the task in some fundamental

3262
01:03:56,770 --> 01:03:56,780
understand the task in some fundamental
 

3263
01:03:56,780 --> 01:03:57,579
understand the task in some fundamental
sense

3264
01:03:57,579 --> 01:03:57,589
sense
 

3265
01:03:57,589 --> 01:03:59,829
sense
and I don't necessarily know that that's

3266
01:03:59,829 --> 01:03:59,839
and I don't necessarily know that that's
 

3267
01:03:59,839 --> 01:04:01,359
and I don't necessarily know that that's
like the philosophical definition of

3268
01:04:01,359 --> 01:04:01,369
like the philosophical definition of
 

3269
01:04:01,369 --> 01:04:02,740
like the philosophical definition of
intelligence but that's something that

3270
01:04:02,740 --> 01:04:02,750
intelligence but that's something that
 

3271
01:04:02,750 --> 01:04:03,970
intelligence but that's something that
would be really cool to build that would

3272
01:04:03,970 --> 01:04:03,980
would be really cool to build that would
 

3273
01:04:03,980 --> 01:04:05,530
would be really cool to build that would
be really useful and would impress me

3274
01:04:05,530 --> 01:04:05,540
be really useful and would impress me
 

3275
01:04:05,540 --> 01:04:07,480
be really useful and would impress me
and would convince me that we've made a

3276
01:04:07,480 --> 01:04:07,490
and would convince me that we've made a
 

3277
01:04:07,490 --> 01:04:09,910
and would convince me that we've made a
step forward in real AI so you give it

3278
01:04:09,910 --> 01:04:09,920
step forward in real AI so you give it
 

3279
01:04:09,920 --> 01:04:15,339
step forward in real AI so you give it
like the URL for Wikipedia and then next

3280
01:04:15,339 --> 01:04:15,349
like the URL for Wikipedia and then next
 

3281
01:04:15,349 --> 01:04:18,190
like the URL for Wikipedia and then next
day expected to be able to solve CFR 10

3282
01:04:18,190 --> 01:04:18,200
day expected to be able to solve CFR 10
 

3283
01:04:18,200 --> 01:04:20,589
day expected to be able to solve CFR 10
or like you type in a paragraph

3284
01:04:20,589 --> 01:04:20,599
or like you type in a paragraph
 

3285
01:04:20,599 --> 01:04:22,390
or like you type in a paragraph
explaining what you want it to do and it

3286
01:04:22,390 --> 01:04:22,400
explaining what you want it to do and it
 

3287
01:04:22,400 --> 01:04:24,579
explaining what you want it to do and it
figures out what web searches it should

3288
01:04:24,579 --> 01:04:24,589
figures out what web searches it should
 

3289
01:04:24,589 --> 01:04:26,559
figures out what web searches it should
run and downloads all the whole

3290
01:04:26,559 --> 01:04:26,569
run and downloads all the whole
 

3291
01:04:26,569 --> 01:04:31,150
run and downloads all the whole
unnecessary ingredients so you have a

3292
01:04:31,150 --> 01:04:31,160
unnecessary ingredients so you have a
 

3293
01:04:31,160 --> 01:04:35,400
unnecessary ingredients so you have a
very clear calm way of speaking no arms

3294
01:04:35,400 --> 01:04:35,410
very clear calm way of speaking no arms
 

3295
01:04:35,410 --> 01:04:38,710
very clear calm way of speaking no arms
easy to edit I've seen comments for both

3296
01:04:38,710 --> 01:04:38,720
easy to edit I've seen comments for both
 

3297
01:04:38,720 --> 01:04:42,250
easy to edit I've seen comments for both
you and I have been identified as both

3298
01:04:42,250 --> 01:04:42,260
you and I have been identified as both
 

3299
01:04:42,260 --> 01:04:44,799
you and I have been identified as both
potentially being robots if you have to

3300
01:04:44,799 --> 01:04:44,809
potentially being robots if you have to
 

3301
01:04:44,809 --> 01:04:46,720
potentially being robots if you have to
prove to the world that you are indeed

3302
01:04:46,720 --> 01:04:46,730
prove to the world that you are indeed
 

3303
01:04:46,730 --> 01:04:51,400
prove to the world that you are indeed
human how would you do it but I can

3304
01:04:51,400 --> 01:04:51,410
human how would you do it but I can
 

3305
01:04:51,410 --> 01:04:54,440
human how would you do it but I can
understand thinking that I'm a robot

3306
01:04:54,440 --> 01:04:54,450
understand thinking that I'm a robot
 

3307
01:04:54,450 --> 01:04:57,210
understand thinking that I'm a robot
it's the flipside yeah touring test I

3308
01:04:57,210 --> 01:04:57,220
it's the flipside yeah touring test I
 

3309
01:04:57,220 --> 01:04:59,370
it's the flipside yeah touring test I
think yeah yeah the proof prove your

3310
01:04:59,370 --> 01:04:59,380
think yeah yeah the proof prove your
 

3311
01:04:59,380 --> 01:05:03,150
think yeah yeah the proof prove your
human test I mean I lecture so you have

3312
01:05:03,150 --> 01:05:03,160
human test I mean I lecture so you have
 

3313
01:05:03,160 --> 01:05:05,940
human test I mean I lecture so you have
to is there something that's truly

3314
01:05:05,940 --> 01:05:05,950
to is there something that's truly
 

3315
01:05:05,950 --> 01:05:09,480
to is there something that's truly
unique in your mind I suppose it doesn't

3316
01:05:09,480 --> 01:05:09,490
unique in your mind I suppose it doesn't
 

3317
01:05:09,490 --> 01:05:11,190
unique in your mind I suppose it doesn't
go back to just natural language again

3318
01:05:11,190 --> 01:05:11,200
go back to just natural language again
 

3319
01:05:11,200 --> 01:05:14,040
go back to just natural language again
just being able to so proving proving

3320
01:05:14,040 --> 01:05:14,050
just being able to so proving proving
 

3321
01:05:14,050 --> 01:05:15,450
just being able to so proving proving
that I'm not a robot with today's

3322
01:05:15,450 --> 01:05:15,460
that I'm not a robot with today's
 

3323
01:05:15,460 --> 01:05:16,470
that I'm not a robot with today's
technology

3324
01:05:16,470 --> 01:05:16,480
technology
 

3325
01:05:16,480 --> 01:05:18,390
technology
yeah that's pretty straightforward too

3326
01:05:18,390 --> 01:05:18,400
yeah that's pretty straightforward too
 

3327
01:05:18,400 --> 01:05:20,520
yeah that's pretty straightforward too
like my conversation today hasn't veered

3328
01:05:20,520 --> 01:05:20,530
like my conversation today hasn't veered
 

3329
01:05:20,530 --> 01:05:23,430
like my conversation today hasn't veered
off into you know talking about the

3330
01:05:23,430 --> 01:05:23,440
off into you know talking about the
 

3331
01:05:23,440 --> 01:05:24,900
off into you know talking about the
stock market or something because in my

3332
01:05:24,900 --> 01:05:24,910
stock market or something because in my
 

3333
01:05:24,910 --> 01:05:27,000
stock market or something because in my
training data but I think it's more

3334
01:05:27,000 --> 01:05:27,010
training data but I think it's more
 

3335
01:05:27,010 --> 01:05:28,410
training data but I think it's more
generally trying to prove that something

3336
01:05:28,410 --> 01:05:28,420
generally trying to prove that something
 

3337
01:05:28,420 --> 01:05:30,690
generally trying to prove that something
is real from the content alone it was

3338
01:05:30,690 --> 01:05:30,700
is real from the content alone it was
 

3339
01:05:30,700 --> 01:05:31,980
is real from the content alone it was
incredibly hard that's one of the main

3340
01:05:31,980 --> 01:05:31,990
incredibly hard that's one of the main
 

3341
01:05:31,990 --> 01:05:32,940
incredibly hard that's one of the main
things I've gotten out of my can

3342
01:05:32,940 --> 01:05:32,950
things I've gotten out of my can
 

3343
01:05:32,950 --> 01:05:37,020
things I've gotten out of my can
research that you can simulate almost

3344
01:05:37,020 --> 01:05:37,030
research that you can simulate almost
 

3345
01:05:37,030 --> 01:05:38,760
research that you can simulate almost
anything and so you have to really step

3346
01:05:38,760 --> 01:05:38,770
anything and so you have to really step
 

3347
01:05:38,770 --> 01:05:41,610
anything and so you have to really step
back to a separate channel to prove that

3348
01:05:41,610 --> 01:05:41,620
back to a separate channel to prove that
 

3349
01:05:41,620 --> 01:05:43,680
back to a separate channel to prove that
slang is real so like I guess I should

3350
01:05:43,680 --> 01:05:43,690
slang is real so like I guess I should
 

3351
01:05:43,690 --> 01:05:45,930
slang is real so like I guess I should
have had myself stamped on a blockchain

3352
01:05:45,930 --> 01:05:45,940
have had myself stamped on a blockchain
 

3353
01:05:45,940 --> 01:05:47,880
have had myself stamped on a blockchain
when I was born or something but I

3354
01:05:47,880 --> 01:05:47,890
when I was born or something but I
 

3355
01:05:47,890 --> 01:05:49,860
when I was born or something but I
didn't do that so according to my own

3356
01:05:49,860 --> 01:05:49,870
didn't do that so according to my own
 

3357
01:05:49,870 --> 01:05:51,330
didn't do that so according to my own
research methodology there's just no way

3358
01:05:51,330 --> 01:05:51,340
research methodology there's just no way
 

3359
01:05:51,340 --> 01:05:53,730
research methodology there's just no way
to know at this point so what

3360
01:05:53,730 --> 01:05:53,740
to know at this point so what
 

3361
01:05:53,740 --> 01:05:55,800
to know at this point so what
last question problem stands all for you

3362
01:05:55,800 --> 01:05:55,810
last question problem stands all for you
 

3363
01:05:55,810 --> 01:05:57,690
last question problem stands all for you
that you're really excited about

3364
01:05:57,690 --> 01:05:57,700
that you're really excited about
 

3365
01:05:57,700 --> 01:06:00,060
that you're really excited about
challenging in the near future so I

3366
01:06:00,060 --> 01:06:00,070
challenging in the near future so I
 

3367
01:06:00,070 --> 01:06:02,610
challenging in the near future so I
think resistance to adversarial examples

3368
01:06:02,610 --> 01:06:02,620
think resistance to adversarial examples
 

3369
01:06:02,620 --> 01:06:04,170
think resistance to adversarial examples
figuring out how to make machine

3370
01:06:04,170 --> 01:06:04,180
figuring out how to make machine
 

3371
01:06:04,180 --> 01:06:06,510
figuring out how to make machine
learning secure against an adversary who

3372
01:06:06,510 --> 01:06:06,520
learning secure against an adversary who
 

3373
01:06:06,520 --> 01:06:08,190
learning secure against an adversary who
wants to interfere it in control with it

3374
01:06:08,190 --> 01:06:08,200
wants to interfere it in control with it
 

3375
01:06:08,200 --> 01:06:10,530
wants to interfere it in control with it
is one of the most important things

3376
01:06:10,530 --> 01:06:10,540
is one of the most important things
 

3377
01:06:10,540 --> 01:06:12,480
is one of the most important things
researchers today could solve in all

3378
01:06:12,480 --> 01:06:12,490
researchers today could solve in all
 

3379
01:06:12,490 --> 01:06:17,790
researchers today could solve in all
domains in image language driving in I

3380
01:06:17,790 --> 01:06:17,800
domains in image language driving in I
 

3381
01:06:17,800 --> 01:06:19,680
domains in image language driving in I
guess I'm most concerned about domains

3382
01:06:19,680 --> 01:06:19,690
guess I'm most concerned about domains
 

3383
01:06:19,690 --> 01:06:22,170
guess I'm most concerned about domains
we haven't really encountered yet like

3384
01:06:22,170 --> 01:06:22,180
we haven't really encountered yet like
 

3385
01:06:22,180 --> 01:06:24,180
we haven't really encountered yet like
like imagine twenty years from now when

3386
01:06:24,180 --> 01:06:24,190
like imagine twenty years from now when
 

3387
01:06:24,190 --> 01:06:26,550
like imagine twenty years from now when
we're using advanced day eyes to do

3388
01:06:26,550 --> 01:06:26,560
we're using advanced day eyes to do
 

3389
01:06:26,560 --> 01:06:28,130
we're using advanced day eyes to do
things we haven't even thought of yet

3390
01:06:28,130 --> 01:06:28,140
things we haven't even thought of yet
 

3391
01:06:28,140 --> 01:06:30,990
things we haven't even thought of yet
like if you ask people what are the

3392
01:06:30,990 --> 01:06:31,000
like if you ask people what are the
 

3393
01:06:31,000 --> 01:06:34,050
like if you ask people what are the
important problems in security of phones

3394
01:06:34,050 --> 01:06:34,060
important problems in security of phones
 

3395
01:06:34,060 --> 01:06:38,160
important problems in security of phones
in in like 2002 I don't think we would

3396
01:06:38,160 --> 01:06:38,170
in in like 2002 I don't think we would
 

3397
01:06:38,170 --> 01:06:39,930
in in like 2002 I don't think we would
have anticipated that we're using them

3398
01:06:39,930 --> 01:06:39,940
have anticipated that we're using them
 

3399
01:06:39,940 --> 01:06:42,240
have anticipated that we're using them
for you know nearly as many things as

3400
01:06:42,240 --> 01:06:42,250
for you know nearly as many things as
 

3401
01:06:42,250 --> 01:06:43,980
for you know nearly as many things as
we're using them for today I think it's

3402
01:06:43,980 --> 01:06:43,990
we're using them for today I think it's
 

3403
01:06:43,990 --> 01:06:45,060
we're using them for today I think it's
going to be like that with AI that you

3404
01:06:45,060 --> 01:06:45,070
going to be like that with AI that you
 

3405
01:06:45,070 --> 01:06:47,370
going to be like that with AI that you
can kind of try to speculate about where

3406
01:06:47,370 --> 01:06:47,380
can kind of try to speculate about where
 

3407
01:06:47,380 --> 01:06:48,840
can kind of try to speculate about where
it's going but really the business

3408
01:06:48,840 --> 01:06:48,850
it's going but really the business
 

3409
01:06:48,850 --> 01:06:50,370
it's going but really the business
opportunities that end up taking off

3410
01:06:50,370 --> 01:06:50,380
opportunities that end up taking off
 

3411
01:06:50,380 --> 01:06:53,330
opportunities that end up taking off
would be hard to predict ahead of time

3412
01:06:53,330 --> 01:06:53,340
would be hard to predict ahead of time
 

3413
01:06:53,340 --> 01:06:55,440
would be hard to predict ahead of time
well you can predict ahead of time is

3414
01:06:55,440 --> 01:06:55,450
well you can predict ahead of time is
 

3415
01:06:55,450 --> 01:06:57,690
well you can predict ahead of time is
that almost anything you can do with

3416
01:06:57,690 --> 01:06:57,700
that almost anything you can do with
 

3417
01:06:57,700 --> 01:06:59,160
that almost anything you can do with
machine learning you would like to make

3418
01:06:59,160 --> 01:06:59,170
machine learning you would like to make
 

3419
01:06:59,170 --> 01:07:02,370
machine learning you would like to make
sure that people can't get it to do what

3420
01:07:02,370 --> 01:07:02,380
sure that people can't get it to do what
 

3421
01:07:02,380 --> 01:07:04,830
sure that people can't get it to do what
they want rather than what you want just

3422
01:07:04,830 --> 01:07:04,840
they want rather than what you want just
 

3423
01:07:04,840 --> 01:07:06,809
they want rather than what you want just
by showing it a funny QR code or

3424
01:07:06,809 --> 01:07:06,819
by showing it a funny QR code or
 

3425
01:07:06,819 --> 01:07:09,059
by showing it a funny QR code or
a funny input pattern and you think that

3426
01:07:09,059 --> 01:07:09,069
a funny input pattern and you think that
 

3427
01:07:09,069 --> 01:07:11,279
a funny input pattern and you think that
the set of methodology to do that can be

3428
01:07:11,279 --> 01:07:11,289
the set of methodology to do that can be
 

3429
01:07:11,289 --> 01:07:13,259
the set of methodology to do that can be
bigger than you want domain and that's I

3430
01:07:13,259 --> 01:07:13,269
bigger than you want domain and that's I
 

3431
01:07:13,269 --> 01:07:16,650
bigger than you want domain and that's I
think so yeah yeah like one methodology

3432
01:07:16,650 --> 01:07:16,660
think so yeah yeah like one methodology
 

3433
01:07:16,660 --> 01:07:20,130
think so yeah yeah like one methodology
that I think is not not a specific

3434
01:07:20,130 --> 01:07:20,140
that I think is not not a specific
 

3435
01:07:20,140 --> 01:07:21,719
that I think is not not a specific
methodology but like a category of

3436
01:07:21,719 --> 01:07:21,729
methodology but like a category of
 

3437
01:07:21,729 --> 01:07:23,669
methodology but like a category of
solutions that I'm excited about today

3438
01:07:23,669 --> 01:07:23,679
solutions that I'm excited about today
 

3439
01:07:23,679 --> 01:07:26,309
solutions that I'm excited about today
is making dynamic models that change

3440
01:07:26,309 --> 01:07:26,319
is making dynamic models that change
 

3441
01:07:26,319 --> 01:07:28,349
is making dynamic models that change
every time they make a prediction so

3442
01:07:28,349 --> 01:07:28,359
every time they make a prediction so
 

3443
01:07:28,359 --> 01:07:31,199
every time they make a prediction so
right now we tend to train models and

3444
01:07:31,199 --> 01:07:31,209
right now we tend to train models and
 

3445
01:07:31,209 --> 01:07:32,489
right now we tend to train models and
then after they're trained we freeze

3446
01:07:32,489 --> 01:07:32,499
then after they're trained we freeze
 

3447
01:07:32,499 --> 01:07:35,309
then after they're trained we freeze
them and we just use the same rule to

3448
01:07:35,309 --> 01:07:35,319
them and we just use the same rule to
 

3449
01:07:35,319 --> 01:07:36,929
them and we just use the same rule to
classify everything that comes in from

3450
01:07:36,929 --> 01:07:36,939
classify everything that comes in from
 

3451
01:07:36,939 --> 01:07:39,239
classify everything that comes in from
then on that's really a sitting duck

3452
01:07:39,239 --> 01:07:39,249
then on that's really a sitting duck
 

3453
01:07:39,249 --> 01:07:42,029
then on that's really a sitting duck
from a security point of view if you

3454
01:07:42,029 --> 01:07:42,039
from a security point of view if you
 

3455
01:07:42,039 --> 01:07:43,589
from a security point of view if you
always output the same answer for the

3456
01:07:43,589 --> 01:07:43,599
always output the same answer for the
 

3457
01:07:43,599 --> 01:07:47,640
always output the same answer for the
same input then people can just run

3458
01:07:47,640 --> 01:07:47,650
same input then people can just run
 

3459
01:07:47,650 --> 01:07:49,109
same input then people can just run
inputs through until they find a mistake

3460
01:07:49,109 --> 01:07:49,119
inputs through until they find a mistake
 

3461
01:07:49,119 --> 01:07:50,880
inputs through until they find a mistake
that benefits them and then they use the

3462
01:07:50,880 --> 01:07:50,890
that benefits them and then they use the
 

3463
01:07:50,890 --> 01:07:52,319
that benefits them and then they use the
same mistake over and over and over

3464
01:07:52,319 --> 01:07:52,329
same mistake over and over and over
 

3465
01:07:52,329 --> 01:07:55,049
same mistake over and over and over
again I think having a model that

3466
01:07:55,049 --> 01:07:55,059
again I think having a model that
 

3467
01:07:55,059 --> 01:07:57,390
again I think having a model that
updates its predictions so that it's

3468
01:07:57,390 --> 01:07:57,400
updates its predictions so that it's
 

3469
01:07:57,400 --> 01:08:00,029
updates its predictions so that it's
harder to predict what you're going to

3470
01:08:00,029 --> 01:08:00,039
harder to predict what you're going to
 

3471
01:08:00,039 --> 01:08:02,279
harder to predict what you're going to
get will make it harder for the for an

3472
01:08:02,279 --> 01:08:02,289
get will make it harder for the for an
 

3473
01:08:02,289 --> 01:08:04,439
get will make it harder for the for an
adversary to really take control of the

3474
01:08:04,439 --> 01:08:04,449
adversary to really take control of the
 

3475
01:08:04,449 --> 01:08:05,699
adversary to really take control of the
system and make it do what they want it

3476
01:08:05,699 --> 01:08:05,709
system and make it do what they want it
 

3477
01:08:05,709 --> 01:08:08,519
system and make it do what they want it
to do yeah models that maintain a bit of

3478
01:08:08,519 --> 01:08:08,529
to do yeah models that maintain a bit of
 

3479
01:08:08,529 --> 01:08:10,229
to do yeah models that maintain a bit of
a sense of mystery and bought them

3480
01:08:10,229 --> 01:08:10,239
a sense of mystery and bought them
 

3481
01:08:10,239 --> 01:08:12,599
a sense of mystery and bought them
because they always keep changing yeah

3482
01:08:12,599 --> 01:08:12,609
because they always keep changing yeah
 

3483
01:08:12,609 --> 01:08:14,339
because they always keep changing yeah
and thanks so much for talking today it

3484
01:08:14,339 --> 01:08:14,349
and thanks so much for talking today it
 

3485
01:08:14,349 --> 01:08:15,630
and thanks so much for talking today it
was awesome thank you for coming in

3486
01:08:15,630 --> 01:08:15,640
was awesome thank you for coming in
 

3487
01:08:15,640 --> 01:08:23,999
was awesome thank you for coming in
that's great to see you

3488
01:08:23,999 --> 01:08:24,009

 

3489
01:08:24,009 --> 01:08:26,069

you


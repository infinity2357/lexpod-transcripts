1
00:00:00,000 --> 00:00:02,000

چه تفاوتی بین

2
00:00:02,000 --> 00:00:02,010
چه تفاوتی بین
 

3
00:00:02,010 --> 00:00:03,649
چه تفاوتی بین
شبکه‌های عصبی بیولوژیکی و شبکه‌های عصبی مصنوعی

4
00:00:03,649 --> 00:00:03,659
شبکه‌های عصبی بیولوژیکی و شبکه‌های عصبی مصنوعی
 

5
00:00:03,659 --> 00:00:06,889
شبکه‌های عصبی بیولوژیکی و شبکه‌های عصبی مصنوعی
مرموزترین

6
00:00:06,889 --> 00:00:06,899
مرموزترین
 

7
00:00:06,899 --> 00:00:11,860
مرموزترین
و عمیق‌ترین است. اول از همه

8
00:00:11,860 --> 00:00:11,870
و عمیق‌ترین است. اول از همه
 

9
00:00:11,870 --> 00:00:13,910
و عمیق‌ترین است. اول از همه
چیزهای زیادی در مورد

10
00:00:13,910 --> 00:00:13,920
چیزهای زیادی در مورد
 

11
00:00:13,920 --> 00:00:15,740
چیزهای زیادی در مورد
شبکه‌های عصبی بیولوژیکی نمی‌دانیم و

12
00:00:15,740 --> 00:00:15,750
شبکه‌های عصبی بیولوژیکی نمی‌دانیم و
 

13
00:00:15,750 --> 00:00:18,099
شبکه‌های عصبی بیولوژیکی نمی‌دانیم و
بسیار اسرارآمیز و فریبنده است زیرا

14
00:00:18,099 --> 00:00:18,109
بسیار اسرارآمیز و فریبنده است زیرا
 

15
00:00:18,109 --> 00:00:22,070
بسیار اسرارآمیز و فریبنده است زیرا
شاید کلید بهبود

16
00:00:22,070 --> 00:00:22,080
شاید کلید بهبود
 

17
00:00:22,080 --> 00:00:24,650
شاید کلید بهبود
عصبی دیفرانسیل ما باشد.  شبکه‌ها یکی از

18
00:00:24,650 --> 00:00:24,660
عصبی دیفرانسیل ما باشد.  شبکه‌ها یکی از
 

19
00:00:24,660 --> 00:00:29,990
عصبی دیفرانسیل ما باشد.  شبکه‌ها یکی از
چیزهایی که اخیراً مطالعه کردم، چیزی که

20
00:00:29,990 --> 00:00:30,000
چیزهایی که اخیراً مطالعه کردم، چیزی که
 

21
00:00:30,000 --> 00:00:32,060
چیزهایی که اخیراً مطالعه کردم، چیزی که
نمی‌دانیم شبکه‌های عصبی بیولوژیکی چگونه

22
00:00:32,060 --> 00:00:32,070
نمی‌دانیم شبکه‌های عصبی بیولوژیکی چگونه
 

23
00:00:32,070 --> 00:00:34,880
نمی‌دانیم شبکه‌های عصبی بیولوژیکی چگونه
انجام می‌دهند، اما

24
00:00:34,880 --> 00:00:34,890
انجام می‌دهند، اما
 

25
00:00:34,890 --> 00:00:39,080
انجام می‌دهند، اما
برای شبکه‌های مصنوعی واقعاً مفید است، توانایی انجام

26
00:00:39,080 --> 00:00:39,090
برای شبکه‌های مصنوعی واقعاً مفید است، توانایی انجام
 

27
00:00:39,090 --> 00:00:42,950
برای شبکه‌های مصنوعی واقعاً مفید است، توانایی انجام
تخصیص اعتبار در بازه‌های زمانی بسیار طولانی است.

28
00:00:42,950 --> 00:00:47,389
تخصیص اعتبار در بازه‌های زمانی بسیار طولانی است.
 

29
00:00:47,389 --> 00:00:47,399

 

30
00:00:47,399 --> 00:00:49,100

شبکه های عصبی مصنوعی

31
00:00:49,100 --> 00:00:49,110
شبکه های عصبی مصنوعی
 

32
00:00:49,110 --> 00:00:50,540
شبکه های عصبی مصنوعی
اما خیلی راحت نیست و از نظر

33
00:00:50,540 --> 00:00:50,550
اما خیلی راحت نیست و از نظر
 

34
00:00:50,550 --> 00:00:53,029
اما خیلی راحت نیست و از نظر
بیولوژیکی قابل قبول نیست و این

35
00:00:53,029 --> 00:00:53,039
بیولوژیکی قابل قبول نیست و این
 

36
00:00:53,039 --> 00:00:56,410
بیولوژیکی قابل قبول نیست و این
عدم تطابق به نظر من ممکن است این نوع عدم تطابق

37
00:00:56,410 --> 00:00:56,420
عدم تطابق به نظر من ممکن است این نوع عدم تطابق
 

38
00:00:56,420 --> 00:01:01,069
عدم تطابق به نظر من ممکن است این نوع عدم تطابق
چیز جالبی برای مطالعه برای

39
00:01:01,069 --> 00:01:01,079
چیز جالبی برای مطالعه برای
 

40
00:01:01,079 --> 00:01:03,380
چیز جالبی برای مطالعه برای
درک بهتر مغزها باشد که چگونه ممکن است

41
00:01:03,380 --> 00:01:03,390
درک بهتر مغزها باشد که چگونه ممکن است
 

42
00:01:03,390 --> 00:01:05,109
درک بهتر مغزها باشد که چگونه ممکن است
این کارها را انجام دهند زیرا ما

43
00:01:05,109 --> 00:01:05,119
این کارها را انجام دهند زیرا ما
 

44
00:01:05,119 --> 00:01:07,730
این کارها را انجام دهند زیرا ما
تئوری های متناظر خوبی با مصنوعی نداریم.

45
00:01:07,730 --> 00:01:07,740
تئوری های متناظر خوبی با مصنوعی نداریم.
 

46
00:01:07,740 --> 00:01:11,750
تئوری های متناظر خوبی با مصنوعی نداریم.
شبکه های عصبی و B ممکن است ایده های جدیدی ارائه دهند

47
00:01:11,750 --> 00:01:11,760
شبکه های عصبی و B ممکن است ایده های جدیدی ارائه دهند
 

48
00:01:11,760 --> 00:01:17,060
شبکه های عصبی و B ممکن است ایده های جدیدی ارائه دهند
که می توانیم در مورد چیزهایی

49
00:01:17,060 --> 00:01:17,070
که می توانیم در مورد چیزهایی
 

50
00:01:17,070 --> 00:01:19,340
که می توانیم در مورد چیزهایی
که مغز به طور متفاوت انجام می دهد و می

51
00:01:19,340 --> 00:01:19,350
که مغز به طور متفاوت انجام می دهد و می
 

52
00:01:19,350 --> 00:01:21,770
که مغز به طور متفاوت انجام می دهد و می
توانیم در

53
00:01:21,770 --> 00:01:21,780
توانیم در
 

54
00:01:21,780 --> 00:01:24,020
توانیم در
شبکه های عصبی مصنوعی بگنجانیم آنها را کشف کنیم، بنابراین بیایید تکلیف ایجاد شده را

55
00:01:24,020 --> 00:01:24,030
شبکه های عصبی مصنوعی بگنجانیم آنها را کشف کنیم، بنابراین بیایید تکلیف ایجاد شده را
 

56
00:01:24,030 --> 00:01:26,270
شبکه های عصبی مصنوعی بگنجانیم آنها را کشف کنیم، بنابراین بیایید تکلیف ایجاد شده را
کمی بیشتر کنیم، بله، چه

57
00:01:26,270 --> 00:01:26,280
کمی بیشتر کنیم، بله، چه
 

58
00:01:26,280 --> 00:01:28,219
کمی بیشتر کنیم، بله، چه
اصطلاح فنی زیبایی است، اما می تواند

59
00:01:28,219 --> 00:01:28,229
اصطلاح فنی زیبایی است، اما می تواند
 

60
00:01:28,229 --> 00:01:31,490
اصطلاح فنی زیبایی است، اما می تواند
چیزهای زیادی را در بر بگیرد.  بنابراین بیشتر

61
00:01:31,490 --> 00:01:31,500
چیزهای زیادی را در بر بگیرد.  بنابراین بیشتر
 

62
00:01:31,500 --> 00:01:36,200
چیزهای زیادی را در بر بگیرد.  بنابراین بیشتر
در حافظه RNN است که فکر کردن

63
00:01:36,200 --> 00:01:36,210
در حافظه RNN است که فکر کردن
 

64
00:01:36,210 --> 00:01:37,700
در حافظه RNN است که فکر کردن
به این صورت است یا چیزی در مورد

65
00:01:37,700 --> 00:01:37,710
به این صورت است یا چیزی در مورد
 

66
00:01:37,710 --> 00:01:39,410
به این صورت است یا چیزی در مورد
دانش ایجاد

67
00:01:39,410 --> 00:01:39,420
دانش ایجاد
 

68
00:01:39,420 --> 00:01:43,609
دانش ایجاد
دانش عقل سلیم در طول زمان است یا بیشتر در

69
00:01:43,609 --> 00:01:43,619
دانش عقل سلیم در طول زمان است یا بیشتر در
 

70
00:01:43,619 --> 00:01:45,830
دانش عقل سلیم در طول زمان است یا بیشتر در
مفهوم یادگیری تقویتی است که شما

71
00:01:45,830 --> 00:01:45,840
مفهوم یادگیری تقویتی است که شما
 

72
00:01:45,840 --> 00:01:47,870
مفهوم یادگیری تقویتی است که شما
در طول زمان برای یک

73
00:01:47,870 --> 00:01:47,880
در طول زمان برای یک
 

74
00:01:47,880 --> 00:01:50,030
در طول زمان برای یک
مورد خاص برای دستیابی به معینی پاداش دریافت می کنید.  از این رو

75
00:01:50,030 --> 00:01:50,040
مورد خاص برای دستیابی به معینی پاداش دریافت می کنید.  از این رو
 

76
00:01:50,040 --> 00:01:51,740
مورد خاص برای دستیابی به معینی پاداش دریافت می کنید.  از این رو
من بیشتر به

77
00:01:51,740 --> 00:01:51,750
من بیشتر به
 

78
00:01:51,750 --> 00:01:57,020
من بیشتر به
دو معنی اول فکر می کردم که به موجب آن ما

79
00:01:57,020 --> 00:01:57,030
دو معنی اول فکر می کردم که به موجب آن ما
 

80
00:01:57,030 --> 00:02:00,590
دو معنی اول فکر می کردم که به موجب آن ما
انواع خاطرات را در

81
00:02:00,590 --> 00:02:00,600
انواع خاطرات را در
 

82
00:02:00,600 --> 00:02:06,139
انواع خاطرات را در
مغز خود ذخیره می کنیم که بعداً می توانیم به آنها دسترسی پیدا کنیم

83
00:02:06,139 --> 00:02:06,149
مغز خود ذخیره می کنیم که بعداً می توانیم به آنها دسترسی پیدا کنیم
 

84
00:02:06,149 --> 00:02:11,180
مغز خود ذخیره می کنیم که بعداً می توانیم به آنها دسترسی پیدا کنیم
تا هم به ما کمک کند هم دلایل

85
00:02:11,180 --> 00:02:11,190
تا هم به ما کمک کند هم دلایل
 

86
00:02:11,190 --> 00:02:13,250
تا هم به ما کمک کند هم دلایل
چیزهایی را که اکنون مشاهده می کنیم استنباط کنیم

87
00:02:13,250 --> 00:02:13,260
چیزهایی را که اکنون مشاهده می کنیم استنباط کنیم
 

88
00:02:13,260 --> 00:02:18,619
چیزهایی را که اکنون مشاهده می کنیم استنباط کنیم
و هم اعتبار را به تصمیم گیری ها اختصاص دهیم.  یا

89
00:02:18,619 --> 00:02:18,629
و هم اعتبار را به تصمیم گیری ها اختصاص دهیم.  یا
 

90
00:02:18,629 --> 00:02:21,350
و هم اعتبار را به تصمیم گیری ها اختصاص دهیم.  یا
تعابیری که مدتی پیش به آنها رسیدیم،

91
00:02:21,350 --> 00:02:21,360
تعابیری که مدتی پیش به آنها رسیدیم،
 

92
00:02:21,360 --> 00:02:23,240
تعابیری که مدتی پیش به آنها رسیدیم،
زمانی که می‌دانستید آن خاطرات

93
00:02:23,240 --> 00:02:23,250
زمانی که می‌دانستید آن خاطرات
 

94
00:02:23,250 --> 00:02:26,809
زمانی که می‌دانستید آن خاطرات
ذخیره شده‌اند و سپس می‌توانیم نحوه

95
00:02:26,809 --> 00:02:26,819
ذخیره شده‌اند و سپس می‌توانیم نحوه
 

96
00:02:26,819 --> 00:02:30,650
ذخیره شده‌اند و سپس می‌توانیم نحوه
واکنش یا تفسیر چیزها را

97
00:02:30,650 --> 00:02:30,660
واکنش یا تفسیر چیزها را
 

98
00:02:30,660 --> 00:02:32,720
واکنش یا تفسیر چیزها را
در گذشته تغییر دهیم و اکنون این

99
00:02:32,720 --> 00:02:32,730
در گذشته تغییر دهیم و اکنون این
 

100
00:02:32,730 --> 00:02:37,640
در گذشته تغییر دهیم و اکنون این
تخصیص اعتباری است که برای یادگیری استفاده می‌شود، بنابراین فکر می‌کنید به چه

101
00:02:37,640 --> 00:02:37,650
تخصیص اعتباری است که برای یادگیری استفاده می‌شود، بنابراین فکر می‌کنید به چه
 

102
00:02:37,650 --> 00:02:40,220
تخصیص اعتباری است که برای یادگیری استفاده می‌شود، بنابراین فکر می‌کنید به چه
روشی عصبی مصنوعی

103
00:02:40,220 --> 00:02:40,230
روشی عصبی مصنوعی
 

104
00:02:40,230 --> 00:02:45,080
روشی عصبی مصنوعی
شبکه‌های LS TM کنونی،

105
00:02:45,080 --> 00:02:45,090
شبکه‌های LS TM کنونی،
 

106
00:02:45,090 --> 00:02:48,039
شبکه‌های LS TM کنونی،
معماری‌های کنونی قادر به گرفتن

107
00:02:48,039 --> 00:02:48,049
معماری‌های کنونی قادر به گرفتن
 

108
00:02:48,049 --> 00:02:52,250
معماری‌های کنونی قادر به گرفتن
آن چیزی نیستند که احتمالاً شما به آن فکر می‌کنید،

109
00:02:52,250 --> 00:02:52,260
آن چیزی نیستند که احتمالاً شما به آن فکر می‌کنید،
 

110
00:02:52,260 --> 00:02:56,270
آن چیزی نیستند که احتمالاً شما به آن فکر می‌کنید،
بله، بنابراین شبکه‌های تکراری کنونی

111
00:02:56,270 --> 00:02:56,280
بله، بنابراین شبکه‌های تکراری کنونی
 

112
00:02:56,280 --> 00:02:58,580
بله، بنابراین شبکه‌های تکراری کنونی
برای

113
00:02:58,580 --> 00:02:58,590
برای
 

114
00:02:58,590 --> 00:03:01,970
برای
دنباله‌هایی با ده‌ها یا صدها

115
00:03:01,970 --> 00:03:01,980
دنباله‌هایی با ده‌ها یا صدها
 

116
00:03:01,980 --> 00:03:05,569
دنباله‌هایی با ده‌ها یا صدها
مهر زمان کار نسبتاً خوبی انجام می‌دهند و سپس کار سخت‌تر می‌شود.

117
00:03:05,569 --> 00:03:05,579
مهر زمان کار نسبتاً خوبی انجام می‌دهند و سپس کار سخت‌تر می‌شود.
 

118
00:03:05,579 --> 00:03:07,550
مهر زمان کار نسبتاً خوبی انجام می‌دهند و سپس کار سخت‌تر می‌شود.
سخت تر و بسته به آنچه که باید به

119
00:03:07,550 --> 00:03:07,560
سخت تر و بسته به آنچه که باید به
 

120
00:03:07,560 --> 00:03:08,839
سخت تر و بسته به آنچه که باید به
خاطر بسپارید و غیره با در نظر گرفتن

121
00:03:08,839 --> 00:03:08,849
خاطر بسپارید و غیره با در نظر گرفتن
 

122
00:03:08,849 --> 00:03:13,400
خاطر بسپارید و غیره با در نظر گرفتن
مدت زمان طولانی تر، در حالی که به نظر می رسد انسان ها می

123
00:03:13,400 --> 00:03:13,410
مدت زمان طولانی تر، در حالی که به نظر می رسد انسان ها می
 

124
00:03:13,410 --> 00:03:16,160
مدت زمان طولانی تر، در حالی که به نظر می رسد انسان ها می
توانند در

125
00:03:16,160 --> 00:03:16,170
توانند در
 

126
00:03:16,170 --> 00:03:18,349
توانند در
زمان های اساساً خودسرانه تخصیص اعتبار را انجام دهند مانند من می توانم

127
00:03:18,349 --> 00:03:18,359
زمان های اساساً خودسرانه تخصیص اعتبار را انجام دهند مانند من می توانم
 

128
00:03:18,359 --> 00:03:19,970
زمان های اساساً خودسرانه تخصیص اعتبار را انجام دهند مانند من می توانم
کاری را که سال گذشته انجام دادم و

129
00:03:19,970 --> 00:03:19,980
کاری را که سال گذشته انجام دادم و
 

130
00:03:19,980 --> 00:03:22,849
کاری را که سال گذشته انجام دادم و
سپس اکنون به خاطر بیاورم، زیرا شواهد جدیدی می بینم.

131
00:03:22,849 --> 00:03:22,859
سپس اکنون به خاطر بیاورم، زیرا شواهد جدیدی می بینم.
 

132
00:03:22,859 --> 00:03:25,940
سپس اکنون به خاطر بیاورم، زیرا شواهد جدیدی می بینم.
من نظرم را در مورد طرز

133
00:03:25,940 --> 00:03:25,950
من نظرم را در مورد طرز
 

134
00:03:25,950 --> 00:03:29,539
من نظرم را در مورد طرز
فکری که در سال گذشته داشتم تغییر خواهم داد و امیدوارم

135
00:03:29,539 --> 00:03:29,549
فکری که در سال گذشته داشتم تغییر خواهم داد و امیدوارم
 

136
00:03:29,549 --> 00:03:33,589
فکری که در سال گذشته داشتم تغییر خواهم داد و امیدوارم
دوباره همان اشتباه را تکرار نکنم، فکر می کنم

137
00:03:33,589 --> 00:03:33,599
دوباره همان اشتباه را تکرار نکنم، فکر می کنم
 

138
00:03:33,599 --> 00:03:35,229
دوباره همان اشتباه را تکرار نکنم، فکر می کنم
بخش بزرگی از آن احتمالا فراموش کردن است که

139
00:03:35,229 --> 00:03:35,239
بخش بزرگی از آن احتمالا فراموش کردن است که
 

140
00:03:35,239 --> 00:03:37,879
بخش بزرگی از آن احتمالا فراموش کردن است که
شما فقط چیزهای واقعا مهم را به خاطر می آورید

141
00:03:37,879 --> 00:03:39,979
شما فقط چیزهای واقعا مهم را به خاطر می آورید
 

142
00:03:39,979 --> 00:03:39,989

 

143
00:03:39,989 --> 00:03:43,849

فراموش کردن بسیار کارآمد است بله بنابراین یک انتخاب وجود دارد  از

144
00:03:43,849 --> 00:03:43,859
فراموش کردن بسیار کارآمد است بله بنابراین یک انتخاب وجود دارد  از
 

145
00:03:43,859 --> 00:03:46,580
فراموش کردن بسیار کارآمد است بله بنابراین یک انتخاب وجود دارد  از
آنچه به یاد می آوریم و من فکر می کنم در

146
00:03:46,580 --> 00:03:48,620
آنچه به یاد می آوریم و من فکر می کنم در
 

147
00:03:48,620 --> 00:03:48,630

 

148
00:03:48,630 --> 00:03:52,180

اینجا ارتباط بسیار جالبی با شناخت سطح بالاتر در رابطه با

149
00:03:52,180 --> 00:03:52,190
اینجا ارتباط بسیار جالبی با شناخت سطح بالاتر در رابطه با
 

150
00:03:52,190 --> 00:03:54,680
اینجا ارتباط بسیار جالبی با شناخت سطح بالاتر در رابطه با
تصمیم گیری هشیاری و و احساساتی مانند

151
00:03:54,680 --> 00:03:54,690
تصمیم گیری هشیاری و و احساساتی مانند
 

152
00:03:54,690 --> 00:03:56,629
تصمیم گیری هشیاری و و احساساتی مانند
تصمیم گیری در مورد اینکه چه چیزی به آگاهی می آید و چه

153
00:03:56,629 --> 00:03:56,639
تصمیم گیری در مورد اینکه چه چیزی به آگاهی می آید و چه
 

154
00:03:56,639 --> 00:04:00,110
تصمیم گیری در مورد اینکه چه چیزی به آگاهی می آید و چه
چیزی در حافظه ذخیره می شود وجود دارد که

155
00:04:00,110 --> 00:04:00,120
چیزی در حافظه ذخیره می شود وجود دارد که
 

156
00:04:00,120 --> 00:04:03,500
چیزی در حافظه ذخیره می شود وجود دارد که
بی اهمیت هم نیستند، بنابراین شما در آن بوده اید

157
00:04:03,500 --> 00:04:03,510
بی اهمیت هم نیستند، بنابراین شما در آن بوده اید
 

158
00:04:03,510 --> 00:04:07,490
بی اهمیت هم نیستند، بنابراین شما در آن بوده اید
پیشرو در تمام طول مدت نشان دادن

159
00:04:07,490 --> 00:04:07,500
پیشرو در تمام طول مدت نشان دادن
 

160
00:04:07,500 --> 00:04:09,110
پیشرو در تمام طول مدت نشان دادن
برخی از کارهای شگفت انگیزی که

161
00:04:09,110 --> 00:04:09,120
برخی از کارهای شگفت انگیزی که
 

162
00:04:09,120 --> 00:04:12,050
برخی از کارهای شگفت انگیزی که
شبکه های عصبی شبکه های عصبی عمیق می توانند در

163
00:04:12,050 --> 00:04:12,060
شبکه های عصبی شبکه های عصبی عمیق می توانند در
 

164
00:04:12,060 --> 00:04:13,640
شبکه های عصبی شبکه های عصبی عمیق می توانند در
زمینه هوش مصنوعی انجام دهند به طور

165
00:04:13,640 --> 00:04:13,650
زمینه هوش مصنوعی انجام دهند به طور
 

166
00:04:13,650 --> 00:04:15,289
زمینه هوش مصنوعی انجام دهند به طور
گسترده در همه انواع

167
00:04:15,289 --> 00:04:15,299
گسترده در همه انواع
 

168
00:04:15,299 --> 00:04:18,589
گسترده در همه انواع
برنامه ها است، اما ما می توانیم برای همیشه در مورد آن صحبت کنیم،

169
00:04:18,589 --> 00:04:18,599
برنامه ها است، اما ما می توانیم برای همیشه در مورد آن صحبت کنیم،
 

170
00:04:18,599 --> 00:04:22,069
برنامه ها است، اما ما می توانیم برای همیشه در مورد آن صحبت کنیم،
اما از نظر شما چه چیزی است زیرا

171
00:04:22,069 --> 00:04:22,079
اما از نظر شما چه چیزی است زیرا
 

172
00:04:22,079 --> 00:04:24,320
اما از نظر شما چه چیزی است زیرا
ما در حال فکر کردن هستیم.  نسبت به آینده

173
00:04:24,320 --> 00:04:24,330
ما در حال فکر کردن هستیم.  نسبت به آینده
 

174
00:04:24,330 --> 00:04:26,360
ما در حال فکر کردن هستیم.  نسبت به آینده
ضعیف ترین جنبه نحوه

175
00:04:26,360 --> 00:04:26,370
ضعیف ترین جنبه نحوه
 

176
00:04:26,370 --> 00:04:28,310
ضعیف ترین جنبه نحوه
نمایش شبکه های عصبی عمیق جهان است، چیزی که

177
00:04:28,310 --> 00:04:28,320
نمایش شبکه های عصبی عمیق جهان است، چیزی که
 

178
00:04:28,320 --> 00:04:32,360
نمایش شبکه های عصبی عمیق جهان است، چیزی که
از نظر شما گم شده است، بنابراین

179
00:04:32,360 --> 00:04:34,870
از نظر شما گم شده است، بنابراین
 

180
00:04:34,870 --> 00:04:34,880

 

181
00:04:34,880 --> 00:04:39,529

شبکه های عصبی پیشرفته فعلی آموزش داده شده بر روی مقادیر زیادی

182
00:04:39,529 --> 00:04:39,539
شبکه های عصبی پیشرفته فعلی آموزش داده شده بر روی مقادیر زیادی
 

183
00:04:39,539 --> 00:04:44,930
شبکه های عصبی پیشرفته فعلی آموزش داده شده بر روی مقادیر زیادی
از تصاویر یا متون دارای سطحی از

184
00:04:44,930 --> 00:04:44,940
از تصاویر یا متون دارای سطحی از
 

185
00:04:44,940 --> 00:04:47,570
از تصاویر یا متون دارای سطحی از
درک شما می‌دانید که چه چیزی

186
00:04:47,570 --> 00:04:47,580
درک شما می‌دانید که چه چیزی
 

187
00:04:47,580 --> 00:04:51,950
درک شما می‌دانید که چه چیزی
این مجموعه داده‌ها را توضیح می‌دهد، اما بسیار اساسی است، زیرا

188
00:04:51,950 --> 00:04:51,960
این مجموعه داده‌ها را توضیح می‌دهد، اما بسیار اساسی است، زیرا
 

189
00:04:51,960 --> 00:04:56,270
این مجموعه داده‌ها را توضیح می‌دهد، اما بسیار اساسی است، زیرا
سطح بسیار پایینی است و

190
00:04:56,270 --> 00:04:56,280
سطح بسیار پایینی است و
 

191
00:04:56,280 --> 00:05:00,520
سطح بسیار پایینی است و
به طور کلی به اندازه درک ما قوی و انتزاعی نیست،

192
00:05:00,520 --> 00:05:00,530
به طور کلی به اندازه درک ما قوی و انتزاعی نیست،
 

193
00:05:00,530 --> 00:05:04,070
به طور کلی به اندازه درک ما قوی و انتزاعی نیست،
بنابراین به

194
00:05:04,070 --> 00:05:04,080
بنابراین به
 

195
00:05:04,080 --> 00:05:07,010
بنابراین به
ما نمی‌گوید چگونه چیزها را اصلاح کنیم، اما فکر می‌کنم

196
00:05:07,010 --> 00:05:07,020
ما نمی‌گوید چگونه چیزها را اصلاح کنیم، اما فکر می‌کنم
 

197
00:05:07,020 --> 00:05:12,129
ما نمی‌گوید چگونه چیزها را اصلاح کنیم، اما فکر می‌کنم
ما را تشویق می‌کند که  به این فکر کنید که چگونه می‌توانیم

198
00:05:12,129 --> 00:05:12,139
ما را تشویق می‌کند که  به این فکر کنید که چگونه می‌توانیم
 

199
00:05:12,139 --> 00:05:15,760
ما را تشویق می‌کند که  به این فکر کنید که چگونه می‌توانیم
شبکه‌های عصبی خود را به گونه‌ای متفاوت آموزش دهیم

200
00:05:15,760 --> 00:05:15,770
شبکه‌های عصبی خود را به گونه‌ای متفاوت آموزش دهیم
 

201
00:05:15,770 --> 00:05:21,140
شبکه‌های عصبی خود را به گونه‌ای متفاوت آموزش دهیم
تا آنها به عنوان مثال بر روی

202
00:05:21,140 --> 00:05:21,150
تا آنها به عنوان مثال بر روی
 

203
00:05:21,150 --> 00:05:23,719
تا آنها به عنوان مثال بر روی
توضیحات علّی تمرکز کنند، چیزی که ما

204
00:05:23,719 --> 00:05:23,729
توضیحات علّی تمرکز کنند، چیزی که ما
 

205
00:05:23,729 --> 00:05:26,149
توضیحات علّی تمرکز کنند، چیزی که ما
در حال حاضر با آموزش شبکه عصبی انجام نمی‌دهیم،

206
00:05:26,149 --> 00:05:26,159
در حال حاضر با آموزش شبکه عصبی انجام نمی‌دهیم،
 

207
00:05:26,159 --> 00:05:30,860
در حال حاضر با آموزش شبکه عصبی انجام نمی‌دهیم،
همچنین یکی از چیزهایی که

208
00:05:30,860 --> 00:05:30,870
همچنین یکی از چیزهایی که
 

209
00:05:30,870 --> 00:05:35,000
همچنین یکی از چیزهایی که
امروز بعدازظهر در سخنرانی‌ام درباره آن صحبت خواهم کرد، به جای

210
00:05:35,000 --> 00:05:35,010
امروز بعدازظهر در سخنرانی‌ام درباره آن صحبت خواهم کرد، به جای
 

211
00:05:35,010 --> 00:05:38,120
امروز بعدازظهر در سخنرانی‌ام درباره آن صحبت خواهم کرد، به جای
یادگیری است.  جدا از تصاویر و

212
00:05:38,120 --> 00:05:38,130
یادگیری است.  جدا از تصاویر و
 

213
00:05:38,130 --> 00:05:40,370
یادگیری است.  جدا از تصاویر و
ویدیوها از یک طرف و از متن از

214
00:05:40,370 --> 00:05:40,380
ویدیوها از یک طرف و از متن از
 

215
00:05:40,380 --> 00:05:44,830
ویدیوها از یک طرف و از متن از
طرف دیگر، ما باید کار بهتری را برای

216
00:05:44,830 --> 00:05:44,840
طرف دیگر، ما باید کار بهتری را برای
 

217
00:05:44,840 --> 00:05:47,330
طرف دیگر، ما باید کار بهتری را برای
یادگیری مشترک زبان و

218
00:05:47,330 --> 00:05:47,340
یادگیری مشترک زبان و
 

219
00:05:47,340 --> 00:05:51,879
یادگیری مشترک زبان و
دنیایی که به آن اشاره دارد انجام دهیم

220
00:05:51,879 --> 00:05:51,889
دنیایی که به آن اشاره دارد انجام دهیم
 

221
00:05:51,889 --> 00:05:54,680
دنیایی که به آن اشاره دارد انجام دهیم
تا بدانید هر دو طرف می توانند به یکدیگر کمک کنند.

222
00:05:54,680 --> 00:05:54,690
تا بدانید هر دو طرف می توانند به یکدیگر کمک کنند.
 

223
00:05:54,690 --> 00:05:57,560
تا بدانید هر دو طرف می توانند به یکدیگر کمک کنند.
مدل‌های جهان

224
00:05:57,560 --> 00:05:57,570
مدل‌های جهان
 

225
00:05:57,570 --> 00:06:01,339
مدل‌های جهان
در شبکه‌های عصبی ما برای آن‌ها برای

226
00:06:01,339 --> 00:06:01,349
در شبکه‌های عصبی ما برای آن‌ها برای
 

227
00:06:01,349 --> 00:06:04,010
در شبکه‌های عصبی ما برای آن‌ها برای
درک واقعی جملاتی که در مورد

228
00:06:04,010 --> 00:06:04,020
درک واقعی جملاتی که در مورد
 

229
00:06:04,020 --> 00:06:06,320
درک واقعی جملاتی که در مورد
آنچه در جهان می‌گذرد صحبت می‌کنند و من فکر می‌کنم

230
00:06:06,320 --> 00:06:06,330
آنچه در جهان می‌گذرد صحبت می‌کنند و من فکر می‌کنم
 

231
00:06:06,330 --> 00:06:11,959
آنچه در جهان می‌گذرد صحبت می‌کنند و من فکر می‌کنم
ما به ورودی زبانی برای کمک به ارائه

232
00:06:11,959 --> 00:06:11,969
ما به ورودی زبانی برای کمک به ارائه
 

233
00:06:11,969 --> 00:06:14,959
ما به ورودی زبانی برای کمک به ارائه
سرنخ‌هایی در مورد اینکه چه مفاهیم سطح بالا

234
00:06:14,959 --> 00:06:14,969
سرنخ‌هایی در مورد اینکه چه مفاهیم سطح بالا
 

235
00:06:14,969 --> 00:06:17,750
سرنخ‌هایی در مورد اینکه چه مفاهیم سطح بالا
مانند مفاهیم معنایی باید

236
00:06:17,750 --> 00:06:17,760
مانند مفاهیم معنایی باید
 

237
00:06:17,760 --> 00:06:20,330
مانند مفاهیم معنایی باید
در سطوح بالای این موارد نمایش داده شوند نیاز داریم.

238
00:06:20,330 --> 00:06:20,340
در سطوح بالای این موارد نمایش داده شوند نیاز داریم.
 

239
00:06:20,340 --> 00:06:23,480
در سطوح بالای این موارد نمایش داده شوند نیاز داریم.
شبکه‌های عصبی در واقع شواهدی وجود دارد

240
00:06:23,480 --> 00:06:23,490
شبکه‌های عصبی در واقع شواهدی وجود دارد
 

241
00:06:23,490 --> 00:06:27,980
شبکه‌های عصبی در واقع شواهدی وجود دارد
که نشان می‌دهد یادگیری صرفاً بدون نظارت

242
00:06:27,980 --> 00:06:27,990
که نشان می‌دهد یادگیری صرفاً بدون نظارت
 

243
00:06:27,990 --> 00:06:30,250
که نشان می‌دهد یادگیری صرفاً بدون نظارت
بازنمایی‌ها منجر به

244
00:06:30,250 --> 00:06:30,260
بازنمایی‌ها منجر به
 

245
00:06:30,260 --> 00:06:33,709
بازنمایی‌ها منجر به
بازنمایی‌های سطح بالایی نمی‌شود که به

246
00:06:33,709 --> 00:06:33,719
بازنمایی‌های سطح بالایی نمی‌شود که به
 

247
00:06:33,719 --> 00:06:36,139
بازنمایی‌های سطح بالایی نمی‌شود که به
اندازه آنهایی که از

248
00:06:36,139 --> 00:06:36,149
اندازه آنهایی که از
 

249
00:06:36,149 --> 00:06:37,640
اندازه آنهایی که از
یادگیری نظارت شده دریافت می‌کنیم قوی هستند

250
00:06:37,640 --> 00:06:37,650
یادگیری نظارت شده دریافت می‌کنیم قوی هستند
 

251
00:06:37,650 --> 00:06:40,100
یادگیری نظارت شده دریافت می‌کنیم قوی هستند
و بنابراین سرنخ‌هایی که فقط

252
00:06:40,100 --> 00:06:40,110
و بنابراین سرنخ‌هایی که فقط
 

253
00:06:40,110 --> 00:06:42,340
و بنابراین سرنخ‌هایی که فقط
با برچسب‌ها به دست می‌آوریم نیست.  حتی جملات

254
00:06:42,340 --> 00:06:42,350
با برچسب‌ها به دست می‌آوریم نیست.  حتی جملات
 

255
00:06:42,350 --> 00:06:45,230
با برچسب‌ها به دست می‌آوریم نیست.  حتی جملات
در حال حاضر بسیار قدرتمند هستند آیا فکر می کنید

256
00:06:45,230 --> 00:06:45,240
در حال حاضر بسیار قدرتمند هستند آیا فکر می کنید
 

257
00:06:45,240 --> 00:06:48,050
در حال حاضر بسیار قدرتمند هستند آیا فکر می کنید
این یک چالش معماری است یا

258
00:06:48,050 --> 00:06:48,060
این یک چالش معماری است یا
 

259
00:06:48,060 --> 00:06:54,740
این یک چالش معماری است یا
یک چالش مجموعه داده است، نه من

260
00:06:54,740 --> 00:06:54,750
یک چالش مجموعه داده است، نه من
 

261
00:06:54,750 --> 00:06:58,370
یک چالش مجموعه داده است، نه من
وسوسه می شوم که آن را در کتابخانه شما به پایان برسانم، البته

262
00:06:58,370 --> 00:06:58,380
وسوسه می شوم که آن را در کتابخانه شما به پایان برسانم، البته
 

263
00:06:58,380 --> 00:07:03,950
وسوسه می شوم که آن را در کتابخانه شما به پایان برسانم، البته
مجموعه داده ها و

264
00:07:03,950 --> 00:07:03,960
مجموعه داده ها و
 

265
00:07:03,960 --> 00:07:05,719
مجموعه داده ها و
معماری ها چیزی هستند که می خواهید

266
00:07:05,719 --> 00:07:05,729
معماری ها چیزی هستند که می خواهید
 

267
00:07:05,729 --> 00:07:07,340
معماری ها چیزی هستند که می خواهید
همیشه با آن بازی کنید، اما من  فکر می کنم

268
00:07:07,340 --> 00:07:07,350
همیشه با آن بازی کنید، اما من  فکر می کنم
 

269
00:07:07,350 --> 00:07:09,350
همیشه با آن بازی کنید، اما من  فکر می کنم
مهم تر،

270
00:07:09,350 --> 00:07:09,360
مهم تر،
 

271
00:07:09,360 --> 00:07:12,590
مهم تر،
اهداف آموزشی چارچوب های آموزشی است، به عنوان

272
00:07:12,590 --> 00:07:12,600
اهداف آموزشی چارچوب های آموزشی است، به عنوان
 

273
00:07:12,600 --> 00:07:15,920
اهداف آموزشی چارچوب های آموزشی است، به عنوان
مثال، رفتن از مشاهده غیرفعال

274
00:07:15,920 --> 00:07:15,930
مثال، رفتن از مشاهده غیرفعال
 

275
00:07:15,930 --> 00:07:21,670
مثال، رفتن از مشاهده غیرفعال
داده ها به عوامل فعال تر که

276
00:07:21,670 --> 00:07:21,680
داده ها به عوامل فعال تر که
 

277
00:07:21,680 --> 00:07:25,159
داده ها به عوامل فعال تر که
با مداخله در جهان

278
00:07:25,159 --> 00:07:25,169
با مداخله در جهان
 

279
00:07:25,169 --> 00:07:27,730
با مداخله در جهان
روابط بین علت ها و معلول ها را یاد می گیرند،

280
00:07:27,730 --> 00:07:27,740
روابط بین علت ها و معلول ها را یاد می گیرند،
 

281
00:07:27,740 --> 00:07:31,640
روابط بین علت ها و معلول ها را یاد می گیرند،
نوع توابع هدفی که

282
00:07:31,640 --> 00:07:31,650
نوع توابع هدفی که
 

283
00:07:31,650 --> 00:07:35,629
نوع توابع هدفی که
می تواند برای اجازه دادن به

284
00:07:35,629 --> 00:07:35,639
می تواند برای اجازه دادن به
 

285
00:07:35,639 --> 00:07:38,930
می تواند برای اجازه دادن به
توضیحات بالاترین سطح به بالا رفتن از

286
00:07:38,930 --> 00:07:38,940
توضیحات بالاترین سطح به بالا رفتن از
 

287
00:07:38,940 --> 00:07:41,450
توضیحات بالاترین سطح به بالا رفتن از
یادگیری که فکر نمی‌کنم

288
00:07:41,450 --> 00:07:41,460
یادگیری که فکر نمی‌کنم
 

289
00:07:41,460 --> 00:07:44,510
یادگیری که فکر نمی‌کنم
اکنون انواع توابع هدف را داریم

290
00:07:44,510 --> 00:07:44,520
اکنون انواع توابع هدف را داریم
 

291
00:07:44,520 --> 00:07:47,860
اکنون انواع توابع هدف را داریم
که می‌توان از آنها برای پاداش دادن به

292
00:07:47,860 --> 00:07:47,870
که می‌توان از آنها برای پاداش دادن به
 

293
00:07:47,870 --> 00:07:49,520
که می‌توان از آنها برای پاداش دادن به
کاوش به نوع درست

294
00:07:49,520 --> 00:07:49,530
کاوش به نوع درست
 

295
00:07:49,530 --> 00:07:51,980
کاوش به نوع درست
کاوش استفاده کرد، بنابراین این نوع سؤالات

296
00:07:51,980 --> 00:07:51,990
کاوش استفاده کرد، بنابراین این نوع سؤالات
 

297
00:07:51,990 --> 00:07:55,010
کاوش استفاده کرد، بنابراین این نوع سؤالات
نه در مجموعه داده‌ها هستند و نه در مجموعه داده‌ها.

298
00:07:55,010 --> 00:07:55,020
نه در مجموعه داده‌ها هستند و نه در مجموعه داده‌ها.
 

299
00:07:55,020 --> 00:07:57,620
نه در مجموعه داده‌ها هستند و نه در مجموعه داده‌ها.
معماری، اما بیشتر در مورد اینکه چگونه یاد می‌گیریم

300
00:07:57,620 --> 00:07:57,630
معماری، اما بیشتر در مورد اینکه چگونه یاد می‌گیریم
 

301
00:07:57,630 --> 00:08:01,730
معماری، اما بیشتر در مورد اینکه چگونه یاد می‌گیریم
تحت چه اهدافی و غیره، بله،

302
00:08:01,730 --> 00:08:01,740
تحت چه اهدافی و غیره، بله،
 

303
00:08:01,740 --> 00:08:03,950
تحت چه اهدافی و غیره، بله،
ترسی است که در چندین زمینه ذکر کردید،

304
00:08:03,950 --> 00:08:03,960
ترسی است که در چندین زمینه ذکر کردید،
 

305
00:08:03,960 --> 00:08:05,750
ترسی است که در چندین زمینه ذکر کردید،
این ایده به نوعی روشی است که

306
00:08:05,750 --> 00:08:05,760
این ایده به نوعی روشی است که
 

307
00:08:05,760 --> 00:08:07,040
این ایده به نوعی روشی است که
کودکان یاد می‌گیرند که با

308
00:08:07,040 --> 00:08:07,050
کودکان یاد می‌گیرند که با
 

309
00:08:07,050 --> 00:08:09,100
کودکان یاد می‌گیرند که با
اشیاء جهان ارتباط برقرار کنند و جذاب به نظر می‌رسد

310
00:08:09,100 --> 00:08:09,110
اشیاء جهان ارتباط برقرار کنند و جذاب به نظر می‌رسد
 

311
00:08:09,110 --> 00:08:12,080
اشیاء جهان ارتباط برقرار کنند و جذاب به نظر می‌رسد
زیرا به جز

312
00:08:12,080 --> 00:08:12,090
زیرا به جز
 

313
00:08:12,090 --> 00:08:14,719
زیرا به جز
در مواردی منطقی است.  در

314
00:08:14,719 --> 00:08:14,729
در مواردی منطقی است.  در
 

315
00:08:14,729 --> 00:08:19,129
در مواردی منطقی است.  در
یادگیری تقویتی، این ایده بخشی از

316
00:08:19,129 --> 00:08:19,139
یادگیری تقویتی، این ایده بخشی از
 

317
00:08:19,139 --> 00:08:22,610
یادگیری تقویتی، این ایده بخشی از
فرآیند یادگیری در شبکه عصبی مصنوعی نیست،

318
00:08:22,610 --> 00:08:22,620
فرآیند یادگیری در شبکه عصبی مصنوعی نیست،
 

319
00:08:22,620 --> 00:08:24,620
فرآیند یادگیری در شبکه عصبی مصنوعی نیست،
بنابراین تقریباً شبیه این است که آیا

320
00:08:24,620 --> 00:08:24,630
بنابراین تقریباً شبیه این است که آیا
 

321
00:08:24,630 --> 00:08:26,839
بنابراین تقریباً شبیه این است که آیا
چیزی شبیه یک تابع هدف را تصور می‌کنید که می‌دانید

322
00:08:26,839 --> 00:08:26,849
چیزی شبیه یک تابع هدف را تصور می‌کنید که می‌دانید
 

323
00:08:26,849 --> 00:08:31,969
چیزی شبیه یک تابع هدف را تصور می‌کنید که می‌دانید
اگر

324
00:08:31,969 --> 00:08:31,979
اگر
 

325
00:08:31,979 --> 00:08:34,279
اگر
این شی را به این شکل فشار دهید،

326
00:08:34,279 --> 00:08:34,289
این شی را به این شکل فشار دهید،
 

327
00:08:34,289 --> 00:08:36,130
این شی را به این شکل فشار دهید،
واقعاً برای من مفید خواهد بود.

328
00:08:36,130 --> 00:08:36,140
واقعاً برای من مفید خواهد بود.
 

329
00:08:36,140 --> 00:08:37,310
واقعاً برای من مفید خواهد بود.

330
00:08:37,310 --> 00:08:37,320

 

331
00:08:37,320 --> 00:08:40,279

بله، بیشتر درست یاد بگیرید،

332
00:08:40,279 --> 00:08:40,289
بله، بیشتر درست یاد بگیرید،
 

333
00:08:40,289 --> 00:08:43,130
بله، بیشتر درست یاد بگیرید،
تقریباً جنبه‌ای از یادگیری

334
00:08:43,130 --> 00:08:43,140
تقریباً جنبه‌ای از یادگیری
 

335
00:08:43,140 --> 00:08:44,750
تقریباً جنبه‌ای از یادگیری
درست را راهنمایی می‌کند، بنابراین من

336
00:08:44,750 --> 00:08:44,760
درست را راهنمایی می‌کند، بنابراین من
 

337
00:08:44,760 --> 00:08:48,230
درست را راهنمایی می‌کند، بنابراین من
فقط یک ساعت پیش با ربکا ساکس صحبت می‌کردم و او

338
00:08:48,230 --> 00:08:48,240
فقط یک ساعت پیش با ربکا ساکس صحبت می‌کردم و او
 

339
00:08:48,240 --> 00:08:50,240
فقط یک ساعت پیش با ربکا ساکس صحبت می‌کردم و او
در مورد شواهد زیادی صحبت می‌کرد که

340
00:08:50,240 --> 00:08:50,250
در مورد شواهد زیادی صحبت می‌کرد که
 

341
00:08:50,250 --> 00:08:51,880
در مورد شواهد زیادی صحبت می‌کرد که

342
00:08:51,880 --> 00:08:51,890

 

343
00:08:51,890 --> 00:08:57,730

به نظر می‌رسد نوزادان به وضوح آنچه را که به

344
00:08:57,730 --> 00:08:57,740
به نظر می‌رسد نوزادان به وضوح آنچه را که به
 

345
00:08:57,740 --> 00:09:02,090
به نظر می‌رسد نوزادان به وضوح آنچه را که به
آنها علاقه دارند، به‌طور مستقیم دریافت می‌کنند.  بنابراین

346
00:09:02,090 --> 00:09:02,100
آنها علاقه دارند، به‌طور مستقیم دریافت می‌کنند.  بنابراین
 

347
00:09:02,100 --> 00:09:05,720
آنها علاقه دارند، به‌طور مستقیم دریافت می‌کنند.  بنابراین
آنها یادگیرنده های منفعل نیستند، بلکه

348
00:09:05,720 --> 00:09:05,730
آنها یادگیرنده های منفعل نیستند، بلکه
 

349
00:09:05,730 --> 00:09:09,110
آنها یادگیرنده های منفعل نیستند، بلکه
توجه خود را بر جنبه هایی از

350
00:09:09,110 --> 00:09:09,120
توجه خود را بر جنبه هایی از
 

351
00:09:09,120 --> 00:09:11,470
توجه خود را بر جنبه هایی از
جهان متمرکز می کنند که جالب ترین آنها را

352
00:09:11,470 --> 00:09:11,480
جهان متمرکز می کنند که جالب ترین آنها را
 

353
00:09:11,480 --> 00:09:14,600
جهان متمرکز می کنند که جالب ترین آنها را
شگفت زده می کند به روشی غیر پیش پا افتاده که

354
00:09:14,600 --> 00:09:14,610
شگفت زده می کند به روشی غیر پیش پا افتاده که
 

355
00:09:14,610 --> 00:09:17,570
شگفت زده می کند به روشی غیر پیش پا افتاده که
باعث می شود نظریه های خود را در مورد

356
00:09:17,570 --> 00:09:17,580
باعث می شود نظریه های خود را در مورد
 

357
00:09:17,580 --> 00:09:23,030
باعث می شود نظریه های خود را در مورد
جهان تغییر دهند به طوری که این یک دیدگاه جذاب از

358
00:09:23,030 --> 00:09:23,040
جهان تغییر دهند به طوری که این یک دیدگاه جذاب از
 

359
00:09:23,040 --> 00:09:26,750
جهان تغییر دهند به طوری که این یک دیدگاه جذاب از
پیشرفت آینده است، اما آنا  بیشتر

360
00:09:26,750 --> 00:09:26,760
پیشرفت آینده است، اما آنا  بیشتر
 

361
00:09:26,760 --> 00:09:30,500
پیشرفت آینده است، اما آنا  بیشتر
شاید خسته کننده باشد آیا فکر می کنید

362
00:09:30,500 --> 00:09:30,510
شاید خسته کننده باشد آیا فکر می کنید
 

363
00:09:30,510 --> 00:09:33,890
شاید خسته کننده باشد آیا فکر می کنید
عمیق تر و بزرگ تر می شوید، بنابراین فکر می کنید

364
00:09:33,890 --> 00:09:33,900
عمیق تر و بزرگ تر می شوید، بنابراین فکر می کنید
 

365
00:09:33,900 --> 00:09:37,460
عمیق تر و بزرگ تر می شوید، بنابراین فکر می کنید
فقط افزایش اندازه چیزهایی

366
00:09:37,460 --> 00:09:37,470
فقط افزایش اندازه چیزهایی
 

367
00:09:37,470 --> 00:09:39,500
فقط افزایش اندازه چیزهایی
که در

368
00:09:39,500 --> 00:09:39,510
که در
 

369
00:09:39,510 --> 00:09:42,410
که در
چند سال گذشته بسیار افزایش یافته اند نیز باعث

370
00:09:42,410 --> 00:09:42,420
چند سال گذشته بسیار افزایش یافته اند نیز باعث
 

371
00:09:42,420 --> 00:09:45,070
چند سال گذشته بسیار افزایش یافته اند نیز باعث
پیشرفت قابل توجهی خواهد شد، بنابراین برخی از

372
00:09:45,070 --> 00:09:45,080
پیشرفت قابل توجهی خواهد شد، بنابراین برخی از
 

373
00:09:45,080 --> 00:09:47,450
پیشرفت قابل توجهی خواهد شد، بنابراین برخی از
مسائل بازنمایی که

374
00:09:47,450 --> 00:09:47,460
مسائل بازنمایی که
 

375
00:09:47,460 --> 00:09:49,010
مسائل بازنمایی که
اشاره کردید  آیا آنها به نوعی

376
00:09:49,010 --> 00:09:49,020
اشاره کردید  آیا آنها به نوعی
 

377
00:09:49,020 --> 00:09:53,960
اشاره کردید  آیا آنها به نوعی
سطحی هستند اوه بالاتر از یک

378
00:09:53,960 --> 00:09:53,970
سطحی هستند اوه بالاتر از یک
 

379
00:09:53,970 --> 00:09:55,550
سطحی هستند اوه بالاتر از یک
مفهوم انتزاعی مستقیم در یک

380
00:09:55,550 --> 00:09:55,560
مفهوم انتزاعی مستقیم در یک
 

381
00:09:55,560 --> 00:09:56,990
مفهوم انتزاعی مستقیم در یک
مفهوم انتزاعی، آنها برخی از آنها را دریافت نمی کنند.

382
00:09:56,990 --> 00:09:57,000
مفهوم انتزاعی، آنها برخی از آنها را دریافت نمی کنند.
 

383
00:09:57,000 --> 00:10:00,740
مفهوم انتزاعی، آنها برخی از آنها را دریافت نمی کنند.
من فکر نمی کنم که داشتن

384
00:10:00,740 --> 00:10:00,750
من فکر نمی کنم که داشتن
 

385
00:10:00,750 --> 00:10:02,300
من فکر نمی کنم که داشتن
عمق بیشتر در شبکه به معنای

386
00:10:02,300 --> 00:10:02,310
عمق بیشتر در شبکه به معنای
 

387
00:10:02,310 --> 00:10:04,160
عمق بیشتر در شبکه به معنای
به جای یک  صد لایه ما ده

388
00:10:04,160 --> 00:10:04,170
به جای یک  صد لایه ما ده
 

389
00:10:04,170 --> 00:10:06,079
به جای یک  صد لایه ما ده
هزار لایه داریم مشکل ما را حل می کند،

390
00:10:06,079 --> 00:10:06,089
هزار لایه داریم مشکل ما را حل می کند،
 

391
00:10:06,089 --> 00:10:10,100
هزار لایه داریم مشکل ما را حل می کند،
شما فکر نمی کنید برای

392
00:10:10,100 --> 00:10:10,110
شما فکر نمی کنید برای
 

393
00:10:10,110 --> 00:10:12,829
شما فکر نمی کنید برای
شما واضح است بله آنچه برای من واضح است این است که

394
00:10:12,829 --> 00:10:12,839
شما واضح است بله آنچه برای من واضح است این است که
 

395
00:10:12,839 --> 00:10:16,400
شما واضح است بله آنچه برای من واضح است این است که
مهندسان و شرکت ها و دانشجویان فارغ التحصیل آزمایشگاه ها

396
00:10:16,400 --> 00:10:16,410
مهندسان و شرکت ها و دانشجویان فارغ التحصیل آزمایشگاه ها
 

397
00:10:16,410 --> 00:10:19,660
مهندسان و شرکت ها و دانشجویان فارغ التحصیل آزمایشگاه ها
به تنظیم

398
00:10:19,660 --> 00:10:19,670
به تنظیم
 

399
00:10:19,670 --> 00:10:22,220
به تنظیم
معماری ها و کشف انواع

400
00:10:22,220 --> 00:10:22,230
معماری ها و کشف انواع
 

401
00:10:22,230 --> 00:10:24,170
معماری ها و کشف انواع
ترفندها ادامه خواهند داد.  وضعیت فعلی

402
00:10:24,170 --> 00:10:24,180
ترفندها ادامه خواهند داد.  وضعیت فعلی
 

403
00:10:24,180 --> 00:10:27,320
ترفندها ادامه خواهند داد.  وضعیت فعلی
هنر را کمی بهتر کند، اما

404
00:10:27,320 --> 00:10:27,330
هنر را کمی بهتر کند، اما
 

405
00:10:27,330 --> 00:10:29,210
هنر را کمی بهتر کند، اما
فکر نمی‌کنم این کافی باشد.

406
00:10:29,210 --> 00:10:30,710
فکر نمی‌کنم این کافی باشد.
 

407
00:10:30,710 --> 00:10:32,720

 

408
00:10:32,720 --> 00:10:37,850

 

409
00:10:37,850 --> 00:10:40,310

 

410
00:10:40,310 --> 00:10:40,320

 

411
00:10:40,320 --> 00:10:42,410

یک روش عمیق محیطی که

412
00:10:42,410 --> 00:10:42,420
یک روش عمیق محیطی که
 

413
00:10:42,420 --> 00:10:45,760
یک روش عمیق محیطی که
آنها در آن هستند مشاهده می کنید و عمل می کنند،

414
00:10:45,760 --> 00:10:45,770
آنها در آن هستند مشاهده می کنید و عمل می کنند،
 

415
00:10:45,770 --> 00:10:49,550
آنها در آن هستند مشاهده می کنید و عمل می کنند،
اما حدس می زنم که من سعی می کردم سؤالی بپرسم از

416
00:10:49,550 --> 00:10:51,050
اما حدس می زنم که من سعی می کردم سؤالی بپرسم از
 

417
00:10:51,050 --> 00:10:51,060

 

418
00:10:51,060 --> 00:10:55,160

لایه های بیشتر جالب تر است، اساساً زمانی است که

419
00:10:55,160 --> 00:10:55,170
لایه های بیشتر جالب تر است، اساساً زمانی است که
 

420
00:10:55,170 --> 00:10:58,370
لایه های بیشتر جالب تر است، اساساً زمانی است که
راهی برای یادگیری از طریق تعامل با

421
00:10:58,370 --> 00:10:58,380
راهی برای یادگیری از طریق تعامل با
 

422
00:10:58,380 --> 00:11:01,400
راهی برای یادگیری از طریق تعامل با
چند پارامتر لازم است.

423
00:11:01,400 --> 00:11:01,410
چند پارامتر لازم است.
 

424
00:11:01,410 --> 00:11:04,009
چند پارامتر لازم است.
این اطلاعات را ذخیره کنید، بنابراین

425
00:11:04,009 --> 00:11:04,019
این اطلاعات را ذخیره کنید، بنابراین
 

426
00:11:04,019 --> 00:11:06,919
این اطلاعات را ذخیره کنید، بنابراین
فکر می کنم مغز ما بسیار بزرگتر از

427
00:11:06,919 --> 00:11:06,929
فکر می کنم مغز ما بسیار بزرگتر از
 

428
00:11:06,929 --> 00:11:08,540
فکر می کنم مغز ما بسیار بزرگتر از
بسیاری از شبکه های عصبی است درست است، اوه،

429
00:11:08,540 --> 00:11:08,550
بسیاری از شبکه های عصبی است درست است، اوه،
 

430
00:11:08,550 --> 00:11:10,340
بسیاری از شبکه های عصبی است درست است، اوه،
منظور شما را متوجه شدم، اوه من با شما هستم،

431
00:11:10,340 --> 00:11:10,350
منظور شما را متوجه شدم، اوه من با شما هستم،
 

432
00:11:10,350 --> 00:11:14,540
منظور شما را متوجه شدم، اوه من با شما هستم،
بنابراین موافقم که برای ساختن

433
00:11:14,540 --> 00:11:14,550
بنابراین موافقم که برای ساختن
 

434
00:11:14,550 --> 00:11:16,729
بنابراین موافقم که برای ساختن
شبکه های عصبی با نوع

435
00:11:16,729 --> 00:11:16,739
شبکه های عصبی با نوع
 

436
00:11:16,739 --> 00:11:18,710
شبکه های عصبی با نوع
دانش گسترده از جهان  اینکه

437
00:11:18,710 --> 00:11:18,720
دانش گسترده از جهان  اینکه
 

438
00:11:18,720 --> 00:11:22,609
دانش گسترده از جهان  اینکه
انسان‌های بالغ معمولی احتمالاً

439
00:11:22,609 --> 00:11:22,619
انسان‌های بالغ معمولی احتمالاً
 

440
00:11:22,619 --> 00:11:24,259
انسان‌های بالغ معمولی احتمالاً
قدرت محاسباتی ما اکنون

441
00:11:24,259 --> 00:11:24,269
قدرت محاسباتی ما اکنون
 

442
00:11:24,269 --> 00:11:27,319
قدرت محاسباتی ما اکنون
ناکافی خواهد بود، خبر خوب این است که

443
00:11:27,319 --> 00:11:27,329
ناکافی خواهد بود، خبر خوب این است که
 

444
00:11:27,329 --> 00:11:28,999
ناکافی خواهد بود، خبر خوب این است که
شرکت‌های سخت‌افزاری وجود دارند که

445
00:11:28,999 --> 00:11:29,009
شرکت‌های سخت‌افزاری وجود دارند که
 

446
00:11:29,009 --> 00:11:30,889
شرکت‌های سخت‌افزاری وجود دارند که
تراشه‌های شبکه عصبی را می‌سازند و بنابراین

447
00:11:30,889 --> 00:11:30,899
تراشه‌های شبکه عصبی را می‌سازند و بنابراین
 

448
00:11:30,899 --> 00:11:35,539
تراشه‌های شبکه عصبی را می‌سازند و بنابراین
بهتر می‌شود، اما خبر خوب به گونه‌ای

449
00:11:35,539 --> 00:11:35,549
بهتر می‌شود، اما خبر خوب به گونه‌ای
 

450
00:11:35,549 --> 00:11:38,929
بهتر می‌شود، اما خبر خوب به گونه‌ای
است که  خبر بد این است که حتی

451
00:11:38,929 --> 00:11:38,939
است که  خبر بد این است که حتی
 

452
00:11:38,939 --> 00:11:42,079
است که  خبر بد این است که حتی
پیشرفته‌ترین روش‌های یادگیری عمیق ما

453
00:11:42,079 --> 00:11:42,089
پیشرفته‌ترین روش‌های یادگیری عمیق ما
 

454
00:11:42,089 --> 00:11:46,009
پیشرفته‌ترین روش‌های یادگیری عمیق ما
نمی‌توانند مدل‌هایی را بیاموزند که

455
00:11:46,009 --> 00:11:46,019
نمی‌توانند مدل‌هایی را بیاموزند که
 

456
00:11:46,019 --> 00:11:48,530
نمی‌توانند مدل‌هایی را بیاموزند که
حتی محیط‌های بسیار ساده‌ای

457
00:11:48,530 --> 00:11:48,540
حتی محیط‌های بسیار ساده‌ای
 

458
00:11:48,540 --> 00:11:51,369
حتی محیط‌های بسیار ساده‌ای
مانند برخی از جهان‌های Grid را که ما

459
00:11:51,369 --> 00:11:51,379
مانند برخی از جهان‌های Grid را که ما
 

460
00:11:51,379 --> 00:11:53,869
مانند برخی از جهان‌های Grid را که ما
حتی این محیط‌های نسبتاً ساده ساخته‌ایم را درک می‌کنند،

461
00:11:53,869 --> 00:11:53,879
حتی این محیط‌های نسبتاً ساده ساخته‌ایم را درک می‌کنند،
 

462
00:11:53,879 --> 00:11:55,460
حتی این محیط‌های نسبتاً ساده ساخته‌ایم را درک می‌کنند،
البته اگر آنها را با

463
00:11:55,460 --> 00:11:55,470
البته اگر آنها را با
 

464
00:11:55,470 --> 00:11:57,049
البته اگر آنها را با
مثال‌های کافی آموزش دهید.  در نهایت آنها آن را دریافت می کنند،

465
00:11:57,049 --> 00:11:57,059
مثال‌های کافی آموزش دهید.  در نهایت آنها آن را دریافت می کنند،
 

466
00:11:57,059 --> 00:11:59,600
مثال‌های کافی آموزش دهید.  در نهایت آنها آن را دریافت می کنند،
اما به جای آنچه که

467
00:11:59,600 --> 00:11:59,610
اما به جای آنچه که
 

468
00:11:59,610 --> 00:12:02,919
اما به جای آنچه که
انسان ها ممکن است به

469
00:12:02,919 --> 00:12:02,929
انسان ها ممکن است به
 

470
00:12:02,929 --> 00:12:05,210
انسان ها ممکن است به
ده ها مثال نیاز داشته باشند، این چیزها به

471
00:12:05,210 --> 00:12:05,220
ده ها مثال نیاز داشته باشند، این چیزها به
 

472
00:12:05,220 --> 00:12:08,509
ده ها مثال نیاز داشته باشند، این چیزها به
میلیون ها نفر برای

473
00:12:08,509 --> 00:12:08,519
میلیون ها نفر برای
 

474
00:12:08,519 --> 00:12:12,109
میلیون ها نفر برای
کارهای بسیار بسیار ساده نیاز دارند و بنابراین من فکر می کنم

475
00:12:12,109 --> 00:12:12,119
کارهای بسیار بسیار ساده نیاز دارند و بنابراین من فکر می کنم
 

476
00:12:12,119 --> 00:12:15,139
کارهای بسیار بسیار ساده نیاز دارند و بنابراین من فکر می کنم
فرصتی برای دانشگاهیان وجود دارد که

477
00:12:15,139 --> 00:12:15,149
فرصتی برای دانشگاهیان وجود دارد که
 

478
00:12:15,149 --> 00:12:17,539
فرصتی برای دانشگاهیان وجود دارد که
این کار را ندارند.  قدرت محاسباتی که می‌گوید

479
00:12:17,539 --> 00:12:17,549
این کار را ندارند.  قدرت محاسباتی که می‌گوید
 

480
00:12:17,549 --> 00:12:20,989
این کار را ندارند.  قدرت محاسباتی که می‌گوید
گوگل باید تحقیقات بسیار مهم و

481
00:12:20,989 --> 00:12:20,999
گوگل باید تحقیقات بسیار مهم و
 

482
00:12:20,999 --> 00:12:23,720
گوگل باید تحقیقات بسیار مهم و
هیجان‌انگیزی انجام دهد تا

483
00:12:23,720 --> 00:12:23,730
هیجان‌انگیزی انجام دهد تا
 

484
00:12:23,730 --> 00:12:26,049
هیجان‌انگیزی انجام دهد تا
پیشرفته‌ترین روش را در چارچوب‌های آموزشی

485
00:12:26,049 --> 00:12:26,059
پیشرفته‌ترین روش را در چارچوب‌های آموزشی
 

486
00:12:26,059 --> 00:12:30,470
پیشرفته‌ترین روش را در چارچوب‌های آموزشی
یادگیری مدل‌های یادگیری عاملی در

487
00:12:30,470 --> 00:12:30,480
یادگیری مدل‌های یادگیری عاملی در
 

488
00:12:30,480 --> 00:12:32,710
یادگیری مدل‌های یادگیری عاملی در
محیط‌های ساده‌ای

489
00:12:32,710 --> 00:12:32,720
محیط‌های ساده‌ای
 

490
00:12:32,720 --> 00:12:35,660
محیط‌های ساده‌ای
که مصنوعی به نظر می‌رسند انجام دهد، اما در عین حال

491
00:12:35,660 --> 00:12:35,670
که مصنوعی به نظر می‌رسند انجام دهد، اما در عین حال
 

492
00:12:35,670 --> 00:12:38,749
که مصنوعی به نظر می‌رسند انجام دهد، اما در عین حال
یادگیری ماشینی کنونی با شکست مواجه شده است.

493
00:12:38,749 --> 00:12:38,759
یادگیری ماشینی کنونی با شکست مواجه شده است.
 

494
00:12:38,759 --> 00:12:42,439
یادگیری ماشینی کنونی با شکست مواجه شده است.
در مورد مقدمات و دانش عقل سلیم صحبت شد، به

495
00:12:42,439 --> 00:12:42,449
در مورد مقدمات و دانش عقل سلیم صحبت شد، به
 

496
00:12:42,449 --> 00:12:47,629
در مورد مقدمات و دانش عقل سلیم صحبت شد، به
نظر می رسد که ما انسان ها دانش زیادی را بدیهی می دانیم،

497
00:12:47,629 --> 00:12:47,639
نظر می رسد که ما انسان ها دانش زیادی را بدیهی می دانیم،
 

498
00:12:47,639 --> 00:12:52,189
نظر می رسد که ما انسان ها دانش زیادی را بدیهی می دانیم،
بنابراین

499
00:12:52,189 --> 00:12:52,199
بنابراین
 

500
00:12:52,199 --> 00:12:54,230
بنابراین
نظر شما در مورد این پیشینیان از شکل گیری

501
00:12:54,230 --> 00:12:54,240
نظر شما در مورد این پیشینیان از شکل گیری
 

502
00:12:54,240 --> 00:12:56,749
نظر شما در مورد این پیشینیان از شکل گیری
این دیدگاه گسترده از جهان، این

503
00:12:56,749 --> 00:12:56,759
این دیدگاه گسترده از جهان، این
 

504
00:12:56,759 --> 00:12:59,480
این دیدگاه گسترده از جهان، این
انباشت اطلاعات چیست و چگونه

505
00:12:59,480 --> 00:12:59,490
انباشت اطلاعات چیست و چگونه
 

506
00:12:59,490 --> 00:13:01,639
انباشت اطلاعات چیست و چگونه
می توانیم شبکه های عصبی یا یادگیری را آموزش دهیم.

507
00:13:01,639 --> 00:13:01,649
می توانیم شبکه های عصبی یا یادگیری را آموزش دهیم.
 

508
00:13:01,649 --> 00:13:03,829
می توانیم شبکه های عصبی یا یادگیری را آموزش دهیم.
سیستم‌هایی که آن دانش را جمع‌آوری می‌کنند تا

509
00:13:03,829 --> 00:13:03,839
سیستم‌هایی که آن دانش را جمع‌آوری می‌کنند تا
 

510
00:13:03,839 --> 00:13:07,069
سیستم‌هایی که آن دانش را جمع‌آوری می‌کنند تا
دانش را برای مدتی می‌دانید

511
00:13:07,069 --> 00:13:07,079
دانش را برای مدتی می‌دانید
 

512
00:13:07,079 --> 00:13:10,519
دانش را برای مدتی می‌دانید
هوش مصنوعی چه شاید در دهه

513
00:13:10,519 --> 00:13:10,529
هوش مصنوعی چه شاید در دهه
 

514
00:13:10,529 --> 00:13:12,799
هوش مصنوعی چه شاید در دهه
80 وجود داشته باشد یا دانش

515
00:13:12,799 --> 00:13:12,809
80 وجود داشته باشد یا دانش
 

516
00:13:12,809 --> 00:13:14,970
80 وجود داشته باشد یا دانش
بازنمایی دانش

517
00:13:14,970 --> 00:13:14,980
بازنمایی دانش
 

518
00:13:14,980 --> 00:13:17,130
بازنمایی دانش
سیستم‌های خبره کسب دانش، منظورم این است که اگرچه

519
00:13:17,130 --> 00:13:17,140
سیستم‌های خبره کسب دانش، منظورم این است که اگرچه
 

520
00:13:17,140 --> 00:13:21,300
سیستم‌های خبره کسب دانش، منظورم این است که اگرچه
هوش مصنوعی نمادین یک دیدگاه بود،

521
00:13:21,300 --> 00:13:21,310
هوش مصنوعی نمادین یک دیدگاه بود،
 

522
00:13:21,310 --> 00:13:23,640
هوش مصنوعی نمادین یک دیدگاه بود،
مشکل جالبی بود که باید حل شود و آن

523
00:13:23,640 --> 00:13:23,650
مشکل جالبی بود که باید حل شود و آن
 

524
00:13:23,650 --> 00:13:26,550
مشکل جالبی بود که باید حل شود و آن
کمی متوقف شد، به

525
00:13:26,550 --> 00:13:26,560
کمی متوقف شد، به
 

526
00:13:26,560 --> 00:13:28,500
کمی متوقف شد، به
نظر می رسد چون کار نمی کند، کار

527
00:13:28,500 --> 00:13:28,510
نظر می رسد چون کار نمی کند، کار
 

528
00:13:28,510 --> 00:13:31,320
نظر می رسد چون کار نمی کند، کار
نمی کند، درست است، اما

529
00:13:31,320 --> 00:13:31,330
نمی کند، درست است، اما
 

530
00:13:31,330 --> 00:13:35,100
نمی کند، درست است، اما
درست است، اما اهداف آن

531
00:13:35,100 --> 00:13:35,110
درست است، اما اهداف آن
 

532
00:13:35,110 --> 00:13:37,170
درست است، اما اهداف آن
مهم باقی می مانند، بله مهم باقی

533
00:13:37,170 --> 00:13:37,180
مهم باقی می مانند، بله مهم باقی
 

534
00:13:37,180 --> 00:13:39,870
مهم باقی می مانند، بله مهم باقی
می مانند.

535
00:13:39,870 --> 00:13:39,880
می مانند.
 

536
00:13:39,880 --> 00:13:41,810
می مانند.
بنابراین اول از همه، من

537
00:13:41,810 --> 00:13:41,820
بنابراین اول از همه، من
 

538
00:13:41,820 --> 00:13:45,530
بنابراین اول از همه، من
معتقدم که یکی از دلایل

539
00:13:45,530 --> 00:13:45,540
معتقدم که یکی از دلایل
 

540
00:13:45,540 --> 00:13:48,180
معتقدم که یکی از دلایل
شکست رویکرد سیستم‌های خبره کلاسیک این

541
00:13:48,180 --> 00:13:48,190
شکست رویکرد سیستم‌های خبره کلاسیک این
 

542
00:13:48,190 --> 00:13:51,840
شکست رویکرد سیستم‌های خبره کلاسیک این
است که بسیاری از دانش‌های ما در اختیار

543
00:13:51,840 --> 00:13:51,850
است که بسیاری از دانش‌های ما در اختیار
 

544
00:13:51,850 --> 00:13:53,600
است که بسیاری از دانش‌های ما در اختیار
داریم، بنابراین شما در مورد شهود عقل سلیم صحبت کردید،

545
00:13:53,600 --> 00:13:53,610
داریم، بنابراین شما در مورد شهود عقل سلیم صحبت کردید،
 

546
00:13:53,610 --> 00:13:58,110
داریم، بنابراین شما در مورد شهود عقل سلیم صحبت کردید،
دانش زیادی

547
00:13:58,110 --> 00:13:58,120
دانش زیادی
 

548
00:13:58,120 --> 00:14:01,740
دانش زیادی
مانند این وجود دارد که آگاهانه

549
00:14:01,740 --> 00:14:01,750
مانند این وجود دارد که آگاهانه
 

550
00:14:01,750 --> 00:14:04,350
مانند این وجود دارد که آگاهانه
در بسیاری از تصمیم‌های ما قابل دسترسی نیست.

551
00:14:04,350 --> 00:14:04,360
در بسیاری از تصمیم‌های ما قابل دسترسی نیست.
 

552
00:14:04,360 --> 00:14:06,090
در بسیاری از تصمیم‌های ما قابل دسترسی نیست.
ما واقعاً نمی‌توانیم توضیح دهیم حتی

553
00:14:06,090 --> 00:14:06,100
ما واقعاً نمی‌توانیم توضیح دهیم حتی
 

554
00:14:06,100 --> 00:14:11,490
ما واقعاً نمی‌توانیم توضیح دهیم حتی
اگر گاهی اوقات داستانی را بسازیم و این

555
00:14:11,490 --> 00:14:11,500
اگر گاهی اوقات داستانی را بسازیم و این
 

556
00:14:11,500 --> 00:14:13,860
اگر گاهی اوقات داستانی را بسازیم و این
دانش برای ماشین‌ها

557
00:14:13,860 --> 00:14:13,870
دانش برای ماشین‌ها
 

558
00:14:13,870 --> 00:14:17,190
دانش برای ماشین‌ها
برای تصمیم‌گیری خوب ضروری است و این

559
00:14:17,190 --> 00:14:17,200
برای تصمیم‌گیری خوب ضروری است و این
 

560
00:14:17,200 --> 00:14:20,340
برای تصمیم‌گیری خوب ضروری است و این
دانش در

561
00:14:20,340 --> 00:14:20,350
دانش در
 

562
00:14:20,350 --> 00:14:22,590
دانش در
سیستم‌های مبتنی بر قانون سیستم‌های خبره سخت است و شما می‌دانید که

563
00:14:22,590 --> 00:14:22,600
سیستم‌های مبتنی بر قانون سیستم‌های خبره سخت است و شما می‌دانید که
 

564
00:14:22,600 --> 00:14:25,080
سیستم‌های مبتنی بر قانون سیستم‌های خبره سخت است و شما می‌دانید که
Costco EAJA فرمالیسم و  البته

565
00:14:25,080 --> 00:14:25,090
Costco EAJA فرمالیسم و  البته
 

566
00:14:25,090 --> 00:14:27,360
Costco EAJA فرمالیسم و  البته
مسائل دیگری در مورد هوش مصنوعی قدیمی وجود دارد،

567
00:14:27,360 --> 00:14:27,370
مسائل دیگری در مورد هوش مصنوعی قدیمی وجود دارد،
 

568
00:14:27,370 --> 00:14:30,990
مسائل دیگری در مورد هوش مصنوعی قدیمی وجود دارد،
مانند روش‌های نه چندان خوب برای مدیریت

569
00:14:30,990 --> 00:14:31,000
مانند روش‌های نه چندان خوب برای مدیریت
 

570
00:14:31,000 --> 00:14:33,930
مانند روش‌های نه چندان خوب برای مدیریت
عدم قطعیت، من می‌توانم چیز

571
00:14:33,930 --> 00:14:33,940
عدم قطعیت، من می‌توانم چیز
 

572
00:14:33,940 --> 00:14:36,930
عدم قطعیت، من می‌توانم چیز
ظریف‌تری بگویم که اکنون بهتر آن را درک می‌کنیم،

573
00:14:36,930 --> 00:14:36,940
ظریف‌تری بگویم که اکنون بهتر آن را درک می‌کنیم،
 

574
00:14:36,940 --> 00:14:39,720
ظریف‌تری بگویم که اکنون بهتر آن را درک می‌کنیم،
اما فکر می‌کنم هنوز در

575
00:14:39,720 --> 00:14:39,730
اما فکر می‌کنم هنوز در
 

576
00:14:39,730 --> 00:14:42,210
اما فکر می‌کنم هنوز در
ذهن مردم کافی نیست، چیزی

577
00:14:42,210 --> 00:14:42,220
ذهن مردم کافی نیست، چیزی
 

578
00:14:42,220 --> 00:14:45,350
ذهن مردم کافی نیست، چیزی
واقعاً قدرتمند وجود دارد که از آن ناشی می‌شود.

579
00:14:45,350 --> 00:14:45,360
واقعاً قدرتمند وجود دارد که از آن ناشی می‌شود.
 

580
00:14:45,360 --> 00:14:47,490
واقعاً قدرتمند وجود دارد که از آن ناشی می‌شود.
بازنمایی های توزیع شده چیزی است

581
00:14:47,490 --> 00:14:47,500
بازنمایی های توزیع شده چیزی است
 

582
00:14:47,500 --> 00:14:50,610
بازنمایی های توزیع شده چیزی است
که واقعاً باعث می شود شبکه های عصبی خیلی

583
00:14:50,610 --> 00:14:50,620
که واقعاً باعث می شود شبکه های عصبی خیلی
 

584
00:14:50,620 --> 00:14:54,960
که واقعاً باعث می شود شبکه های عصبی خیلی
خوب کار کنند و تکرار آن

585
00:14:54,960 --> 00:14:54,970
خوب کار کنند و تکرار آن
 

586
00:14:54,970 --> 00:14:59,640
خوب کار کنند و تکرار آن
نوع قدرت در دنیای نمادین دشوار است،

587
00:14:59,640 --> 00:14:59,650
نوع قدرت در دنیای نمادین دشوار است،
 

588
00:14:59,650 --> 00:15:01,920
نوع قدرت در دنیای نمادین دشوار است،
دانش در سیستم های خبره و غیره به

589
00:15:01,920 --> 00:15:01,930
دانش در سیستم های خبره و غیره به
 

590
00:15:01,930 --> 00:15:05,550
دانش در سیستم های خبره و غیره به
خوبی به مجموعه ای

591
00:15:05,550 --> 00:15:05,560
خوبی به مجموعه ای
 

592
00:15:05,560 --> 00:15:07,500
خوبی به مجموعه ای
از قوانین تجزیه می شود، در حالی که اگر به یک عصبی فکر کنید.

593
00:15:07,500 --> 00:15:07,510
از قوانین تجزیه می شود، در حالی که اگر به یک عصبی فکر کنید.
 

594
00:15:07,510 --> 00:15:09,390
از قوانین تجزیه می شود، در حالی که اگر به یک عصبی فکر کنید.
net برعکس این است که شما

595
00:15:09,390 --> 00:15:09,400
net برعکس این است که شما
 

596
00:15:09,400 --> 00:15:12,510
net برعکس این است که شما
این لکه بزرگ از پارامترها را دارید که

597
00:15:12,510 --> 00:15:12,520
این لکه بزرگ از پارامترها را دارید که
 

598
00:15:12,520 --> 00:15:14,280
این لکه بزرگ از پارامترها را دارید که
به شدت با هم کار می کنند تا

599
00:15:14,280 --> 00:15:14,290
به شدت با هم کار می کنند تا
 

600
00:15:14,290 --> 00:15:16,890
به شدت با هم کار می کنند تا
همه چیزهایی را که شبکه می داند نشان دهد و به

601
00:15:16,890 --> 00:15:16,900
همه چیزهایی را که شبکه می داند نشان دهد و به
 

602
00:15:16,900 --> 00:15:20,340
همه چیزهایی را که شبکه می داند نشان دهد و به
اندازه کافی فاکتورگیری نشده است، بنابراین

603
00:15:20,340 --> 00:15:20,350
اندازه کافی فاکتورگیری نشده است، بنابراین
 

604
00:15:20,350 --> 00:15:22,290
اندازه کافی فاکتورگیری نشده است، بنابراین
فکر می کنم این یکی از نقاط ضعف

605
00:15:22,290 --> 00:15:22,300
فکر می کنم این یکی از نقاط ضعف
 

606
00:15:22,300 --> 00:15:25,260
فکر می کنم این یکی از نقاط ضعف
شبکه های عصبی فعلی است که ما باید

607
00:15:25,260 --> 00:15:25,270
شبکه های عصبی فعلی است که ما باید
 

608
00:15:25,270 --> 00:15:28,200
شبکه های عصبی فعلی است که ما باید
از آن درس های کلاسیک بگیریم.

609
00:15:28,200 --> 00:15:28,210
از آن درس های کلاسیک بگیریم.
 

610
00:15:28,210 --> 00:15:31,410
از آن درس های کلاسیک بگیریم.
به منظور وارد کردن نوع دیگری از

611
00:15:31,410 --> 00:15:31,420
به منظور وارد کردن نوع دیگری از
 

612
00:15:31,420 --> 00:15:33,269
به منظور وارد کردن نوع دیگری از
ترکیب بندی که در

613
00:15:33,269 --> 00:15:33,279
ترکیب بندی که در
 

614
00:15:33,279 --> 00:15:35,090
ترکیب بندی که در
زبان به عنوان مثال و در این قوانین

615
00:15:35,090 --> 00:15:35,100
زبان به عنوان مثال و در این قوانین
 

616
00:15:35,100 --> 00:15:39,470
زبان به عنوان مثال و در این قوانین
رایج است، اما در نیو اولم اد

617
00:15:39,470 --> 00:15:39,480
رایج است، اما در نیو اولم اد
 

618
00:15:39,480 --> 00:15:43,400
رایج است، اما در نیو اولم اد
و در آن خط فکری

619
00:15:43,400 --> 00:15:43,410
و در آن خط فکری
 

620
00:15:43,410 --> 00:15:47,850
و در آن خط فکری
بازنمودهای گسسته نیست.

621
00:15:47,850 --> 00:15:49,139
بازنمودهای گسسته نیست.
 

622
00:15:49,139 --> 00:15:49,149

 

623
00:15:49,149 --> 00:15:51,420

اگر

624
00:15:51,420 --> 00:15:51,430
اگر
 

625
00:15:51,430 --> 00:15:54,630
اگر
اشکالی ندارد بله دقیقاً همینطور برای سالهای متمادی

626
00:15:54,630 --> 00:15:54,640
اشکالی ندارد بله دقیقاً همینطور برای سالهای متمادی
 

627
00:15:54,640 --> 00:15:56,760
اشکالی ندارد بله دقیقاً همینطور برای سالهای متمادی
فکر می‌کردم و هنوز هم معتقدم که

628
00:15:56,760 --> 00:15:56,770
فکر می‌کردم و هنوز هم معتقدم که
 

629
00:15:56,770 --> 00:15:58,500
فکر می‌کردم و هنوز هم معتقدم که
واقعاً مهم است که

630
00:15:58,500 --> 00:15:58,510
واقعاً مهم است که
 

631
00:15:58,510 --> 00:16:01,680
واقعاً مهم است که
الگوریتم‌های یادگیری را بی‌نظارت

632
00:16:01,680 --> 00:16:01,690
الگوریتم‌های یادگیری را بی‌نظارت
 

633
00:16:01,690 --> 00:16:03,840
الگوریتم‌های یادگیری را بی‌نظارت
یا تحت نظارت، اما یا اجرای

634
00:16:03,840 --> 00:16:03,850
یا تحت نظارت، اما یا اجرای
 

635
00:16:03,850 --> 00:16:06,510
یا تحت نظارت، اما یا اجرای
هر چیزی که در آن بازنمایی‌هایی ایجاد می‌کند که در

636
00:16:06,510 --> 00:16:06,520
هر چیزی که در آن بازنمایی‌هایی ایجاد می‌کند که در
 

637
00:16:06,520 --> 00:16:09,930
هر چیزی که در آن بازنمایی‌هایی ایجاد می‌کند که در
آن عوامل مهم، امیدواریم

638
00:16:09,930 --> 00:16:09,940
آن عوامل مهم، امیدواریم
 

639
00:16:09,940 --> 00:16:12,389
آن عوامل مهم، امیدواریم
عوامل علّی هستند، ایجاد کنیم، مهم است.  به خوبی جدا شده و به

640
00:16:12,389 --> 00:16:12,399
عوامل علّی هستند، ایجاد کنیم، مهم است.  به خوبی جدا شده و به
 

641
00:16:12,399 --> 00:16:14,400
عوامل علّی هستند، ایجاد کنیم، مهم است.  به خوبی جدا شده و به
راحتی از نمایش برداشت می شود،

642
00:16:14,400 --> 00:16:14,410
راحتی از نمایش برداشت می شود،
 

643
00:16:14,410 --> 00:16:16,380
راحتی از نمایش برداشت می شود،
بنابراین ایده جدا کردن

644
00:16:16,380 --> 00:16:16,390
بنابراین ایده جدا کردن
 

645
00:16:16,390 --> 00:16:18,660
بنابراین ایده جدا کردن
بازنمایی ها این است که می گوید

646
00:16:18,660 --> 00:16:18,670
بازنمایی ها این است که می گوید
 

647
00:16:18,670 --> 00:16:20,730
بازنمایی ها این است که می گوید
داده ها را به فضایی تبدیل کنید که در آن همه چیز

648
00:16:20,730 --> 00:16:20,740
داده ها را به فضایی تبدیل کنید که در آن همه چیز
 

649
00:16:20,740 --> 00:16:23,160
داده ها را به فضایی تبدیل کنید که در آن همه چیز
آسان می شود، شاید فقط بتوانیم

650
00:16:23,160 --> 00:16:23,170
آسان می شود، شاید فقط بتوانیم
 

651
00:16:23,170 --> 00:16:25,980
آسان می شود، شاید فقط بتوانیم
با مدل های خطی در مورد چیزهایی که

652
00:16:25,980 --> 00:16:25,990
با مدل های خطی در مورد چیزهایی که
 

653
00:16:25,990 --> 00:16:28,860
با مدل های خطی در مورد چیزهایی که
به آنها اهمیت می دهیم یاد بگیریم و هنوز هم فکر می کنم این است

654
00:16:28,860 --> 00:16:28,870
به آنها اهمیت می دهیم یاد بگیریم و هنوز هم فکر می کنم این است
 

655
00:16:28,870 --> 00:16:30,540
به آنها اهمیت می دهیم یاد بگیریم و هنوز هم فکر می کنم این است
مهم است، اما من فکر می‌کنم این

656
00:16:30,540 --> 00:16:30,550
مهم است، اما من فکر می‌کنم این
 

657
00:16:30,550 --> 00:16:34,760
مهم است، اما من فکر می‌کنم این
یک عنصر بسیار مهم را از دست می‌دهد که

658
00:16:34,760 --> 00:16:34,770
یک عنصر بسیار مهم را از دست می‌دهد که
 

659
00:16:34,770 --> 00:16:37,310
یک عنصر بسیار مهم را از دست می‌دهد که
سیستم‌های هوش مصنوعی کلاسیک می‌توانند آن را به ما یادآوری کنند،

660
00:16:37,310 --> 00:16:37,320
سیستم‌های هوش مصنوعی کلاسیک می‌توانند آن را به ما یادآوری کنند،
 

661
00:16:37,320 --> 00:16:39,900
سیستم‌های هوش مصنوعی کلاسیک می‌توانند آن را به ما یادآوری کنند،
بنابراین بیایید بگوییم که ما این فناوری‌های طراحی را داریم،

662
00:16:39,900 --> 00:16:40,710
بنابراین بیایید بگوییم که ما این فناوری‌های طراحی را داریم،
 

663
00:16:40,710 --> 00:16:40,720

 

664
00:16:40,720 --> 00:16:43,400

شما هنوز باید در مورد

665
00:16:43,400 --> 00:16:43,410
شما هنوز باید در مورد
 

666
00:16:43,410 --> 00:16:45,300
شما هنوز باید در مورد
روابط بین متغیرها

667
00:16:45,300 --> 00:16:45,310
روابط بین متغیرها
 

668
00:16:45,310 --> 00:16:46,920
روابط بین متغیرها
و متغیرهای معنایی سطح بالا

669
00:16:46,920 --> 00:16:46,930
و متغیرهای معنایی سطح بالا
 

670
00:16:46,930 --> 00:16:48,210
و متغیرهای معنایی سطح بالا
آنها بیاموزید.  نمی‌خواهم مستقل باشم،

671
00:16:48,210 --> 00:16:48,220
آنها بیاموزید.  نمی‌خواهم مستقل باشم،
 

672
00:16:48,220 --> 00:16:49,860
آنها بیاموزید.  نمی‌خواهم مستقل باشم،
منظورم این است که این تصور بیش از حد است که

673
00:16:49,860 --> 00:16:49,870
منظورم این است که این تصور بیش از حد است که
 

674
00:16:49,870 --> 00:16:52,079
منظورم این است که این تصور بیش از حد است که
آنها

675
00:16:52,079 --> 00:16:52,089
آنها
 

676
00:16:52,089 --> 00:16:53,940
آنها
روابط جالبی خواهند داشت که به

677
00:16:53,940 --> 00:16:53,950
روابط جالبی خواهند داشت که به
 

678
00:16:53,950 --> 00:16:55,860
روابط جالبی خواهند داشت که به
پیش‌بینی چیزهایی در آینده اجازه می‌دهد تا

679
00:16:55,860 --> 00:16:55,870
پیش‌بینی چیزهایی در آینده اجازه می‌دهد تا
 

680
00:16:55,870 --> 00:16:58,260
پیش‌بینی چیزهایی در آینده اجازه می‌دهد تا
آنچه را که در گذشته اتفاق افتاده است، نوع

681
00:16:58,260 --> 00:16:58,270
آنچه را که در گذشته اتفاق افتاده است، نوع
 

682
00:16:58,270 --> 00:17:00,300
آنچه را که در گذشته اتفاق افتاده است، نوع
دانش درباره آن روابط در یک

683
00:17:00,300 --> 00:17:00,310
دانش درباره آن روابط در یک
 

684
00:17:00,310 --> 00:17:02,790
دانش درباره آن روابط در یک
هوش مصنوعی کلاسیک توضیح دهد.  سیستم در قوانین رمزگذاری شده است

685
00:17:02,790 --> 00:17:02,800
هوش مصنوعی کلاسیک توضیح دهد.  سیستم در قوانین رمزگذاری شده است
 

686
00:17:02,800 --> 00:17:04,350
هوش مصنوعی کلاسیک توضیح دهد.  سیستم در قوانین رمزگذاری شده است
مانند یک قانون دقیقاً مانند یک دانش کوچک است

687
00:17:04,350 --> 00:17:04,360
مانند یک قانون دقیقاً مانند یک دانش کوچک است
 

688
00:17:04,360 --> 00:17:06,390
مانند یک قانون دقیقاً مانند یک دانش کوچک است
که می گوید آه من

689
00:17:06,390 --> 00:17:06,400
که می گوید آه من
 

690
00:17:06,400 --> 00:17:09,179
که می گوید آه من
این دو سه چهار متغیر را دارم که

691
00:17:09,179 --> 00:17:09,189
این دو سه چهار متغیر را دارم که
 

692
00:17:09,189 --> 00:17:11,370
این دو سه چهار متغیر را دارم که
به این روش جالب به هم مرتبط شده اند سپس

693
00:17:11,370 --> 00:17:11,380
به این روش جالب به هم مرتبط شده اند سپس
 

694
00:17:11,380 --> 00:17:13,199
به این روش جالب به هم مرتبط شده اند سپس
می توانم در مورد یک یا دو مورد از

695
00:17:13,199 --> 00:17:13,209
می توانم در مورد یک یا دو مورد از
 

696
00:17:13,209 --> 00:17:15,030
می توانم در مورد یک یا دو مورد از
آنها با چند مورد دیگر چیزی بگویم.  درست

697
00:17:15,030 --> 00:17:15,040
آنها با چند مورد دیگر چیزی بگویم.  درست
 

698
00:17:15,040 --> 00:17:19,110
آنها با چند مورد دیگر چیزی بگویم.  درست
علاوه بر جدا کردن

699
00:17:19,110 --> 00:17:19,120
علاوه بر جدا کردن
 

700
00:17:19,120 --> 00:17:21,240
علاوه بر جدا کردن
عناصر نمایش که

701
00:17:21,240 --> 00:17:21,250
عناصر نمایش که
 

702
00:17:21,250 --> 00:17:23,610
عناصر نمایش که
مانند متغیرها در سیستم مبتنی بر قانون هستند،

703
00:17:23,610 --> 00:17:23,620
مانند متغیرها در سیستم مبتنی بر قانون هستند،
 

704
00:17:23,620 --> 00:17:28,740
مانند متغیرها در سیستم مبتنی بر قانون هستند،
باید

705
00:17:28,740 --> 00:17:28,750
باید
 

706
00:17:28,750 --> 00:17:32,340
باید
مکانیسم‌هایی را که آن متغیرها را

707
00:17:32,340 --> 00:17:32,350
مکانیسم‌هایی را که آن متغیرها را
 

708
00:17:32,350 --> 00:17:34,710
مکانیسم‌هایی را که آن متغیرها را
به یکدیگر مرتبط می‌کنند، از هم جدا کنید، بنابراین مانند قوانین،

709
00:17:34,710 --> 00:17:34,720
به یکدیگر مرتبط می‌کنند، از هم جدا کنید، بنابراین مانند قوانین،
 

710
00:17:34,720 --> 00:17:36,450
به یکدیگر مرتبط می‌کنند، از هم جدا کنید، بنابراین مانند قوانین،
قوانین به‌طور منظمی مانند هر قانون از هم جدا شوند.

711
00:17:36,450 --> 00:17:36,460
قوانین به‌طور منظمی مانند هر قانون از هم جدا شوند.
 

712
00:17:36,460 --> 00:17:38,580
قوانین به‌طور منظمی مانند هر قانون از هم جدا شوند.
شما می دانید که به تنهایی زندگی می کنید و

713
00:17:38,580 --> 00:17:38,590
شما می دانید که به تنهایی زندگی می کنید و
 

714
00:17:38,590 --> 00:17:41,250
شما می دانید که به تنهایی زندگی می کنید و
زمانی که من یک قانون را تغییر می دهم، زیرا در حال یادگیری هستم،

715
00:17:41,250 --> 00:17:41,260
زمانی که من یک قانون را تغییر می دهم، زیرا در حال یادگیری هستم،
 

716
00:17:41,260 --> 00:17:42,300
زمانی که من یک قانون را تغییر می دهم، زیرا در حال یادگیری هستم،

717
00:17:42,300 --> 00:17:42,310

 

718
00:17:42,310 --> 00:17:44,610

نیازی به زیر پا گذاشتن قوانین دیگر نیست،

719
00:17:44,610 --> 00:17:44,620
نیازی به زیر پا گذاشتن قوانین دیگر نیست،
 

720
00:17:44,620 --> 00:17:46,830
نیازی به زیر پا گذاشتن قوانین دیگر نیست،
در حالی که متدهای فعلی شما به عنوان مثال

721
00:17:46,830 --> 00:17:46,840
در حالی که متدهای فعلی شما به عنوان مثال
 

722
00:17:46,840 --> 00:17:48,390
در حالی که متدهای فعلی شما به عنوان مثال
به چیزی که

723
00:17:48,390 --> 00:17:48,400
به چیزی که
 

724
00:17:48,400 --> 00:17:51,480
به چیزی که
فراموشی فاجعه بار می گویند، پس از

725
00:17:51,480 --> 00:17:51,490
فراموشی فاجعه بار می گویند، پس از
 

726
00:17:51,490 --> 00:17:53,130
فراموشی فاجعه بار می گویند، پس از
آموختن برخی چیزها و سپس، بسیار حساس هستند.  چیزهای جدیدی یاد می‌گیرم،

727
00:17:53,130 --> 00:17:53,140
آموختن برخی چیزها و سپس، بسیار حساس هستند.  چیزهای جدیدی یاد می‌گیرم،
 

728
00:17:53,140 --> 00:17:55,440
آموختن برخی چیزها و سپس، بسیار حساس هستند.  چیزهای جدیدی یاد می‌گیرم،
آنها می‌توانند چیزهای قدیمی‌ای را

729
00:17:55,440 --> 00:17:55,450
آنها می‌توانند چیزهای قدیمی‌ای را
 

730
00:17:55,450 --> 00:17:57,960
آنها می‌توانند چیزهای قدیمی‌ای را
که من یاد گرفته بودم، از بین ببرند، اگر

731
00:17:57,960 --> 00:17:57,970
که من یاد گرفته بودم، از بین ببرند، اگر
 

732
00:17:57,970 --> 00:18:01,310
که من یاد گرفته بودم، از بین ببرند، اگر
دانش بهتر فاکتورسازی می‌شد و

733
00:18:01,310 --> 00:18:01,320
دانش بهتر فاکتورسازی می‌شد و
 

734
00:18:01,320 --> 00:18:04,350
دانش بهتر فاکتورسازی می‌شد و
جدا می‌شد، از

735
00:18:04,350 --> 00:18:04,360
جدا می‌شد، از
 

736
00:18:04,360 --> 00:18:07,530
جدا می‌شد، از
خیلی چیزها اجتناب می‌کردی، حالا نمی‌توانی

737
00:18:07,530 --> 00:18:07,540
خیلی چیزها اجتناب می‌کردی، حالا نمی‌توانی
 

738
00:18:07,540 --> 00:18:12,570
خیلی چیزها اجتناب می‌کردی، حالا نمی‌توانی
این کار را در حوزه حسی انجام بدهی، اما

739
00:18:12,570 --> 00:18:12,580
این کار را در حوزه حسی انجام بدهی، اما
 

740
00:18:12,580 --> 00:18:15,900
این کار را در حوزه حسی انجام بدهی، اما
خوب مثل یک  فضای پیکسلی اما ایده من

741
00:18:15,900 --> 00:18:15,910
خوب مثل یک  فضای پیکسلی اما ایده من
 

742
00:18:15,910 --> 00:18:17,730
خوب مثل یک  فضای پیکسلی اما ایده من
این است که وقتی داده‌ها را در

743
00:18:17,730 --> 00:18:17,740
این است که وقتی داده‌ها را در
 

744
00:18:17,740 --> 00:18:19,410
این است که وقتی داده‌ها را در
فضای معنایی درست پیش‌بینی می‌کنید،

745
00:18:19,410 --> 00:18:19,420
فضای معنایی درست پیش‌بینی می‌کنید،
 

746
00:18:19,420 --> 00:18:22,880
فضای معنایی درست پیش‌بینی می‌کنید،
اکنون می‌توانید این دانش اضافی را

747
00:18:22,880 --> 00:18:22,890
اکنون می‌توانید این دانش اضافی را
 

748
00:18:22,890 --> 00:18:25,170
اکنون می‌توانید این دانش اضافی را
فراتر از تبدیل از ورودی به

749
00:18:25,170 --> 00:18:25,180
فراتر از تبدیل از ورودی به
 

750
00:18:25,180 --> 00:18:26,760
فراتر از تبدیل از ورودی به
نمایش‌ها نشان دهید، یعنی نحوه

751
00:18:26,760 --> 00:18:26,770
نمایش‌ها نشان دهید، یعنی نحوه
 

752
00:18:26,770 --> 00:18:28,920
نمایش‌ها نشان دهید، یعنی نحوه
عملکرد نمایش‌ها بر روی یکدیگر و

753
00:18:28,920 --> 00:18:28,930
عملکرد نمایش‌ها بر روی یکدیگر و
 

754
00:18:28,930 --> 00:18:31,680
عملکرد نمایش‌ها بر روی یکدیگر و
پیش‌بینی آینده و غیره در  روشی

755
00:18:31,680 --> 00:18:31,690
پیش‌بینی آینده و غیره در  روشی
 

756
00:18:31,690 --> 00:18:35,910
پیش‌بینی آینده و غیره در  روشی
که می‌توان آن را به‌خوبی جدا کرد، بنابراین اکنون

757
00:18:35,910 --> 00:18:35,920
که می‌توان آن را به‌خوبی جدا کرد، بنابراین اکنون
 

758
00:18:35,920 --> 00:18:37,710
که می‌توان آن را به‌خوبی جدا کرد، بنابراین اکنون
قوانین یا تفکیک از یکدیگر هستند

759
00:18:37,710 --> 00:18:37,720
قوانین یا تفکیک از یکدیگر هستند
 

760
00:18:37,720 --> 00:18:39,180
قوانین یا تفکیک از یکدیگر هستند
و نه فقط متغیرهایی که

761
00:18:39,180 --> 00:18:39,190
و نه فقط متغیرهایی که
 

762
00:18:39,190 --> 00:18:40,760
و نه فقط متغیرهایی که
از یکدیگر جدا می‌شوند و شما

763
00:18:40,760 --> 00:18:40,770
از یکدیگر جدا می‌شوند و شما
 

764
00:18:40,770 --> 00:18:43,050
از یکدیگر جدا می‌شوند و شما
بین

765
00:18:43,050 --> 00:18:43,060
بین
 

766
00:18:43,060 --> 00:18:45,780
بین
فضای معنایی و پیکسل تمایز قائل می‌شوید، مثلاً بله، باید

767
00:18:45,780 --> 00:18:45,790
فضای معنایی و پیکسل تمایز قائل می‌شوید، مثلاً بله، باید
 

768
00:18:45,790 --> 00:18:47,760
فضای معنایی و پیکسل تمایز قائل می‌شوید، مثلاً بله، باید
تفاوت معماری وجود داشته باشد یا خوب

769
00:18:47,760 --> 00:18:47,770
تفاوت معماری وجود داشته باشد یا خوب
 

770
00:18:47,770 --> 00:18:49,680
تفاوت معماری وجود داشته باشد یا خوب
بله،  بنابراین فضای حسی مانند

771
00:18:49,680 --> 00:18:49,690
بله،  بنابراین فضای حسی مانند
 

772
00:18:49,690 --> 00:18:51,420
بله،  بنابراین فضای حسی مانند
پیکسل ها وجود دارد که در آن همه چیز

773
00:18:51,420 --> 00:18:51,430
پیکسل ها وجود دارد که در آن همه چیز
 

774
00:18:51,430 --> 00:18:54,720
پیکسل ها وجود دارد که در آن همه چیز
گسسته است، اطلاعاتی مانند

775
00:18:54,720 --> 00:18:54,730
گسسته است، اطلاعاتی مانند
 

776
00:18:54,730 --> 00:18:56,190
گسسته است، اطلاعاتی مانند
متغیرها کاملاً

777
00:18:56,190 --> 00:18:56,200
متغیرها کاملاً
 

778
00:18:56,200 --> 00:18:59,430
متغیرها کاملاً
به روش های بسیار پیچیده به یکدیگر وابسته هستند و همچنین

779
00:18:59,430 --> 00:18:59,440
به روش های بسیار پیچیده به یکدیگر وابسته هستند و همچنین
 

780
00:18:59,440 --> 00:19:02,490
به روش های بسیار پیچیده به یکدیگر وابسته هستند و همچنین
محاسباتی مانند این که فقط

781
00:19:02,490 --> 00:19:02,500
محاسباتی مانند این که فقط
 

782
00:19:02,500 --> 00:19:03,960
محاسباتی مانند این که فقط
متغیرها نیستند، نحوه ارتباط آنها

783
00:19:03,960 --> 00:19:03,970
متغیرها نیستند، نحوه ارتباط آنها
 

784
00:19:03,970 --> 00:19:06,810
متغیرها نیستند، نحوه ارتباط آنها
با یکدیگر نیز همه در هم تنیده شده است،

785
00:19:06,810 --> 00:19:06,820
با یکدیگر نیز همه در هم تنیده شده است،
 

786
00:19:06,820 --> 00:19:09,540
با یکدیگر نیز همه در هم تنیده شده است،
اما من  من این فرضیه را مطرح می کنم که در

787
00:19:09,540 --> 00:19:09,550
اما من  من این فرضیه را مطرح می کنم که در
 

788
00:19:09,550 --> 00:19:12,930
اما من  من این فرضیه را مطرح می کنم که در
فضای نمایش سطح بالا،

789
00:19:12,930 --> 00:19:12,940
فضای نمایش سطح بالا،
 

790
00:19:12,940 --> 00:19:16,050
فضای نمایش سطح بالا،
هم متغیرها و هم نحوه ارتباط آنها

791
00:19:16,050 --> 00:19:16,060
هم متغیرها و هم نحوه ارتباط آنها
 

792
00:19:16,060 --> 00:19:18,390
هم متغیرها و هم نحوه ارتباط آنها
با یکدیگر می توانند از هم گسسته شوند و

793
00:19:18,390 --> 00:19:18,400
با یکدیگر می توانند از هم گسسته شوند و
 

794
00:19:18,400 --> 00:19:19,710
با یکدیگر می توانند از هم گسسته شوند و
این مقدار زیادی

795
00:19:19,710 --> 00:19:19,720
این مقدار زیادی
 

796
00:19:19,720 --> 00:19:22,410
این مقدار زیادی
قدرت تعمیم

797
00:19:22,410 --> 00:19:22,420
قدرت تعمیم
 

798
00:19:22,420 --> 00:19:25,440
قدرت تعمیم
قدرت تعمیم بله توزیع مجموعه آزمون را که

799
00:19:25,440 --> 00:19:25,450
قدرت تعمیم بله توزیع مجموعه آزمون را که
 

800
00:19:25,450 --> 00:19:28,500
قدرت تعمیم بله توزیع مجموعه آزمون را که
او فرض می کرد یکسان است ارائه می دهد.

801
00:19:28,500 --> 00:19:28,510
او فرض می کرد یکسان است ارائه می دهد.
 

802
00:19:28,510 --> 00:19:30,390
او فرض می کرد یکسان است ارائه می دهد.
توزیع مجموعه آموزشی درست

803
00:19:30,390 --> 00:19:30,400
توزیع مجموعه آموزشی درست
 

804
00:19:30,400 --> 00:19:32,850
توزیع مجموعه آموزشی درست
اینجاست که یادگیری ماشین فعلی

805
00:19:32,850 --> 00:19:32,860
اینجاست که یادگیری ماشین فعلی
 

806
00:19:32,860 --> 00:19:36,360
اینجاست که یادگیری ماشین فعلی
خیلی ضعیف است و به ما نمی گوید هیچ چیزی

807
00:19:36,360 --> 00:19:36,370
خیلی ضعیف است و به ما نمی گوید هیچ چیزی
 

808
00:19:36,370 --> 00:19:38,130
خیلی ضعیف است و به ما نمی گوید هیچ چیزی
نمی تواند چیزی در مورد وضعیت شما به ما بگوید، فرض کنید ما

809
00:19:38,130 --> 00:19:40,410
نمی تواند چیزی در مورد وضعیت شما به ما بگوید، فرض کنید ما
 

810
00:19:40,410 --> 00:19:40,420

 

811
00:19:40,420 --> 00:19:43,770

به توزیع جدیدی تعمیم می دهیم و می

812
00:19:43,770 --> 00:19:43,780
به توزیع جدیدی تعمیم می دهیم و می
 

813
00:19:43,780 --> 00:19:45,270
به توزیع جدیدی تعمیم می دهیم و می
دانید که مردم ممکن است فکر کنند  خوب، اما

814
00:19:45,270 --> 00:19:45,280
دانید که مردم ممکن است فکر کنند  خوب، اما
 

815
00:19:45,280 --> 00:19:46,500
دانید که مردم ممکن است فکر کنند  خوب، اما
اگر

816
00:19:46,500 --> 00:19:46,510
اگر
 

817
00:19:46,510 --> 00:19:48,210
اگر
ندانیم توزیع جدید چه خواهد بود، چیزی نمی توانیم بگوییم،

818
00:19:48,210 --> 00:19:48,220
ندانیم توزیع جدید چه خواهد بود، چیزی نمی توانیم بگوییم،
 

819
00:19:48,220 --> 00:19:51,330
ندانیم توزیع جدید چه خواهد بود، چیزی نمی توانیم بگوییم،
حقیقت این است که انسان ها می توانند به

820
00:19:51,330 --> 00:19:51,340
حقیقت این است که انسان ها می توانند به
 

821
00:19:51,340 --> 00:19:54,060
حقیقت این است که انسان ها می توانند به
توزیع های جدید تعمیم دهند، چگونه می

822
00:19:54,060 --> 00:19:54,070
توزیع های جدید تعمیم دهند، چگونه می
 

823
00:19:54,070 --> 00:19:56,010
توزیع های جدید تعمیم دهند، چگونه می
توانیم این کار را انجام دهیم، بله، زیرا

824
00:19:56,010 --> 00:19:56,020
توانیم این کار را انجام دهیم، بله، زیرا
 

825
00:19:56,020 --> 00:19:58,260
توانیم این کار را انجام دهیم، بله، زیرا
چیزی که این توزیع های جدید

826
00:19:58,260 --> 00:19:58,270
چیزی که این توزیع های جدید
 

827
00:19:58,270 --> 00:19:59,520
چیزی که این توزیع های جدید
می توانند بسیار به نظر برسند  متفاوت

828
00:19:59,520 --> 00:19:59,530
می توانند بسیار به نظر برسند  متفاوت
 

829
00:19:59,530 --> 00:20:01,800
می توانند بسیار به نظر برسند  متفاوت
از راه حل های آموزشی آنها

830
00:20:01,800 --> 00:20:01,810
از راه حل های آموزشی آنها
 

831
00:20:01,810 --> 00:20:03,120
از راه حل های آموزشی آنها
چیزهای مشترکی دارند، بنابراین اجازه دهید یک

832
00:20:03,120 --> 00:20:03,130
چیزهای مشترکی دارند، بنابراین اجازه دهید یک
 

833
00:20:03,130 --> 00:20:05,070
چیزهای مشترکی دارند، بنابراین اجازه دهید یک
مثال ملموس به شما بگویم شما یک

834
00:20:05,070 --> 00:20:05,080
مثال ملموس به شما بگویم شما یک
 

835
00:20:05,080 --> 00:20:07,440
مثال ملموس به شما بگویم شما یک
رمان علمی تخیلی بخوانید رمان علمی تخیلی

836
00:20:07,440 --> 00:20:07,450
رمان علمی تخیلی بخوانید رمان علمی تخیلی
 

837
00:20:07,450 --> 00:20:11,850
رمان علمی تخیلی بخوانید رمان علمی تخیلی
شاید می دانید که شما را به سیاره دیگری می آورد

838
00:20:11,850 --> 00:20:11,860
شاید می دانید که شما را به سیاره دیگری می آورد
 

839
00:20:11,860 --> 00:20:14,910
شاید می دانید که شما را به سیاره دیگری می آورد
که در آن همه چیز در سطح بسیار متفاوت به نظر می رسد

840
00:20:14,910 --> 00:20:14,920
که در آن همه چیز در سطح بسیار متفاوت به نظر می رسد
 

841
00:20:14,920 --> 00:20:17,070
که در آن همه چیز در سطح بسیار متفاوت به نظر می رسد
اما هنوز هم همان است

842
00:20:17,070 --> 00:20:17,080
اما هنوز هم همان است
 

843
00:20:17,080 --> 00:20:19,470
اما هنوز هم همان است
قوانین فیزیک بسیار خوب است و بنابراین شما می توانید

844
00:20:19,470 --> 00:20:19,480
قوانین فیزیک بسیار خوب است و بنابراین شما می توانید
 

845
00:20:19,480 --> 00:20:21,090
قوانین فیزیک بسیار خوب است و بنابراین شما می توانید
کتاب را بخوانید و متوجه می شوید که چه اتفاقی می

846
00:20:21,090 --> 00:20:21,100
کتاب را بخوانید و متوجه می شوید که چه اتفاقی می
 

847
00:20:21,100 --> 00:20:22,220
کتاب را بخوانید و متوجه می شوید که چه اتفاقی می
افتد،

848
00:20:22,220 --> 00:20:22,230
افتد،
 

849
00:20:22,230 --> 00:20:24,980
افتد،
بنابراین توزیع بسیار متفاوت است،

850
00:20:24,980 --> 00:20:24,990
بنابراین توزیع بسیار متفاوت است،
 

851
00:20:24,990 --> 00:20:28,530
بنابراین توزیع بسیار متفاوت است،
اما به این دلیل که می توانید بسیاری از

852
00:20:28,530 --> 00:20:28,540
اما به این دلیل که می توانید بسیاری از
 

853
00:20:28,540 --> 00:20:30,360
اما به این دلیل که می توانید بسیاری از
دانش خود را از زمین در مورد روابط

854
00:20:30,360 --> 00:20:30,370
دانش خود را از زمین در مورد روابط
 

855
00:20:30,370 --> 00:20:33,060
دانش خود را از زمین در مورد روابط
علت و معلولی

856
00:20:33,060 --> 00:20:33,070
علت و معلولی
 

857
00:20:33,070 --> 00:20:35,460
علت و معلولی
و مکانیسم های فیزیکی

858
00:20:35,460 --> 00:20:35,470
و مکانیسم های فیزیکی
 

859
00:20:35,470 --> 00:20:37,530
و مکانیسم های فیزیکی
و همه چیز منتقل کنید.  که و شاید حتی

860
00:20:37,530 --> 00:20:37,540
و همه چیز منتقل کنید.  که و شاید حتی
 

861
00:20:37,540 --> 00:20:40,140
و همه چیز منتقل کنید.  که و شاید حتی
تعاملات اجتماعی شما اکنون می توانید

862
00:20:40,140 --> 00:20:40,150
تعاملات اجتماعی شما اکنون می توانید
 

863
00:20:40,150 --> 00:20:41,520
تعاملات اجتماعی شما اکنون می توانید
آنچه را که در این سیاره اتفاق می افتد درک کنید، جایی که

864
00:20:41,520 --> 00:20:41,530
آنچه را که در این سیاره اتفاق می افتد درک کنید، جایی که
 

865
00:20:41,530 --> 00:20:43,320
آنچه را که در این سیاره اتفاق می افتد درک کنید، جایی که
مثلاً از نظر بصری همه چیز

866
00:20:43,320 --> 00:20:43,330
مثلاً از نظر بصری همه چیز
 

867
00:20:43,330 --> 00:20:45,380
مثلاً از نظر بصری همه چیز
کاملاً متفاوت است و

868
00:20:45,380 --> 00:20:45,390
کاملاً متفاوت است و
 

869
00:20:45,390 --> 00:20:47,460
کاملاً متفاوت است و
این قیاس را بیشتر می کند و

870
00:20:47,460 --> 00:20:47,470
این قیاس را بیشتر می کند و
 

871
00:20:47,470 --> 00:20:50,610
این قیاس را بیشتر می کند و
آن را تحریف می کند، بیایید وارد

872
00:20:50,610 --> 00:20:50,620
آن را تحریف می کند، بیایید وارد
 

873
00:20:50,620 --> 00:20:53,580
آن را تحریف می کند، بیایید وارد
دنیای علمی تخیلی نشانه ای شویم تا بگوییم ادیسه فضایی 2001

874
00:20:53,580 --> 00:20:53,590
دنیای علمی تخیلی نشانه ای شویم تا بگوییم ادیسه فضایی 2001
 

875
00:20:53,590 --> 00:20:57,990
دنیای علمی تخیلی نشانه ای شویم تا بگوییم ادیسه فضایی 2001
با جهنم بله.  یا یا شاید که

876
00:20:57,990 --> 00:20:58,000
با جهنم بله.  یا یا شاید که
 

877
00:20:58,000 --> 00:21:00,330
با جهنم بله.  یا یا شاید که
احتمالاً یکی از فیلم‌های مورد علاقه من با هوش مصنوعی است

878
00:21:00,330 --> 00:21:00,340
احتمالاً یکی از فیلم‌های مورد علاقه من با هوش مصنوعی است
 

879
00:21:00,340 --> 00:21:03,390
احتمالاً یکی از فیلم‌های مورد علاقه من با هوش مصنوعی است
و بعد از آن - و سپس یکی دیگر از آن‌ها وجود دارد

880
00:21:03,390 --> 00:21:03,400
و بعد از آن - و سپس یکی دیگر از آن‌ها وجود دارد
 

881
00:21:03,400 --> 00:21:05,010
و بعد از آن - و سپس یکی دیگر از آن‌ها وجود دارد
که بسیاری از مردم دوست دارند که

882
00:21:05,010 --> 00:21:05,020
که بسیاری از مردم دوست دارند که
 

883
00:21:05,020 --> 00:21:07,200
که بسیاری از مردم دوست دارند که
ممکن است کمی خارج از جامعه هوش مصنوعی باشد،

884
00:21:07,200 --> 00:21:07,210
ممکن است کمی خارج از جامعه هوش مصنوعی باشد،
 

885
00:21:07,210 --> 00:21:10,170
ممکن است کمی خارج از جامعه هوش مصنوعی باشد،
درست نمی‌دانم

886
00:21:10,170 --> 00:21:10,180
درست نمی‌دانم
 

887
00:21:10,180 --> 00:21:13,020
درست نمی‌دانم
شما  آن را دیده‌ام بله، اما

888
00:21:13,020 --> 00:21:13,030
شما  آن را دیده‌ام بله، اما
 

889
00:21:13,030 --> 00:21:14,640
شما  آن را دیده‌ام بله، اما
نظر شما در مورد آن فیلم چیست،

890
00:21:14,640 --> 00:21:14,650
نظر شما در مورد آن فیلم چیست،
 

891
00:21:14,650 --> 00:21:17,430
نظر شما در مورد آن فیلم چیست،
آیا می‌توانید چیزهایی را بپوشید که من

892
00:21:17,430 --> 00:21:17,440
آیا می‌توانید چیزهایی را بپوشید که من
 

893
00:21:17,440 --> 00:21:22,530
آیا می‌توانید چیزهایی را بپوشید که من
دوست دارم و از چیزهایی که من متنفرم، بنابراین شاید

894
00:21:22,530 --> 00:21:22,540
دوست دارم و از چیزهایی که من متنفرم، بنابراین شاید
 

895
00:21:22,540 --> 00:21:24,210
دوست دارم و از چیزهایی که من متنفرم، بنابراین شاید
بتوانید در مورد آن در چارچوب

896
00:21:24,210 --> 00:21:24,220
بتوانید در مورد آن در چارچوب
 

897
00:21:24,220 --> 00:21:26,280
بتوانید در مورد آن در چارچوب
سوالی که می‌خواهم بپرسم صحبت کنید.

898
00:21:26,280 --> 00:21:26,290
سوالی که می‌خواهم بپرسم صحبت کنید.
 

899
00:21:26,290 --> 00:21:28,140
سوالی که می‌خواهم بپرسم صحبت کنید.
جامعه بزرگی از

900
00:21:28,140 --> 00:21:28,150
جامعه بزرگی از
 

901
00:21:28,150 --> 00:21:30,750
جامعه بزرگی از
افراد با پیشینه‌های مختلف و اغلب

902
00:21:30,750 --> 00:21:30,760
افراد با پیشینه‌های مختلف و اغلب
 

903
00:21:30,760 --> 00:21:33,000
افراد با پیشینه‌های مختلف و اغلب
خارج از هوش مصنوعی وجود دارد که نگران

904
00:21:33,000 --> 00:21:33,010
خارج از هوش مصنوعی وجود دارد که نگران
 

905
00:21:33,010 --> 00:21:34,710
خارج از هوش مصنوعی وجود دارد که نگران
تهدید وجودی هوش مصنوعی هستند.

906
00:21:34,710 --> 00:21:37,170
تهدید وجودی هوش مصنوعی هستند.
 

907
00:21:37,170 --> 00:21:39,030

 

908
00:21:39,030 --> 00:21:41,790

 

909
00:21:41,790 --> 00:21:41,800

 

910
00:21:41,800 --> 00:21:43,200

روشی برای صحبت در مورد یک

911
00:21:43,200 --> 00:21:43,210
روشی برای صحبت در مورد یک
 

912
00:21:43,210 --> 00:21:45,870
روشی برای صحبت در مورد یک
ایمنی برای فکر کردن در مورد آن برای برگزاری این

913
00:21:45,870 --> 00:21:45,880
ایمنی برای فکر کردن در مورد آن برای برگزاری این
 

914
00:21:45,880 --> 00:21:48,540
ایمنی برای فکر کردن در مورد آن برای برگزاری این
دوره آموزشی در مورد آن در جامعه هوش مصنوعی و

915
00:21:48,540 --> 00:21:48,550
دوره آموزشی در مورد آن در جامعه هوش مصنوعی و
 

916
00:21:48,550 --> 00:21:51,900
دوره آموزشی در مورد آن در جامعه هوش مصنوعی و
خارج از آن و مبتنی بر این واقعیت است که ex

917
00:21:51,900 --> 00:21:51,910
خارج از آن و مبتنی بر این واقعیت است که ex
 

918
00:21:51,910 --> 00:21:53,880
خارج از آن و مبتنی بر این واقعیت است که ex
machina یکی از منابع اصلی

919
00:21:53,880 --> 00:21:53,890
machina یکی از منابع اصلی
 

920
00:21:53,890 --> 00:21:55,800
machina یکی از منابع اصلی
اطلاعات برای عموم مردم در مورد

921
00:21:55,800 --> 00:21:55,810
اطلاعات برای عموم مردم در مورد
 

922
00:21:55,810 --> 00:21:58,170
اطلاعات برای عموم مردم در مورد
هوش مصنوعی است، بنابراین فکر می کنم شما فکر می کنم.  درست بگویم،

923
00:21:58,170 --> 00:21:58,180
هوش مصنوعی است، بنابراین فکر می کنم شما فکر می کنم.  درست بگویم،
 

924
00:21:58,180 --> 00:22:00,080
هوش مصنوعی است، بنابراین فکر می کنم شما فکر می کنم.  درست بگویم،
تفاوت زیادی بین

925
00:22:00,080 --> 00:22:00,090
تفاوت زیادی بین
 

926
00:22:00,090 --> 00:22:03,000
تفاوت زیادی بین
نوع بحثی که باید

927
00:22:03,000 --> 00:22:03,010
نوع بحثی که باید
 

928
00:22:03,010 --> 00:22:06,120
نوع بحثی که باید
در جامعه AG داشته باشیم و نوع

929
00:22:06,120 --> 00:22:06,130
در جامعه AG داشته باشیم و نوع
 

930
00:22:06,130 --> 00:22:07,950
در جامعه AG داشته باشیم و نوع
بحثی که واقعاً برای عموم مردم اهمیت دارد، وجود دارد،

931
00:22:07,950 --> 00:22:09,200
بحثی که واقعاً برای عموم مردم اهمیت دارد، وجود دارد،
 

932
00:22:09,200 --> 00:22:09,210

 

933
00:22:09,210 --> 00:22:12,170

بنابراین من فکر می‌کنم تصویر نابودگر

934
00:22:12,170 --> 00:22:12,180
بنابراین من فکر می‌کنم تصویر نابودگر
 

935
00:22:12,180 --> 00:22:16,790
بنابراین من فکر می‌کنم تصویر نابودگر
و شما می‌دانید که هوش مصنوعی انسان‌ها را از دست می‌دهد

936
00:22:16,790 --> 00:22:16,800
و شما می‌دانید که هوش مصنوعی انسان‌ها را از دست می‌دهد
 

937
00:22:16,800 --> 00:22:19,160
و شما می‌دانید که هوش مصنوعی انسان‌ها را از دست می‌دهد
و می‌کشد.  هوشی که

938
00:22:19,160 --> 00:22:19,170
و می‌کشد.  هوشی که
 

939
00:22:19,170 --> 00:22:22,300
و می‌کشد.  هوشی که
هر چه تلاش کنیم ما را از بین می‌برد، واقعاً

940
00:22:22,300 --> 00:22:22,310
هر چه تلاش کنیم ما را از بین می‌برد، واقعاً
 

941
00:22:22,310 --> 00:22:25,940
هر چه تلاش کنیم ما را از بین می‌برد، واقعاً
برای بحث عمومی مفید نیست،

942
00:22:25,940 --> 00:22:25,950
برای بحث عمومی مفید نیست،
 

943
00:22:25,950 --> 00:22:28,670
برای بحث عمومی مفید نیست،
زیرا برای بحث عمومی

944
00:22:28,670 --> 00:22:28,680
زیرا برای بحث عمومی
 

945
00:22:28,680 --> 00:22:32,330
زیرا برای بحث عمومی
چیزهایی که به اعتقاد من واقعاً مهم هستند،

946
00:22:32,330 --> 00:22:34,550
چیزهایی که به اعتقاد من واقعاً مهم هستند،
 

947
00:22:34,550 --> 00:22:34,560

 

948
00:22:34,560 --> 00:22:36,920

تأثیرات منفی کوتاه‌مدت و کوتاه مدت هوش مصنوعی بر جامعه است،

949
00:22:36,920 --> 00:22:36,930
تأثیرات منفی کوتاه‌مدت و کوتاه مدت هوش مصنوعی بر جامعه است،
 

950
00:22:36,930 --> 00:22:41,120
تأثیرات منفی کوتاه‌مدت و کوتاه مدت هوش مصنوعی بر جامعه است،
چه از نظر امنیتی باشد.  شما

951
00:22:41,120 --> 00:22:41,130
چه از نظر امنیتی باشد.  شما
 

952
00:22:41,130 --> 00:22:42,650
چه از نظر امنیتی باشد.  شما
سناریوهای برادر بزرگ با

953
00:22:42,650 --> 00:22:42,660
سناریوهای برادر بزرگ با
 

954
00:22:42,660 --> 00:22:45,350
سناریوهای برادر بزرگ با
تشخیص چهره یا روبات های قاتل یا

955
00:22:45,350 --> 00:22:45,360
تشخیص چهره یا روبات های قاتل یا
 

956
00:22:45,360 --> 00:22:47,050
تشخیص چهره یا روبات های قاتل یا
تاثیر بر بازار کار یا

957
00:22:47,050 --> 00:22:47,060
تاثیر بر بازار کار یا
 

958
00:22:47,060 --> 00:22:49,160
تاثیر بر بازار کار یا
تمرکز قدرت و

959
00:22:49,160 --> 00:22:49,170
تمرکز قدرت و
 

960
00:22:49,170 --> 00:22:51,290
تمرکز قدرت و
تبعیض انواع

961
00:22:51,290 --> 00:22:51,300
تبعیض انواع
 

962
00:22:51,300 --> 00:22:55,250
تبعیض انواع
مسائل اجتماعی را می شناسید که در واقع برخی از آنها

963
00:22:55,250 --> 00:22:55,260
مسائل اجتماعی را می شناسید که در واقع برخی از آنها
 

964
00:22:55,260 --> 00:22:58,040
مسائل اجتماعی را می شناسید که در واقع برخی از آنها
می توانند واقعاً دموکراسی را تهدید کنند، برای

965
00:22:58,040 --> 00:22:58,050
می توانند واقعاً دموکراسی را تهدید کنند، برای
 

966
00:22:58,050 --> 00:23:00,260
می توانند واقعاً دموکراسی را تهدید کنند، برای
مثال فقط برای روشن شدن اینکه وقتی گفتید

967
00:23:00,260 --> 00:23:00,270
مثال فقط برای روشن شدن اینکه وقتی گفتید
 

968
00:23:00,270 --> 00:23:02,360
مثال فقط برای روشن شدن اینکه وقتی گفتید
ربات های قاتل شما هستند.  منظور از

969
00:23:02,360 --> 00:23:02,370
ربات های قاتل شما هستند.  منظور از
 

970
00:23:02,370 --> 00:23:04,720
ربات های قاتل شما هستند.  منظور از
سلاح های خودمختار بله سیستم های تسلیحاتی بله من

971
00:23:04,720 --> 00:23:04,730
سلاح های خودمختار بله سیستم های تسلیحاتی بله من
 

972
00:23:04,730 --> 00:23:06,800
سلاح های خودمختار بله سیستم های تسلیحاتی بله من
فسخ نمی کنم این درست است،

973
00:23:06,800 --> 00:23:06,810
فسخ نمی کنم این درست است،
 

974
00:23:06,810 --> 00:23:09,170
فسخ نمی کنم این درست است،
بنابراین فکر می کنم این

975
00:23:09,170 --> 00:23:09,180
بنابراین فکر می کنم این
 

976
00:23:09,180 --> 00:23:12,740
بنابراین فکر می کنم این
نگرانی های کوتاه مدت و میان مدت باید

977
00:23:12,740 --> 00:23:12,750
نگرانی های کوتاه مدت و میان مدت باید
 

978
00:23:12,750 --> 00:23:14,050
نگرانی های کوتاه مدت و میان مدت باید
بخش مهمی از بحث عمومی باشد در حال حاضر

979
00:23:14,050 --> 00:23:14,060
بخش مهمی از بحث عمومی باشد در حال حاضر
 

980
00:23:14,060 --> 00:23:17,060
بخش مهمی از بحث عمومی باشد در حال حاضر
خطر وجودی برای من یک

981
00:23:17,060 --> 00:23:17,070
خطر وجودی برای من یک
 

982
00:23:17,070 --> 00:23:22,750
خطر وجودی برای من یک
ملاحظات بسیار بعید است اما هنوز ارزش

983
00:23:22,750 --> 00:23:22,760
ملاحظات بسیار بعید است اما هنوز ارزش
 

984
00:23:22,760 --> 00:23:26,000
ملاحظات بسیار بعید است اما هنوز ارزش
بررسی آکادمیک را دارد.  به روشی

985
00:23:26,000 --> 00:23:26,010
بررسی آکادمیک را دارد.  به روشی
 

986
00:23:26,010 --> 00:23:28,250
بررسی آکادمیک را دارد.  به روشی
که می توانید بگویید آیا

987
00:23:28,250 --> 00:23:28,260
که می توانید بگویید آیا
 

988
00:23:28,260 --> 00:23:31,280
که می توانید بگویید آیا
اگر شهاب سنگی که می دانید

989
00:23:31,280 --> 00:23:31,290
اگر شهاب سنگی که می دانید
 

990
00:23:31,290 --> 00:23:33,080
اگر شهاب سنگی که می دانید
به زمین بیاید و آن را نابود کند، باید مطالعه کنیم چه اتفاقی می افتد، بنابراین من فکر می کنم

991
00:23:33,080 --> 00:23:33,090
به زمین بیاید و آن را نابود کند، باید مطالعه کنیم چه اتفاقی می افتد، بنابراین من فکر می کنم
 

992
00:23:33,090 --> 00:23:34,670
به زمین بیاید و آن را نابود کند، باید مطالعه کنیم چه اتفاقی می افتد، بنابراین من فکر می کنم
خیلی بعید است که این

993
00:23:34,670 --> 00:23:34,680
خیلی بعید است که این
 

994
00:23:34,680 --> 00:23:37,160
خیلی بعید است که این
اتفاق بیفتد و یا در آینده ای معقول اتفاق بیفتد،

995
00:23:37,160 --> 00:23:37,170
اتفاق بیفتد و یا در آینده ای معقول اتفاق بیفتد،
 

996
00:23:37,170 --> 00:23:41,060
اتفاق بیفتد و یا در آینده ای معقول اتفاق بیفتد،
این همان

997
00:23:41,060 --> 00:23:41,070
این همان
 

998
00:23:41,070 --> 00:23:43,970
این همان
سناریویی است که  سست شدن هوش مصنوعی بر

999
00:23:43,970 --> 00:23:43,980
سناریویی است که  سست شدن هوش مصنوعی بر
 

1000
00:23:43,980 --> 00:23:45,530
سناریویی است که  سست شدن هوش مصنوعی بر
خلاف درک من از حداقل

1001
00:23:45,530 --> 00:23:45,540
خلاف درک من از حداقل
 

1002
00:23:45,540 --> 00:23:47,120
خلاف درک من از حداقل
یادگیری ماشینی فعلی و

1003
00:23:47,120 --> 00:23:47,130
یادگیری ماشینی فعلی و
 

1004
00:23:47,130 --> 00:23:49,220
یادگیری ماشینی فعلی و
شبکه های عصبی فعلی و غیره است که برای من قابل قبول نیست،

1005
00:23:49,220 --> 00:23:49,230
شبکه های عصبی فعلی و غیره است که برای من قابل قبول نیست،
 

1006
00:23:49,230 --> 00:23:51,230
شبکه های عصبی فعلی و غیره است که برای من قابل قبول نیست،
اما البته من یک

1007
00:23:51,230 --> 00:23:51,240
اما البته من یک
 

1008
00:23:51,240 --> 00:23:53,120
اما البته من یک
توپ کریستالی ندارم و چه کسی می داند که

1009
00:23:53,120 --> 00:23:53,130
توپ کریستالی ندارم و چه کسی می داند که
 

1010
00:23:53,130 --> 00:23:55,010
توپ کریستالی ندارم و چه کسی می داند که
در پنجاه سال آینده چگونه خواهم شد.  من فکر می کنم

1011
00:23:55,010 --> 00:23:55,020
در پنجاه سال آینده چگونه خواهم شد.  من فکر می کنم
 

1012
00:23:55,020 --> 00:23:56,720
در پنجاه سال آینده چگونه خواهم شد.  من فکر می کنم
ارزش دارد که دانشمندان این مشکلات را مطالعه کنند و

1013
00:23:56,720 --> 00:23:58,700
ارزش دارد که دانشمندان این مشکلات را مطالعه کنند و
 

1014
00:23:58,700 --> 00:23:58,710

 

1015
00:23:58,710 --> 00:24:01,570

تا آنجا که به من مربوط می شود یک سوال مبرم نیست، بنابراین

1016
00:24:01,570 --> 00:24:01,580
تا آنجا که به من مربوط می شود یک سوال مبرم نیست، بنابراین
 

1017
00:24:01,580 --> 00:24:04,190
تا آنجا که به من مربوط می شود یک سوال مبرم نیست، بنابراین
قبل از ادامه خط چند

1018
00:24:04,190 --> 00:24:04,200
قبل از ادامه خط چند
 

1019
00:24:04,200 --> 00:24:07,520
قبل از ادامه خط چند
سوال در آنجا وجود دارد، اما چه چیزی را

1020
00:24:07,520 --> 00:24:07,530
سوال در آنجا وجود دارد، اما چه چیزی را
 

1021
00:24:07,530 --> 00:24:09,590
سوال در آنجا وجود دارد، اما چه چیزی را
در مورد ex machina به عنوان یک فیلم دوست دارید و چه چیزی را دوست ندارید

1022
00:24:09,590 --> 00:24:09,600
در مورد ex machina به عنوان یک فیلم دوست دارید و چه چیزی را دوست ندارید
 

1023
00:24:09,600 --> 00:24:11,450
در مورد ex machina به عنوان یک فیلم دوست دارید و چه چیزی را دوست ندارید
زیرا من من  در واقع برای بار دوم آن را تماشا کردم

1024
00:24:11,450 --> 00:24:11,460
زیرا من من  در واقع برای بار دوم آن را تماشا کردم
 

1025
00:24:11,460 --> 00:24:14,090
زیرا من من  در واقع برای بار دوم آن را تماشا کردم
و از آن لذت بردم.

1026
00:24:14,090 --> 00:24:14,100
و از آن لذت بردم.
 

1027
00:24:14,100 --> 00:24:17,090
و از آن لذت بردم.
بار اول از آن متنفر بودم و

1028
00:24:17,090 --> 00:24:17,100
بار اول از آن متنفر بودم و
 

1029
00:24:17,100 --> 00:24:18,800
بار اول از آن متنفر بودم و
بار دوم که به نوعی

1030
00:24:18,800 --> 00:24:18,810
بار دوم که به نوعی
 

1031
00:24:18,810 --> 00:24:21,090
بار دوم که به نوعی
یاد گرفتم

1032
00:24:21,090 --> 00:24:21,100
یاد گرفتم
 

1033
00:24:21,100 --> 00:24:25,470
یاد گرفتم
قطعات خاصی از آن را بپذیرم CC یک فیلم مفهومی است

1034
00:24:25,470 --> 00:24:25,480
قطعات خاصی از آن را بپذیرم CC یک فیلم مفهومی است
 

1035
00:24:25,480 --> 00:24:26,610
قطعات خاصی از آن را بپذیرم CC یک فیلم مفهومی است
سلام تجربه شما چه بود.

1036
00:24:26,610 --> 00:24:26,620
سلام تجربه شما چه بود.
 

1037
00:24:26,620 --> 00:24:29,760
سلام تجربه شما چه بود.
لورا افکار شما پس

1038
00:24:29,760 --> 00:24:29,770
لورا افکار شما پس
 

1039
00:24:29,770 --> 00:24:34,919
لورا افکار شما پس
منفی است تصویری که از علم ترسیم می کند، علم

1040
00:24:34,919 --> 00:24:34,929
منفی است تصویری که از علم ترسیم می کند، علم
 

1041
00:24:34,929 --> 00:24:38,549
منفی است تصویری که از علم ترسیم می کند، علم
به طور کلی اشتباه است

1042
00:24:38,549 --> 00:24:38,559
به طور کلی اشتباه است
 

1043
00:24:38,559 --> 00:24:41,130
به طور کلی اشتباه است
و علم هوش مصنوعی به طور خاص علم

1044
00:24:41,130 --> 00:24:41,140
و علم هوش مصنوعی به طور خاص علم
 

1045
00:24:41,140 --> 00:24:45,810
و علم هوش مصنوعی به طور خاص علم
در مکانی پنهان اتفاق نمی افتد توسط

1046
00:24:45,810 --> 00:24:45,820
در مکانی پنهان اتفاق نمی افتد توسط
 

1047
00:24:45,820 --> 00:24:48,900
در مکانی پنهان اتفاق نمی افتد توسط
برخی شما می شناسید واقعاً مرد باهوش یک

1048
00:24:48,900 --> 00:24:48,910
برخی شما می شناسید واقعاً مرد باهوش یک
 

1049
00:24:48,910 --> 00:24:50,130
برخی شما می شناسید واقعاً مرد باهوش یک
نفر یک نفر

1050
00:24:50,130 --> 00:24:50,140
نفر یک نفر
 

1051
00:24:50,140 --> 00:24:52,500
نفر یک نفر
این کاملا غیر واقعی است، این نیست

1052
00:24:52,500 --> 00:24:52,510
این کاملا غیر واقعی است، این نیست
 

1053
00:24:52,510 --> 00:24:53,570
این کاملا غیر واقعی است، این نیست
چگونه اتفاق می افتد،

1054
00:24:53,570 --> 00:24:53,580
چگونه اتفاق می افتد،
 

1055
00:24:53,580 --> 00:24:57,120
چگونه اتفاق می افتد،
حتی یک تیم از مردم در یک مکان منزوی،

1056
00:24:57,120 --> 00:24:59,060
حتی یک تیم از مردم در یک مکان منزوی،
 

1057
00:24:59,060 --> 00:24:59,070

 

1058
00:24:59,070 --> 00:25:02,430

به لطف

1059
00:25:02,430 --> 00:25:02,440
به لطف
 

1060
00:25:02,440 --> 00:25:07,350
به لطف
همکاری و اجتماع

1061
00:25:07,350 --> 00:25:07,360
همکاری و اجتماع
 

1062
00:25:07,360 --> 00:25:10,880
همکاری و اجتماع
تعداد زیادی از مردم در تعامل و

1063
00:25:10,880 --> 00:25:10,890
تعداد زیادی از مردم در تعامل و
 

1064
00:25:10,890 --> 00:25:12,260
تعداد زیادی از مردم در تعامل و
[موسیقی]

1065
00:25:12,260 --> 00:25:12,270
[موسیقی]
 

1066
00:25:12,270 --> 00:25:14,730
[موسیقی]
همه دانشمندانی که در

1067
00:25:14,730 --> 00:25:14,740
همه دانشمندانی که در
 

1068
00:25:14,740 --> 00:25:16,380
همه دانشمندانی که در
زمینه خود متخصص هستند Canon Oh What

1069
00:25:16,380 --> 00:25:16,390
زمینه خود متخصص هستند Canon Oh What
 

1070
00:25:16,390 --> 00:25:19,220
زمینه خود متخصص هستند Canon Oh What
حتی در آزمایشگاه‌های صنعتی نیز

1071
00:25:19,220 --> 00:25:19,230
حتی در آزمایشگاه‌های صنعتی نیز
 

1072
00:25:19,230 --> 00:25:21,870
حتی در آزمایشگاه‌های صنعتی نیز
جریان دارد و اطلاعاتش درز می‌کند و غیره

1073
00:25:21,870 --> 00:25:24,480
جریان دارد و اطلاعاتش درز می‌کند و غیره
 

1074
00:25:24,480 --> 00:25:27,120

 

1075
00:25:27,120 --> 00:25:29,370

 

1076
00:25:29,370 --> 00:25:31,980

 

1077
00:25:31,980 --> 00:25:31,990

 

1078
00:25:31,990 --> 00:25:34,919

تا اینجا بله،

1079
00:25:34,919 --> 00:25:34,929
تا اینجا بله،
 

1080
00:25:34,929 --> 00:25:36,480
تا اینجا بله،
حتی اگر تحقیق در داخل

1081
00:25:36,480 --> 00:25:36,490
حتی اگر تحقیق در داخل
 

1082
00:25:36,490 --> 00:25:38,220
حتی اگر تحقیق در داخل
گوگل یا فیس بوک در داخل شرکت ها انجام شود،

1083
00:25:38,220 --> 00:25:38,230
گوگل یا فیس بوک در داخل شرکت ها انجام شود،
 

1084
00:25:38,230 --> 00:25:40,680
گوگل یا فیس بوک در داخل شرکت ها انجام شود،
باز هم به گونه ای ظاهر می شود که بله،

1085
00:25:40,680 --> 00:25:40,690
باز هم به گونه ای ظاهر می شود که بله،
 

1086
00:25:40,690 --> 00:25:42,240
باز هم به گونه ای ظاهر می شود که بله،
کاملا فکر می کنم که همیشه همین طور خواهد بود،

1087
00:25:42,240 --> 00:25:42,250
کاملا فکر می کنم که همیشه همین طور خواهد بود،
 

1088
00:25:42,250 --> 00:25:43,890
کاملا فکر می کنم که همیشه همین طور خواهد بود،
بنابراین من می توانم

1089
00:25:43,890 --> 00:25:43,900
بنابراین من می توانم
 

1090
00:25:43,900 --> 00:25:48,210
بنابراین من می توانم
ایده ها را تا جایی که بطری می کنیم، جمع آوری کنیم.

1091
00:25:48,210 --> 00:25:48,220
ایده ها را تا جایی که بطری می کنیم، جمع آوری کنیم.
 

1092
00:25:48,220 --> 00:25:49,620
ایده ها را تا جایی که بطری می کنیم، جمع آوری کنیم.
مجموعه‌ای از پیشرفت‌ها وجود دارد که

1093
00:25:49,620 --> 00:25:49,630
مجموعه‌ای از پیشرفت‌ها وجود دارد که
 

1094
00:25:49,630 --> 00:25:51,810
مجموعه‌ای از پیشرفت‌ها وجود دارد که
توسط جامعه تحقیقاتی عمومی کاملاً کشف نشده است،

1095
00:25:51,810 --> 00:25:51,820
توسط جامعه تحقیقاتی عمومی کاملاً کشف نشده است،
 

1096
00:25:51,820 --> 00:25:53,070
توسط جامعه تحقیقاتی عمومی کاملاً کشف نشده است،
آیا فکر می‌کنید که حتی

1097
00:25:53,070 --> 00:25:53,080
آیا فکر می‌کنید که حتی
 

1098
00:25:53,080 --> 00:25:56,640
آیا فکر می‌کنید که حتی
امکان‌پذیر است، اما

1099
00:25:56,640 --> 00:25:56,650
امکان‌پذیر است، اما
 

1100
00:25:56,650 --> 00:26:00,120
امکان‌پذیر است، اما
بعید به نظر می‌رسد که اینطور نیست که اکنون انجام می‌شود،

1101
00:26:00,120 --> 00:26:00,130
بعید به نظر می‌رسد که اینطور نیست که اکنون انجام می‌شود،
 

1102
00:26:00,130 --> 00:26:03,419
بعید به نظر می‌رسد که اینطور نیست که اکنون انجام می‌شود،
اینطور نیست که بتوانم آن را در

1103
00:26:03,419 --> 00:26:03,429
اینطور نیست که بتوانم آن را در
 

1104
00:26:03,429 --> 00:26:06,810
اینطور نیست که بتوانم آن را در
آینده قابل پیش‌بینی پیش‌بینی کنم، اما البته نمی‌توانم آن را پیش‌بینی کنم.  من

1105
00:26:06,810 --> 00:26:06,820
آینده قابل پیش‌بینی پیش‌بینی کنم، اما البته نمی‌توانم آن را پیش‌بینی کنم.  من
 

1106
00:26:06,820 --> 00:26:12,720
آینده قابل پیش‌بینی پیش‌بینی کنم، اما البته نمی‌توانم آن را پیش‌بینی کنم.  من
یک توپ کریستالی ندارم و پس چه کسی می داند که

1107
00:26:12,720 --> 00:26:12,730
یک توپ کریستالی ندارم و پس چه کسی می داند که
 

1108
00:26:12,730 --> 00:26:15,480
یک توپ کریستالی ندارم و پس چه کسی می داند که
این یک داستان علمی تخیلی است،

1109
00:26:15,480 --> 00:26:15,490
این یک داستان علمی تخیلی است،
 

1110
00:26:15,490 --> 00:26:17,220
این یک داستان علمی تخیلی است،
اما معمولاً شوم خاموش

1111
00:26:17,220 --> 00:26:17,230
اما معمولاً شوم خاموش
 

1112
00:26:17,230 --> 00:26:20,450
اما معمولاً شوم خاموش
شدن چراغ ها در طول آن بحث است،

1113
00:26:20,450 --> 00:26:20,460
شدن چراغ ها در طول آن بحث است،
 

1114
00:26:20,460 --> 00:26:23,340
شدن چراغ ها در طول آن بحث است،
بنابراین مشکل دوباره اینجاست که می دانید

1115
00:26:23,340 --> 00:26:23,350
بنابراین مشکل دوباره اینجاست که می دانید
 

1116
00:26:23,350 --> 00:26:24,600
بنابراین مشکل دوباره اینجاست که می دانید
یک چیز فیلم است و می توانید

1117
00:26:24,600 --> 00:26:24,610
یک چیز فیلم است و می توانید
 

1118
00:26:24,610 --> 00:26:26,159
یک چیز فیلم است و می توانید
همه نوع فیلم را تصور کنید.  داستان علمی تخیلی

1119
00:26:26,159 --> 00:26:26,169
همه نوع فیلم را تصور کنید.  داستان علمی تخیلی
 

1120
00:26:26,169 --> 00:26:28,620
همه نوع فیلم را تصور کنید.  داستان علمی تخیلی
مشکلی که برای من وجود ندارد ممکن است شبیه

1121
00:26:28,620 --> 00:26:28,630
مشکلی که برای من وجود ندارد ممکن است شبیه
 

1122
00:26:28,630 --> 00:26:30,270
مشکلی که برای من وجود ندارد ممکن است شبیه
به سوال در مورد خطر وجودی باشد این است

1123
00:26:30,270 --> 00:26:30,280
به سوال در مورد خطر وجودی باشد این است
 

1124
00:26:30,280 --> 00:26:34,710
به سوال در مورد خطر وجودی باشد این است
که این نوع فیلم دردناک است،

1125
00:26:34,710 --> 00:26:34,720
که این نوع فیلم دردناک است،
 

1126
00:26:34,720 --> 00:26:37,529
که این نوع فیلم دردناک است،
تصویر اشتباهی از آنچه واقعی است

1127
00:26:37,529 --> 00:26:37,539
تصویر اشتباهی از آنچه واقعی است
 

1128
00:26:37,539 --> 00:26:40,080
تصویر اشتباهی از آنچه واقعی است
شما علم واقعی را می دانید و چگونه

1129
00:26:40,080 --> 00:26:40,090
شما علم واقعی را می دانید و چگونه
 

1130
00:26:40,090 --> 00:26:42,510
شما علم واقعی را می دانید و چگونه
اتفاق می افتد که می تواند

1131
00:26:42,510 --> 00:26:42,520
اتفاق می افتد که می تواند
 

1132
00:26:42,520 --> 00:26:44,220
اتفاق می افتد که می تواند
اثرات ناگواری داشته باشد.  بر

1133
00:26:44,220 --> 00:26:44,230
اثرات ناگواری داشته باشد.  بر
 

1134
00:26:44,230 --> 00:26:47,370
اثرات ناگواری داشته باشد.  بر
درک مردم از علم روز و

1135
00:26:47,370 --> 00:26:47,380
درک مردم از علم روز و
 

1136
00:26:47,380 --> 00:26:51,510
درک مردم از علم روز و
بنابراین تا حدی غم انگیز است که آیا این یک

1137
00:26:51,510 --> 00:26:51,520
بنابراین تا حدی غم انگیز است که آیا این یک
 

1138
00:26:51,520 --> 00:26:55,860
بنابراین تا حدی غم انگیز است که آیا این یک
اصل مهم در تحقیق است که تنوع است،

1139
00:26:55,860 --> 00:26:55,870
اصل مهم در تحقیق است که تنوع است،
 

1140
00:26:55,870 --> 00:26:58,590
اصل مهم در تحقیق است که تنوع است،
به عبارت دیگر تحقیق

1141
00:26:58,590 --> 00:26:58,600
به عبارت دیگر تحقیق
 

1142
00:26:58,600 --> 00:27:00,600
به عبارت دیگر تحقیق
انفجار منابع اکتشافی در

1143
00:27:00,600 --> 00:27:00,610
انفجار منابع اکتشافی در
 

1144
00:27:00,610 --> 00:27:03,029
انفجار منابع اکتشافی در
فضای ایده ها است و افراد مختلف

1145
00:27:03,029 --> 00:27:03,039
فضای ایده ها است و افراد مختلف
 

1146
00:27:03,039 --> 00:27:05,399
فضای ایده ها است و افراد مختلف
به جهات مختلف توجه می کنند و این

1147
00:27:05,399 --> 00:27:05,409
به جهات مختلف توجه می کنند و این
 

1148
00:27:05,409 --> 00:27:09,149
به جهات مختلف توجه می کنند و این
فقط نیست.  خوب، ضروری است، بنابراین

1149
00:27:09,149 --> 00:27:09,159
فقط نیست.  خوب، ضروری است، بنابراین
 

1150
00:27:09,159 --> 00:27:12,270
فقط نیست.  خوب، ضروری است، بنابراین
با افرادی که

1151
00:27:12,270 --> 00:27:12,280
با افرادی که
 

1152
00:27:12,280 --> 00:27:14,909
با افرادی که
مسیرهایی را که مغایر با مسیر من هستند یا

1153
00:27:14,909 --> 00:27:14,919
مسیرهایی را که مغایر با مسیر من هستند یا
 

1154
00:27:14,919 --> 00:27:19,890
مسیرهایی را که مغایر با مسیر من هستند یا
متعامد به نظر می رسند را بررسی می کنند،

1155
00:27:19,890 --> 00:27:22,260
متعامد به نظر می رسند را بررسی می کنند،
 

1156
00:27:22,260 --> 00:27:24,990

 

1157
00:27:24,990 --> 00:27:25,000

 

1158
00:27:25,000 --> 00:27:26,789

کاملاً خوب هستم.

1159
00:27:26,789 --> 00:27:26,799
کاملاً خوب هستم.
 

1160
00:27:26,799 --> 00:27:29,190
کاملاً خوب هستم.
در آینده چه اتفاقی می‌افتد، حالا که

1161
00:27:29,190 --> 00:27:29,200
در آینده چه اتفاقی می‌افتد، حالا که
 

1162
00:27:29,200 --> 00:27:31,770
در آینده چه اتفاقی می‌افتد، حالا که
گفته می‌شود ما شهود خود را داریم و

1163
00:27:31,770 --> 00:27:31,780
گفته می‌شود ما شهود خود را داریم و
 

1164
00:27:31,780 --> 00:27:35,039
گفته می‌شود ما شهود خود را داریم و
سپس بر اساس آن عمل می‌کنیم که

1165
00:27:35,039 --> 00:27:35,049
سپس بر اساس آن عمل می‌کنیم که
 

1166
00:27:35,049 --> 00:27:37,799
سپس بر اساس آن عمل می‌کنیم که
فکر می‌کنیم در کجا می‌توانیم بیشترین سود را داشته باشیم و در

1167
00:27:37,799 --> 00:27:37,809
فکر می‌کنیم در کجا می‌توانیم بیشترین سود را داشته باشیم و در
 

1168
00:27:37,809 --> 00:27:39,600
فکر می‌کنیم در کجا می‌توانیم بیشترین سود را داشته باشیم و در
کجا جامعه بیشترین سود یا

1169
00:27:39,600 --> 00:27:39,610
کجا جامعه بیشترین سود یا
 

1170
00:27:39,610 --> 00:27:43,640
کجا جامعه بیشترین سود یا
ضرر را دارد، باید آن بحث‌ها و

1171
00:27:43,640 --> 00:27:43,650
ضرر را دارد، باید آن بحث‌ها و
 

1172
00:27:43,650 --> 00:27:47,340
ضرر را دارد، باید آن بحث‌ها و
و و و نه پایان یابد.  در جامعه‌ای

1173
00:27:47,340 --> 00:27:47,350
و و و نه پایان یابد.  در جامعه‌ای
 

1174
00:27:47,350 --> 00:27:49,350
و و و نه پایان یابد.  در جامعه‌ای
که تنها یک صدا و یک طرز

1175
00:27:49,350 --> 00:27:49,360
که تنها یک صدا و یک طرز
 

1176
00:27:49,360 --> 00:27:52,919
که تنها یک صدا و یک طرز
تفکر در تحقیق وجود دارد، پول پراکنده است،

1177
00:27:52,919 --> 00:27:52,929
تفکر در تحقیق وجود دارد، پول پراکنده است،
 

1178
00:27:52,929 --> 00:27:57,990
تفکر در تحقیق وجود دارد، پول پراکنده است،
بنابراین اختلاف نظر نشانه یک

1179
00:27:57,990 --> 00:27:58,000
بنابراین اختلاف نظر نشانه یک
 

1180
00:27:58,000 --> 00:28:01,919
بنابراین اختلاف نظر نشانه یک
تحقیق خوب علم خوب است، بنابراین بله، ایده

1181
00:28:01,919 --> 00:28:01,929
تحقیق خوب علم خوب است، بنابراین بله، ایده
 

1182
00:28:01,929 --> 00:28:04,820
تحقیق خوب علم خوب است، بنابراین بله، ایده
سوگیری در معنای انسانی تعصب بله،

1183
00:28:04,820 --> 00:28:04,830
سوگیری در معنای انسانی تعصب بله،
 

1184
00:28:04,830 --> 00:28:08,310
سوگیری در معنای انسانی تعصب بله،
شما در مورد القا کردن چگونه فکر می‌کنید؟  در

1185
00:28:08,310 --> 00:28:08,320
شما در مورد القا کردن چگونه فکر می‌کنید؟  در
 

1186
00:28:08,320 --> 00:28:10,470
شما در مورد القا کردن چگونه فکر می‌کنید؟  در
یادگیری ماشینی چیزی که

1187
00:28:10,470 --> 00:28:10,480
یادگیری ماشینی چیزی که
 

1188
00:28:10,480 --> 00:28:13,260
یادگیری ماشینی چیزی که
از نظر سوگیری با ارزش‌های انسانی همسو است،

1189
00:28:13,260 --> 00:28:13,270
از نظر سوگیری با ارزش‌های انسانی همسو است،
 

1190
00:28:13,270 --> 00:28:15,750
از نظر سوگیری با ارزش‌های انسانی همسو است،
ما و انسان‌ها به طور شهودی این

1191
00:28:15,750 --> 00:28:15,760
ما و انسان‌ها به طور شهودی این
 

1192
00:28:15,760 --> 00:28:17,789
ما و انسان‌ها به طور شهودی این
مفهوم را داریم که تعصب به چه معناست که

1193
00:28:17,789 --> 00:28:17,799
مفهوم را داریم که تعصب به چه معناست که
 

1194
00:28:17,799 --> 00:28:21,240
مفهوم را داریم که تعصب به چه معناست که
احترام اساسی به انسان‌های دیگر به چه

1195
00:28:21,240 --> 00:28:21,250
احترام اساسی به انسان‌های دیگر به چه
 

1196
00:28:21,250 --> 00:28:23,580
احترام اساسی به انسان‌های دیگر به چه
معناست، اما به نظر شما چگونه می‌توانیم آن را

1197
00:28:23,580 --> 00:28:23,590
معناست، اما به نظر شما چگونه می‌توانیم آن را
 

1198
00:28:23,590 --> 00:28:25,140
معناست، اما به نظر شما چگونه می‌توانیم آن را
در سیستم‌های یادگیری ماشین القا کنیم.

1199
00:28:25,140 --> 00:28:28,560
در سیستم‌های یادگیری ماشین القا کنیم.
 

1200
00:28:28,560 --> 00:28:28,570

 

1201
00:28:28,570 --> 00:28:31,620

چیزهای کوتاه‌مدتی هستند که در حال حاضر اتفاق می‌افتند و

1202
00:28:31,620 --> 00:28:31,630
چیزهای کوتاه‌مدتی هستند که در حال حاضر اتفاق می‌افتند و
 

1203
00:28:31,630 --> 00:28:33,419
چیزهای کوتاه‌مدتی هستند که در حال حاضر اتفاق می‌افتند و
سپس کارهای بلندمدتی وجود دارد که

1204
00:28:33,419 --> 00:28:33,429
سپس کارهای بلندمدتی وجود دارد که
 

1205
00:28:33,429 --> 00:28:36,840
سپس کارهای بلندمدتی وجود دارد که
باید انجام دهیم و در کوتاه‌مدت

1206
00:28:36,840 --> 00:28:36,850
باید انجام دهیم و در کوتاه‌مدت
 

1207
00:28:36,850 --> 00:28:39,240
باید انجام دهیم و در کوتاه‌مدت
تکنیک‌هایی وجود دارد که پیشنهاد شده‌اند و

1208
00:28:39,240 --> 00:28:39,250
تکنیک‌هایی وجود دارد که پیشنهاد شده‌اند و
 

1209
00:28:39,250 --> 00:28:41,100
تکنیک‌هایی وجود دارد که پیشنهاد شده‌اند و
فکر می‌کنم همچنان بهبود خواهند یافت و

1210
00:28:41,100 --> 00:28:41,110
فکر می‌کنم همچنان بهبود خواهند یافت و
 

1211
00:28:41,110 --> 00:28:43,740
فکر می‌کنم همچنان بهبود خواهند یافت و
شاید جایگزین‌هایی برای آن‌ها پیش بیاید.

1212
00:28:43,740 --> 00:28:43,750
شاید جایگزین‌هایی برای آن‌ها پیش بیاید.
 

1213
00:28:43,750 --> 00:28:46,770
شاید جایگزین‌هایی برای آن‌ها پیش بیاید.
مجموعه داده هایی که در آن ها می دانیم سوگیری وجود دارد، می

1214
00:28:46,770 --> 00:28:46,780
مجموعه داده هایی که در آن ها می دانیم سوگیری وجود دارد، می
 

1215
00:28:46,780 --> 00:28:49,919
مجموعه داده هایی که در آن ها می دانیم سوگیری وجود دارد، می
توانیم آن را تقریباً هر

1216
00:28:49,919 --> 00:28:49,929
توانیم آن را تقریباً هر
 

1217
00:28:49,929 --> 00:28:51,750
توانیم آن را تقریباً هر
مجموعه داده ای که در آن انسان ها حضور دارند اندازه گیری کنیم.

1218
00:28:51,750 --> 00:28:53,700
مجموعه داده ای که در آن انسان ها حضور دارند اندازه گیری کنیم.
 

1219
00:28:53,700 --> 00:28:55,770

 

1220
00:28:55,770 --> 00:28:59,399

 

1221
00:28:59,399 --> 00:29:01,440

 

1222
00:29:01,440 --> 00:29:01,450

 

1223
00:29:01,450 --> 00:29:04,409

طبقه‌بندی‌کننده‌های پیش‌بینی‌کننده‌ای که

1224
00:29:04,409 --> 00:29:04,419
طبقه‌بندی‌کننده‌های پیش‌بینی‌کننده‌ای که
 

1225
00:29:04,419 --> 00:29:09,180
طبقه‌بندی‌کننده‌های پیش‌بینی‌کننده‌ای که
قرار است سوگیری کمتری داشته باشند، می‌توانیم آن را انجام دهیم، به

1226
00:29:09,180 --> 00:29:09,190
قرار است سوگیری کمتری داشته باشند، می‌توانیم آن را انجام دهیم، به
 

1227
00:29:09,190 --> 00:29:11,669
قرار است سوگیری کمتری داشته باشند، می‌توانیم آن را انجام دهیم، به
عنوان مثال، با استفاده از روش‌های متخاصم برای اینکه

1228
00:29:11,669 --> 00:29:11,679
عنوان مثال، با استفاده از روش‌های متخاصم برای اینکه
 

1229
00:29:11,679 --> 00:29:15,210
عنوان مثال، با استفاده از روش‌های متخاصم برای اینکه
سیستم‌هایمان نسبت به این متغیرها حساسیت کمتری داشته باشند،

1230
00:29:15,210 --> 00:29:15,220
سیستم‌هایمان نسبت به این متغیرها حساسیت کمتری داشته باشند،
 

1231
00:29:15,220 --> 00:29:17,760
سیستم‌هایمان نسبت به این متغیرها حساسیت کمتری داشته باشند،
ما نباید به آن‌ها حساس باشیم،

1232
00:29:17,760 --> 00:29:17,770
ما نباید به آن‌ها حساس باشیم،
 

1233
00:29:17,770 --> 00:29:20,850
ما نباید به آن‌ها حساس باشیم،
بنابراین اینها راه‌های کاملاً تعریف‌شده‌ای برای

1234
00:29:20,850 --> 00:29:20,860
بنابراین اینها راه‌های کاملاً تعریف‌شده‌ای برای
 

1235
00:29:20,860 --> 00:29:22,649
بنابراین اینها راه‌های کاملاً تعریف‌شده‌ای برای
تلاش برای رسیدگی به مشکلی هستند که ممکن است

1236
00:29:22,649 --> 00:29:22,659
تلاش برای رسیدگی به مشکلی هستند که ممکن است
 

1237
00:29:22,659 --> 00:29:24,330
تلاش برای رسیدگی به مشکلی هستند که ممکن است
داشته باشند.  نقاط ضعف و می دانید

1238
00:29:24,330 --> 00:29:24,340
داشته باشند.  نقاط ضعف و می دانید
 

1239
00:29:24,340 --> 00:29:26,669
داشته باشند.  نقاط ضعف و می دانید
تحقیقات بیشتری مورد نیاز است و غیره، اما من فکر می کنم

1240
00:29:26,669 --> 00:29:26,679
تحقیقات بیشتری مورد نیاز است و غیره، اما من فکر می کنم
 

1241
00:29:26,679 --> 00:29:28,039
تحقیقات بیشتری مورد نیاز است و غیره، اما من فکر می کنم
در واقع آنها به اندازه کافی بالغ هستند

1242
00:29:28,039 --> 00:29:28,049
در واقع آنها به اندازه کافی بالغ هستند
 

1243
00:29:28,049 --> 00:29:31,529
در واقع آنها به اندازه کافی بالغ هستند
که دولت ها باید شروع به تنظیم

1244
00:29:31,529 --> 00:29:31,539
که دولت ها باید شروع به تنظیم
 

1245
00:29:31,539 --> 00:29:33,720
که دولت ها باید شروع به تنظیم
شرکت ها در جایی که مهم است مانند

1246
00:29:33,720 --> 00:29:33,730
شرکت ها در جایی که مهم است مانند
 

1247
00:29:33,730 --> 00:29:36,029
شرکت ها در جایی که مهم است مانند
شرکت های بیمه کنند تا از

1248
00:29:36,029 --> 00:29:36,039
شرکت های بیمه کنند تا از
 

1249
00:29:36,039 --> 00:29:37,919
شرکت های بیمه کنند تا از
این تکنیک ها استفاده کنند زیرا این

1250
00:29:37,919 --> 00:29:37,929
این تکنیک ها استفاده کنند زیرا این
 

1251
00:29:37,929 --> 00:29:42,270
این تکنیک ها استفاده کنند زیرا این
تکنیک ها باعث تعصب می شود اما با

1252
00:29:42,270 --> 00:29:42,280
تکنیک ها باعث تعصب می شود اما با
 

1253
00:29:42,280 --> 00:29:44,159
تکنیک ها باعث تعصب می شود اما با
هزینه.  به عنوان مثال، شاید

1254
00:29:44,159 --> 00:29:44,169
هزینه.  به عنوان مثال، شاید
 

1255
00:29:44,169 --> 00:29:46,049
هزینه.  به عنوان مثال، شاید
پیش‌بینی‌های آنها کمتر دقیق باشد و بنابراین

1256
00:29:46,049 --> 00:29:46,059
پیش‌بینی‌های آنها کمتر دقیق باشد و بنابراین
 

1257
00:29:46,059 --> 00:29:47,760
پیش‌بینی‌های آنها کمتر دقیق باشد و بنابراین
شرکت‌ها این کار را انجام نمی‌دهند تا زمانی که

1258
00:29:47,760 --> 00:29:47,770
شرکت‌ها این کار را انجام نمی‌دهند تا زمانی که
 

1259
00:29:47,770 --> 00:29:50,100
شرکت‌ها این کار را انجام نمی‌دهند تا زمانی که
آنها را مجبور نکنید، بنابراین این کوتاه مدت بلندمدت است.

1260
00:29:50,100 --> 00:29:54,080
آنها را مجبور نکنید، بنابراین این کوتاه مدت بلندمدت است.
 

1261
00:29:54,080 --> 00:29:57,840

 

1262
00:29:57,840 --> 00:29:59,760

 

1263
00:29:59,760 --> 00:29:59,770

 

1264
00:29:59,770 --> 00:30:01,860

ما در

1265
00:30:01,860 --> 00:30:01,870
ما در
 

1266
00:30:01,870 --> 00:30:05,370
ما در
پنج یا ده سال آینده به این نتیجه خواهیم رسید که چگونه می‌توانیم بدانیم که

1267
00:30:05,370 --> 00:30:05,380
پنج یا ده سال آینده به این نتیجه خواهیم رسید که چگونه می‌توانیم بدانیم که
 

1268
00:30:05,380 --> 00:30:07,590
پنج یا ده سال آینده به این نتیجه خواهیم رسید که چگونه می‌توانیم بدانیم که
قبلاً در تشخیص

1269
00:30:07,590 --> 00:30:07,600
قبلاً در تشخیص
 

1270
00:30:07,600 --> 00:30:10,740
قبلاً در تشخیص
احساسات به عنوان مثال در تصاویر و

1271
00:30:10,740 --> 00:30:10,750
احساسات به عنوان مثال در تصاویر و
 

1272
00:30:10,750 --> 00:30:16,770
احساسات به عنوان مثال در تصاویر و
صداها و متون و همچنین مطالعه نحوه

1273
00:30:16,770 --> 00:30:16,780
صداها و متون و همچنین مطالعه نحوه
 

1274
00:30:16,780 --> 00:30:19,380
صداها و متون و همچنین مطالعه نحوه
تعامل عوامل مختلف به

1275
00:30:19,380 --> 00:30:19,390
تعامل عوامل مختلف به
 

1276
00:30:19,390 --> 00:30:22,460
تعامل عوامل مختلف به
روش‌های مختلف ممکن است با

1277
00:30:22,460 --> 00:30:22,470
روش‌های مختلف ممکن است با
 

1278
00:30:22,470 --> 00:30:26,610
روش‌های مختلف ممکن است با
الگوهای بی‌عدالتی مطابقت داشته باشد که می‌تواند

1279
00:30:26,610 --> 00:30:26,620
الگوهای بی‌عدالتی مطابقت داشته باشد که می‌تواند
 

1280
00:30:26,620 --> 00:30:29,430
الگوهای بی‌عدالتی مطابقت داشته باشد که می‌تواند
باعث شود.  خشم، بنابراین اینها چیزهایی هستند که می‌توانیم

1281
00:30:29,430 --> 00:30:29,440
باعث شود.  خشم، بنابراین اینها چیزهایی هستند که می‌توانیم
 

1282
00:30:29,440 --> 00:30:33,060
باعث شود.  خشم، بنابراین اینها چیزهایی هستند که می‌توانیم
در میان مدت انجام دهیم و در نهایت

1283
00:30:33,060 --> 00:30:33,070
در میان مدت انجام دهیم و در نهایت
 

1284
00:30:33,070 --> 00:30:38,610
در میان مدت انجام دهیم و در نهایت
رایانه‌ها را آموزش دهیم تا به عنوان مثال نحوه

1285
00:30:38,610 --> 00:30:38,620
رایانه‌ها را آموزش دهیم تا به عنوان مثال نحوه
 

1286
00:30:38,620 --> 00:30:42,510
رایانه‌ها را آموزش دهیم تا به عنوان مثال نحوه
واکنش عاطفی انسان‌ها را الگوبرداری کنند، من می‌توانم بگویم

1287
00:30:42,510 --> 00:30:42,520
واکنش عاطفی انسان‌ها را الگوبرداری کنند، من می‌توانم بگویم
 

1288
00:30:42,520 --> 00:30:46,440
واکنش عاطفی انسان‌ها را الگوبرداری کنند، من می‌توانم بگویم
ساده‌ترین چیز موقعیت‌های ناعادلانه است

1289
00:30:46,440 --> 00:30:46,450
ساده‌ترین چیز موقعیت‌های ناعادلانه است
 

1290
00:30:46,450 --> 00:30:49,529
ساده‌ترین چیز موقعیت‌های ناعادلانه است
که خشم را تحریک می‌کند. این یکی از

1291
00:30:49,529 --> 00:30:49,539
که خشم را تحریک می‌کند. این یکی از
 

1292
00:30:49,539 --> 00:30:50,909
که خشم را تحریک می‌کند. این یکی از
ابتدایی‌ترین احساساتی است که ما با دیگران به اشتراک می‌گذاریم.

1293
00:30:50,909 --> 00:30:50,919
ابتدایی‌ترین احساساتی است که ما با دیگران به اشتراک می‌گذاریم.
 

1294
00:30:50,919 --> 00:30:53,250
ابتدایی‌ترین احساساتی است که ما با دیگران به اشتراک می‌گذاریم.
حیوانات فکر می‌کنم

1295
00:30:53,250 --> 00:30:53,260
حیوانات فکر می‌کنم
 

1296
00:30:53,260 --> 00:30:55,560
حیوانات فکر می‌کنم
در چند سال آینده کاملاً امکان‌پذیر است، بنابراین ما می‌توانیم

1297
00:30:55,560 --> 00:30:55,570
در چند سال آینده کاملاً امکان‌پذیر است، بنابراین ما می‌توانیم
 

1298
00:30:55,570 --> 00:30:57,280
در چند سال آینده کاملاً امکان‌پذیر است، بنابراین ما می‌توانیم
سیستم‌هایی بسازیم که می‌توانند

1299
00:30:57,280 --> 00:30:57,290
سیستم‌هایی بسازیم که می‌توانند
 

1300
00:30:57,290 --> 00:30:59,830
سیستم‌هایی بسازیم که می‌توانند
این گونه چیزها را به حدی ببرند

1301
00:30:59,830 --> 00:30:59,840
این گونه چیزها را به حدی ببرند
 

1302
00:30:59,840 --> 00:31:01,300
این گونه چیزها را به حدی ببرند
که متأسفانه آن‌ها به

1303
00:31:01,300 --> 00:31:01,310
که متأسفانه آن‌ها به
 

1304
00:31:01,310 --> 00:31:04,360
که متأسفانه آن‌ها به
اندازه کافی درباره دنیای اطراف ما که

1305
00:31:04,360 --> 00:31:04,370
اندازه کافی درباره دنیای اطراف ما که
 

1306
00:31:04,370 --> 00:31:07,210
اندازه کافی درباره دنیای اطراف ما که
زمان زیادی دور است درک کنند، اما شاید بتوانیم در

1307
00:31:07,210 --> 00:31:07,220
زمان زیادی دور است درک کنند، اما شاید بتوانیم در
 

1308
00:31:07,220 --> 00:31:09,670
زمان زیادی دور است درک کنند، اما شاید بتوانیم در
ابتدا این کار را در

1309
00:31:09,670 --> 00:31:09,680
ابتدا این کار را در
 

1310
00:31:09,680 --> 00:31:11,230
ابتدا این کار را در
محیط‌های مجازی، بنابراین می‌توانید تصور کنید که

1311
00:31:11,230 --> 00:31:11,240
محیط‌های مجازی، بنابراین می‌توانید تصور کنید که
 

1312
00:31:11,240 --> 00:31:14,650
محیط‌های مجازی، بنابراین می‌توانید تصور کنید که
ما مامورانمان به روش‌هایی مانند یک بازی ویدیویی با هم در تعامل هستیم

1313
00:31:14,650 --> 00:31:14,660
ما مامورانمان به روش‌هایی مانند یک بازی ویدیویی با هم در تعامل هستیم
 

1314
00:31:14,660 --> 00:31:16,750
ما مامورانمان به روش‌هایی مانند یک بازی ویدیویی با هم در تعامل هستیم
و سپس برخی موقعیت‌ها باعث

1315
00:31:16,750 --> 00:31:16,760
و سپس برخی موقعیت‌ها باعث
 

1316
00:31:16,760 --> 00:31:19,750
و سپس برخی موقعیت‌ها باعث
ایجاد یک احساس می‌شوند.

1317
00:31:19,750 --> 00:31:21,790
ایجاد یک احساس می‌شوند.
 

1318
00:31:21,790 --> 00:31:23,320

 

1319
00:31:23,320 --> 00:31:24,760

 

1320
00:31:24,760 --> 00:31:24,770

 

1321
00:31:24,770 --> 00:31:28,120

انسان یکی از

1322
00:31:28,120 --> 00:31:28,130
انسان یکی از
 

1323
00:31:28,130 --> 00:31:31,270
انسان یکی از
شخصیت‌هایی را بازی می‌کرد که شما هیجان‌زده بودید

1324
00:31:31,270 --> 00:31:31,280
شخصیت‌هایی را بازی می‌کرد که شما هیجان‌زده بودید
 

1325
00:31:31,280 --> 00:31:33,160
شخصیت‌هایی را بازی می‌کرد که شما هیجان‌زده بودید
و کارهای بسیار خوبی را با

1326
00:31:33,160 --> 00:31:33,170
و کارهای بسیار خوبی را با
 

1327
00:31:33,170 --> 00:31:36,520
و کارهای بسیار خوبی را با
یادگیری نظارت شده انجام دادید، اما در مورد یک سوپرباگ، می‌دانید که

1328
00:31:36,520 --> 00:31:36,530
یادگیری نظارت شده انجام دادید، اما در مورد یک سوپرباگ، می‌دانید که
 

1329
00:31:36,530 --> 00:31:38,440
یادگیری نظارت شده انجام دادید، اما در مورد یک سوپرباگ، می‌دانید که
موفقیت زیادی

1330
00:31:38,440 --> 00:31:38,450
موفقیت زیادی
 

1331
00:31:38,450 --> 00:31:41,050
موفقیت زیادی
در یادگیری تحت نظارت داشته‌اید، بله، بله و

1332
00:31:41,050 --> 00:31:41,060
در یادگیری تحت نظارت داشته‌اید، بله، بله و
 

1333
00:31:41,060 --> 00:31:43,330
در یادگیری تحت نظارت داشته‌اید، بله، بله و
یکی از چیزهایی که من واقعاً

1334
00:31:43,330 --> 00:31:43,340
یکی از چیزهایی که من واقعاً
 

1335
00:31:43,340 --> 00:31:45,340
یکی از چیزهایی که من واقعاً
به آن علاقه دارم.  این است که چگونه انسان‌ها و ربات‌ها

1336
00:31:45,340 --> 00:31:45,350
به آن علاقه دارم.  این است که چگونه انسان‌ها و ربات‌ها
 

1337
00:31:45,350 --> 00:31:48,490
به آن علاقه دارم.  این است که چگونه انسان‌ها و ربات‌ها
با هم کار می‌کنند و در زمینه

1338
00:31:48,490 --> 00:31:48,500
با هم کار می‌کنند و در زمینه
 

1339
00:31:48,500 --> 00:31:50,290
با هم کار می‌کنند و در زمینه
یادگیری تحت نظارت، یعنی

1340
00:31:50,290 --> 00:31:50,300
یادگیری تحت نظارت، یعنی
 

1341
00:31:50,300 --> 00:31:53,140
یادگیری تحت نظارت، یعنی
فرآیند حاشیه‌نویسی

1342
00:31:53,140 --> 00:31:53,150
فرآیند حاشیه‌نویسی
 

1343
00:31:53,150 --> 00:31:56,140
فرآیند حاشیه‌نویسی
به

1344
00:31:56,140 --> 00:31:56,150
به
 

1345
00:31:56,150 --> 00:31:59,740
به
روش جالب‌تری در مورد مشکل حاشیه‌نویسی فکر می‌کنید آیا انسان‌ها

1346
00:31:59,740 --> 00:31:59,750
روش جالب‌تری در مورد مشکل حاشیه‌نویسی فکر می‌کنید آیا انسان‌ها
 

1347
00:31:59,750 --> 00:32:03,250
روش جالب‌تری در مورد مشکل حاشیه‌نویسی فکر می‌کنید آیا انسان‌ها
ماشین‌ها را آموزش می‌دهند بله وجود دارد بله فکر می‌کنم

1348
00:32:03,250 --> 00:32:03,260
ماشین‌ها را آموزش می‌دهند بله وجود دارد بله فکر می‌کنم
 

1349
00:32:03,260 --> 00:32:05,650
ماشین‌ها را آموزش می‌دهند بله وجود دارد بله فکر می‌کنم
موضوع مهمی است که کاهش می‌دهد.

1350
00:32:05,650 --> 00:32:05,660
موضوع مهمی است که کاهش می‌دهد.
 

1351
00:32:05,660 --> 00:32:09,100
موضوع مهمی است که کاهش می‌دهد.
یادداشت برداری ممکن است برای کسی که

1352
00:32:09,100 --> 00:32:09,110
یادداشت برداری ممکن است برای کسی که
 

1353
00:32:09,110 --> 00:32:12,030
یادداشت برداری ممکن است برای کسی که
فردا سیستمی را بسازد مفید باشد، اما به

1354
00:32:12,030 --> 00:32:14,940
فردا سیستمی را بسازد مفید باشد، اما به
 

1355
00:32:14,940 --> 00:32:14,950

 

1356
00:32:14,950 --> 00:32:17,080

نظر من فرآیند آموزش درازمدت چیزی است که مستحق

1357
00:32:17,080 --> 00:32:17,090
نظر من فرآیند آموزش درازمدت چیزی است که مستحق
 

1358
00:32:17,090 --> 00:32:18,550
نظر من فرآیند آموزش درازمدت چیزی است که مستحق
توجه بیشتر جامعه یادگیری ماشینی است،

1359
00:32:18,550 --> 00:32:18,560
توجه بیشتر جامعه یادگیری ماشینی است،
 

1360
00:32:18,560 --> 00:32:20,110
توجه بیشتر جامعه یادگیری ماشینی است،
بنابراین افرادی هستند که

1361
00:32:20,110 --> 00:32:20,120
بنابراین افرادی هستند که
 

1362
00:32:20,120 --> 00:32:23,050
بنابراین افرادی هستند که
اصطلاح آموزش ماشین را ابداع کرده اند، بنابراین

1363
00:32:23,050 --> 00:32:23,060
اصطلاح آموزش ماشین را ابداع کرده اند، بنابراین
 

1364
00:32:23,060 --> 00:32:24,490
اصطلاح آموزش ماشین را ابداع کرده اند، بنابراین
استراتژی های خوبی چیست.  برای آموزش یک

1365
00:32:24,490 --> 00:32:24,500
استراتژی های خوبی چیست.  برای آموزش یک
 

1366
00:32:24,500 --> 00:32:29,800
استراتژی های خوبی چیست.  برای آموزش یک
عامل یادگیری و آیا می‌توانیم

1367
00:32:29,800 --> 00:32:29,810
عامل یادگیری و آیا می‌توانیم
 

1368
00:32:29,810 --> 00:32:31,660
عامل یادگیری و آیا می‌توانیم
سیستمی طراحی کنیم که می‌تواند معلم خوبی باشد،

1369
00:32:31,660 --> 00:32:31,670
سیستمی طراحی کنیم که می‌تواند معلم خوبی باشد،
 

1370
00:32:31,670 --> 00:32:34,390
سیستمی طراحی کنیم که می‌تواند معلم خوبی باشد،
بنابراین در گروه من

1371
00:32:34,390 --> 00:32:34,400
بنابراین در گروه من
 

1372
00:32:34,400 --> 00:32:37,960
بنابراین در گروه من
پروژه‌ای به نام بازی کودک من یا کودک من داریم

1373
00:32:37,960 --> 00:32:37,970
پروژه‌ای به نام بازی کودک من یا کودک من داریم
 

1374
00:32:37,970 --> 00:32:42,640
پروژه‌ای به نام بازی کودک من یا کودک من داریم
که در آن یک بازی یا سناریو وجود دارد که در آن

1375
00:32:42,640 --> 00:32:42,650
که در آن یک بازی یا سناریو وجود دارد که در آن
 

1376
00:32:42,650 --> 00:32:45,550
که در آن یک بازی یا سناریو وجود دارد که در آن
یک عامل یادگیری وجود دارد.  و یک

1377
00:32:45,550 --> 00:32:45,560
یک عامل یادگیری وجود دارد.  و یک
 

1378
00:32:45,560 --> 00:32:48,310
یک عامل یادگیری وجود دارد.  و یک
عامل آموزشی احتمالاً عامل آموزشی

1379
00:32:48,310 --> 00:32:48,320
عامل آموزشی احتمالاً عامل آموزشی
 

1380
00:32:48,320 --> 00:32:51,370
عامل آموزشی احتمالاً عامل آموزشی
در نهایت یک انسان خواهد بود، اما ما

1381
00:32:51,370 --> 00:32:51,380
در نهایت یک انسان خواهد بود، اما ما
 

1382
00:32:51,380 --> 00:32:56,560
در نهایت یک انسان خواهد بود، اما ما
هنوز به آنجا نرسیده‌ایم و نقش

1383
00:32:56,560 --> 00:32:56,570
هنوز به آنجا نرسیده‌ایم و نقش
 

1384
00:32:56,570 --> 00:32:58,780
هنوز به آنجا نرسیده‌ایم و نقش
معلم استفاده از دانش خود از

1385
00:32:58,780 --> 00:32:58,790
معلم استفاده از دانش خود از
 

1386
00:32:58,790 --> 00:33:00,610
معلم استفاده از دانش خود از
محیط است که می‌تواند با استفاده از

1387
00:33:00,610 --> 00:33:00,620
محیط است که می‌تواند با استفاده از
 

1388
00:33:00,620 --> 00:33:06,010
محیط است که می‌تواند با استفاده از
هر نیروی وحشیانه برای کمک به

1389
00:33:06,010 --> 00:33:06,020
هر نیروی وحشیانه برای کمک به
 

1390
00:33:06,020 --> 00:33:09,160
هر نیروی وحشیانه برای کمک به
یادگیرنده در یادگیری به دست آورد.  در سریع ترین زمان ممکن، به طوری که

1391
00:33:09,160 --> 00:33:09,170
یادگیرنده در یادگیری به دست آورد.  در سریع ترین زمان ممکن، به طوری که
 

1392
00:33:09,170 --> 00:33:10,660
یادگیرنده در یادگیری به دست آورد.  در سریع ترین زمان ممکن، به طوری که
یادگیرنده سعی کند با آن یاد بگیرد،

1393
00:33:10,660 --> 00:33:10,670
یادگیرنده سعی کند با آن یاد بگیرد،
 

1394
00:33:10,670 --> 00:33:10,960
یادگیرنده سعی کند با آن یاد بگیرد،

1395
00:33:10,960 --> 00:33:10,970

 

1396
00:33:10,970 --> 00:33:13,210

شاید از اکتشاف استفاده کند و

1397
00:33:13,210 --> 00:33:13,220
شاید از اکتشاف استفاده کند و
 

1398
00:33:13,220 --> 00:33:18,340
شاید از اکتشاف استفاده کند و
هر چیزی که معلم می تواند انتخاب کند

1399
00:33:18,340 --> 00:33:18,350
هر چیزی که معلم می تواند انتخاب کند
 

1400
00:33:18,350 --> 00:33:20,140
هر چیزی که معلم می تواند انتخاب کند
می تواند بر

1401
00:33:20,140 --> 00:33:20,150
می تواند بر
 

1402
00:33:20,150 --> 00:33:22,149
می تواند بر
تعامل با زبان آموز تأثیر بگذارد تا

1403
00:33:22,149 --> 00:33:22,159
تعامل با زبان آموز تأثیر بگذارد تا
 

1404
00:33:22,159 --> 00:33:26,950
تعامل با زبان آموز تأثیر بگذارد تا
یادگیرنده را راهنمایی کند، شاید چیزهایی را به او بیاموزد.

1405
00:33:26,950 --> 00:33:26,960
یادگیرنده را راهنمایی کند، شاید چیزهایی را به او بیاموزد.
 

1406
00:33:26,960 --> 00:33:28,720
یادگیرنده را راهنمایی کند، شاید چیزهایی را به او بیاموزد.
که یادگیرنده بیشترین مشکل را

1407
00:33:28,720 --> 00:33:28,730
که یادگیرنده بیشترین مشکل را
 

1408
00:33:28,730 --> 00:33:30,279
که یادگیرنده بیشترین مشکل را
با یا فقط در مرز بین

1409
00:33:30,279 --> 00:33:30,289
با یا فقط در مرز بین
 

1410
00:33:30,289 --> 00:33:32,020
با یا فقط در مرز بین
آنچه می داند و نمی داند و غیره دارد،

1411
00:33:32,020 --> 00:33:32,030
آنچه می داند و نمی داند و غیره دارد،
 

1412
00:33:32,030 --> 00:33:34,630
آنچه می داند و نمی داند و غیره دارد،
بنابراین این یک سنت از این

1413
00:33:34,630 --> 00:33:34,640
بنابراین این یک سنت از این
 

1414
00:33:34,640 --> 00:33:39,010
بنابراین این یک سنت از این
نوع ایده ها از زمینه های دیگر و مانند

1415
00:33:39,010 --> 00:33:39,020
نوع ایده ها از زمینه های دیگر و مانند
 

1416
00:33:39,020 --> 00:33:41,340
نوع ایده ها از زمینه های دیگر و مانند
سیستم های آموزشی برای مثال وجود دارد و آنها من

1417
00:33:41,340 --> 00:33:41,350
سیستم های آموزشی برای مثال وجود دارد و آنها من
 

1418
00:33:41,350 --> 00:33:44,860
سیستم های آموزشی برای مثال وجود دارد و آنها من
و  البته افرادی در

1419
00:33:44,860 --> 00:33:44,870
و  البته افرادی در
 

1420
00:33:44,870 --> 00:33:46,000
و  البته افرادی در
علوم انسانی به

1421
00:33:46,000 --> 00:33:46,010
علوم انسانی به
 

1422
00:33:46,010 --> 00:33:47,440
علوم انسانی به
این سوالات فکر کرده‌اند، اما فکر می‌کنم وقت آن رسیده است

1423
00:33:47,440 --> 00:33:47,450
این سوالات فکر کرده‌اند، اما فکر می‌کنم وقت آن رسیده است
 

1424
00:33:47,450 --> 00:33:50,110
این سوالات فکر کرده‌اند، اما فکر می‌کنم وقت آن رسیده است
که افراد یادگیری ماشین به

1425
00:33:50,110 --> 00:33:50,120
که افراد یادگیری ماشین به
 

1426
00:33:50,120 --> 00:33:51,880
که افراد یادگیری ماشین به
این موضوع نگاه کنند، زیرا در آینده

1427
00:33:51,880 --> 00:33:51,890
این موضوع نگاه کنند، زیرا در آینده
 

1428
00:33:51,890 --> 00:33:54,789
این موضوع نگاه کنند، زیرا در آینده
تعامل بیشتری با ماشین انسان

1429
00:33:54,789 --> 00:33:54,799
تعامل بیشتری با ماشین انسان
 

1430
00:33:54,799 --> 00:33:58,180
تعامل بیشتری با ماشین انسان
با یک انسان در حلقه خواهیم داشت و فکر می‌کنم

1431
00:33:58,180 --> 00:33:58,190
با یک انسان در حلقه خواهیم داشت و فکر می‌کنم
 

1432
00:33:58,190 --> 00:33:59,950
با یک انسان در حلقه خواهیم داشت و فکر می‌کنم
درک چگونگی ساخت  این کار

1433
00:33:59,950 --> 00:33:59,960
درک چگونگی ساخت  این کار
 

1434
00:33:59,960 --> 00:34:01,840
درک چگونگی ساخت  این کار
بهتر است همه مشکلات اطراف را که

1435
00:34:01,840 --> 00:34:01,850
بهتر است همه مشکلات اطراف را که
 

1436
00:34:01,850 --> 00:34:03,640
بهتر است همه مشکلات اطراف را که
بسیار جالب هستند و به اندازه کافی به آنها

1437
00:34:03,640 --> 00:34:03,650
بسیار جالب هستند و به اندازه کافی به آنها
 

1438
00:34:03,650 --> 00:34:06,220
بسیار جالب هستند و به اندازه کافی به آنها
پرداخته نشده است، شما با زبان کار زیادی انجام داده اید که

1439
00:34:06,220 --> 00:34:06,230
پرداخته نشده است، شما با زبان کار زیادی انجام داده اید که
 

1440
00:34:06,230 --> 00:34:10,030
پرداخته نشده است، شما با زبان کار زیادی انجام داده اید که
در چه جنبه ای از

1441
00:34:10,030 --> 00:34:10,040
در چه جنبه ای از
 

1442
00:34:10,040 --> 00:34:12,510
در چه جنبه ای از
آزمون تورینگ فرمول بندی شده سنتی،

1443
00:34:12,510 --> 00:34:12,520
آزمون تورینگ فرمول بندی شده سنتی،
 

1444
00:34:12,520 --> 00:34:15,010
آزمون تورینگ فرمول بندی شده سنتی،
آزمون زبان طبیعی درک یک

1445
00:34:15,010 --> 00:34:15,020
آزمون زبان طبیعی درک یک
 

1446
00:34:15,020 --> 00:34:17,200
آزمون زبان طبیعی درک یک
نسل در چشم شما دشوارترین است.

1447
00:34:17,200 --> 00:34:17,210
نسل در چشم شما دشوارترین است.
 

1448
00:34:17,210 --> 00:34:19,960
نسل در چشم شما دشوارترین است.
مکالمه اما از

1449
00:34:19,960 --> 00:34:19,970
مکالمه اما از
 

1450
00:34:19,970 --> 00:34:21,790
مکالمه اما از
نظر شما سخت‌ترین بخش مکالمه

1451
00:34:21,790 --> 00:34:21,800
نظر شما سخت‌ترین بخش مکالمه
 

1452
00:34:21,800 --> 00:34:25,060
نظر شما سخت‌ترین بخش مکالمه
برای حل کردن ماشین‌ها است، بنابراین می‌توانم بگویم

1453
00:34:25,060 --> 00:34:25,070
برای حل کردن ماشین‌ها است، بنابراین می‌توانم بگویم
 

1454
00:34:25,070 --> 00:34:28,629
برای حل کردن ماشین‌ها است، بنابراین می‌توانم بگویم
همه چیز مربوط به

1455
00:34:28,629 --> 00:34:28,639
همه چیز مربوط به
 

1456
00:34:28,639 --> 00:34:30,520
همه چیز مربوط به
دانش غیرزبانی است که

1457
00:34:30,520 --> 00:34:30,530
دانش غیرزبانی است که
 

1458
00:34:30,530 --> 00:34:32,619
دانش غیرزبانی است که
به طور ضمنی برای

1459
00:34:32,619 --> 00:34:32,629
به طور ضمنی برای
 

1460
00:34:32,629 --> 00:34:35,470
به طور ضمنی برای
درک جملاتی مانند

1461
00:34:35,470 --> 00:34:35,480
درک جملاتی مانند
 

1462
00:34:35,480 --> 00:34:37,450
درک جملاتی مانند
طرحواره‌های وینوگراد به آن نیاز دارید، بنابراین این جملات  از

1463
00:34:37,450 --> 00:34:37,460
طرحواره‌های وینوگراد به آن نیاز دارید، بنابراین این جملات  از
 

1464
00:34:37,460 --> 00:34:40,540
طرحواره‌های وینوگراد به آن نیاز دارید، بنابراین این جملات  از
نظر معنایی مبهم است به

1465
00:34:40,540 --> 00:34:40,550
نظر معنایی مبهم است به
 

1466
00:34:40,550 --> 00:34:42,220
نظر معنایی مبهم است به
عبارت دیگر شما باید به اندازه کافی

1467
00:34:42,220 --> 00:34:42,230
عبارت دیگر شما باید به اندازه کافی
 

1468
00:34:42,230 --> 00:34:44,560
عبارت دیگر شما باید به اندازه کافی
در مورد جهان درک کنید تا

1469
00:34:44,560 --> 00:34:44,570
در مورد جهان درک کنید تا
 

1470
00:34:44,570 --> 00:34:47,070
در مورد جهان درک کنید تا
احتمالاً آن جملات را واقعاً تفسیر کنید. من

1471
00:34:47,070 --> 00:34:47,080
احتمالاً آن جملات را واقعاً تفسیر کنید. من
 

1472
00:34:47,080 --> 00:34:49,329
احتمالاً آن جملات را واقعاً تفسیر کنید. من
فکر می کنم اینها چالش های جالبی

1473
00:34:49,329 --> 00:34:49,339
فکر می کنم اینها چالش های جالبی
 

1474
00:34:49,339 --> 00:34:51,310
فکر می کنم اینها چالش های جالبی
برای یادگیری ماشینی ما هستند، زیرا آنها

1475
00:34:51,310 --> 00:34:51,320
برای یادگیری ماشینی ما هستند، زیرا آنها
 

1476
00:34:51,320 --> 00:34:54,790
برای یادگیری ماشینی ما هستند، زیرا آنها
به سمت ساختن

1477
00:34:54,790 --> 00:34:54,800
به سمت ساختن
 

1478
00:34:54,800 --> 00:34:58,000
به سمت ساختن
سیستم هایی اشاره می کنند که هم نحوه

1479
00:34:58,000 --> 00:34:58,010
سیستم هایی اشاره می کنند که هم نحوه
 

1480
00:34:58,010 --> 00:34:59,710
سیستم هایی اشاره می کنند که هم نحوه
عملکرد جهان و هم علت آن را درک می کنند.

1481
00:34:59,710 --> 00:34:59,720
عملکرد جهان و هم علت آن را درک می کنند.
 

1482
00:34:59,720 --> 00:35:02,829
عملکرد جهان و هم علت آن را درک می کنند.
روابط در جهان و

1483
00:35:02,829 --> 00:35:02,839
روابط در جهان و
 

1484
00:35:02,839 --> 00:35:06,490
روابط در جهان و
این دانش را با نحوه بیان آن به

1485
00:35:06,490 --> 00:35:06,500
این دانش را با نحوه بیان آن به
 

1486
00:35:06,500 --> 00:35:11,099
این دانش را با نحوه بیان آن به
زبان، چه برای خواندن یا نوشتن، مرتبط کنید،

1487
00:35:11,099 --> 00:35:11,109
زبان، چه برای خواندن یا نوشتن، مرتبط کنید،
 

1488
00:35:11,109 --> 00:35:14,020
زبان، چه برای خواندن یا نوشتن، مرتبط کنید،
شما فرانسوی صحبت می کنید بله، زبان مادری من است،

1489
00:35:14,020 --> 00:35:14,030
شما فرانسوی صحبت می کنید بله، زبان مادری من است،
 

1490
00:35:14,030 --> 00:35:16,329
شما فرانسوی صحبت می کنید بله، زبان مادری من است،
یکی از زبان های رمانتیک است،

1491
00:35:16,329 --> 00:35:16,339
یکی از زبان های رمانتیک است،
 

1492
00:35:16,339 --> 00:35:19,290
یکی از زبان های رمانتیک است،
آیا فکر می کنید قبولی در آزمون تورینگ و

1493
00:35:19,290 --> 00:35:19,300
آیا فکر می کنید قبولی در آزمون تورینگ و
 

1494
00:35:19,300 --> 00:35:21,670
آیا فکر می کنید قبولی در آزمون تورینگ و
همه چالش های اساسی که به آن

1495
00:35:21,670 --> 00:35:21,680
همه چالش های اساسی که به آن
 

1496
00:35:21,680 --> 00:35:23,320
همه چالش های اساسی که به آن
اشاره کردیم بستگی دارد.  در مورد زبان به

1497
00:35:23,320 --> 00:35:23,330
اشاره کردیم بستگی دارد.  در مورد زبان به
 

1498
00:35:23,330 --> 00:35:24,740
اشاره کردیم بستگی دارد.  در مورد زبان به
نظر شما ممکن است ساده تر باشد

1499
00:35:24,740 --> 00:35:24,750
نظر شما ممکن است ساده تر باشد
 

1500
00:35:24,750 --> 00:35:27,590
نظر شما ممکن است ساده تر باشد
که به زبان انگلیسی است اکنون مستقل از

1501
00:35:27,590 --> 00:35:27,600
که به زبان انگلیسی است اکنون مستقل از
 

1502
00:35:27,600 --> 00:35:28,880
که به زبان انگلیسی است اکنون مستقل از
زبان mmm

1503
00:35:28,880 --> 00:35:28,890
زبان mmm
 

1504
00:35:28,890 --> 00:35:31,640
زبان mmm
من فکر می کنم مستقل از زبان است من

1505
00:35:31,640 --> 00:35:31,650
من فکر می کنم مستقل از زبان است من
 

1506
00:35:31,650 --> 00:35:36,920
من فکر می کنم مستقل از زبان است من
می خواهم سیستم هایی بسازم که بتوانند از

1507
00:35:36,920 --> 00:35:36,930
می خواهم سیستم هایی بسازم که بتوانند از
 

1508
00:35:36,930 --> 00:35:39,890
می خواهم سیستم هایی بسازم که بتوانند از
همان اصول از همان

1509
00:35:39,890 --> 00:35:39,900
همان اصول از همان
 

1510
00:35:39,900 --> 00:35:44,810
همان اصول از همان
مکانیسم های یادگیری برای یادگیری از عوامل انسانی استفاده کنند.

1511
00:35:44,810 --> 00:35:44,820
مکانیسم های یادگیری برای یادگیری از عوامل انسانی استفاده کنند.
 

1512
00:35:44,820 --> 00:35:47,810
مکانیسم های یادگیری برای یادگیری از عوامل انسانی استفاده کنند.
زبان خوب، مطمئناً

1513
00:35:47,810 --> 00:35:47,820
زبان خوب، مطمئناً
 

1514
00:35:47,820 --> 00:35:50,840
زبان خوب، مطمئناً
ما انسانها می‌توانیم

1515
00:35:50,840 --> 00:35:50,850
ما انسانها می‌توانیم
 

1516
00:35:50,850 --> 00:35:52,790
ما انسانها می‌توانیم
در شعر زیباتر و روان‌تر صحبت کنیم، بعضی از روسی‌ها

1517
00:35:52,790 --> 00:35:52,800
در شعر زیباتر و روان‌تر صحبت کنیم، بعضی از روسی‌ها
 

1518
00:35:52,800 --> 00:35:56,290
در شعر زیباتر و روان‌تر صحبت کنیم، بعضی از روسی‌ها
در اصل من شعر را می‌دانم و روسی

1519
00:35:56,290 --> 00:35:56,300
در اصل من شعر را می‌دانم و روسی
 

1520
00:35:56,300 --> 00:36:00,320
در اصل من شعر را می‌دانم و روسی
شاید راحت‌تر از انگلیسی است که ایده‌های پیچیده را منتقل کند،

1521
00:36:00,320 --> 00:36:00,330
شاید راحت‌تر از انگلیسی است که ایده‌های پیچیده را منتقل کند،
 

1522
00:36:00,330 --> 00:36:03,290
شاید راحت‌تر از انگلیسی است که ایده‌های پیچیده را منتقل کند،
اما شاید من

1523
00:36:03,290 --> 00:36:03,300
اما شاید من
 

1524
00:36:03,300 --> 00:36:04,910
اما شاید من
تعصب خود را نشان می‌دهم و برخی افراد می‌توانند

1525
00:36:04,910 --> 00:36:04,920
تعصب خود را نشان می‌دهم و برخی افراد می‌توانند
 

1526
00:36:04,920 --> 00:36:08,570
تعصب خود را نشان می‌دهم و برخی افراد می‌توانند
این را در مورد نیمه جلویی بگویند.  فرانسوی اما البته

1527
00:36:08,570 --> 00:36:08,580
این را در مورد نیمه جلویی بگویند.  فرانسوی اما البته
 

1528
00:36:08,580 --> 00:36:11,690
این را در مورد نیمه جلویی بگویند.  فرانسوی اما البته
هدف در نهایت این است که مغز انسان ما

1529
00:36:11,690 --> 00:36:11,700
هدف در نهایت این است که مغز انسان ما
 

1530
00:36:11,700 --> 00:36:14,030
هدف در نهایت این است که مغز انسان ما
بتواند از هر نوع

1531
00:36:14,030 --> 00:36:14,040
بتواند از هر نوع
 

1532
00:36:14,040 --> 00:36:17,060
بتواند از هر نوع
زبانی استفاده کند تا از آنها به عنوان ابزاری برای

1533
00:36:17,060 --> 00:36:17,070
زبانی استفاده کند تا از آنها به عنوان ابزاری برای
 

1534
00:36:17,070 --> 00:36:19,190
زبانی استفاده کند تا از آنها به عنوان ابزاری برای
انتقال معنی استفاده کند.

1535
00:36:19,190 --> 00:36:20,570
انتقال معنی استفاده کند.
 

1536
00:36:20,570 --> 00:36:22,430

 

1537
00:36:22,430 --> 00:36:22,440

 

1538
00:36:22,440 --> 00:36:24,160

طرحی از چیزهایی

1539
00:36:24,160 --> 00:36:24,170
طرحی از چیزهایی
 

1540
00:36:24,170 --> 00:36:26,210
طرحی از چیزهایی
که در آن سعی می‌کنیم بفهمیم

1541
00:36:26,210 --> 00:36:26,220
که در آن سعی می‌کنیم بفهمیم
 

1542
00:36:26,220 --> 00:36:28,370
که در آن سعی می‌کنیم بفهمیم
مغز چگونه کار می‌کند و زبان و غیره،

1543
00:36:28,370 --> 00:36:28,380
مغز چگونه کار می‌کند و زبان و غیره،
 

1544
00:36:28,380 --> 00:36:33,080
مغز چگونه کار می‌کند و زبان و غیره،
فکر می‌کنم این تفاوت‌ها یک دقیقه هستند، بنابراین

1545
00:36:33,080 --> 00:36:33,090
فکر می‌کنم این تفاوت‌ها یک دقیقه هستند، بنابراین
 

1546
00:36:33,090 --> 00:36:36,710
فکر می‌کنم این تفاوت‌ها یک دقیقه هستند، بنابراین
شما شاید در زمستانی با هوش مصنوعی زندگی کرده‌اید،

1547
00:36:36,710 --> 00:36:36,720
شما شاید در زمستانی با هوش مصنوعی زندگی کرده‌اید،
 

1548
00:36:36,720 --> 00:36:40,490
شما شاید در زمستانی با هوش مصنوعی زندگی کرده‌اید،
بله چگونه

1549
00:36:40,490 --> 00:36:40,500
بله چگونه
 

1550
00:36:40,500 --> 00:36:43,910
بله چگونه
گرم ماندید و ادامه دادید و  ظاهر شدن دوباره

1551
00:36:43,910 --> 00:36:43,920
گرم ماندید و ادامه دادید و  ظاهر شدن دوباره
 

1552
00:36:43,920 --> 00:36:46,430
گرم ماندید و ادامه دادید و  ظاهر شدن دوباره
با دوستان و دوستان گرم بمانید

1553
00:36:46,430 --> 00:36:46,440
با دوستان و دوستان گرم بمانید
 

1554
00:36:46,440 --> 00:36:48,140
با دوستان و دوستان گرم بمانید
خوب است، بنابراین مهم است که دوستان داشته باشید

1555
00:36:48,140 --> 00:36:48,150
خوب است، بنابراین مهم است که دوستان داشته باشید
 

1556
00:36:48,150 --> 00:36:51,200
خوب است، بنابراین مهم است که دوستان داشته باشید
و آنچه از تجربه آموخته اید

1557
00:36:51,200 --> 00:36:51,210
و آنچه از تجربه آموخته اید
 

1558
00:36:51,210 --> 00:36:54,790
و آنچه از تجربه آموخته اید
به ندای درونی خود گوش دهید، آیا

1559
00:36:54,790 --> 00:36:54,800
به ندای درونی خود گوش دهید، آیا
 

1560
00:36:54,800 --> 00:37:00,500
به ندای درونی خود گوش دهید، آیا
نمی دانید که سعی کنید فقط

1561
00:37:00,500 --> 00:37:00,510
نمی دانید که سعی کنید فقط
 

1562
00:37:00,510 --> 00:37:04,700
نمی دانید که سعی کنید فقط
جمعیت و مد را راضی نگه دارید و اگر

1563
00:37:04,700 --> 00:37:04,710
جمعیت و مد را راضی نگه دارید و اگر
 

1564
00:37:04,710 --> 00:37:07,750
جمعیت و مد را راضی نگه دارید و اگر
شهود قوی دارید.  در مورد چیزی

1565
00:37:07,750 --> 00:37:07,760
شهود قوی دارید.  در مورد چیزی
 

1566
00:37:07,760 --> 00:37:10,760
شهود قوی دارید.  در مورد چیزی
که با شواهد واقعی در تناقض نیست،

1567
00:37:10,760 --> 00:37:10,770
که با شواهد واقعی در تناقض نیست،
 

1568
00:37:10,770 --> 00:37:14,540
که با شواهد واقعی در تناقض نیست،
آن را دنبال کنید، منظورم این است که ممکن است

1569
00:37:14,540 --> 00:37:14,550
آن را دنبال کنید، منظورم این است که ممکن است
 

1570
00:37:14,550 --> 00:37:17,720
آن را دنبال کنید، منظورم این است که ممکن است
توسط مردم مخالفت شود، اما نه غریزه خود شما

1571
00:37:17,720 --> 00:37:17,730
توسط مردم مخالفت شود، اما نه غریزه خود شما
 

1572
00:37:17,730 --> 00:37:19,820
توسط مردم مخالفت شود، اما نه غریزه خود شما
بر اساس همه چیزهایی که می دانید،

1573
00:37:19,820 --> 00:37:19,830
بر اساس همه چیزهایی که می دانید،
 

1574
00:37:19,830 --> 00:37:21,950
بر اساس همه چیزهایی که می دانید،
البته، البته باید

1575
00:37:21,950 --> 00:37:21,960
البته، البته باید
 

1576
00:37:21,960 --> 00:37:25,160
البته، البته باید
باورهای خود را تطبیق دهید، زمانی که آزمایشات شما با

1577
00:37:25,160 --> 00:37:25,170
باورهای خود را تطبیق دهید، زمانی که آزمایشات شما با
 

1578
00:37:25,170 --> 00:37:28,520
باورهای خود را تطبیق دهید، زمانی که آزمایشات شما با
این باورها در تضاد است، اما شما

1579
00:37:28,520 --> 00:37:28,530
این باورها در تضاد است، اما شما
 

1580
00:37:28,530 --> 00:37:30,910
این باورها در تضاد است، اما شما
باید به باورهای خود پایبند باشید، در غیر این صورت

1581
00:37:30,910 --> 00:37:30,920
باید به باورهای خود پایبند باشید، در غیر این صورت
 

1582
00:37:30,920 --> 00:37:33,980
باید به باورهای خود پایبند باشید، در غیر این صورت
این چیزی است که به من اجازه داد

1583
00:37:33,980 --> 00:37:33,990
این چیزی است که به من اجازه داد
 

1584
00:37:33,990 --> 00:37:35,750
این چیزی است که به من اجازه داد
آن سال ها را پشت سر بگذارم، این چیزی است که به من اجازه داد

1585
00:37:35,750 --> 00:37:35,760
آن سال ها را پشت سر بگذارم، این چیزی است که به من اجازه داد
 

1586
00:37:35,760 --> 00:37:37,070
آن سال ها را پشت سر بگذارم، این چیزی است که به من اجازه داد

1587
00:37:37,070 --> 00:37:37,080

 

1588
00:37:37,080 --> 00:37:39,950

در مسیرهایی ادامه دهم که می دانید

1589
00:37:39,950 --> 00:37:39,960
در مسیرهایی ادامه دهم که می دانید
 

1590
00:37:39,960 --> 00:37:42,980
در مسیرهایی ادامه دهم که می دانید
هر آنچه که همه مردم فکر می کنند

1591
00:37:42,980 --> 00:37:42,990
هر آنچه که همه مردم فکر می کنند
 

1592
00:37:42,990 --> 00:37:48,080
هر آنچه که همه مردم فکر می کنند
زمان می برد تا بالغ شود و شما ثمرات می آورید تا

1593
00:37:48,080 --> 00:37:48,090
زمان می برد تا بالغ شود و شما ثمرات می آورید تا
 

1594
00:37:48,090 --> 00:37:52,490
زمان می برد تا بالغ شود و شما ثمرات می آورید تا
تاریخچه هوش مصنوعی مشخص شود.  البته با این موارد،

1595
00:37:52,490 --> 00:37:53,720
تاریخچه هوش مصنوعی مشخص شود.  البته با این موارد،
 

1596
00:37:53,720 --> 00:37:53,730

 

1597
00:37:53,730 --> 00:37:55,640

پیشرفت های فنی را نشان می دهد، اما همچنین با

1598
00:37:55,640 --> 00:37:55,650
پیشرفت های فنی را نشان می دهد، اما همچنین با
 

1599
00:37:55,650 --> 00:37:58,040
پیشرفت های فنی را نشان می دهد، اما همچنین با
این رویدادهای مهم که

1600
00:37:58,040 --> 00:37:58,050
این رویدادهای مهم که
 

1601
00:37:58,050 --> 00:38:01,430
این رویدادهای مهم که
تخیل جامعه را تسخیر می کند، مشخص شده است.

1602
00:38:01,430 --> 00:38:01,440
تخیل جامعه را تسخیر می کند، مشخص شده است.
 

1603
00:38:01,440 --> 00:38:04,490
تخیل جامعه را تسخیر می کند، مشخص شده است.
می توانم بگویم آلفاگو شکست دادن

1604
00:38:04,490 --> 00:38:04,500
می توانم بگویم آلفاگو شکست دادن
 

1605
00:38:04,500 --> 00:38:06,560
می توانم بگویم آلفاگو شکست دادن
بازیکن قهرمان جهان انسان برو یکی از

1606
00:38:06,560 --> 00:38:06,570
بازیکن قهرمان جهان انسان برو یکی از
 

1607
00:38:06,570 --> 00:38:10,370
بازیکن قهرمان جهان انسان برو یکی از
آن لحظات بود، به نظر شما

1608
00:38:10,370 --> 00:38:10,380
آن لحظات بود، به نظر شما
 

1609
00:38:10,380 --> 00:38:13,760
آن لحظات بود، به نظر شما
چنین لحظه بعدی چیست؟  سطح ممکن است خوب باشد اول

1610
00:38:13,760 --> 00:38:13,770
چنین لحظه بعدی چیست؟  سطح ممکن است خوب باشد اول
 

1611
00:38:13,770 --> 00:38:15,380
چنین لحظه بعدی چیست؟  سطح ممکن است خوب باشد اول
از همه من فکر می کنم که این

1612
00:38:15,380 --> 00:38:15,390
از همه من فکر می کنم که این
 

1613
00:38:15,390 --> 00:38:22,970
از همه من فکر می کنم که این
رویدادهای به اصطلاح مهم بیش از حد ارزیابی می شوند همانطور که گفتم

1614
00:38:22,970 --> 00:38:22,980
رویدادهای به اصطلاح مهم بیش از حد ارزیابی می شوند همانطور که گفتم
 

1615
00:38:22,980 --> 00:38:26,030
رویدادهای به اصطلاح مهم بیش از حد ارزیابی می شوند همانطور که گفتم
علم واقعاً با گام های کوچک حرکت می کند اکنون

1616
00:38:26,030 --> 00:38:26,040
علم واقعاً با گام های کوچک حرکت می کند اکنون
 

1617
00:38:26,040 --> 00:38:30,260
علم واقعاً با گام های کوچک حرکت می کند اکنون
آنچه اتفاق می افتد این است که شما یک قدم کوچک دیگر بردارید

1618
00:38:30,260 --> 00:38:30,270
آنچه اتفاق می افتد این است که شما یک قدم کوچک دیگر بردارید
 

1619
00:38:30,270 --> 00:38:34,010
آنچه اتفاق می افتد این است که شما یک قدم کوچک دیگر بردارید
و این مانند قطره ای است که می

1620
00:38:34,010 --> 00:38:34,020
و این مانند قطره ای است که می
 

1621
00:38:34,020 --> 00:38:36,860
و این مانند قطره ای است که می
دانید اجازه می دهد تا پر شود  سطل و و

1622
00:38:36,860 --> 00:38:36,870
دانید اجازه می دهد تا پر شود  سطل و و
 

1623
00:38:36,870 --> 00:38:39,560
دانید اجازه می دهد تا پر شود  سطل و و
و سپس عواقب شدیدی دارید

1624
00:38:39,560 --> 00:38:39,570
و سپس عواقب شدیدی دارید
 

1625
00:38:39,570 --> 00:38:41,210
و سپس عواقب شدیدی دارید
زیرا اکنون می توانید

1626
00:38:41,210 --> 00:38:41,220
زیرا اکنون می توانید
 

1627
00:38:41,220 --> 00:38:42,500
زیرا اکنون می توانید
کاری را انجام دهید که قبلاً قادر به انجام آن نبودید یا

1628
00:38:42,500 --> 00:38:42,510
کاری را انجام دهید که قبلاً قادر به انجام آن نبودید یا
 

1629
00:38:42,510 --> 00:38:46,160
کاری را انجام دهید که قبلاً قادر به انجام آن نبودید یا
اکنون می گویید هزینه ساخت

1630
00:38:46,160 --> 00:38:46,170
اکنون می گویید هزینه ساخت
 

1631
00:38:46,170 --> 00:38:48,430
اکنون می گویید هزینه ساخت
یک دستگاه یا حل یک مشکل

1632
00:38:48,430 --> 00:38:48,440
یک دستگاه یا حل یک مشکل
 

1633
00:38:48,440 --> 00:38:51,020
یک دستگاه یا حل یک مشکل
ارزان تر از آنچه وجود داشته است می شود و شما یک

1634
00:38:51,020 --> 00:38:51,030
ارزان تر از آنچه وجود داشته است می شود و شما یک
 

1635
00:38:51,030 --> 00:38:52,970
ارزان تر از آنچه وجود داشته است می شود و شما یک
بازار جدید دارید.  که به درستی باز می شود، بنابراین

1636
00:38:52,970 --> 00:38:52,980
بازار جدید دارید.  که به درستی باز می شود، بنابراین
 

1637
00:38:52,980 --> 00:38:55,210
بازار جدید دارید.  که به درستی باز می شود، بنابراین
به خصوص در دنیای تجارت و

1638
00:38:55,210 --> 00:38:55,220
به خصوص در دنیای تجارت و
 

1639
00:38:55,220 --> 00:38:59,480
به خصوص در دنیای تجارت و
برنامه های کاربردی، تأثیر یک

1640
00:38:59,480 --> 00:38:59,490
برنامه های کاربردی، تأثیر یک
 

1641
00:38:59,490 --> 00:39:04,040
برنامه های کاربردی، تأثیر یک
پیشرفت علمی کوچک می تواند بسیار زیاد باشد، اما در

1642
00:39:04,040 --> 00:39:04,050
پیشرفت علمی کوچک می تواند بسیار زیاد باشد، اما در
 

1643
00:39:04,050 --> 00:39:05,810
پیشرفت علمی کوچک می تواند بسیار زیاد باشد، اما در
خود علم فکر می کنم بسیار

1644
00:39:05,810 --> 00:39:05,820
خود علم فکر می کنم بسیار
 

1645
00:39:05,820 --> 00:39:09,890
خود علم فکر می کنم بسیار
بسیار تدریجی است و جایی که این مراحل

1646
00:39:09,890 --> 00:39:09,900
بسیار تدریجی است و جایی که این مراحل
 

1647
00:39:09,900 --> 00:39:13,250
بسیار تدریجی است و جایی که این مراحل
اکنون برداشته می شود، بنابراین نظارت درستی وجود دارد، بنابراین

1648
00:39:13,250 --> 00:39:13,260
اکنون برداشته می شود، بنابراین نظارت درستی وجود دارد، بنابراین
 

1649
00:39:13,260 --> 00:39:17,450
اکنون برداشته می شود، بنابراین نظارت درستی وجود دارد، بنابراین
اگر نگاه کنم  در یکی از گرایش‌هایی که

1650
00:39:17,450 --> 00:39:17,460
اگر نگاه کنم  در یکی از گرایش‌هایی که
 

1651
00:39:17,460 --> 00:39:22,040
اگر نگاه کنم  در یکی از گرایش‌هایی که
در جامعه‌ام دوست دارم، به‌عنوان مثال در من

1652
00:39:22,040 --> 00:39:22,050
در جامعه‌ام دوست دارم، به‌عنوان مثال در من
 

1653
00:39:22,050 --> 00:39:23,810
در جامعه‌ام دوست دارم، به‌عنوان مثال در من
در مؤسسه‌ام دروغ می‌گوید: دو

1654
00:39:23,810 --> 00:39:23,820
در مؤسسه‌ام دروغ می‌گوید: دو
 

1655
00:39:23,820 --> 00:39:28,160
در مؤسسه‌ام دروغ می‌گوید: دو
موضوع داغ چیست Gans و Rain برای

1656
00:39:28,160 --> 00:39:28,170
موضوع داغ چیست Gans و Rain برای
 

1657
00:39:28,170 --> 00:39:32,000
موضوع داغ چیست Gans و Rain برای
دور زدن، حتی اگر در مونترال به‌ویژه

1658
00:39:32,000 --> 00:39:32,010
دور زدن، حتی اگر در مونترال به‌ویژه
 

1659
00:39:32,010 --> 00:39:33,050
دور زدن، حتی اگر در مونترال به‌ویژه
مانند یادگیری تقویتی

1660
00:39:33,050 --> 00:39:33,060
مانند یادگیری تقویتی
 

1661
00:39:33,060 --> 00:39:36,350
مانند یادگیری تقویتی
چیزی تقریباً غایب بود فقط

1662
00:39:36,350 --> 00:39:36,360
چیزی تقریباً غایب بود فقط
 

1663
00:39:36,360 --> 00:39:39,470
چیزی تقریباً غایب بود فقط
دو یا  سه سال پیش، بنابراین واقعاً

1664
00:39:39,470 --> 00:39:39,480
دو یا  سه سال پیش، بنابراین واقعاً
 

1665
00:39:39,480 --> 00:39:42,800
دو یا  سه سال پیش، بنابراین واقعاً
علاقه زیادی از سوی دانش‌آموزان است و

1666
00:39:42,800 --> 00:39:42,810
علاقه زیادی از سوی دانش‌آموزان است و
 

1667
00:39:42,810 --> 00:39:46,880
علاقه زیادی از سوی دانش‌آموزان است و
علاقه زیادی از سوی افرادی مانند من وجود دارد،

1668
00:39:46,880 --> 00:39:46,890

 

1669
00:39:46,890 --> 00:39:49,019

بنابراین می‌توانم بگویم این چیزی است که در آن

1670
00:39:49,019 --> 00:39:49,029
بنابراین می‌توانم بگویم این چیزی است که در آن
 

1671
00:39:49,029 --> 00:39:51,630
بنابراین می‌توانم بگویم این چیزی است که در آن
ما پیشرفت بیشتری را شاهد خواهیم بود، حتی

1672
00:39:51,630 --> 00:39:51,640
ما پیشرفت بیشتری را شاهد خواهیم بود، حتی
 

1673
00:39:51,640 --> 00:39:54,420
ما پیشرفت بیشتری را شاهد خواهیم بود، حتی
اگر هنوز از

1674
00:39:54,420 --> 00:39:54,430
اگر هنوز از
 

1675
00:39:54,430 --> 00:39:58,289
اگر هنوز از
نظر عواقب صنعتی واقعی چیزی ارائه نکرده است.  حتی

1676
00:39:58,289 --> 00:39:58,299
نظر عواقب صنعتی واقعی چیزی ارائه نکرده است.  حتی
 

1677
00:39:58,299 --> 00:40:00,029
نظر عواقب صنعتی واقعی چیزی ارائه نکرده است.  حتی
با وجود اینکه الفاگو وجود دارد،

1678
00:40:00,029 --> 00:40:00,039
با وجود اینکه الفاگو وجود دارد،
 

1679
00:40:00,039 --> 00:40:01,799
با وجود اینکه الفاگو وجود دارد،
گوگل در حال حاضر از این بابت پول در نمی آورد،

1680
00:40:01,799 --> 00:40:01,809
گوگل در حال حاضر از این بابت پول در نمی آورد،
 

1681
00:40:01,809 --> 00:40:04,529
گوگل در حال حاضر از این بابت پول در نمی آورد،
اما من فکر می کنم در درازمدت

1682
00:40:04,529 --> 00:40:04,539
اما من فکر می کنم در درازمدت
 

1683
00:40:04,539 --> 00:40:06,209
اما من فکر می کنم در درازمدت
این واقعاً به دلایل زیادی بسیار مهم است،

1684
00:40:06,209 --> 00:40:06,219
این واقعاً به دلایل زیادی بسیار مهم است،
 

1685
00:40:06,219 --> 00:40:10,049
این واقعاً به دلایل زیادی بسیار مهم است،
بنابراین به عبارت دیگر عامل، می توانم

1686
00:40:10,049 --> 00:40:10,059
بنابراین به عبارت دیگر عامل، می توانم
 

1687
00:40:10,059 --> 00:40:12,390
بنابراین به عبارت دیگر عامل، می توانم
بگویم یادگیری تقویتی عزیزم، به

1688
00:40:12,390 --> 00:40:12,400
بگویم یادگیری تقویتی عزیزم، به
 

1689
00:40:12,400 --> 00:40:14,039
بگویم یادگیری تقویتی عزیزم، به
طور کلی، یادگیری عاملی، زیرا این کار را

1690
00:40:14,039 --> 00:40:14,049
طور کلی، یادگیری عاملی، زیرا این کار را
 

1691
00:40:14,049 --> 00:40:15,870
طور کلی، یادگیری عاملی، زیرا این کار را
انجام نمی دهد.  لازم نیست با پاداش همراه باشید، ممکن است

1692
00:40:15,870 --> 00:40:15,880
انجام نمی دهد.  لازم نیست با پاداش همراه باشید، ممکن است
 

1693
00:40:15,880 --> 00:40:17,729
انجام نمی دهد.  لازم نیست با پاداش همراه باشید، ممکن است
به هر طریقی باشد که یک عامل در حال

1694
00:40:17,729 --> 00:40:17,739
به هر طریقی باشد که یک عامل در حال
 

1695
00:40:17,739 --> 00:40:20,789
به هر طریقی باشد که یک عامل در حال
یادگیری در مورد محیط خود است و اکنون

1696
00:40:20,789 --> 00:40:20,799
یادگیری در مورد محیط خود است و اکنون
 

1697
00:40:20,799 --> 00:40:22,469
یادگیری در مورد محیط خود است و اکنون
یادگیری شما را تقویت می کند که شما در مورد آن هیجان زده اید،

1698
00:40:22,469 --> 00:40:22,479
یادگیری شما را تقویت می کند که شما در مورد آن هیجان زده اید،
 

1699
00:40:22,479 --> 00:40:26,009
یادگیری شما را تقویت می کند که شما در مورد آن هیجان زده اید،
آیا فکر می کنید که Gans می تواند

1700
00:40:26,009 --> 00:40:26,019
آیا فکر می کنید که Gans می تواند
 

1701
00:40:26,019 --> 00:40:30,479
آیا فکر می کنید که Gans می تواند
چیزی را ارائه دهد بله، لحظه ای در

1702
00:40:30,479 --> 00:40:30,489
چیزی را ارائه دهد بله، لحظه ای در
 

1703
00:40:30,489 --> 00:40:34,769
چیزی را ارائه دهد بله، لحظه ای در
چاه Gans یا  دیگر مدل‌های مولد به

1704
00:40:34,769 --> 00:40:34,779
چاه Gans یا  دیگر مدل‌های مولد به
 

1705
00:40:34,779 --> 00:40:38,819
چاه Gans یا  دیگر مدل‌های مولد به
اعتقاد من اجزای حیاتی در

1706
00:40:38,819 --> 00:40:38,829
اعتقاد من اجزای حیاتی در
 

1707
00:40:38,829 --> 00:40:41,549
اعتقاد من اجزای حیاتی در
ساخت عواملی خواهند بود که می‌توانند

1708
00:40:41,549 --> 00:40:41,559
ساخت عواملی خواهند بود که می‌توانند
 

1709
00:40:41,559 --> 00:40:44,999
ساخت عواملی خواهند بود که می‌توانند
جهان را درک کنند بسیاری از موفقیت‌های

1710
00:40:44,999 --> 00:40:45,009
جهان را درک کنند بسیاری از موفقیت‌های
 

1711
00:40:45,009 --> 00:40:46,769
جهان را درک کنند بسیاری از موفقیت‌های
یادگیری تقویتی در گذشته

1712
00:40:46,769 --> 00:40:46,779
یادگیری تقویتی در گذشته
 

1713
00:40:46,779 --> 00:40:49,589
یادگیری تقویتی در گذشته
با گرادیان خط‌مشی بوده است، جایی که

1714
00:40:49,589 --> 00:40:49,599
با گرادیان خط‌مشی بوده است، جایی که
 

1715
00:40:49,599 --> 00:40:51,209
با گرادیان خط‌مشی بوده است، جایی که
شما فقط یک خط‌مشی را یاد می‌گیرید و در

1716
00:40:51,209 --> 00:40:51,219
شما فقط یک خط‌مشی را یاد می‌گیرید و در
 

1717
00:40:51,219 --> 00:40:53,489
شما فقط یک خط‌مشی را یاد می‌گیرید و در
واقع یک مدل را نمی‌آموزید.  در جهان، اما

1718
00:40:53,489 --> 00:40:53,499
واقع یک مدل را نمی‌آموزید.  در جهان، اما
 

1719
00:40:53,499 --> 00:40:55,620
واقع یک مدل را نمی‌آموزید.  در جهان، اما
مشکلات زیادی در این زمینه وجود دارد و

1720
00:40:55,620 --> 00:40:55,630
مشکلات زیادی در این زمینه وجود دارد و
 

1721
00:40:55,630 --> 00:40:57,390
مشکلات زیادی در این زمینه وجود دارد و
ما نمی دانیم که چگونه می توانیم بر اساس مدل خودمان را

1722
00:40:57,390 --> 00:40:57,400
ما نمی دانیم که چگونه می توانیم بر اساس مدل خودمان را
 

1723
00:40:57,400 --> 00:41:00,390
ما نمی دانیم که چگونه می توانیم بر اساس مدل خودمان را
در حال حاضر انجام دهیم، اما فکر می کنم اینجا جایی است که باید

1724
00:41:00,390 --> 00:41:00,400
در حال حاضر انجام دهیم، اما فکر می کنم اینجا جایی است که باید
 

1725
00:41:00,400 --> 00:41:03,569
در حال حاضر انجام دهیم، اما فکر می کنم اینجا جایی است که باید
برویم تا مدل هایی بسازیم

1726
00:41:03,569 --> 00:41:03,579
برویم تا مدل هایی بسازیم
 

1727
00:41:03,579 --> 00:41:05,849
برویم تا مدل هایی بسازیم
که بتوانند سریع تر و بهتر تعمیم دهند.

1728
00:41:05,849 --> 00:41:05,859
که بتوانند سریع تر و بهتر تعمیم دهند.
 

1729
00:41:05,859 --> 00:41:09,900
که بتوانند سریع تر و بهتر تعمیم دهند.
توزیع‌های جدیدی که

1730
00:41:09,900 --> 00:41:09,910
توزیع‌های جدیدی که
 

1731
00:41:09,910 --> 00:41:12,319
توزیع‌های جدیدی که
تا حدودی حداقل

1732
00:41:12,319 --> 00:41:12,329
تا حدودی حداقل
 

1733
00:41:12,329 --> 00:41:16,019
تا حدودی حداقل
مکانیسم‌های علت و معلولی در جهان را در بر می‌گیرند، آخرین

1734
00:41:16,019 --> 00:41:16,029
مکانیسم‌های علت و معلولی در جهان را در بر می‌گیرند، آخرین
 

1735
00:41:16,029 --> 00:41:19,349
مکانیسم‌های علت و معلولی در جهان را در بر می‌گیرند، آخرین
سوالی را مطرح می‌کنند که چه چیزی باعث شد عاشق

1736
00:41:19,349 --> 00:41:19,359
سوالی را مطرح می‌کنند که چه چیزی باعث شد عاشق
 

1737
00:41:19,359 --> 00:41:21,739
سوالی را مطرح می‌کنند که چه چیزی باعث شد عاشق
هوش مصنوعی شوید، اگر به گذشته نگاه کنید

1738
00:41:21,739 --> 00:41:21,749
هوش مصنوعی شوید، اگر به گذشته نگاه کنید
 

1739
00:41:21,749 --> 00:41:25,579
هوش مصنوعی شوید، اگر به گذشته نگاه کنید
اولین لحظه زندگی‌تان چه بوده است،

1740
00:41:25,579 --> 00:41:25,589
اولین لحظه زندگی‌تان چه بوده است،
 

1741
00:41:25,589 --> 00:41:28,140
اولین لحظه زندگی‌تان چه بوده است،
زمانی که او مجذوب

1742
00:41:28,140 --> 00:41:28,150
زمانی که او مجذوب
 

1743
00:41:28,150 --> 00:41:29,999
زمانی که او مجذوب
انسان شده‌اید.  ذهن یا

1744
00:41:29,999 --> 00:41:30,009
انسان شده‌اید.  ذهن یا
 

1745
00:41:30,009 --> 00:41:32,189
انسان شده‌اید.  ذهن یا
ذهن مصنوعی که میدونی وقتی سر

1746
00:41:32,189 --> 00:41:32,199
ذهن مصنوعی که میدونی وقتی سر
 

1747
00:41:32,199 --> 00:41:34,189
ذهن مصنوعی که میدونی وقتی سر
درس نبودم زیاد میخوندم و بعد

1748
00:41:34,189 --> 00:41:34,199
درس نبودم زیاد میخوندم و بعد
 

1749
00:41:34,199 --> 00:41:37,979
درس نبودم زیاد میخوندم و بعد
شروع کردم به خوندن داستانهای علمی تخیلی اونجا

1750
00:41:37,979 --> 00:41:37,989
شروع کردم به خوندن داستانهای علمی تخیلی اونجا
 

1751
00:41:37,989 --> 00:41:40,650
شروع کردم به خوندن داستانهای علمی تخیلی اونجا
میری ولی فهمیدم که

1752
00:41:40,650 --> 00:41:40,660
میری ولی فهمیدم که
 

1753
00:41:40,660 --> 00:41:42,089
میری ولی فهمیدم که
اونجا گیر کردم و

1754
00:41:42,089 --> 00:41:42,099
اونجا گیر کردم و
 

1755
00:41:42,099 --> 00:41:45,239
اونجا گیر کردم و
بعد و بعد میدونی که من  یکی از

1756
00:41:45,239 --> 00:41:45,249
بعد و بعد میدونی که من  یکی از
 

1757
00:41:45,249 --> 00:41:48,839
بعد و بعد میدونی که من  یکی از
اولین رایانه های شخصی را داشتم و من

1758
00:41:48,839 --> 00:41:48,849
اولین رایانه های شخصی را داشتم و من
 

1759
00:41:48,849 --> 00:41:52,109
اولین رایانه های شخصی را داشتم و من
به برنامه نویسی علاقه مند شدم و بنابراین می

1760
00:41:52,109 --> 00:41:52,119
به برنامه نویسی علاقه مند شدم و بنابراین می
 

1761
00:41:52,119 --> 00:41:53,999
به برنامه نویسی علاقه مند شدم و بنابراین می
دانید که با داستان شروع کنید و سپس آن را به واقعیت تبدیل کنید،

1762
00:41:53,999 --> 00:41:54,009
دانید که با داستان شروع کنید و سپس آن را به واقعیت تبدیل کنید،
 

1763
00:41:54,009 --> 00:41:55,349
دانید که با داستان شروع کنید و سپس آن را به واقعیت تبدیل کنید،
درست است

1764
00:41:55,349 --> 00:41:55,359
درست است
 

1765
00:41:55,359 --> 00:41:57,479
درست است
یوشیو از شما بسیار سپاسگزارم که با

1766
00:41:57,479 --> 00:41:57,489
یوشیو از شما بسیار سپاسگزارم که با
 

1767
00:41:57,489 --> 00:42:05,740
یوشیو از شما بسیار سپاسگزارم که با
خوشحالی من صحبت کردید

1768
00:42:05,740 --> 00:42:05,750

 

1769
00:42:05,750 --> 00:42:07,810



1
00:00:00,060 --> 00:00:01,579

the following is a conversation with

2
00:00:01,579 --> 00:00:01,589
the following is a conversation with
 

3
00:00:01,589 --> 00:00:04,090
the following is a conversation with
Kate darling a researcher at MIT

4
00:00:04,090 --> 00:00:04,100
Kate darling a researcher at MIT
 

5
00:00:04,100 --> 00:00:06,829
Kate darling a researcher at MIT
interested in social robotics robotics

6
00:00:06,829 --> 00:00:06,839
interested in social robotics robotics
 

7
00:00:06,839 --> 00:00:09,589
interested in social robotics robotics
and generally how technology intersects

8
00:00:09,589 --> 00:00:09,599
and generally how technology intersects
 

9
00:00:09,599 --> 00:00:12,379
and generally how technology intersects
with society she explores the emotional

10
00:00:12,379 --> 00:00:12,389
with society she explores the emotional
 

11
00:00:12,389 --> 00:00:13,730
with society she explores the emotional
connection between human beings and

12
00:00:13,730 --> 00:00:13,740
connection between human beings and
 

13
00:00:13,740 --> 00:00:17,180
connection between human beings and
lifelike machines which for me is one of

14
00:00:17,180 --> 00:00:17,190
lifelike machines which for me is one of
 

15
00:00:17,190 --> 00:00:19,400
lifelike machines which for me is one of
the most exciting topics in all of

16
00:00:19,400 --> 00:00:19,410
the most exciting topics in all of
 

17
00:00:19,410 --> 00:00:22,189
the most exciting topics in all of
artificial intelligence as she writes in

18
00:00:22,189 --> 00:00:22,199
artificial intelligence as she writes in
 

19
00:00:22,199 --> 00:00:24,890
artificial intelligence as she writes in
her bio she's a caretaker of several

20
00:00:24,890 --> 00:00:24,900
her bio she's a caretaker of several
 

21
00:00:24,900 --> 00:00:27,290
her bio she's a caretaker of several
domestic robots including her plio

22
00:00:27,290 --> 00:00:27,300
domestic robots including her plio
 

23
00:00:27,300 --> 00:00:32,299
domestic robots including her plio
dinosaur robots named Yochai Peter and

24
00:00:32,299 --> 00:00:32,309
dinosaur robots named Yochai Peter and
 

25
00:00:32,309 --> 00:00:34,639
dinosaur robots named Yochai Peter and
mr. spaghetti she is one of the funniest

26
00:00:34,639 --> 00:00:34,649
mr. spaghetti she is one of the funniest
 

27
00:00:34,649 --> 00:00:36,410
mr. spaghetti she is one of the funniest
and brightest minds I've ever had the

28
00:00:36,410 --> 00:00:36,420
and brightest minds I've ever had the
 

29
00:00:36,420 --> 00:00:38,869
and brightest minds I've ever had the
fortune to talk to this conversation was

30
00:00:38,869 --> 00:00:38,879
fortune to talk to this conversation was
 

31
00:00:38,879 --> 00:00:40,700
fortune to talk to this conversation was
recorded recently but before the

32
00:00:40,700 --> 00:00:40,710
recorded recently but before the
 

33
00:00:40,710 --> 00:00:42,860
recorded recently but before the
outbreak of the pandemic for everyone

34
00:00:42,860 --> 00:00:42,870
outbreak of the pandemic for everyone
 

35
00:00:42,870 --> 00:00:44,660
outbreak of the pandemic for everyone
feeling the burden of this crisis

36
00:00:44,660 --> 00:00:44,670
feeling the burden of this crisis
 

37
00:00:44,670 --> 00:00:47,600
feeling the burden of this crisis
I'm sending love your way this is the

38
00:00:47,600 --> 00:00:47,610
I'm sending love your way this is the
 

39
00:00:47,610 --> 00:00:49,580
I'm sending love your way this is the
artificial intelligence podcast if you

40
00:00:49,580 --> 00:00:49,590
artificial intelligence podcast if you
 

41
00:00:49,590 --> 00:00:51,860
artificial intelligence podcast if you
enjoy it subscribe on YouTube review it

42
00:00:51,860 --> 00:00:51,870
enjoy it subscribe on YouTube review it
 

43
00:00:51,870 --> 00:00:53,360
enjoy it subscribe on YouTube review it
with five stars an apple podcast

44
00:00:53,360 --> 00:00:53,370
with five stars an apple podcast
 

45
00:00:53,370 --> 00:00:55,760
with five stars an apple podcast
supported on patreon are simply connect

46
00:00:55,760 --> 00:00:55,770
supported on patreon are simply connect
 

47
00:00:55,770 --> 00:00:58,310
supported on patreon are simply connect
with me on Twitter Alex Friedman spelled

48
00:00:58,310 --> 00:00:58,320
with me on Twitter Alex Friedman spelled
 

49
00:00:58,320 --> 00:01:01,910
with me on Twitter Alex Friedman spelled
Fri D ma n as usual I'll do a few

50
00:01:01,910 --> 00:01:01,920
Fri D ma n as usual I'll do a few
 

51
00:01:01,920 --> 00:01:03,860
Fri D ma n as usual I'll do a few
minutes of ads now and never any ads in

52
00:01:03,860 --> 00:01:03,870
minutes of ads now and never any ads in
 

53
00:01:03,870 --> 00:01:05,390
minutes of ads now and never any ads in
the middle that can break the flow of

54
00:01:05,390 --> 00:01:05,400
the middle that can break the flow of
 

55
00:01:05,400 --> 00:01:07,580
the middle that can break the flow of
the conversation I hope that works for

56
00:01:07,580 --> 00:01:07,590
the conversation I hope that works for
 

57
00:01:07,590 --> 00:01:09,230
the conversation I hope that works for
you and doesn't hurt the listening

58
00:01:09,230 --> 00:01:09,240
you and doesn't hurt the listening
 

59
00:01:09,240 --> 00:01:12,649
you and doesn't hurt the listening
experience quick summary of the ads to

60
00:01:12,649 --> 00:01:12,659
experience quick summary of the ads to
 

61
00:01:12,659 --> 00:01:15,789
experience quick summary of the ads to
sponsors masterclass and expressvpn

62
00:01:15,789 --> 00:01:15,799
sponsors masterclass and expressvpn
 

63
00:01:15,799 --> 00:01:18,170
sponsors masterclass and expressvpn
please consider supporting the podcast

64
00:01:18,170 --> 00:01:18,180
please consider supporting the podcast
 

65
00:01:18,180 --> 00:01:20,660
please consider supporting the podcast
by signing up to master class and master

66
00:01:20,660 --> 00:01:20,670
by signing up to master class and master
 

67
00:01:20,670 --> 00:01:24,590
by signing up to master class and master
class complex and getting expressvpn and

68
00:01:24,590 --> 00:01:24,600
class complex and getting expressvpn and
 

69
00:01:24,600 --> 00:01:28,940
class complex and getting expressvpn and
expressvpn comm slash flex pod this show

70
00:01:28,940 --> 00:01:28,950
expressvpn comm slash flex pod this show
 

71
00:01:28,950 --> 00:01:32,330
expressvpn comm slash flex pod this show
is sponsored by master class sign-up and

72
00:01:32,330 --> 00:01:32,340
is sponsored by master class sign-up and
 

73
00:01:32,340 --> 00:01:34,789
is sponsored by master class sign-up and
master class comm / flex to get a

74
00:01:34,789 --> 00:01:34,799
master class comm / flex to get a
 

75
00:01:34,799 --> 00:01:37,130
master class comm / flex to get a
discount and to support this podcast

76
00:01:37,130 --> 00:01:37,140
discount and to support this podcast
 

77
00:01:37,140 --> 00:01:39,679
discount and to support this podcast
when I first heard about master class I

78
00:01:39,679 --> 00:01:39,689
when I first heard about master class I
 

79
00:01:39,689 --> 00:01:42,080
when I first heard about master class I
thought it was too good to be true for

80
00:01:42,080 --> 00:01:42,090
thought it was too good to be true for
 

81
00:01:42,090 --> 00:01:45,050
thought it was too good to be true for
$180 a year you get an all-access pass

82
00:01:45,050 --> 00:01:45,060
$180 a year you get an all-access pass
 

83
00:01:45,060 --> 00:01:47,600
$180 a year you get an all-access pass
to watch courses from the list some of

84
00:01:47,600 --> 00:01:47,610
to watch courses from the list some of
 

85
00:01:47,610 --> 00:01:50,300
to watch courses from the list some of
my favorites Chris Hatfield on space

86
00:01:50,300 --> 00:01:50,310
my favorites Chris Hatfield on space
 

87
00:01:50,310 --> 00:01:52,639
my favorites Chris Hatfield on space
exploration Neil deGrasse Tyson on

88
00:01:52,639 --> 00:01:52,649
exploration Neil deGrasse Tyson on
 

89
00:01:52,649 --> 00:01:54,109
exploration Neil deGrasse Tyson on
scientific thinking and communication

90
00:01:54,109 --> 00:01:54,119
scientific thinking and communication
 

91
00:01:54,119 --> 00:01:57,830
scientific thinking and communication
will write creator SimCity and sims love

92
00:01:57,830 --> 00:01:57,840
will write creator SimCity and sims love
 

93
00:01:57,840 --> 00:02:00,770
will write creator SimCity and sims love
those games on game design Carlos

94
00:02:00,770 --> 00:02:00,780
those games on game design Carlos
 

95
00:02:00,780 --> 00:02:03,800
those games on game design Carlos
Santana on guitar garry kasparov on

96
00:02:03,800 --> 00:02:03,810
Santana on guitar garry kasparov on
 

97
00:02:03,810 --> 00:02:06,560
Santana on guitar garry kasparov on
chess daniel negreanu on poker and many

98
00:02:06,560 --> 00:02:06,570
chess daniel negreanu on poker and many
 

99
00:02:06,570 --> 00:02:08,340
chess daniel negreanu on poker and many
more Chris had

100
00:02:08,340 --> 00:02:08,350
more Chris had
 

101
00:02:08,350 --> 00:02:10,560
more Chris had
explaining how Rockets work and the

102
00:02:10,560 --> 00:02:10,570
explaining how Rockets work and the
 

103
00:02:10,570 --> 00:02:11,910
explaining how Rockets work and the
experience of being launched into space

104
00:02:11,910 --> 00:02:11,920
experience of being launched into space
 

105
00:02:11,920 --> 00:02:15,150
experience of being launched into space
alone is worth the money by the way you

106
00:02:15,150 --> 00:02:15,160
alone is worth the money by the way you
 

107
00:02:15,160 --> 00:02:17,600
alone is worth the money by the way you
can watch it on basically any device

108
00:02:17,600 --> 00:02:17,610
can watch it on basically any device
 

109
00:02:17,610 --> 00:02:20,550
can watch it on basically any device
once again sign up on master class comm

110
00:02:20,550 --> 00:02:20,560
once again sign up on master class comm
 

111
00:02:20,560 --> 00:02:23,520
once again sign up on master class comm
/ flex to get a discount and to support

112
00:02:23,520 --> 00:02:23,530
/ flex to get a discount and to support
 

113
00:02:23,530 --> 00:02:26,340
/ flex to get a discount and to support
this podcast this show sponsored by

114
00:02:26,340 --> 00:02:26,350
this podcast this show sponsored by
 

115
00:02:26,350 --> 00:02:30,960
this podcast this show sponsored by
Express vpm get it at expressvpn comm /

116
00:02:30,960 --> 00:02:30,970
Express vpm get it at expressvpn comm /
 

117
00:02:30,970 --> 00:02:34,020
Express vpm get it at expressvpn comm /
FlexPod to get a discount and to support

118
00:02:34,020 --> 00:02:34,030
FlexPod to get a discount and to support
 

119
00:02:34,030 --> 00:02:36,420
FlexPod to get a discount and to support
this podcast I've been using expressvpn

120
00:02:36,420 --> 00:02:36,430
this podcast I've been using expressvpn
 

121
00:02:36,430 --> 00:02:39,840
this podcast I've been using expressvpn
for many years I love it it's easy to

122
00:02:39,840 --> 00:02:39,850
for many years I love it it's easy to
 

123
00:02:39,850 --> 00:02:42,330
for many years I love it it's easy to
use press the big power on button and

124
00:02:42,330 --> 00:02:42,340
use press the big power on button and
 

125
00:02:42,340 --> 00:02:44,940
use press the big power on button and
your privacy is protected and if you

126
00:02:44,940 --> 00:02:44,950
your privacy is protected and if you
 

127
00:02:44,950 --> 00:02:47,070
your privacy is protected and if you
like you can make it look like your

128
00:02:47,070 --> 00:02:47,080
like you can make it look like your
 

129
00:02:47,080 --> 00:02:48,930
like you can make it look like your
locations anywhere else in the world I

130
00:02:48,930 --> 00:02:48,940
locations anywhere else in the world I
 

131
00:02:48,940 --> 00:02:51,210
locations anywhere else in the world I
might be in Boston now but it can make

132
00:02:51,210 --> 00:02:51,220
might be in Boston now but it can make
 

133
00:02:51,220 --> 00:02:52,800
might be in Boston now but it can make
it look like I'm in New York London

134
00:02:52,800 --> 00:02:52,810
it look like I'm in New York London
 

135
00:02:52,810 --> 00:02:55,950
it look like I'm in New York London
Paris or anywhere else this has a large

136
00:02:55,950 --> 00:02:55,960
Paris or anywhere else this has a large
 

137
00:02:55,960 --> 00:02:58,470
Paris or anywhere else this has a large
number of obvious benefits certainly it

138
00:02:58,470 --> 00:02:58,480
number of obvious benefits certainly it
 

139
00:02:58,480 --> 00:02:59,850
number of obvious benefits certainly it
allows you to access international

140
00:02:59,850 --> 00:02:59,860
allows you to access international
 

141
00:02:59,860 --> 00:03:01,950
allows you to access international
versions of streaming websites like the

142
00:03:01,950 --> 00:03:01,960
versions of streaming websites like the
 

143
00:03:01,960 --> 00:03:04,640
versions of streaming websites like the
Japanese Netflix or the UK Hulu

144
00:03:04,640 --> 00:03:04,650
Japanese Netflix or the UK Hulu
 

145
00:03:04,650 --> 00:03:07,530
Japanese Netflix or the UK Hulu
expressvpn works on any device you can

146
00:03:07,530 --> 00:03:07,540
expressvpn works on any device you can
 

147
00:03:07,540 --> 00:03:11,130
expressvpn works on any device you can
imagine I use it on Linux shout-out to

148
00:03:11,130 --> 00:03:11,140
imagine I use it on Linux shout-out to
 

149
00:03:11,140 --> 00:03:15,900
imagine I use it on Linux shout-out to
bond to 2004 Windows Android but it's

150
00:03:15,900 --> 00:03:15,910
bond to 2004 Windows Android but it's
 

151
00:03:15,910 --> 00:03:18,240
bond to 2004 Windows Android but it's
available everywhere else to once again

152
00:03:18,240 --> 00:03:18,250
available everywhere else to once again
 

153
00:03:18,250 --> 00:03:22,740
available everywhere else to once again
get it at expressvpn comm / luxe pod to

154
00:03:22,740 --> 00:03:22,750
get it at expressvpn comm / luxe pod to
 

155
00:03:22,750 --> 00:03:24,480
get it at expressvpn comm / luxe pod to
get a discount and to support this

156
00:03:24,480 --> 00:03:24,490
get a discount and to support this
 

157
00:03:24,490 --> 00:03:28,230
get a discount and to support this
podcast and now here's my conversation

158
00:03:28,230 --> 00:03:28,240
podcast and now here's my conversation
 

159
00:03:28,240 --> 00:03:31,450
podcast and now here's my conversation
with Kate darling

160
00:03:31,450 --> 00:03:31,460
with Kate darling
 

161
00:03:31,460 --> 00:03:34,330
with Kate darling
Kota robot ethics at Harvard what are

162
00:03:34,330 --> 00:03:34,340
Kota robot ethics at Harvard what are
 

163
00:03:34,340 --> 00:03:37,450
Kota robot ethics at Harvard what are
some ethical issues that arise in the

164
00:03:37,450 --> 00:03:37,460
some ethical issues that arise in the
 

165
00:03:37,460 --> 00:03:40,750
some ethical issues that arise in the
world with robots yeah that was a

166
00:03:40,750 --> 00:03:40,760
world with robots yeah that was a
 

167
00:03:40,760 --> 00:03:43,000
world with robots yeah that was a
reading group that I did when I like at

168
00:03:43,000 --> 00:03:43,010
reading group that I did when I like at
 

169
00:03:43,010 --> 00:03:45,070
reading group that I did when I like at
the very beginning first became

170
00:03:45,070 --> 00:03:45,080
the very beginning first became
 

171
00:03:45,080 --> 00:03:47,980
the very beginning first became
interested in this topic so I think if I

172
00:03:47,980 --> 00:03:47,990
interested in this topic so I think if I
 

173
00:03:47,990 --> 00:03:49,300
interested in this topic so I think if I
taught that class today would look very

174
00:03:49,300 --> 00:03:49,310
taught that class today would look very
 

175
00:03:49,310 --> 00:03:53,080
taught that class today would look very
very different robot ethics

176
00:03:53,080 --> 00:03:53,090
very different robot ethics
 

177
00:03:53,090 --> 00:03:54,450
very different robot ethics
it sounds very science fictiony

178
00:03:54,450 --> 00:03:54,460
it sounds very science fictiony
 

179
00:03:54,460 --> 00:03:57,340
it sounds very science fictiony
especially did back then but I think

180
00:03:57,340 --> 00:03:57,350
especially did back then but I think
 

181
00:03:57,350 --> 00:04:01,330
especially did back then but I think
that some of the issues that people in

182
00:04:01,330 --> 00:04:01,340
that some of the issues that people in
 

183
00:04:01,340 --> 00:04:03,310
that some of the issues that people in
robot ethics are concerned with her just

184
00:04:03,310 --> 00:04:03,320
robot ethics are concerned with her just
 

185
00:04:03,320 --> 00:04:04,720
robot ethics are concerned with her just
around the ethical use of robotic

186
00:04:04,720 --> 00:04:04,730
around the ethical use of robotic
 

187
00:04:04,730 --> 00:04:06,720
around the ethical use of robotic
technology in general so for example

188
00:04:06,720 --> 00:04:06,730
technology in general so for example
 

189
00:04:06,730 --> 00:04:09,070
technology in general so for example
responsibility for harm automated weapon

190
00:04:09,070 --> 00:04:09,080
responsibility for harm automated weapon
 

191
00:04:09,080 --> 00:04:10,990
responsibility for harm automated weapon
systems things like privacy and data

192
00:04:10,990 --> 00:04:11,000
systems things like privacy and data
 

193
00:04:11,000 --> 00:04:15,010
systems things like privacy and data
security things like and automation and

194
00:04:15,010 --> 00:04:15,020
security things like and automation and
 

195
00:04:15,020 --> 00:04:19,150
security things like and automation and
labor markets and then personally I'm

196
00:04:19,150 --> 00:04:19,160
labor markets and then personally I'm
 

197
00:04:19,160 --> 00:04:20,590
labor markets and then personally I'm
really interested in some of the social

198
00:04:20,590 --> 00:04:20,600
really interested in some of the social
 

199
00:04:20,600 --> 00:04:22,600
really interested in some of the social
issues that come out of our social

200
00:04:22,600 --> 00:04:22,610
issues that come out of our social
 

201
00:04:22,610 --> 00:04:24,450
issues that come out of our social
relationships with robot one-on-one

202
00:04:24,450 --> 00:04:24,460
relationships with robot one-on-one
 

203
00:04:24,460 --> 00:04:26,980
relationships with robot one-on-one
relationship with robot yeah I think

204
00:04:26,980 --> 00:04:26,990
relationship with robot yeah I think
 

205
00:04:26,990 --> 00:04:28,360
relationship with robot yeah I think
most of stuff we have to talk about is

206
00:04:28,360 --> 00:04:28,370
most of stuff we have to talk about is
 

207
00:04:28,370 --> 00:04:30,070
most of stuff we have to talk about is
like one-on-one social stuff that's what

208
00:04:30,070 --> 00:04:30,080
like one-on-one social stuff that's what
 

209
00:04:30,080 --> 00:04:31,720
like one-on-one social stuff that's what
I love and I think that's what you're

210
00:04:31,720 --> 00:04:31,730
I love and I think that's what you're
 

211
00:04:31,730 --> 00:04:33,790
I love and I think that's what you're
you know as well and they're expert in

212
00:04:33,790 --> 00:04:33,800
you know as well and they're expert in
 

213
00:04:33,800 --> 00:04:36,970
you know as well and they're expert in
but a societal oh there's like there's a

214
00:04:36,970 --> 00:04:36,980
but a societal oh there's like there's a
 

215
00:04:36,980 --> 00:04:38,710
but a societal oh there's like there's a
presidential candidate now and Joo yang

216
00:04:38,710 --> 00:04:38,720
presidential candidate now and Joo yang
 

217
00:04:38,720 --> 00:04:43,870
presidential candidate now and Joo yang
running concerned about automation and

218
00:04:43,870 --> 00:04:43,880
running concerned about automation and
 

219
00:04:43,880 --> 00:04:46,030
running concerned about automation and
robots and AI and general taking away

220
00:04:46,030 --> 00:04:46,040
robots and AI and general taking away
 

221
00:04:46,040 --> 00:04:49,240
robots and AI and general taking away
jobs he has a proposal of ubi universal

222
00:04:49,240 --> 00:04:49,250
jobs he has a proposal of ubi universal
 

223
00:04:49,250 --> 00:04:50,950
jobs he has a proposal of ubi universal
basic income of everybody gets a

224
00:04:50,950 --> 00:04:50,960
basic income of everybody gets a
 

225
00:04:50,960 --> 00:04:53,910
basic income of everybody gets a
thousand bucks yeah as a way to sort of

226
00:04:53,910 --> 00:04:53,920
thousand bucks yeah as a way to sort of
 

227
00:04:53,920 --> 00:04:56,170
thousand bucks yeah as a way to sort of
save you if you lose your job from

228
00:04:56,170 --> 00:04:56,180
save you if you lose your job from
 

229
00:04:56,180 --> 00:04:58,840
save you if you lose your job from
automation to allow you time to discover

230
00:04:58,840 --> 00:04:58,850
automation to allow you time to discover
 

231
00:04:58,850 --> 00:05:03,070
automation to allow you time to discover
what it is that you would like to or

232
00:05:03,070 --> 00:05:03,080
what it is that you would like to or
 

233
00:05:03,080 --> 00:05:06,670
what it is that you would like to or
even love to do yes so I lived in

234
00:05:06,670 --> 00:05:06,680
even love to do yes so I lived in
 

235
00:05:06,680 --> 00:05:09,370
even love to do yes so I lived in
Switzerland for 20 years and universal

236
00:05:09,370 --> 00:05:09,380
Switzerland for 20 years and universal
 

237
00:05:09,380 --> 00:05:12,130
Switzerland for 20 years and universal
basic income has been more of a topic

238
00:05:12,130 --> 00:05:12,140
basic income has been more of a topic
 

239
00:05:12,140 --> 00:05:14,950
basic income has been more of a topic
there separate from the whole robots and

240
00:05:14,950 --> 00:05:14,960
there separate from the whole robots and
 

241
00:05:14,960 --> 00:05:18,580
there separate from the whole robots and
jobs issue so it's so interesting to me

242
00:05:18,580 --> 00:05:18,590
jobs issue so it's so interesting to me
 

243
00:05:18,590 --> 00:05:20,860
jobs issue so it's so interesting to me
to see kind of these Silicon Valley

244
00:05:20,860 --> 00:05:20,870
to see kind of these Silicon Valley
 

245
00:05:20,870 --> 00:05:23,590
to see kind of these Silicon Valley
people latch on to this concept that

246
00:05:23,590 --> 00:05:23,600
people latch on to this concept that
 

247
00:05:23,600 --> 00:05:27,130
people latch on to this concept that
came from a very kind of left-wing

248
00:05:27,130 --> 00:05:27,140
came from a very kind of left-wing
 

249
00:05:27,140 --> 00:05:30,610
came from a very kind of left-wing
socialist you know

250
00:05:30,610 --> 00:05:30,620
socialist you know
 

251
00:05:30,620 --> 00:05:33,860
socialist you know
kind of a different place in Europe

252
00:05:33,860 --> 00:05:33,870
kind of a different place in Europe
 

253
00:05:33,870 --> 00:05:36,710
kind of a different place in Europe
but on the automation labor markets

254
00:05:36,710 --> 00:05:36,720
but on the automation labor markets
 

255
00:05:36,720 --> 00:05:40,870
but on the automation labor markets
topic I think that it's very is so

256
00:05:40,870 --> 00:05:40,880
topic I think that it's very is so
 

257
00:05:40,880 --> 00:05:43,190
topic I think that it's very is so
sometimes in those conversations I think

258
00:05:43,190 --> 00:05:43,200
sometimes in those conversations I think
 

259
00:05:43,200 --> 00:05:45,920
sometimes in those conversations I think
people overestimate where robotic

260
00:05:45,920 --> 00:05:45,930
people overestimate where robotic
 

261
00:05:45,930 --> 00:05:49,250
people overestimate where robotic
technology is right now and we also have

262
00:05:49,250 --> 00:05:49,260
technology is right now and we also have
 

263
00:05:49,260 --> 00:05:50,870
technology is right now and we also have
this fallacy of constantly comparing

264
00:05:50,870 --> 00:05:50,880
this fallacy of constantly comparing
 

265
00:05:50,880 --> 00:05:53,690
this fallacy of constantly comparing
robots to humans and thinking of this as

266
00:05:53,690 --> 00:05:53,700
robots to humans and thinking of this as
 

267
00:05:53,700 --> 00:05:55,790
robots to humans and thinking of this as
a one-to-one replacement of jobs so even

268
00:05:55,790 --> 00:05:55,800
a one-to-one replacement of jobs so even
 

269
00:05:55,800 --> 00:05:58,520
a one-to-one replacement of jobs so even
like Bill Gates a few years ago said

270
00:05:58,520 --> 00:05:58,530
like Bill Gates a few years ago said
 

271
00:05:58,530 --> 00:06:00,290
like Bill Gates a few years ago said
something about you know maybe we should

272
00:06:00,290 --> 00:06:00,300
something about you know maybe we should
 

273
00:06:00,300 --> 00:06:02,990
something about you know maybe we should
have a system that taxes robots for

274
00:06:02,990 --> 00:06:03,000
have a system that taxes robots for
 

275
00:06:03,000 --> 00:06:07,100
have a system that taxes robots for
taking people's jobs and it just I I

276
00:06:07,100 --> 00:06:07,110
taking people's jobs and it just I I
 

277
00:06:07,110 --> 00:06:08,870
taking people's jobs and it just I I
mean I'm sure that was taken out of

278
00:06:08,870 --> 00:06:08,880
mean I'm sure that was taken out of
 

279
00:06:08,880 --> 00:06:10,430
mean I'm sure that was taken out of
context you know he's a really smart guy

280
00:06:10,430 --> 00:06:10,440
context you know he's a really smart guy
 

281
00:06:10,440 --> 00:06:12,230
context you know he's a really smart guy
but that sounds to me like kind of

282
00:06:12,230 --> 00:06:12,240
but that sounds to me like kind of
 

283
00:06:12,240 --> 00:06:13,940
but that sounds to me like kind of
viewing it as a one to one replacement

284
00:06:13,940 --> 00:06:13,950
viewing it as a one to one replacement
 

285
00:06:13,950 --> 00:06:17,330
viewing it as a one to one replacement
versus viewing this technology as kind

286
00:06:17,330 --> 00:06:17,340
versus viewing this technology as kind
 

287
00:06:17,340 --> 00:06:20,150
versus viewing this technology as kind
of a supplemental tool that of course is

288
00:06:20,150 --> 00:06:20,160
of a supplemental tool that of course is
 

289
00:06:20,160 --> 00:06:21,710
of a supplemental tool that of course is
going to shake up a lot of stuff it's

290
00:06:21,710 --> 00:06:21,720
going to shake up a lot of stuff it's
 

291
00:06:21,720 --> 00:06:23,960
going to shake up a lot of stuff it's
gonna change the job landscape but I

292
00:06:23,960 --> 00:06:23,970
gonna change the job landscape but I
 

293
00:06:23,970 --> 00:06:27,500
gonna change the job landscape but I
don't see you know robots taking all the

294
00:06:27,500 --> 00:06:27,510
don't see you know robots taking all the
 

295
00:06:27,510 --> 00:06:29,090
don't see you know robots taking all the
jobs in the next 20 years that's just

296
00:06:29,090 --> 00:06:29,100
jobs in the next 20 years that's just
 

297
00:06:29,100 --> 00:06:31,430
jobs in the next 20 years that's just
not how it's gonna work all right so

298
00:06:31,430 --> 00:06:31,440
not how it's gonna work all right so
 

299
00:06:31,440 --> 00:06:34,100
not how it's gonna work all right so
maybe drifting into the land of more

300
00:06:34,100 --> 00:06:34,110
maybe drifting into the land of more
 

301
00:06:34,110 --> 00:06:36,260
maybe drifting into the land of more
personal relationships with robots and

302
00:06:36,260 --> 00:06:36,270
personal relationships with robots and
 

303
00:06:36,270 --> 00:06:40,010
personal relationships with robots and
interaction and so on I gotta warn you I

304
00:06:40,010 --> 00:06:40,020
interaction and so on I gotta warn you I
 

305
00:06:40,020 --> 00:06:42,980
interaction and so on I gotta warn you I
go I may ask some silly philosophical

306
00:06:42,980 --> 00:06:42,990
go I may ask some silly philosophical
 

307
00:06:42,990 --> 00:06:44,090
go I may ask some silly philosophical
questions I apologize

308
00:06:44,090 --> 00:06:44,100
questions I apologize
 

309
00:06:44,100 --> 00:06:47,450
questions I apologize
so please do okay do you think humans

310
00:06:47,450 --> 00:06:47,460
so please do okay do you think humans
 

311
00:06:47,460 --> 00:06:50,900
so please do okay do you think humans
will abuse robots in their interaction

312
00:06:50,900 --> 00:06:50,910
will abuse robots in their interaction
 

313
00:06:50,910 --> 00:06:53,150
will abuse robots in their interaction
so you've you've had a lot of and we'll

314
00:06:53,150 --> 00:06:53,160
so you've you've had a lot of and we'll
 

315
00:06:53,160 --> 00:06:55,670
so you've you've had a lot of and we'll
talk about it sort of anthropomorphize a

316
00:06:55,670 --> 00:06:55,680
talk about it sort of anthropomorphize a
 

317
00:06:55,680 --> 00:06:59,330
talk about it sort of anthropomorphize a
ssin and and work you know this this

318
00:06:59,330 --> 00:06:59,340
ssin and and work you know this this
 

319
00:06:59,340 --> 00:07:01,640
ssin and and work you know this this
intricate dance emotional dance between

320
00:07:01,640 --> 00:07:01,650
intricate dance emotional dance between
 

321
00:07:01,650 --> 00:07:04,190
intricate dance emotional dance between
human and robot but this seems to be

322
00:07:04,190 --> 00:07:04,200
human and robot but this seems to be
 

323
00:07:04,200 --> 00:07:06,530
human and robot but this seems to be
also a darker side what people when they

324
00:07:06,530 --> 00:07:06,540
also a darker side what people when they
 

325
00:07:06,540 --> 00:07:10,880
also a darker side what people when they
treat the other as servants especially

326
00:07:10,880 --> 00:07:10,890
treat the other as servants especially
 

327
00:07:10,890 --> 00:07:12,530
treat the other as servants especially
they can be a little bit abusive or a

328
00:07:12,530 --> 00:07:12,540
they can be a little bit abusive or a
 

329
00:07:12,540 --> 00:07:15,110
they can be a little bit abusive or a
lot abusive do you think about that do

330
00:07:15,110 --> 00:07:15,120
lot abusive do you think about that do
 

331
00:07:15,120 --> 00:07:17,390
lot abusive do you think about that do
you worry about that yeah I do you think

332
00:07:17,390 --> 00:07:17,400
you worry about that yeah I do you think
 

333
00:07:17,400 --> 00:07:20,990
you worry about that yeah I do you think
about that so I mean one of my one of my

334
00:07:20,990 --> 00:07:21,000
about that so I mean one of my one of my
 

335
00:07:21,000 --> 00:07:22,730
about that so I mean one of my one of my
main interests is the fact that people

336
00:07:22,730 --> 00:07:22,740
main interests is the fact that people
 

337
00:07:22,740 --> 00:07:24,950
main interests is the fact that people
subconsciously treat robots like living

338
00:07:24,950 --> 00:07:24,960
subconsciously treat robots like living
 

339
00:07:24,960 --> 00:07:27,530
subconsciously treat robots like living
things and even though they know that

340
00:07:27,530 --> 00:07:27,540
things and even though they know that
 

341
00:07:27,540 --> 00:07:29,060
things and even though they know that
they're interacting with a machine and

342
00:07:29,060 --> 00:07:29,070
they're interacting with a machine and
 

343
00:07:29,070 --> 00:07:32,060
they're interacting with a machine and
what it means in that context to behave

344
00:07:32,060 --> 00:07:32,070
what it means in that context to behave
 

345
00:07:32,070 --> 00:07:34,970
what it means in that context to behave
you know violently I don't know if you

346
00:07:34,970 --> 00:07:34,980
you know violently I don't know if you
 

347
00:07:34,980 --> 00:07:36,260
you know violently I don't know if you
could say abuse because you're not

348
00:07:36,260 --> 00:07:36,270
could say abuse because you're not
 

349
00:07:36,270 --> 00:07:39,890
could say abuse because you're not
actually you know abusing the the inner

350
00:07:39,890 --> 00:07:39,900
actually you know abusing the the inner
 

351
00:07:39,900 --> 00:07:41,480
actually you know abusing the the inner
mind of the robot that robot isn't

352
00:07:41,480 --> 00:07:41,490
mind of the robot that robot isn't
 

353
00:07:41,490 --> 00:07:43,280
mind of the robot that robot isn't
doesn't have any feelings as far as you

354
00:07:43,280 --> 00:07:43,290
doesn't have any feelings as far as you
 

355
00:07:43,290 --> 00:07:45,410
doesn't have any feelings as far as you
know well yeah

356
00:07:45,410 --> 00:07:45,420
know well yeah
 

357
00:07:45,420 --> 00:07:46,540
know well yeah
it was

358
00:07:46,540 --> 00:07:46,550
it was
 

359
00:07:46,550 --> 00:07:48,010
it was
depends on how we define feelings and

360
00:07:48,010 --> 00:07:48,020
depends on how we define feelings and
 

361
00:07:48,020 --> 00:07:50,770
depends on how we define feelings and
consciousness but I think that's another

362
00:07:50,770 --> 00:07:50,780
consciousness but I think that's another
 

363
00:07:50,780 --> 00:07:52,630
consciousness but I think that's another
area where people kind of overestimate

364
00:07:52,630 --> 00:07:52,640
area where people kind of overestimate
 

365
00:07:52,640 --> 00:07:53,650
area where people kind of overestimate
where we currently are with the

366
00:07:53,650 --> 00:07:53,660
where we currently are with the
 

367
00:07:53,660 --> 00:07:55,570
where we currently are with the
technology like the robots are not even

368
00:07:55,570 --> 00:07:55,580
technology like the robots are not even
 

369
00:07:55,580 --> 00:07:58,540
technology like the robots are not even
as smart as insects right now and so I'm

370
00:07:58,540 --> 00:07:58,550
as smart as insects right now and so I'm
 

371
00:07:58,550 --> 00:08:01,030
as smart as insects right now and so I'm
not worried about abuse in that sense

372
00:08:01,030 --> 00:08:01,040
not worried about abuse in that sense
 

373
00:08:01,040 --> 00:08:02,850
not worried about abuse in that sense
but it is interesting to think about

374
00:08:02,850 --> 00:08:02,860
but it is interesting to think about
 

375
00:08:02,860 --> 00:08:05,680
but it is interesting to think about
what does people's behavior towards

376
00:08:05,680 --> 00:08:05,690
what does people's behavior towards
 

377
00:08:05,690 --> 00:08:08,670
what does people's behavior towards
these things mean for our own behavior

378
00:08:08,670 --> 00:08:08,680
these things mean for our own behavior
 

379
00:08:08,680 --> 00:08:12,460
these things mean for our own behavior
is it desensitizing the people to you

380
00:08:12,460 --> 00:08:12,470
is it desensitizing the people to you
 

381
00:08:12,470 --> 00:08:14,710
is it desensitizing the people to you
know be verbally abusive to a robot or

382
00:08:14,710 --> 00:08:14,720
know be verbally abusive to a robot or
 

383
00:08:14,720 --> 00:08:16,690
know be verbally abusive to a robot or
even physically abusive and we don't

384
00:08:16,690 --> 00:08:16,700
even physically abusive and we don't
 

385
00:08:16,700 --> 00:08:19,510
even physically abusive and we don't
know is a similar connection from like

386
00:08:19,510 --> 00:08:19,520
know is a similar connection from like
 

387
00:08:19,520 --> 00:08:21,910
know is a similar connection from like
if you play violent video games what

388
00:08:21,910 --> 00:08:21,920
if you play violent video games what
 

389
00:08:21,920 --> 00:08:24,640
if you play violent video games what
connection does that have to desensitize

390
00:08:24,640 --> 00:08:24,650
connection does that have to desensitize
 

391
00:08:24,650 --> 00:08:28,390
connection does that have to desensitize
ation to violence as I haven't haven't

392
00:08:28,390 --> 00:08:28,400
ation to violence as I haven't haven't
 

393
00:08:28,400 --> 00:08:29,950
ation to violence as I haven't haven't
read literature on that I wonder about

394
00:08:29,950 --> 00:08:29,960
read literature on that I wonder about
 

395
00:08:29,960 --> 00:08:33,220
read literature on that I wonder about
that because everything I've heard

396
00:08:33,220 --> 00:08:33,230
that because everything I've heard
 

397
00:08:33,230 --> 00:08:35,650
that because everything I've heard
people don't seem to any longer be so

398
00:08:35,650 --> 00:08:35,660
people don't seem to any longer be so
 

399
00:08:35,660 --> 00:08:37,810
people don't seem to any longer be so
worried about violent video games

400
00:08:37,810 --> 00:08:37,820
worried about violent video games
 

401
00:08:37,820 --> 00:08:38,740
worried about violent video games
correct

402
00:08:38,740 --> 00:08:38,750
correct
 

403
00:08:38,750 --> 00:08:41,760
correct
we've seemed the the research on it is

404
00:08:41,760 --> 00:08:41,770
we've seemed the the research on it is
 

405
00:08:41,770 --> 00:08:44,830
we've seemed the the research on it is
it's a difficult thing to research so

406
00:08:44,830 --> 00:08:44,840
it's a difficult thing to research so
 

407
00:08:44,840 --> 00:08:47,760
it's a difficult thing to research so
it's sort of inconclusive but we seem to

408
00:08:47,760 --> 00:08:47,770
it's sort of inconclusive but we seem to
 

409
00:08:47,770 --> 00:08:50,590
it's sort of inconclusive but we seem to
have gotten a sense at least as a

410
00:08:50,590 --> 00:08:50,600
have gotten a sense at least as a
 

411
00:08:50,600 --> 00:08:53,050
have gotten a sense at least as a
society that people can compartmentalize

412
00:08:53,050 --> 00:08:53,060
society that people can compartmentalize
 

413
00:08:53,060 --> 00:08:54,970
society that people can compartmentalize
when it's something on a screen and

414
00:08:54,970 --> 00:08:54,980
when it's something on a screen and
 

415
00:08:54,980 --> 00:08:56,740
when it's something on a screen and
you're like you know shooting a bunch of

416
00:08:56,740 --> 00:08:56,750
you're like you know shooting a bunch of
 

417
00:08:56,750 --> 00:08:58,420
you're like you know shooting a bunch of
characters or running over people with

418
00:08:58,420 --> 00:08:58,430
characters or running over people with
 

419
00:08:58,430 --> 00:09:00,430
characters or running over people with
your car that doesn't necessarily

420
00:09:00,430 --> 00:09:00,440
your car that doesn't necessarily
 

421
00:09:00,440 --> 00:09:02,290
your car that doesn't necessarily
translate to you doing that in real life

422
00:09:02,290 --> 00:09:02,300
translate to you doing that in real life
 

423
00:09:02,300 --> 00:09:05,080
translate to you doing that in real life
we do however have some concerns about

424
00:09:05,080 --> 00:09:05,090
we do however have some concerns about
 

425
00:09:05,090 --> 00:09:07,030
we do however have some concerns about
children playing violent video games and

426
00:09:07,030 --> 00:09:07,040
children playing violent video games and
 

427
00:09:07,040 --> 00:09:10,300
children playing violent video games and
so we do restrict it there I'm not sure

428
00:09:10,300 --> 00:09:10,310
so we do restrict it there I'm not sure
 

429
00:09:10,310 --> 00:09:12,550
so we do restrict it there I'm not sure
that's based on any real evidence either

430
00:09:12,550 --> 00:09:12,560
that's based on any real evidence either
 

431
00:09:12,560 --> 00:09:14,440
that's based on any real evidence either
but it's just the way that we've kind of

432
00:09:14,440 --> 00:09:14,450
but it's just the way that we've kind of
 

433
00:09:14,450 --> 00:09:16,330
but it's just the way that we've kind of
decided you know we want to be a little

434
00:09:16,330 --> 00:09:16,340
decided you know we want to be a little
 

435
00:09:16,340 --> 00:09:18,040
decided you know we want to be a little
more cautious there and the reason I

436
00:09:18,040 --> 00:09:18,050
more cautious there and the reason I
 

437
00:09:18,050 --> 00:09:19,570
more cautious there and the reason I
think robots are a little bit different

438
00:09:19,570 --> 00:09:19,580
think robots are a little bit different
 

439
00:09:19,580 --> 00:09:21,430
think robots are a little bit different
is because there is a lot of research

440
00:09:21,430 --> 00:09:21,440
is because there is a lot of research
 

441
00:09:21,440 --> 00:09:23,410
is because there is a lot of research
showing that we respond differently to

442
00:09:23,410 --> 00:09:23,420
showing that we respond differently to
 

443
00:09:23,420 --> 00:09:25,270
showing that we respond differently to
something in our physical space than

444
00:09:25,270 --> 00:09:25,280
something in our physical space than
 

445
00:09:25,280 --> 00:09:27,550
something in our physical space than
something on a screen we will treat it

446
00:09:27,550 --> 00:09:27,560
something on a screen we will treat it
 

447
00:09:27,560 --> 00:09:30,010
something on a screen we will treat it
much more viscerally much more like a

448
00:09:30,010 --> 00:09:30,020
much more viscerally much more like a
 

449
00:09:30,020 --> 00:09:34,210
much more viscerally much more like a
physical actor and so I it's it's

450
00:09:34,210 --> 00:09:34,220
physical actor and so I it's it's
 

451
00:09:34,220 --> 00:09:36,850
physical actor and so I it's it's
totally possible that this is not a

452
00:09:36,850 --> 00:09:36,860
totally possible that this is not a
 

453
00:09:36,860 --> 00:09:39,310
totally possible that this is not a
problem and it's the same thing as

454
00:09:39,310 --> 00:09:39,320
problem and it's the same thing as
 

455
00:09:39,320 --> 00:09:40,810
problem and it's the same thing as
violence in video games you know maybe

456
00:09:40,810 --> 00:09:40,820
violence in video games you know maybe
 

457
00:09:40,820 --> 00:09:42,970
violence in video games you know maybe
you know restrict it with kids to be

458
00:09:42,970 --> 00:09:42,980
you know restrict it with kids to be
 

459
00:09:42,980 --> 00:09:44,590
you know restrict it with kids to be
safe but adults can do what they want

460
00:09:44,590 --> 00:09:44,600
safe but adults can do what they want
 

461
00:09:44,600 --> 00:09:47,380
safe but adults can do what they want
but we just need to ask the question

462
00:09:47,380 --> 00:09:47,390
but we just need to ask the question
 

463
00:09:47,390 --> 00:09:49,450
but we just need to ask the question
again because we don't have any evidence

464
00:09:49,450 --> 00:09:49,460
again because we don't have any evidence
 

465
00:09:49,460 --> 00:09:52,450
again because we don't have any evidence
at all yet maybe there's an intermediate

466
00:09:52,450 --> 00:09:52,460
at all yet maybe there's an intermediate
 

467
00:09:52,460 --> 00:09:57,580
at all yet maybe there's an intermediate
place to I did my research on twitter by

468
00:09:57,580 --> 00:09:57,590
place to I did my research on twitter by
 

469
00:09:57,590 --> 00:09:59,230
place to I did my research on twitter by
research I mean scrolling through your

470
00:09:59,230 --> 00:09:59,240
research I mean scrolling through your
 

471
00:09:59,240 --> 00:10:00,340
research I mean scrolling through your
Twitter feed

472
00:10:00,340 --> 00:10:00,350
Twitter feed
 

473
00:10:00,350 --> 00:10:02,170
Twitter feed
you mentioned that you were going at

474
00:10:02,170 --> 00:10:02,180
you mentioned that you were going at
 

475
00:10:02,180 --> 00:10:03,820
you mentioned that you were going at
some point to an animal law conference

476
00:10:03,820 --> 00:10:03,830
some point to an animal law conference
 

477
00:10:03,830 --> 00:10:06,220
some point to an animal law conference
so I have to ask do you think there's

478
00:10:06,220 --> 00:10:06,230
so I have to ask do you think there's
 

479
00:10:06,230 --> 00:10:10,030
so I have to ask do you think there's
something that we can learn from animal

480
00:10:10,030 --> 00:10:10,040
something that we can learn from animal
 

481
00:10:10,040 --> 00:10:11,740
something that we can learn from animal
rights the guys are thinking about

482
00:10:11,740 --> 00:10:11,750
rights the guys are thinking about
 

483
00:10:11,750 --> 00:10:14,680
rights the guys are thinking about
robots oh I think there is so much to

484
00:10:14,680 --> 00:10:14,690
robots oh I think there is so much to
 

485
00:10:14,690 --> 00:10:16,180
robots oh I think there is so much to
learn from that I'm actually writing a

486
00:10:16,180 --> 00:10:16,190
learn from that I'm actually writing a
 

487
00:10:16,190 --> 00:10:17,470
learn from that I'm actually writing a
book on it right now that's why I'm

488
00:10:17,470 --> 00:10:17,480
book on it right now that's why I'm
 

489
00:10:17,480 --> 00:10:21,010
book on it right now that's why I'm
going is conference so I'm I'm writing a

490
00:10:21,010 --> 00:10:21,020
going is conference so I'm I'm writing a
 

491
00:10:21,020 --> 00:10:22,510
going is conference so I'm I'm writing a
book that looks at the history of animal

492
00:10:22,510 --> 00:10:22,520
book that looks at the history of animal
 

493
00:10:22,520 --> 00:10:24,400
book that looks at the history of animal
domestication and how we've used animals

494
00:10:24,400 --> 00:10:24,410
domestication and how we've used animals
 

495
00:10:24,410 --> 00:10:26,500
domestication and how we've used animals
for work for weaponry for companionship

496
00:10:26,500 --> 00:10:26,510
for work for weaponry for companionship
 

497
00:10:26,510 --> 00:10:29,920
for work for weaponry for companionship
and you know one of the things the books

498
00:10:29,920 --> 00:10:29,930
and you know one of the things the books
 

499
00:10:29,930 --> 00:10:31,780
and you know one of the things the books
the book tries to do is move away from

500
00:10:31,780 --> 00:10:31,790
the book tries to do is move away from
 

501
00:10:31,790 --> 00:10:34,180
the book tries to do is move away from
this fallacy that I talked about of

502
00:10:34,180 --> 00:10:34,190
this fallacy that I talked about of
 

503
00:10:34,190 --> 00:10:35,920
this fallacy that I talked about of
comparing robots in humans because I

504
00:10:35,920 --> 00:10:35,930
comparing robots in humans because I
 

505
00:10:35,930 --> 00:10:38,380
comparing robots in humans because I
don't think that's the right analogy but

506
00:10:38,380 --> 00:10:38,390
don't think that's the right analogy but
 

507
00:10:38,390 --> 00:10:41,470
don't think that's the right analogy but
I do think that on a social level even

508
00:10:41,470 --> 00:10:41,480
I do think that on a social level even
 

509
00:10:41,480 --> 00:10:42,970
I do think that on a social level even
on a social level there's so much that

510
00:10:42,970 --> 00:10:42,980
on a social level there's so much that
 

511
00:10:42,980 --> 00:10:44,260
on a social level there's so much that
we can learn from looking at that

512
00:10:44,260 --> 00:10:44,270
we can learn from looking at that
 

513
00:10:44,270 --> 00:10:46,600
we can learn from looking at that
history because throughout history we've

514
00:10:46,600 --> 00:10:46,610
history because throughout history we've
 

515
00:10:46,610 --> 00:10:48,910
history because throughout history we've
treated most animals like tools like

516
00:10:48,910 --> 00:10:48,920
treated most animals like tools like
 

517
00:10:48,920 --> 00:10:50,560
treated most animals like tools like
products and then some of them we've

518
00:10:50,560 --> 00:10:50,570
products and then some of them we've
 

519
00:10:50,570 --> 00:10:51,970
products and then some of them we've
treated differently and we're starting

520
00:10:51,970 --> 00:10:51,980
treated differently and we're starting
 

521
00:10:51,980 --> 00:10:53,620
treated differently and we're starting
to see people treat robots in really

522
00:10:53,620 --> 00:10:53,630
to see people treat robots in really
 

523
00:10:53,630 --> 00:10:55,300
to see people treat robots in really
similar ways so I think it's a really

524
00:10:55,300 --> 00:10:55,310
similar ways so I think it's a really
 

525
00:10:55,310 --> 00:10:57,670
similar ways so I think it's a really
helpful predictor to how we're going to

526
00:10:57,670 --> 00:10:57,680
helpful predictor to how we're going to
 

527
00:10:57,680 --> 00:10:59,560
helpful predictor to how we're going to
interact with the robots do you think

528
00:10:59,560 --> 00:10:59,570
interact with the robots do you think
 

529
00:10:59,570 --> 00:11:01,480
interact with the robots do you think
we'll look back at this time like a

530
00:11:01,480 --> 00:11:01,490
we'll look back at this time like a
 

531
00:11:01,490 --> 00:11:05,890
we'll look back at this time like a
hundred years from now and see what we

532
00:11:05,890 --> 00:11:05,900
hundred years from now and see what we
 

533
00:11:05,900 --> 00:11:08,950
hundred years from now and see what we
do to animals is like some of the way we

534
00:11:08,950 --> 00:11:08,960
do to animals is like some of the way we
 

535
00:11:08,960 --> 00:11:12,760
do to animals is like some of the way we
view like the Holocaust with the world

536
00:11:12,760 --> 00:11:12,770
view like the Holocaust with the world
 

537
00:11:12,770 --> 00:11:15,130
view like the Holocaust with the world
war two that's a great question I mean I

538
00:11:15,130 --> 00:11:15,140
war two that's a great question I mean I
 

539
00:11:15,140 --> 00:11:20,500
war two that's a great question I mean I
hope so I am not convinced that we will

540
00:11:20,500 --> 00:11:20,510
hope so I am not convinced that we will
 

541
00:11:20,510 --> 00:11:23,290
hope so I am not convinced that we will
but I often wonder you know what are my

542
00:11:23,290 --> 00:11:23,300
but I often wonder you know what are my
 

543
00:11:23,300 --> 00:11:25,830
but I often wonder you know what are my
grandkids gonna view as you know

544
00:11:25,830 --> 00:11:25,840
grandkids gonna view as you know
 

545
00:11:25,840 --> 00:11:28,810
grandkids gonna view as you know
abhorrent that my generation did that

546
00:11:28,810 --> 00:11:28,820
abhorrent that my generation did that
 

547
00:11:28,820 --> 00:11:30,580
abhorrent that my generation did that
they would never do and I'm like well

548
00:11:30,580 --> 00:11:30,590
they would never do and I'm like well
 

549
00:11:30,590 --> 00:11:33,190
they would never do and I'm like well
what's the big deal you know it's it's a

550
00:11:33,190 --> 00:11:33,200
what's the big deal you know it's it's a
 

551
00:11:33,200 --> 00:11:34,540
what's the big deal you know it's it's a
fun question to ask yourself

552
00:11:34,540 --> 00:11:34,550
fun question to ask yourself
 

553
00:11:34,550 --> 00:11:35,680
fun question to ask yourself
there's always seems that there's

554
00:11:35,680 --> 00:11:35,690
there's always seems that there's
 

555
00:11:35,690 --> 00:11:40,990
there's always seems that there's
atrocities that we discover later so the

556
00:11:40,990 --> 00:11:41,000
atrocities that we discover later so the
 

557
00:11:41,000 --> 00:11:42,490
atrocities that we discover later so the
things that at the time people didn't

558
00:11:42,490 --> 00:11:42,500
things that at the time people didn't
 

559
00:11:42,500 --> 00:11:45,550
things that at the time people didn't
see as you know you look at everything

560
00:11:45,550 --> 00:11:45,560
see as you know you look at everything
 

561
00:11:45,560 --> 00:11:50,020
see as you know you look at everything
from slavery to any kinds of abuse

562
00:11:50,020 --> 00:11:50,030
from slavery to any kinds of abuse
 

563
00:11:50,030 --> 00:11:51,610
from slavery to any kinds of abuse
throughout history so I think the kind

564
00:11:51,610 --> 00:11:51,620
throughout history so I think the kind
 

565
00:11:51,620 --> 00:11:54,510
throughout history so I think the kind
of insane wars that were happening to

566
00:11:54,510 --> 00:11:54,520
of insane wars that were happening to
 

567
00:11:54,520 --> 00:11:58,660
of insane wars that were happening to
the way war was carried out and rape and

568
00:11:58,660 --> 00:11:58,670
the way war was carried out and rape and
 

569
00:11:58,670 --> 00:12:00,370
the way war was carried out and rape and
the kind of violence that was happening

570
00:12:00,370 --> 00:12:00,380
the kind of violence that was happening
 

571
00:12:00,380 --> 00:12:05,590
the kind of violence that was happening
during war in that we now you know we

572
00:12:05,590 --> 00:12:05,600
during war in that we now you know we
 

573
00:12:05,600 --> 00:12:07,180
during war in that we now you know we
see his atrocities but at the time

574
00:12:07,180 --> 00:12:07,190
see his atrocities but at the time
 

575
00:12:07,190 --> 00:12:11,280
see his atrocities but at the time
perhaps didn't as much and so now

576
00:12:11,280 --> 00:12:11,290
perhaps didn't as much and so now
 

577
00:12:11,290 --> 00:12:14,340
perhaps didn't as much and so now
I have this intuition that I have this

578
00:12:14,340 --> 00:12:14,350
I have this intuition that I have this
 

579
00:12:14,350 --> 00:12:17,610
I have this intuition that I have this
worry maybe I'm you're going to probably

580
00:12:17,610 --> 00:12:17,620
worry maybe I'm you're going to probably
 

581
00:12:17,620 --> 00:12:20,240
worry maybe I'm you're going to probably
criticize me but I do anthropomorphize

582
00:12:20,240 --> 00:12:20,250
criticize me but I do anthropomorphize
 

583
00:12:20,250 --> 00:12:25,949
criticize me but I do anthropomorphize
robots I have I don't see a fundamental

584
00:12:25,949 --> 00:12:25,959
robots I have I don't see a fundamental
 

585
00:12:25,959 --> 00:12:28,710
robots I have I don't see a fundamental
philosophical difference in a robot in a

586
00:12:28,710 --> 00:12:28,720
philosophical difference in a robot in a
 

587
00:12:28,720 --> 00:12:33,420
philosophical difference in a robot in a
human being in terms of once the

588
00:12:33,420 --> 00:12:33,430
human being in terms of once the
 

589
00:12:33,430 --> 00:12:37,410
human being in terms of once the
capabilities are matched so the fact

590
00:12:37,410 --> 00:12:37,420
capabilities are matched so the fact
 

591
00:12:37,420 --> 00:12:40,769
capabilities are matched so the fact
that we're really far away doesn't in

592
00:12:40,769 --> 00:12:40,779
that we're really far away doesn't in
 

593
00:12:40,779 --> 00:12:42,600
that we're really far away doesn't in
terms of capabilities and then that from

594
00:12:42,600 --> 00:12:42,610
terms of capabilities and then that from
 

595
00:12:42,610 --> 00:12:43,850
terms of capabilities and then that from
from natural language processing

596
00:12:43,850 --> 00:12:43,860
from natural language processing
 

597
00:12:43,860 --> 00:12:45,930
from natural language processing
understanding generation to just

598
00:12:45,930 --> 00:12:45,940
understanding generation to just
 

599
00:12:45,940 --> 00:12:47,999
understanding generation to just
reasoning and all that stuff I think

600
00:12:47,999 --> 00:12:48,009
reasoning and all that stuff I think
 

601
00:12:48,009 --> 00:12:50,519
reasoning and all that stuff I think
once you solve it I see though this is a

602
00:12:50,519 --> 00:12:50,529
once you solve it I see though this is a
 

603
00:12:50,529 --> 00:12:53,309
once you solve it I see though this is a
very great area and I don't feel

604
00:12:53,309 --> 00:12:53,319
very great area and I don't feel
 

605
00:12:53,319 --> 00:12:54,629
very great area and I don't feel
comfortable the kind of abuse that

606
00:12:54,629 --> 00:12:54,639
comfortable the kind of abuse that
 

607
00:12:54,639 --> 00:12:56,900
comfortable the kind of abuse that
people throw robots

608
00:12:56,900 --> 00:12:56,910
people throw robots
 

609
00:12:56,910 --> 00:13:00,449
people throw robots
subtle but I can see it becoming I can

610
00:13:00,449 --> 00:13:00,459
subtle but I can see it becoming I can
 

611
00:13:00,459 --> 00:13:02,340
subtle but I can see it becoming I can
see basically a civil rights movement

612
00:13:02,340 --> 00:13:02,350
see basically a civil rights movement
 

613
00:13:02,350 --> 00:13:05,129
see basically a civil rights movement
for robots in the future do you think

614
00:13:05,129 --> 00:13:05,139
for robots in the future do you think
 

615
00:13:05,139 --> 00:13:07,170
for robots in the future do you think
let me put it in the form of a question

616
00:13:07,170 --> 00:13:07,180
let me put it in the form of a question
 

617
00:13:07,180 --> 00:13:09,210
let me put it in the form of a question
do you think robots should have some

618
00:13:09,210 --> 00:13:09,220
do you think robots should have some
 

619
00:13:09,220 --> 00:13:11,939
do you think robots should have some
kinds of rights well it's interesting

620
00:13:11,939 --> 00:13:11,949
kinds of rights well it's interesting
 

621
00:13:11,949 --> 00:13:15,210
kinds of rights well it's interesting
because I came at this originally from

622
00:13:15,210 --> 00:13:15,220
because I came at this originally from
 

623
00:13:15,220 --> 00:13:17,040
because I came at this originally from
your perspective I was like you know

624
00:13:17,040 --> 00:13:17,050
your perspective I was like you know
 

625
00:13:17,050 --> 00:13:19,800
your perspective I was like you know
what there's no fundamental difference

626
00:13:19,800 --> 00:13:19,810
what there's no fundamental difference
 

627
00:13:19,810 --> 00:13:22,710
what there's no fundamental difference
between technology and like human

628
00:13:22,710 --> 00:13:22,720
between technology and like human
 

629
00:13:22,720 --> 00:13:24,420
between technology and like human
consciousness like we we can probably

630
00:13:24,420 --> 00:13:24,430
consciousness like we we can probably
 

631
00:13:24,430 --> 00:13:26,670
consciousness like we we can probably
recreate anything we just don't know how

632
00:13:26,670 --> 00:13:26,680
recreate anything we just don't know how
 

633
00:13:26,680 --> 00:13:30,590
recreate anything we just don't know how
yet and so there's no reason not to give

634
00:13:30,590 --> 00:13:30,600
yet and so there's no reason not to give
 

635
00:13:30,600 --> 00:13:33,240
yet and so there's no reason not to give
machines the same rights that we have

636
00:13:33,240 --> 00:13:33,250
machines the same rights that we have
 

637
00:13:33,250 --> 00:13:35,250
machines the same rights that we have
once like you say they're kind of on an

638
00:13:35,250 --> 00:13:35,260
once like you say they're kind of on an
 

639
00:13:35,260 --> 00:13:38,250
once like you say they're kind of on an
equivalent level but I realized that

640
00:13:38,250 --> 00:13:38,260
equivalent level but I realized that
 

641
00:13:38,260 --> 00:13:41,160
equivalent level but I realized that
that is kind of a far future question I

642
00:13:41,160 --> 00:13:41,170
that is kind of a far future question I
 

643
00:13:41,170 --> 00:13:42,150
that is kind of a far future question I
still think we should talk about it

644
00:13:42,150 --> 00:13:42,160
still think we should talk about it
 

645
00:13:42,160 --> 00:13:42,840
still think we should talk about it
because I think it's really interesting

646
00:13:42,840 --> 00:13:42,850
because I think it's really interesting
 

647
00:13:42,850 --> 00:13:46,170
because I think it's really interesting
but I realized that it's actually we

648
00:13:46,170 --> 00:13:46,180
but I realized that it's actually we
 

649
00:13:46,180 --> 00:13:47,790
but I realized that it's actually we
might need to ask the robot rice

650
00:13:47,790 --> 00:13:47,800
might need to ask the robot rice
 

651
00:13:47,800 --> 00:13:50,189
might need to ask the robot rice
question even sooner than that um well

652
00:13:50,189 --> 00:13:50,199
question even sooner than that um well
 

653
00:13:50,199 --> 00:13:52,230
question even sooner than that um well
the machines are still you know quote

654
00:13:52,230 --> 00:13:52,240
the machines are still you know quote
 

655
00:13:52,240 --> 00:13:55,829
the machines are still you know quote
unquote really you know dumb and not on

656
00:13:55,829 --> 00:13:55,839
unquote really you know dumb and not on
 

657
00:13:55,839 --> 00:13:58,199
unquote really you know dumb and not on
our level because of the way that we

658
00:13:58,199 --> 00:13:58,209
our level because of the way that we
 

659
00:13:58,209 --> 00:14:00,360
our level because of the way that we
perceive them and I think one of the

660
00:14:00,360 --> 00:14:00,370
perceive them and I think one of the
 

661
00:14:00,370 --> 00:14:01,800
perceive them and I think one of the
lessons we learn from looking at the

662
00:14:01,800 --> 00:14:01,810
lessons we learn from looking at the
 

663
00:14:01,810 --> 00:14:03,389
lessons we learn from looking at the
history of animal rights and one of the

664
00:14:03,389 --> 00:14:03,399
history of animal rights and one of the
 

665
00:14:03,399 --> 00:14:06,300
history of animal rights and one of the
reasons we may not get to a place in a

666
00:14:06,300 --> 00:14:06,310
reasons we may not get to a place in a
 

667
00:14:06,310 --> 00:14:07,769
reasons we may not get to a place in a
hundred years where we view it as wrong

668
00:14:07,769 --> 00:14:07,779
hundred years where we view it as wrong
 

669
00:14:07,779 --> 00:14:10,679
hundred years where we view it as wrong
to you know eat or otherwise you know

670
00:14:10,679 --> 00:14:10,689
to you know eat or otherwise you know
 

671
00:14:10,689 --> 00:14:12,540
to you know eat or otherwise you know
use animals for our own purposes is

672
00:14:12,540 --> 00:14:12,550
use animals for our own purposes is
 

673
00:14:12,550 --> 00:14:14,900
use animals for our own purposes is
because historically we've always

674
00:14:14,900 --> 00:14:14,910
because historically we've always
 

675
00:14:14,910 --> 00:14:17,040
because historically we've always
protected those things that we relate to

676
00:14:17,040 --> 00:14:17,050
protected those things that we relate to
 

677
00:14:17,050 --> 00:14:20,819
protected those things that we relate to
the most so one example is whales no one

678
00:14:20,819 --> 00:14:20,829
the most so one example is whales no one
 

679
00:14:20,829 --> 00:14:22,829
the most so one example is whales no one
gave a [\h__\h] about the whales am I

680
00:14:22,829 --> 00:14:22,839
gave a [\h__\h] about the whales am I
 

681
00:14:22,839 --> 00:14:26,170
gave a [\h__\h] about the whales am I
allowed to swear

682
00:14:26,170 --> 00:14:26,180

 

683
00:14:26,180 --> 00:14:28,310

freedom yeah no one gave a [\h__\h] about

684
00:14:28,310 --> 00:14:28,320
freedom yeah no one gave a [\h__\h] about
 

685
00:14:28,320 --> 00:14:30,020
freedom yeah no one gave a [\h__\h] about
the whales until someone recorded them

686
00:14:30,020 --> 00:14:30,030
the whales until someone recorded them
 

687
00:14:30,030 --> 00:14:32,150
the whales until someone recorded them
singing and suddenly people were like oh

688
00:14:32,150 --> 00:14:32,160
singing and suddenly people were like oh
 

689
00:14:32,160 --> 00:14:34,670
singing and suddenly people were like oh
this is a beautiful creature and now we

690
00:14:34,670 --> 00:14:34,680
this is a beautiful creature and now we
 

691
00:14:34,680 --> 00:14:36,290
this is a beautiful creature and now we
need to save the whales and that started

692
00:14:36,290 --> 00:14:36,300
need to save the whales and that started
 

693
00:14:36,300 --> 00:14:37,850
need to save the whales and that started
the whole save the whales movement in

694
00:14:37,850 --> 00:14:37,860
the whole save the whales movement in
 

695
00:14:37,860 --> 00:14:44,360
the whole save the whales movement in
the 70s so I'm as much as I and and I

696
00:14:44,360 --> 00:14:44,370
the 70s so I'm as much as I and and I
 

697
00:14:44,370 --> 00:14:45,950
the 70s so I'm as much as I and and I
think a lot of people want to believe

698
00:14:45,950 --> 00:14:45,960
think a lot of people want to believe
 

699
00:14:45,960 --> 00:14:49,520
think a lot of people want to believe
that we care about consistent biological

700
00:14:49,520 --> 00:14:49,530
that we care about consistent biological
 

701
00:14:49,530 --> 00:14:52,730
that we care about consistent biological
criteria that's not historically how we

702
00:14:52,730 --> 00:14:52,740
criteria that's not historically how we
 

703
00:14:52,740 --> 00:14:56,030
criteria that's not historically how we
formed our alliances yeah so what why do

704
00:14:56,030 --> 00:14:56,040
formed our alliances yeah so what why do
 

705
00:14:56,040 --> 00:15:00,380
formed our alliances yeah so what why do
we why do we believe that all humans are

706
00:15:00,380 --> 00:15:00,390
we why do we believe that all humans are
 

707
00:15:00,390 --> 00:15:01,580
we why do we believe that all humans are
created equal

708
00:15:01,580 --> 00:15:01,590
created equal
 

709
00:15:01,590 --> 00:15:04,160
created equal
killing of a human being no matter who

710
00:15:04,160 --> 00:15:04,170
killing of a human being no matter who
 

711
00:15:04,170 --> 00:15:06,230
killing of a human being no matter who
the human being is that's what I meant

712
00:15:06,230 --> 00:15:06,240
the human being is that's what I meant
 

713
00:15:06,240 --> 00:15:10,340
the human being is that's what I meant
by equality is bad and then because I'm

714
00:15:10,340 --> 00:15:10,350
by equality is bad and then because I'm
 

715
00:15:10,350 --> 00:15:12,590
by equality is bad and then because I'm
connecting that to robots and I'm

716
00:15:12,590 --> 00:15:12,600
connecting that to robots and I'm
 

717
00:15:12,600 --> 00:15:14,930
connecting that to robots and I'm
wondering whether mortality so the

718
00:15:14,930 --> 00:15:14,940
wondering whether mortality so the
 

719
00:15:14,940 --> 00:15:16,850
wondering whether mortality so the
killing Act is what makes something

720
00:15:16,850 --> 00:15:16,860
killing Act is what makes something
 

721
00:15:16,860 --> 00:15:19,970
killing Act is what makes something
that's the fundamental first right so

722
00:15:19,970 --> 00:15:19,980
that's the fundamental first right so
 

723
00:15:19,980 --> 00:15:22,880
that's the fundamental first right so
I'm I am currently allowed to take a

724
00:15:22,880 --> 00:15:22,890
I'm I am currently allowed to take a
 

725
00:15:22,890 --> 00:15:26,600
I'm I am currently allowed to take a
shotgun and shoot a Roomba I think I'm

726
00:15:26,600 --> 00:15:26,610
shotgun and shoot a Roomba I think I'm
 

727
00:15:26,610 --> 00:15:29,270
shotgun and shoot a Roomba I think I'm
not sure but I'm pretty sure it's not

728
00:15:29,270 --> 00:15:29,280
not sure but I'm pretty sure it's not
 

729
00:15:29,280 --> 00:15:32,390
not sure but I'm pretty sure it's not
considered murder right or even shutting

730
00:15:32,390 --> 00:15:32,400
considered murder right or even shutting
 

731
00:15:32,400 --> 00:15:35,470
considered murder right or even shutting
them off so that's that's where the line

732
00:15:35,470 --> 00:15:35,480
them off so that's that's where the line
 

733
00:15:35,480 --> 00:15:39,430
them off so that's that's where the line
appears to be right is is mortality a

734
00:15:39,430 --> 00:15:39,440
appears to be right is is mortality a
 

735
00:15:39,440 --> 00:15:42,470
appears to be right is is mortality a
critical thing here I think here again

736
00:15:42,470 --> 00:15:42,480
critical thing here I think here again
 

737
00:15:42,480 --> 00:15:44,780
critical thing here I think here again
like the animal analogy is really useful

738
00:15:44,780 --> 00:15:44,790
like the animal analogy is really useful
 

739
00:15:44,790 --> 00:15:46,310
like the animal analogy is really useful
because you're also allowed to shoot

740
00:15:46,310 --> 00:15:46,320
because you're also allowed to shoot
 

741
00:15:46,320 --> 00:15:49,130
because you're also allowed to shoot
your dog but people won't be happy about

742
00:15:49,130 --> 00:15:49,140
your dog but people won't be happy about
 

743
00:15:49,140 --> 00:15:49,640
your dog but people won't be happy about
it

744
00:15:49,640 --> 00:15:49,650
it
 

745
00:15:49,650 --> 00:15:52,760
it
so we give we do give animals certain

746
00:15:52,760 --> 00:15:52,770
so we give we do give animals certain
 

747
00:15:52,770 --> 00:15:55,850
so we give we do give animals certain
protections from like you know you're

748
00:15:55,850 --> 00:15:55,860
protections from like you know you're
 

749
00:15:55,860 --> 00:15:57,470
protections from like you know you're
not allowed to torture your dog and you

750
00:15:57,470 --> 00:15:57,480
not allowed to torture your dog and you
 

751
00:15:57,480 --> 00:15:59,150
not allowed to torture your dog and you
know set it on fire at least in most

752
00:15:59,150 --> 00:15:59,160
know set it on fire at least in most
 

753
00:15:59,160 --> 00:16:02,930
know set it on fire at least in most
states and countries you know but you're

754
00:16:02,930 --> 00:16:02,940
states and countries you know but you're
 

755
00:16:02,940 --> 00:16:04,700
states and countries you know but you're
still allowed to treat it like a piece

756
00:16:04,700 --> 00:16:04,710
still allowed to treat it like a piece
 

757
00:16:04,710 --> 00:16:06,440
still allowed to treat it like a piece
of property in a lot of other ways and

758
00:16:06,440 --> 00:16:06,450
of property in a lot of other ways and
 

759
00:16:06,450 --> 00:16:10,550
of property in a lot of other ways and
so we draw these you know arbitrary

760
00:16:10,550 --> 00:16:10,560
so we draw these you know arbitrary
 

761
00:16:10,560 --> 00:16:14,510
so we draw these you know arbitrary
lines all the time and you know there's

762
00:16:14,510 --> 00:16:14,520
lines all the time and you know there's
 

763
00:16:14,520 --> 00:16:18,530
lines all the time and you know there's
a lot of philosophical thought on why

764
00:16:18,530 --> 00:16:18,540
a lot of philosophical thought on why
 

765
00:16:18,540 --> 00:16:22,520
a lot of philosophical thought on why
viewing humans is something unique is

766
00:16:22,520 --> 00:16:22,530
viewing humans is something unique is
 

767
00:16:22,530 --> 00:16:26,960
viewing humans is something unique is
not is just speciesism and not you know

768
00:16:26,960 --> 00:16:26,970
not is just speciesism and not you know
 

769
00:16:26,970 --> 00:16:29,570
not is just speciesism and not you know
based on any criteria that would

770
00:16:29,570 --> 00:16:29,580
based on any criteria that would
 

771
00:16:29,580 --> 00:16:32,270
based on any criteria that would
actually justify making a difference

772
00:16:32,270 --> 00:16:32,280
actually justify making a difference
 

773
00:16:32,280 --> 00:16:34,670
actually justify making a difference
between us and other species do you

774
00:16:34,670 --> 00:16:34,680
between us and other species do you
 

775
00:16:34,680 --> 00:16:37,949
between us and other species do you
think in general people

776
00:16:37,949 --> 00:16:37,959
think in general people
 

777
00:16:37,959 --> 00:16:42,420
think in general people
most people are good do you think do you

778
00:16:42,420 --> 00:16:42,430
most people are good do you think do you
 

779
00:16:42,430 --> 00:16:47,360
most people are good do you think do you
think there's evil and good in all of us

780
00:16:47,360 --> 00:16:47,370

 

781
00:16:47,370 --> 00:16:49,860

that's revealed through our

782
00:16:49,860 --> 00:16:49,870
that's revealed through our
 

783
00:16:49,870 --> 00:16:51,449
that's revealed through our
circumstances and through our

784
00:16:51,449 --> 00:16:51,459
circumstances and through our
 

785
00:16:51,459 --> 00:16:54,660
circumstances and through our
interactions I like to view myself as a

786
00:16:54,660 --> 00:16:54,670
interactions I like to view myself as a
 

787
00:16:54,670 --> 00:16:56,670
interactions I like to view myself as a
person who like believes that there's no

788
00:16:56,670 --> 00:16:56,680
person who like believes that there's no
 

789
00:16:56,680 --> 00:16:58,259
person who like believes that there's no
absolute evil and good and that

790
00:16:58,259 --> 00:16:58,269
absolute evil and good and that
 

791
00:16:58,269 --> 00:17:03,269
absolute evil and good and that
everything is you know gray but I do

792
00:17:03,269 --> 00:17:03,279
everything is you know gray but I do
 

793
00:17:03,279 --> 00:17:06,630
everything is you know gray but I do
think it's an interesting question like

794
00:17:06,630 --> 00:17:06,640
think it's an interesting question like
 

795
00:17:06,640 --> 00:17:08,610
think it's an interesting question like
when I see people being violent towards

796
00:17:08,610 --> 00:17:08,620
when I see people being violent towards
 

797
00:17:08,620 --> 00:17:10,559
when I see people being violent towards
robotic objects you said that bothers

798
00:17:10,559 --> 00:17:10,569
robotic objects you said that bothers
 

799
00:17:10,569 --> 00:17:13,409
robotic objects you said that bothers
you because the robots might someday you

800
00:17:13,409 --> 00:17:13,419
you because the robots might someday you
 

801
00:17:13,419 --> 00:17:17,789
you because the robots might someday you
know be smart and it is that what well

802
00:17:17,789 --> 00:17:17,799
know be smart and it is that what well
 

803
00:17:17,799 --> 00:17:19,829
know be smart and it is that what well
it bothers me because it reveals so I

804
00:17:19,829 --> 00:17:19,839
it bothers me because it reveals so I
 

805
00:17:19,839 --> 00:17:22,799
it bothers me because it reveals so I
personally believe because I've studied

806
00:17:22,799 --> 00:17:22,809
personally believe because I've studied
 

807
00:17:22,809 --> 00:17:24,630
personally believe because I've studied
way to my some Jewish I studied the

808
00:17:24,630 --> 00:17:24,640
way to my some Jewish I studied the
 

809
00:17:24,640 --> 00:17:27,299
way to my some Jewish I studied the
Holocaust in World War two exceptionally

810
00:17:27,299 --> 00:17:27,309
Holocaust in World War two exceptionally
 

811
00:17:27,309 --> 00:17:29,310
Holocaust in World War two exceptionally
well I personally believe that most of

812
00:17:29,310 --> 00:17:29,320
well I personally believe that most of
 

813
00:17:29,320 --> 00:17:34,080
well I personally believe that most of
us have evil in us that what bothers me

814
00:17:34,080 --> 00:17:34,090
us have evil in us that what bothers me
 

815
00:17:34,090 --> 00:17:37,289
us have evil in us that what bothers me
is the abuse of robots reveals the evil

816
00:17:37,289 --> 00:17:37,299
is the abuse of robots reveals the evil
 

817
00:17:37,299 --> 00:17:39,180
is the abuse of robots reveals the evil
and human beings yeah

818
00:17:39,180 --> 00:17:39,190
and human beings yeah
 

819
00:17:39,190 --> 00:17:42,390
and human beings yeah
and it's I think it doesn't but just

820
00:17:42,390 --> 00:17:42,400
and it's I think it doesn't but just
 

821
00:17:42,400 --> 00:17:45,030
and it's I think it doesn't but just
bother me it's I think it's an

822
00:17:45,030 --> 00:17:45,040
bother me it's I think it's an
 

823
00:17:45,040 --> 00:17:50,610
bother me it's I think it's an
opportunity for roboticists to make help

824
00:17:50,610 --> 00:17:50,620
opportunity for roboticists to make help
 

825
00:17:50,620 --> 00:17:53,460
opportunity for roboticists to make help
people be find the better sides the

826
00:17:53,460 --> 00:17:53,470
people be find the better sides the
 

827
00:17:53,470 --> 00:17:55,890
people be find the better sides the
angels of their nature right yeah that

828
00:17:55,890 --> 00:17:55,900
angels of their nature right yeah that
 

829
00:17:55,900 --> 00:17:58,350
angels of their nature right yeah that
abuse isn't just a fun side thing that's

830
00:17:58,350 --> 00:17:58,360
abuse isn't just a fun side thing that's
 

831
00:17:58,360 --> 00:18:00,990
abuse isn't just a fun side thing that's
a you revealing a dark part that you

832
00:18:00,990 --> 00:18:01,000
a you revealing a dark part that you
 

833
00:18:01,000 --> 00:18:02,700
a you revealing a dark part that you
shouldn't there should be hidden deep

834
00:18:02,700 --> 00:18:02,710
shouldn't there should be hidden deep
 

835
00:18:02,710 --> 00:18:07,799
shouldn't there should be hidden deep
inside yeah I mean molasse but some of

836
00:18:07,799 --> 00:18:07,809
inside yeah I mean molasse but some of
 

837
00:18:07,809 --> 00:18:10,039
inside yeah I mean molasse but some of
our research does indicate that maybe

838
00:18:10,039 --> 00:18:10,049
our research does indicate that maybe
 

839
00:18:10,049 --> 00:18:12,659
our research does indicate that maybe
people's behavior towards robots reveals

840
00:18:12,659 --> 00:18:12,669
people's behavior towards robots reveals
 

841
00:18:12,669 --> 00:18:14,310
people's behavior towards robots reveals
something about their tendencies for

842
00:18:14,310 --> 00:18:14,320
something about their tendencies for
 

843
00:18:14,320 --> 00:18:16,200
something about their tendencies for
empathy generally even using very simple

844
00:18:16,200 --> 00:18:16,210
empathy generally even using very simple
 

845
00:18:16,210 --> 00:18:17,700
empathy generally even using very simple
robots that we have today that like

846
00:18:17,700 --> 00:18:17,710
robots that we have today that like
 

847
00:18:17,710 --> 00:18:20,789
robots that we have today that like
clearly don't feel anything so you know

848
00:18:20,789 --> 00:18:20,799
clearly don't feel anything so you know
 

849
00:18:20,799 --> 00:18:25,230
clearly don't feel anything so you know
West world is maybe you know not so far

850
00:18:25,230 --> 00:18:25,240
West world is maybe you know not so far
 

851
00:18:25,240 --> 00:18:28,500
West world is maybe you know not so far
often it's like you know depicting the

852
00:18:28,500 --> 00:18:28,510
often it's like you know depicting the
 

853
00:18:28,510 --> 00:18:30,750
often it's like you know depicting the
bad characters as willing to go around

854
00:18:30,750 --> 00:18:30,760
bad characters as willing to go around
 

855
00:18:30,760 --> 00:18:32,039
bad characters as willing to go around
and shoot and rape the robots and the

856
00:18:32,039 --> 00:18:32,049
and shoot and rape the robots and the
 

857
00:18:32,049 --> 00:18:33,450
and shoot and rape the robots and the
good characters is not wanting to do

858
00:18:33,450 --> 00:18:33,460
good characters is not wanting to do
 

859
00:18:33,460 --> 00:18:36,060
good characters is not wanting to do
that even without assuming that the

860
00:18:36,060 --> 00:18:36,070
that even without assuming that the
 

861
00:18:36,070 --> 00:18:38,070
that even without assuming that the
robots have consciousness so there's a

862
00:18:38,070 --> 00:18:38,080
robots have consciousness so there's a
 

863
00:18:38,080 --> 00:18:40,830
robots have consciousness so there's a
opportunity at Cynthia's opportunity to

864
00:18:40,830 --> 00:18:40,840
opportunity at Cynthia's opportunity to
 

865
00:18:40,840 --> 00:18:45,690
opportunity at Cynthia's opportunity to
almost practice empathy the on robots is

866
00:18:45,690 --> 00:18:45,700
almost practice empathy the on robots is
 

867
00:18:45,700 --> 00:18:47,600
almost practice empathy the on robots is
an opportunity to practice empathy I

868
00:18:47,600 --> 00:18:47,610
an opportunity to practice empathy I
 

869
00:18:47,610 --> 00:18:51,270
an opportunity to practice empathy I
agree with you some people would say

870
00:18:51,270 --> 00:18:51,280
agree with you some people would say
 

871
00:18:51,280 --> 00:18:53,730
agree with you some people would say
why are we practicing empathy on robots

872
00:18:53,730 --> 00:18:53,740
why are we practicing empathy on robots
 

873
00:18:53,740 --> 00:18:55,860
why are we practicing empathy on robots
instead of you know on our fellow humans

874
00:18:55,860 --> 00:18:55,870
instead of you know on our fellow humans
 

875
00:18:55,870 --> 00:18:58,170
instead of you know on our fellow humans
or on animals that are actually alive

876
00:18:58,170 --> 00:18:58,180
or on animals that are actually alive
 

877
00:18:58,180 --> 00:19:00,900
or on animals that are actually alive
and experienced the world and I don't

878
00:19:00,900 --> 00:19:00,910
and experienced the world and I don't
 

879
00:19:00,910 --> 00:19:02,190
and experienced the world and I don't
agree with them because I don't think

880
00:19:02,190 --> 00:19:02,200
agree with them because I don't think
 

881
00:19:02,200 --> 00:19:03,810
agree with them because I don't think
empathy is a zero-sum game and I do

882
00:19:03,810 --> 00:19:03,820
empathy is a zero-sum game and I do
 

883
00:19:03,820 --> 00:19:05,220
empathy is a zero-sum game and I do
think that it's a muscle that you can

884
00:19:05,220 --> 00:19:05,230
think that it's a muscle that you can
 

885
00:19:05,230 --> 00:19:06,960
think that it's a muscle that you can
train and that we should be doing that

886
00:19:06,960 --> 00:19:06,970
train and that we should be doing that
 

887
00:19:06,970 --> 00:19:11,340
train and that we should be doing that
but some people disagree so the

888
00:19:11,340 --> 00:19:11,350
but some people disagree so the
 

889
00:19:11,350 --> 00:19:14,280
but some people disagree so the
interesting thing you've heard you know

890
00:19:14,280 --> 00:19:14,290
interesting thing you've heard you know
 

891
00:19:14,290 --> 00:19:20,430
interesting thing you've heard you know
raising kids sort of asking them or

892
00:19:20,430 --> 00:19:20,440
raising kids sort of asking them or
 

893
00:19:20,440 --> 00:19:23,520
raising kids sort of asking them or
telling them to be nice to the smart

894
00:19:23,520 --> 00:19:23,530
telling them to be nice to the smart
 

895
00:19:23,530 --> 00:19:26,700
telling them to be nice to the smart
speakers to Alexa and so on saying

896
00:19:26,700 --> 00:19:26,710
speakers to Alexa and so on saying
 

897
00:19:26,710 --> 00:19:28,860
speakers to Alexa and so on saying
please and so on during the requests I

898
00:19:28,860 --> 00:19:28,870
please and so on during the requests I
 

899
00:19:28,870 --> 00:19:31,260
please and so on during the requests I
don't know if I'm a huge fan of that

900
00:19:31,260 --> 00:19:31,270
don't know if I'm a huge fan of that
 

901
00:19:31,270 --> 00:19:33,870
don't know if I'm a huge fan of that
idea because yeah that's towards the

902
00:19:33,870 --> 00:19:33,880
idea because yeah that's towards the
 

903
00:19:33,880 --> 00:19:34,980
idea because yeah that's towards the
idea of practicing empathy

904
00:19:34,980 --> 00:19:34,990
idea of practicing empathy
 

905
00:19:34,990 --> 00:19:37,080
idea of practicing empathy
I feel like politeness I'm always polite

906
00:19:37,080 --> 00:19:37,090
I feel like politeness I'm always polite
 

907
00:19:37,090 --> 00:19:39,200
I feel like politeness I'm always polite
to all the all the systems that we build

908
00:19:39,200 --> 00:19:39,210
to all the all the systems that we build
 

909
00:19:39,210 --> 00:19:41,070
to all the all the systems that we build
especially anything that speech

910
00:19:41,070 --> 00:19:41,080
especially anything that speech
 

911
00:19:41,080 --> 00:19:42,750
especially anything that speech
interaction-based like when we talk to

912
00:19:42,750 --> 00:19:42,760
interaction-based like when we talk to
 

913
00:19:42,760 --> 00:19:45,300
interaction-based like when we talk to
the car I will always have a pretty good

914
00:19:45,300 --> 00:19:45,310
the car I will always have a pretty good
 

915
00:19:45,310 --> 00:19:48,180
the car I will always have a pretty good
detector for please - I feel like there

916
00:19:48,180 --> 00:19:48,190
detector for please - I feel like there
 

917
00:19:48,190 --> 00:19:51,300
detector for please - I feel like there
should be a room for encouraging empathy

918
00:19:51,300 --> 00:19:51,310
should be a room for encouraging empathy
 

919
00:19:51,310 --> 00:19:54,390
should be a room for encouraging empathy
in those interactions yeah okay so I

920
00:19:54,390 --> 00:19:54,400
in those interactions yeah okay so I
 

921
00:19:54,400 --> 00:19:55,740
in those interactions yeah okay so I
agree with you so I'm gonna play devil's

922
00:19:55,740 --> 00:19:55,750
agree with you so I'm gonna play devil's
 

923
00:19:55,750 --> 00:19:59,910
agree with you so I'm gonna play devil's
advocate so what is then what is the

924
00:19:59,910 --> 00:19:59,920
advocate so what is then what is the
 

925
00:19:59,920 --> 00:20:01,650
advocate so what is then what is the
dose our argument there the devil's

926
00:20:01,650 --> 00:20:01,660
dose our argument there the devil's
 

927
00:20:01,660 --> 00:20:04,380
dose our argument there the devil's
advocate argument is that if you are the

928
00:20:04,380 --> 00:20:04,390
advocate argument is that if you are the
 

929
00:20:04,390 --> 00:20:06,270
advocate argument is that if you are the
type of person who has abusive

930
00:20:06,270 --> 00:20:06,280
type of person who has abusive
 

931
00:20:06,280 --> 00:20:08,550
type of person who has abusive
tendencies or needs to get some sort of

932
00:20:08,550 --> 00:20:08,560
tendencies or needs to get some sort of
 

933
00:20:08,560 --> 00:20:10,380
tendencies or needs to get some sort of
like behavior like that out needs an

934
00:20:10,380 --> 00:20:10,390
like behavior like that out needs an
 

935
00:20:10,390 --> 00:20:12,540
like behavior like that out needs an
outlet for it that it's great to have a

936
00:20:12,540 --> 00:20:12,550
outlet for it that it's great to have a
 

937
00:20:12,550 --> 00:20:15,480
outlet for it that it's great to have a
robot that you can scream at so that

938
00:20:15,480 --> 00:20:15,490
robot that you can scream at so that
 

939
00:20:15,490 --> 00:20:17,550
robot that you can scream at so that
you're not screaming at a person and we

940
00:20:17,550 --> 00:20:17,560
you're not screaming at a person and we
 

941
00:20:17,560 --> 00:20:19,770
you're not screaming at a person and we
just don't know whether that's true

942
00:20:19,770 --> 00:20:19,780
just don't know whether that's true
 

943
00:20:19,780 --> 00:20:21,540
just don't know whether that's true
whether it's an outlet for people or

944
00:20:21,540 --> 00:20:21,550
whether it's an outlet for people or
 

945
00:20:21,550 --> 00:20:23,190
whether it's an outlet for people or
whether it just kind of as my friend

946
00:20:23,190 --> 00:20:23,200
whether it just kind of as my friend
 

947
00:20:23,200 --> 00:20:24,870
whether it just kind of as my friend
once said trains their cruelty muscles

948
00:20:24,870 --> 00:20:24,880
once said trains their cruelty muscles
 

949
00:20:24,880 --> 00:20:26,130
once said trains their cruelty muscles
and makes them more cruel in other

950
00:20:26,130 --> 00:20:26,140
and makes them more cruel in other
 

951
00:20:26,140 --> 00:20:30,810
and makes them more cruel in other
situations oh boy yeah in that expanse

952
00:20:30,810 --> 00:20:30,820
situations oh boy yeah in that expanse
 

953
00:20:30,820 --> 00:20:35,070
situations oh boy yeah in that expanse
to other topics which they I don't know

954
00:20:35,070 --> 00:20:35,080
to other topics which they I don't know
 

955
00:20:35,080 --> 00:20:38,010
to other topics which they I don't know
that you know there's a is a topic of

956
00:20:38,010 --> 00:20:38,020
that you know there's a is a topic of
 

957
00:20:38,020 --> 00:20:40,890
that you know there's a is a topic of
sex which is weird one that I tend to

958
00:20:40,890 --> 00:20:40,900
sex which is weird one that I tend to
 

959
00:20:40,900 --> 00:20:43,080
sex which is weird one that I tend to
avoid is from robotics perspective and

960
00:20:43,080 --> 00:20:43,090
avoid is from robotics perspective and
 

961
00:20:43,090 --> 00:20:45,870
avoid is from robotics perspective and
mostly general public doesn't they talk

962
00:20:45,870 --> 00:20:45,880
mostly general public doesn't they talk
 

963
00:20:45,880 --> 00:20:49,050
mostly general public doesn't they talk
about sex robots and so on is that an

964
00:20:49,050 --> 00:20:49,060
about sex robots and so on is that an
 

965
00:20:49,060 --> 00:20:52,460
about sex robots and so on is that an
area you've touched at all research-wise

966
00:20:52,460 --> 00:20:52,470
area you've touched at all research-wise
 

967
00:20:52,470 --> 00:20:55,110
area you've touched at all research-wise
like the way because that's what people

968
00:20:55,110 --> 00:20:55,120
like the way because that's what people
 

969
00:20:55,120 --> 00:20:58,620
like the way because that's what people
imagine sort of any kind of interaction

970
00:20:58,620 --> 00:20:58,630
imagine sort of any kind of interaction
 

971
00:20:58,630 --> 00:21:01,500
imagine sort of any kind of interaction
between human and robot that shows any

972
00:21:01,500 --> 00:21:01,510
between human and robot that shows any
 

973
00:21:01,510 --> 00:21:03,840
between human and robot that shows any
kind of compassion they immediately

974
00:21:03,840 --> 00:21:03,850
kind of compassion they immediately
 

975
00:21:03,850 --> 00:21:04,680
kind of compassion they immediately
think from

976
00:21:04,680 --> 00:21:04,690
think from
 

977
00:21:04,690 --> 00:21:07,610
think from
product perspective in the near term is

978
00:21:07,610 --> 00:21:07,620
product perspective in the near term is
 

979
00:21:07,620 --> 00:21:10,320
product perspective in the near term is
sort of expansion of what pornography is

980
00:21:10,320 --> 00:21:10,330
sort of expansion of what pornography is
 

981
00:21:10,330 --> 00:21:14,190
sort of expansion of what pornography is
and all that kind of stuff yeah that's

982
00:21:14,190 --> 00:21:14,200
and all that kind of stuff yeah that's
 

983
00:21:14,200 --> 00:21:16,380
and all that kind of stuff yeah that's
kind of you to like characterize it as

984
00:21:16,380 --> 00:21:16,390
kind of you to like characterize it as
 

985
00:21:16,390 --> 00:21:17,880
kind of you to like characterize it as
though there's thinking rationally about

986
00:21:17,880 --> 00:21:17,890
though there's thinking rationally about
 

987
00:21:17,890 --> 00:21:20,550
though there's thinking rationally about
product I feel like sex robots are just

988
00:21:20,550 --> 00:21:20,560
product I feel like sex robots are just
 

989
00:21:20,560 --> 00:21:22,740
product I feel like sex robots are just
such a like titillating news hook for

990
00:21:22,740 --> 00:21:22,750
such a like titillating news hook for
 

991
00:21:22,750 --> 00:21:25,680
such a like titillating news hook for
people that they become like the story

992
00:21:25,680 --> 00:21:25,690
people that they become like the story
 

993
00:21:25,690 --> 00:21:29,010
people that they become like the story
and it's really hard to not get fatigued

994
00:21:29,010 --> 00:21:29,020
and it's really hard to not get fatigued
 

995
00:21:29,020 --> 00:21:30,930
and it's really hard to not get fatigued
by it when you're in the space because

996
00:21:30,930 --> 00:21:30,940
by it when you're in the space because
 

997
00:21:30,940 --> 00:21:32,580
by it when you're in the space because
you tell someone you do human robot

998
00:21:32,580 --> 00:21:32,590
you tell someone you do human robot
 

999
00:21:32,590 --> 00:21:33,990
you tell someone you do human robot
interaction of course the first thing

1000
00:21:33,990 --> 00:21:34,000
interaction of course the first thing
 

1001
00:21:34,000 --> 00:21:35,430
interaction of course the first thing
they want to talk about is sex robots

1002
00:21:35,430 --> 00:21:35,440
they want to talk about is sex robots
 

1003
00:21:35,440 --> 00:21:38,820
they want to talk about is sex robots
really yeah it happens a lot and it's

1004
00:21:38,820 --> 00:21:38,830
really yeah it happens a lot and it's
 

1005
00:21:38,830 --> 00:21:41,310
really yeah it happens a lot and it's
it's unfortunate that I'm so fatigued by

1006
00:21:41,310 --> 00:21:41,320
it's unfortunate that I'm so fatigued by
 

1007
00:21:41,320 --> 00:21:42,450
it's unfortunate that I'm so fatigued by
it because I do think that there are

1008
00:21:42,450 --> 00:21:42,460
it because I do think that there are
 

1009
00:21:42,460 --> 00:21:45,000
it because I do think that there are
some interesting questions that become

1010
00:21:45,000 --> 00:21:45,010
some interesting questions that become
 

1011
00:21:45,010 --> 00:21:47,370
some interesting questions that become
salient when you talk about you know sex

1012
00:21:47,370 --> 00:21:47,380
salient when you talk about you know sex
 

1013
00:21:47,380 --> 00:21:49,710
salient when you talk about you know sex
with robots see what I think would

1014
00:21:49,710 --> 00:21:49,720
with robots see what I think would
 

1015
00:21:49,720 --> 00:21:52,170
with robots see what I think would
happen when people get sex robots like

1016
00:21:52,170 --> 00:21:52,180
happen when people get sex robots like
 

1017
00:21:52,180 --> 00:21:53,940
happen when people get sex robots like
if you let some guys okay guys get

1018
00:21:53,940 --> 00:21:53,950
if you let some guys okay guys get
 

1019
00:21:53,950 --> 00:21:56,820
if you let some guys okay guys get
female sex robots what I think there's

1020
00:21:56,820 --> 00:21:56,830
female sex robots what I think there's
 

1021
00:21:56,830 --> 00:22:01,440
female sex robots what I think there's
an opportunity for is an actual like

1022
00:22:01,440 --> 00:22:01,450
an opportunity for is an actual like
 

1023
00:22:01,450 --> 00:22:06,540
an opportunity for is an actual like
like they'll actually interact what I'm

1024
00:22:06,540 --> 00:22:06,550
like they'll actually interact what I'm
 

1025
00:22:06,550 --> 00:22:08,850
like they'll actually interact what I'm
trying to say they won't outside of the

1026
00:22:08,850 --> 00:22:08,860
trying to say they won't outside of the
 

1027
00:22:08,860 --> 00:22:10,580
trying to say they won't outside of the
sex would be the most fulfilling part

1028
00:22:10,580 --> 00:22:10,590
sex would be the most fulfilling part
 

1029
00:22:10,590 --> 00:22:13,380
sex would be the most fulfilling part
like the interaction it's like the folks

1030
00:22:13,380 --> 00:22:13,390
like the interaction it's like the folks
 

1031
00:22:13,390 --> 00:22:16,050
like the interaction it's like the folks
who this movies on this right who pray

1032
00:22:16,050 --> 00:22:16,060
who this movies on this right who pray
 

1033
00:22:16,060 --> 00:22:19,200
who this movies on this right who pray
pay a prostitute and then end up just

1034
00:22:19,200 --> 00:22:19,210
pay a prostitute and then end up just
 

1035
00:22:19,210 --> 00:22:21,270
pay a prostitute and then end up just
talking to her the whole time so I feel

1036
00:22:21,270 --> 00:22:21,280
talking to her the whole time so I feel
 

1037
00:22:21,280 --> 00:22:23,130
talking to her the whole time so I feel
like there's an opportunity it's like

1038
00:22:23,130 --> 00:22:23,140
like there's an opportunity it's like
 

1039
00:22:23,140 --> 00:22:25,680
like there's an opportunity it's like
most guys and people in general joke

1040
00:22:25,680 --> 00:22:25,690
most guys and people in general joke
 

1041
00:22:25,690 --> 00:22:28,980
most guys and people in general joke
about the sex act but really people are

1042
00:22:28,980 --> 00:22:28,990
about the sex act but really people are
 

1043
00:22:28,990 --> 00:22:30,960
about the sex act but really people are
just lonely inside and I'm looking for

1044
00:22:30,960 --> 00:22:30,970
just lonely inside and I'm looking for
 

1045
00:22:30,970 --> 00:22:33,810
just lonely inside and I'm looking for
connection many of them and it'd be

1046
00:22:33,810 --> 00:22:33,820
connection many of them and it'd be
 

1047
00:22:33,820 --> 00:22:38,670
connection many of them and it'd be
unfortunate if that it's that connection

1048
00:22:38,670 --> 00:22:38,680
unfortunate if that it's that connection
 

1049
00:22:38,680 --> 00:22:40,320
unfortunate if that it's that connection
is established through the sex industry

1050
00:22:40,320 --> 00:22:40,330
is established through the sex industry
 

1051
00:22:40,330 --> 00:22:42,120
is established through the sex industry
I feel like it should go too

1052
00:22:42,120 --> 00:22:42,130
I feel like it should go too
 

1053
00:22:42,130 --> 00:22:45,090
I feel like it should go too
into the front door of like people are

1054
00:22:45,090 --> 00:22:45,100
into the front door of like people are
 

1055
00:22:45,100 --> 00:22:47,610
into the front door of like people are
lonely and they want a connection well I

1056
00:22:47,610 --> 00:22:47,620
lonely and they want a connection well I
 

1057
00:22:47,620 --> 00:22:49,050
lonely and they want a connection well I
also feel like we should kind of deep

1058
00:22:49,050 --> 00:22:49,060
also feel like we should kind of deep
 

1059
00:22:49,060 --> 00:22:52,110
also feel like we should kind of deep
you know D stigmatize the sex industry

1060
00:22:52,110 --> 00:22:52,120
you know D stigmatize the sex industry
 

1061
00:22:52,120 --> 00:22:56,490
you know D stigmatize the sex industry
because you know even prostitution like

1062
00:22:56,490 --> 00:22:56,500
because you know even prostitution like
 

1063
00:22:56,500 --> 00:22:58,460
because you know even prostitution like
they're prostitutes that specialize in

1064
00:22:58,460 --> 00:22:58,470
they're prostitutes that specialize in
 

1065
00:22:58,470 --> 00:23:01,590
they're prostitutes that specialize in
disabled people who don't have the same

1066
00:23:01,590 --> 00:23:01,600
disabled people who don't have the same
 

1067
00:23:01,600 --> 00:23:04,830
disabled people who don't have the same
kind of opportunities to explore their

1068
00:23:04,830 --> 00:23:04,840
kind of opportunities to explore their
 

1069
00:23:04,840 --> 00:23:08,070
kind of opportunities to explore their
sexuality so it's I I feel like we

1070
00:23:08,070 --> 00:23:08,080
sexuality so it's I I feel like we
 

1071
00:23:08,080 --> 00:23:09,630
sexuality so it's I I feel like we
should like D stigmatize all of that

1072
00:23:09,630 --> 00:23:09,640
should like D stigmatize all of that
 

1073
00:23:09,640 --> 00:23:12,180
should like D stigmatize all of that
generally yeah but yeah that connection

1074
00:23:12,180 --> 00:23:12,190
generally yeah but yeah that connection
 

1075
00:23:12,190 --> 00:23:13,760
generally yeah but yeah that connection
and that loneliness is an interesting

1076
00:23:13,760 --> 00:23:13,770
and that loneliness is an interesting
 

1077
00:23:13,770 --> 00:23:16,280
and that loneliness is an interesting
you know topic that you bring up because

1078
00:23:16,280 --> 00:23:16,290
you know topic that you bring up because
 

1079
00:23:16,290 --> 00:23:18,390
you know topic that you bring up because
while people are Const

1080
00:23:18,390 --> 00:23:18,400
while people are Const
 

1081
00:23:18,400 --> 00:23:20,430
while people are Const
we worried about robots replacing humans

1082
00:23:20,430 --> 00:23:20,440
we worried about robots replacing humans
 

1083
00:23:20,440 --> 00:23:22,470
we worried about robots replacing humans
and oh if people get sex robots and the

1084
00:23:22,470 --> 00:23:22,480
and oh if people get sex robots and the
 

1085
00:23:22,480 --> 00:23:23,820
and oh if people get sex robots and the
sex is really good then they won't want

1086
00:23:23,820 --> 00:23:23,830
sex is really good then they won't want
 

1087
00:23:23,830 --> 00:23:26,640
sex is really good then they won't want
their you know partner or whatever but

1088
00:23:26,640 --> 00:23:26,650
their you know partner or whatever but
 

1089
00:23:26,650 --> 00:23:28,590
their you know partner or whatever but
we rarely talk about robots actually

1090
00:23:28,590 --> 00:23:28,600
we rarely talk about robots actually
 

1091
00:23:28,600 --> 00:23:30,630
we rarely talk about robots actually
filling a hole where there's nothing

1092
00:23:30,630 --> 00:23:30,640
filling a hole where there's nothing
 

1093
00:23:30,640 --> 00:23:33,240
filling a hole where there's nothing
yeah and what benefit that can provide

1094
00:23:33,240 --> 00:23:33,250
yeah and what benefit that can provide
 

1095
00:23:33,250 --> 00:23:35,580
yeah and what benefit that can provide
to people yeah I think that's an

1096
00:23:35,580 --> 00:23:35,590
to people yeah I think that's an
 

1097
00:23:35,590 --> 00:23:38,580
to people yeah I think that's an
exciting there's a whole giant there's a

1098
00:23:38,580 --> 00:23:38,590
exciting there's a whole giant there's a
 

1099
00:23:38,590 --> 00:23:41,010
exciting there's a whole giant there's a
giant hole that's not unfillable by

1100
00:23:41,010 --> 00:23:41,020
giant hole that's not unfillable by
 

1101
00:23:41,020 --> 00:23:43,830
giant hole that's not unfillable by
humans it's asking too much of your of

1102
00:23:43,830 --> 00:23:43,840
humans it's asking too much of your of
 

1103
00:23:43,840 --> 00:23:45,300
humans it's asking too much of your of
people you your friends and people

1104
00:23:45,300 --> 00:23:45,310
people you your friends and people
 

1105
00:23:45,310 --> 00:23:46,440
people you your friends and people
you're in a relationship with in your

1106
00:23:46,440 --> 00:23:46,450
you're in a relationship with in your
 

1107
00:23:46,450 --> 00:23:48,600
you're in a relationship with in your
family to fill that hole there's a

1108
00:23:48,600 --> 00:23:48,610
family to fill that hole there's a
 

1109
00:23:48,610 --> 00:23:52,380
family to fill that hole there's a
because you know it's exploring the full

1110
00:23:52,380 --> 00:23:52,390
because you know it's exploring the full
 

1111
00:23:52,390 --> 00:23:54,720
because you know it's exploring the full
like people you know exploring the full

1112
00:23:54,720 --> 00:23:54,730
like people you know exploring the full
 

1113
00:23:54,730 --> 00:23:56,390
like people you know exploring the full
complexity and richness of who you are

1114
00:23:56,390 --> 00:23:56,400
complexity and richness of who you are
 

1115
00:23:56,400 --> 00:24:00,960
complexity and richness of who you are
like who are you really like the people

1116
00:24:00,960 --> 00:24:00,970
like who are you really like the people
 

1117
00:24:00,970 --> 00:24:03,420
like who are you really like the people
your family doesn't have enough patience

1118
00:24:03,420 --> 00:24:03,430
your family doesn't have enough patience
 

1119
00:24:03,430 --> 00:24:05,070
your family doesn't have enough patience
to really sit there and listen to who

1120
00:24:05,070 --> 00:24:05,080
to really sit there and listen to who
 

1121
00:24:05,080 --> 00:24:07,140
to really sit there and listen to who
are you really and I feel like there's

1122
00:24:07,140 --> 00:24:07,150
are you really and I feel like there's
 

1123
00:24:07,150 --> 00:24:08,790
are you really and I feel like there's
an opportunity to really make that

1124
00:24:08,790 --> 00:24:08,800
an opportunity to really make that
 

1125
00:24:08,800 --> 00:24:10,140
an opportunity to really make that
connection with robots

1126
00:24:10,140 --> 00:24:10,150
connection with robots
 

1127
00:24:10,150 --> 00:24:13,680
connection with robots
I just really were complex as humans and

1128
00:24:13,680 --> 00:24:13,690
I just really were complex as humans and
 

1129
00:24:13,690 --> 00:24:16,140
I just really were complex as humans and
we're capable of lots of different types

1130
00:24:16,140 --> 00:24:16,150
we're capable of lots of different types
 

1131
00:24:16,150 --> 00:24:18,960
we're capable of lots of different types
of relationships so whether that's you

1132
00:24:18,960 --> 00:24:18,970
of relationships so whether that's you
 

1133
00:24:18,970 --> 00:24:20,490
of relationships so whether that's you
know with family members with friends

1134
00:24:20,490 --> 00:24:20,500
know with family members with friends
 

1135
00:24:20,500 --> 00:24:23,070
know with family members with friends
with our pets or with robots I feel like

1136
00:24:23,070 --> 00:24:23,080
with our pets or with robots I feel like
 

1137
00:24:23,080 --> 00:24:25,230
with our pets or with robots I feel like
there's space for all of that and all of

1138
00:24:25,230 --> 00:24:25,240
there's space for all of that and all of
 

1139
00:24:25,240 --> 00:24:27,360
there's space for all of that and all of
that can provide value in a different

1140
00:24:27,360 --> 00:24:27,370
that can provide value in a different
 

1141
00:24:27,370 --> 00:24:31,350
that can provide value in a different
way yeah absolutely so I'm jumping

1142
00:24:31,350 --> 00:24:31,360
way yeah absolutely so I'm jumping
 

1143
00:24:31,360 --> 00:24:34,380
way yeah absolutely so I'm jumping
around currently most of my works and

1144
00:24:34,380 --> 00:24:34,390
around currently most of my works and
 

1145
00:24:34,390 --> 00:24:37,890
around currently most of my works and
autonomous vehicles so the most popular

1146
00:24:37,890 --> 00:24:37,900
autonomous vehicles so the most popular
 

1147
00:24:37,900 --> 00:24:43,590
autonomous vehicles so the most popular
topic amongst is the trolley problem so

1148
00:24:43,590 --> 00:24:43,600
topic amongst is the trolley problem so
 

1149
00:24:43,600 --> 00:24:49,260
topic amongst is the trolley problem so
most most most robots just uh kind of

1150
00:24:49,260 --> 00:24:49,270
most most most robots just uh kind of
 

1151
00:24:49,270 --> 00:24:51,420
most most most robots just uh kind of
hate this question but what do you think

1152
00:24:51,420 --> 00:24:51,430
hate this question but what do you think
 

1153
00:24:51,430 --> 00:24:53,160
hate this question but what do you think
of this thought experiment what do you

1154
00:24:53,160 --> 00:24:53,170
of this thought experiment what do you
 

1155
00:24:53,170 --> 00:24:54,540
of this thought experiment what do you
think we can learn from it outside of

1156
00:24:54,540 --> 00:24:54,550
think we can learn from it outside of
 

1157
00:24:54,550 --> 00:24:56,880
think we can learn from it outside of
the silliness of the actual application

1158
00:24:56,880 --> 00:24:56,890
the silliness of the actual application
 

1159
00:24:56,890 --> 00:24:59,340
the silliness of the actual application
of it to the autonomous vehicle I think

1160
00:24:59,340 --> 00:24:59,350
of it to the autonomous vehicle I think
 

1161
00:24:59,350 --> 00:25:00,540
of it to the autonomous vehicle I think
it's still an interesting ethical

1162
00:25:00,540 --> 00:25:00,550
it's still an interesting ethical
 

1163
00:25:00,550 --> 00:25:04,890
it's still an interesting ethical
question and that's in itself just like

1164
00:25:04,890 --> 00:25:04,900
question and that's in itself just like
 

1165
00:25:04,900 --> 00:25:07,110
question and that's in itself just like
much of the interaction with robots has

1166
00:25:07,110 --> 00:25:07,120
much of the interaction with robots has
 

1167
00:25:07,120 --> 00:25:08,130
much of the interaction with robots has
something to teach us

1168
00:25:08,130 --> 00:25:08,140
something to teach us
 

1169
00:25:08,140 --> 00:25:09,870
something to teach us
but from your perspective do you think

1170
00:25:09,870 --> 00:25:09,880
but from your perspective do you think
 

1171
00:25:09,880 --> 00:25:11,640
but from your perspective do you think
there's anything there well I think

1172
00:25:11,640 --> 00:25:11,650
there's anything there well I think
 

1173
00:25:11,650 --> 00:25:13,140
there's anything there well I think
you're right that it does have something

1174
00:25:13,140 --> 00:25:13,150
you're right that it does have something
 

1175
00:25:13,150 --> 00:25:15,390
you're right that it does have something
to teach us because but but I think what

1176
00:25:15,390 --> 00:25:15,400
to teach us because but but I think what
 

1177
00:25:15,400 --> 00:25:17,310
to teach us because but but I think what
people are forgetting in all these

1178
00:25:17,310 --> 00:25:17,320
people are forgetting in all these
 

1179
00:25:17,320 --> 00:25:19,650
people are forgetting in all these
conversations is the origins of the

1180
00:25:19,650 --> 00:25:19,660
conversations is the origins of the
 

1181
00:25:19,660 --> 00:25:21,270
conversations is the origins of the
trolley problem and what it was meant to

1182
00:25:21,270 --> 00:25:21,280
trolley problem and what it was meant to
 

1183
00:25:21,280 --> 00:25:23,940
trolley problem and what it was meant to
show us which is that there is no right

1184
00:25:23,940 --> 00:25:23,950
show us which is that there is no right
 

1185
00:25:23,950 --> 00:25:26,280
show us which is that there is no right
answer and that sometimes our moral

1186
00:25:26,280 --> 00:25:26,290
answer and that sometimes our moral
 

1187
00:25:26,290 --> 00:25:29,250
answer and that sometimes our moral
intuition that comes to us instinctively

1188
00:25:29,250 --> 00:25:29,260
intuition that comes to us instinctively
 

1189
00:25:29,260 --> 00:25:31,950
intuition that comes to us instinctively
is not actually what

1190
00:25:31,950 --> 00:25:31,960
is not actually what
 

1191
00:25:31,960 --> 00:25:34,410
is not actually what
we should follow if we care about

1192
00:25:34,410 --> 00:25:34,420
we should follow if we care about
 

1193
00:25:34,420 --> 00:25:36,330
we should follow if we care about
creating systematic rules that apply to

1194
00:25:36,330 --> 00:25:36,340
creating systematic rules that apply to
 

1195
00:25:36,340 --> 00:25:39,350
creating systematic rules that apply to
everyone so I think that as a

1196
00:25:39,350 --> 00:25:39,360
everyone so I think that as a
 

1197
00:25:39,360 --> 00:25:43,350
everyone so I think that as a
philosophical concept it could teach us

1198
00:25:43,350 --> 00:25:43,360
philosophical concept it could teach us
 

1199
00:25:43,360 --> 00:25:45,900
philosophical concept it could teach us
at least that but that's not how people

1200
00:25:45,900 --> 00:25:45,910
at least that but that's not how people
 

1201
00:25:45,910 --> 00:25:48,120
at least that but that's not how people
are using it right now like we have and

1202
00:25:48,120 --> 00:25:48,130
are using it right now like we have and
 

1203
00:25:48,130 --> 00:25:49,800
are using it right now like we have and
these are friends of mine and like I

1204
00:25:49,800 --> 00:25:49,810
these are friends of mine and like I
 

1205
00:25:49,810 --> 00:25:51,930
these are friends of mine and like I
love them dearly and their project adds

1206
00:25:51,930 --> 00:25:51,940
love them dearly and their project adds
 

1207
00:25:51,940 --> 00:25:55,320
love them dearly and their project adds
a lot of value but if we're viewing the

1208
00:25:55,320 --> 00:25:55,330
a lot of value but if we're viewing the
 

1209
00:25:55,330 --> 00:25:58,020
a lot of value but if we're viewing the
moral machine project as what we can

1210
00:25:58,020 --> 00:25:58,030
moral machine project as what we can
 

1211
00:25:58,030 --> 00:25:59,550
moral machine project as what we can
learn from the trolley problems the

1212
00:25:59,550 --> 00:25:59,560
learn from the trolley problems the
 

1213
00:25:59,560 --> 00:26:01,800
learn from the trolley problems the
moral machine is I'm sure you're

1214
00:26:01,800 --> 00:26:01,810
moral machine is I'm sure you're
 

1215
00:26:01,810 --> 00:26:03,450
moral machine is I'm sure you're
familiar it's this website that you can

1216
00:26:03,450 --> 00:26:03,460
familiar it's this website that you can
 

1217
00:26:03,460 --> 00:26:04,800
familiar it's this website that you can
go to and it gives you different

1218
00:26:04,800 --> 00:26:04,810
go to and it gives you different
 

1219
00:26:04,810 --> 00:26:07,410
go to and it gives you different
scenarios like oh you're in a car you

1220
00:26:07,410 --> 00:26:07,420
scenarios like oh you're in a car you
 

1221
00:26:07,420 --> 00:26:09,510
scenarios like oh you're in a car you
can decide to run over you know these

1222
00:26:09,510 --> 00:26:09,520
can decide to run over you know these
 

1223
00:26:09,520 --> 00:26:11,910
can decide to run over you know these
two people or this child you know what

1224
00:26:11,910 --> 00:26:11,920
two people or this child you know what
 

1225
00:26:11,920 --> 00:26:13,830
two people or this child you know what
do you choose do you choose the homeless

1226
00:26:13,830 --> 00:26:13,840
do you choose do you choose the homeless
 

1227
00:26:13,840 --> 00:26:15,300
do you choose do you choose the homeless
person do you choose the person who's

1228
00:26:15,300 --> 00:26:15,310
person do you choose the person who's
 

1229
00:26:15,310 --> 00:26:18,390
person do you choose the person who's
jaywalking and so it pits these like

1230
00:26:18,390 --> 00:26:18,400
jaywalking and so it pits these like
 

1231
00:26:18,400 --> 00:26:20,790
jaywalking and so it pits these like
moral choices against each other and

1232
00:26:20,790 --> 00:26:20,800
moral choices against each other and
 

1233
00:26:20,800 --> 00:26:22,710
moral choices against each other and
then tries to crowdsource the

1234
00:26:22,710 --> 00:26:22,720
then tries to crowdsource the
 

1235
00:26:22,720 --> 00:26:26,280
then tries to crowdsource the
quote-unquote correct answer which is

1236
00:26:26,280 --> 00:26:26,290
quote-unquote correct answer which is
 

1237
00:26:26,290 --> 00:26:28,350
quote-unquote correct answer which is
really interesting and I think valuable

1238
00:26:28,350 --> 00:26:28,360
really interesting and I think valuable
 

1239
00:26:28,360 --> 00:26:30,510
really interesting and I think valuable
data but I don't think that's what we

1240
00:26:30,510 --> 00:26:30,520
data but I don't think that's what we
 

1241
00:26:30,520 --> 00:26:32,610
data but I don't think that's what we
should base our rules in autonomous

1242
00:26:32,610 --> 00:26:32,620
should base our rules in autonomous
 

1243
00:26:32,620 --> 00:26:35,070
should base our rules in autonomous
vehicles on because it is exactly what

1244
00:26:35,070 --> 00:26:35,080
vehicles on because it is exactly what
 

1245
00:26:35,080 --> 00:26:37,140
vehicles on because it is exactly what
the trolley problem is trying to show

1246
00:26:37,140 --> 00:26:37,150
the trolley problem is trying to show
 

1247
00:26:37,150 --> 00:26:39,780
the trolley problem is trying to show
which is your first instinct might not

1248
00:26:39,780 --> 00:26:39,790
which is your first instinct might not
 

1249
00:26:39,790 --> 00:26:42,720
which is your first instinct might not
be the correct one if you look at rules

1250
00:26:42,720 --> 00:26:42,730
be the correct one if you look at rules
 

1251
00:26:42,730 --> 00:26:44,610
be the correct one if you look at rules
that then have to apply to everyone and

1252
00:26:44,610 --> 00:26:44,620
that then have to apply to everyone and
 

1253
00:26:44,620 --> 00:26:47,310
that then have to apply to everyone and
everything so how do we encode these

1254
00:26:47,310 --> 00:26:47,320
everything so how do we encode these
 

1255
00:26:47,320 --> 00:26:49,110
everything so how do we encode these
ethical choices in interaction with

1256
00:26:49,110 --> 00:26:49,120
ethical choices in interaction with
 

1257
00:26:49,120 --> 00:26:51,390
ethical choices in interaction with
robots so for example Lata knows

1258
00:26:51,390 --> 00:26:51,400
robots so for example Lata knows
 

1259
00:26:51,400 --> 00:26:52,680
robots so for example Lata knows
vehicles there is a serious ethical

1260
00:26:52,680 --> 00:26:52,690
vehicles there is a serious ethical
 

1261
00:26:52,690 --> 00:26:59,040
vehicles there is a serious ethical
question of do I protect myself but

1262
00:26:59,040 --> 00:26:59,050
question of do I protect myself but
 

1263
00:26:59,050 --> 00:27:00,960
question of do I protect myself but
that's my life I have higher priority

1264
00:27:00,960 --> 00:27:00,970
that's my life I have higher priority
 

1265
00:27:00,970 --> 00:27:03,200
that's my life I have higher priority
than the life of another human being

1266
00:27:03,200 --> 00:27:03,210
than the life of another human being
 

1267
00:27:03,210 --> 00:27:06,390
than the life of another human being
because that changes certain control

1268
00:27:06,390 --> 00:27:06,400
because that changes certain control
 

1269
00:27:06,400 --> 00:27:09,360
because that changes certain control
decisions that you make so if your life

1270
00:27:09,360 --> 00:27:09,370
decisions that you make so if your life
 

1271
00:27:09,370 --> 00:27:11,040
decisions that you make so if your life
matters more than other human beings

1272
00:27:11,040 --> 00:27:11,050
matters more than other human beings
 

1273
00:27:11,050 --> 00:27:13,860
matters more than other human beings
then you'd be more likely to swerve out

1274
00:27:13,860 --> 00:27:13,870
then you'd be more likely to swerve out
 

1275
00:27:13,870 --> 00:27:15,710
then you'd be more likely to swerve out
of your current lane so currently

1276
00:27:15,710 --> 00:27:15,720
of your current lane so currently
 

1277
00:27:15,720 --> 00:27:17,820
of your current lane so currently
automated emergency braking systems that

1278
00:27:17,820 --> 00:27:17,830
automated emergency braking systems that
 

1279
00:27:17,830 --> 00:27:21,320
automated emergency braking systems that
just break they don't ever swerve right

1280
00:27:21,320 --> 00:27:21,330
just break they don't ever swerve right
 

1281
00:27:21,330 --> 00:27:25,560
just break they don't ever swerve right
so swerving into oncoming traffic or or

1282
00:27:25,560 --> 00:27:25,570
so swerving into oncoming traffic or or
 

1283
00:27:25,570 --> 00:27:27,840
so swerving into oncoming traffic or or
no just in a different Lane can cause

1284
00:27:27,840 --> 00:27:27,850
no just in a different Lane can cause
 

1285
00:27:27,850 --> 00:27:30,450
no just in a different Lane can cause
significant harm to others but it's

1286
00:27:30,450 --> 00:27:30,460
significant harm to others but it's
 

1287
00:27:30,460 --> 00:27:32,670
significant harm to others but it's
possible that it causes less harm to you

1288
00:27:32,670 --> 00:27:32,680
possible that it causes less harm to you
 

1289
00:27:32,680 --> 00:27:34,710
possible that it causes less harm to you
so that's a difficult ethical question

1290
00:27:34,710 --> 00:27:34,720
so that's a difficult ethical question
 

1291
00:27:34,720 --> 00:27:38,910
so that's a difficult ethical question
do you you do you do you have a hope

1292
00:27:38,910 --> 00:27:38,920
do you you do you do you have a hope
 

1293
00:27:38,920 --> 00:27:42,960
do you you do you do you have a hope
that like the trolley problem is not

1294
00:27:42,960 --> 00:27:42,970
that like the trolley problem is not
 

1295
00:27:42,970 --> 00:27:44,669
that like the trolley problem is not
supposed to have a right answer

1296
00:27:44,669 --> 00:27:44,679
supposed to have a right answer
 

1297
00:27:44,679 --> 00:27:47,820
supposed to have a right answer
do you hope that when we have robots at

1298
00:27:47,820 --> 00:27:47,830
do you hope that when we have robots at
 

1299
00:27:47,830 --> 00:27:49,769
do you hope that when we have robots at
the table we'll be able to discover the

1300
00:27:49,769 --> 00:27:49,779
the table we'll be able to discover the
 

1301
00:27:49,779 --> 00:27:52,549
the table we'll be able to discover the
right answer for some of these questions

1302
00:27:52,549 --> 00:27:52,559
right answer for some of these questions
 

1303
00:27:52,559 --> 00:27:54,749
right answer for some of these questions
well what's happening right now I think

1304
00:27:54,749 --> 00:27:54,759
well what's happening right now I think
 

1305
00:27:54,759 --> 00:27:57,659
well what's happening right now I think
is this this question that we're facing

1306
00:27:57,659 --> 00:27:57,669
is this this question that we're facing
 

1307
00:27:57,669 --> 00:28:00,720
is this this question that we're facing
of you know what ethical rules should we

1308
00:28:00,720 --> 00:28:00,730
of you know what ethical rules should we
 

1309
00:28:00,730 --> 00:28:02,220
of you know what ethical rules should we
be programming into the machines is

1310
00:28:02,220 --> 00:28:02,230
be programming into the machines is
 

1311
00:28:02,230 --> 00:28:04,710
be programming into the machines is
revealing to us that our ethical rules

1312
00:28:04,710 --> 00:28:04,720
revealing to us that our ethical rules
 

1313
00:28:04,720 --> 00:28:08,249
revealing to us that our ethical rules
are much less programmable than we you

1314
00:28:08,249 --> 00:28:08,259
are much less programmable than we you
 

1315
00:28:08,259 --> 00:28:10,230
are much less programmable than we you
know probably thought before and so

1316
00:28:10,230 --> 00:28:10,240
know probably thought before and so
 

1317
00:28:10,240 --> 00:28:14,180
know probably thought before and so
that's a really valuable insight I think

1318
00:28:14,180 --> 00:28:14,190
that's a really valuable insight I think
 

1319
00:28:14,190 --> 00:28:17,820
that's a really valuable insight I think
that these issues are very complicated

1320
00:28:17,820 --> 00:28:17,830
that these issues are very complicated
 

1321
00:28:17,830 --> 00:28:20,430
that these issues are very complicated
and that in in a lot of these cases it's

1322
00:28:20,430 --> 00:28:20,440
and that in in a lot of these cases it's
 

1323
00:28:20,440 --> 00:28:23,159
and that in in a lot of these cases it's
you can't really make that call like not

1324
00:28:23,159 --> 00:28:23,169
you can't really make that call like not
 

1325
00:28:23,169 --> 00:28:26,129
you can't really make that call like not
even as a legislator and so what's gonna

1326
00:28:26,129 --> 00:28:26,139
even as a legislator and so what's gonna
 

1327
00:28:26,139 --> 00:28:28,499
even as a legislator and so what's gonna
happen in reality I think is that you

1328
00:28:28,499 --> 00:28:28,509
happen in reality I think is that you
 

1329
00:28:28,509 --> 00:28:31,320
happen in reality I think is that you
know car manufacturers are just gonna

1330
00:28:31,320 --> 00:28:31,330
know car manufacturers are just gonna
 

1331
00:28:31,330 --> 00:28:33,629
know car manufacturers are just gonna
try and avoid the problem and avoid

1332
00:28:33,629 --> 00:28:33,639
try and avoid the problem and avoid
 

1333
00:28:33,639 --> 00:28:35,669
try and avoid the problem and avoid
liability in any way possible or like

1334
00:28:35,669 --> 00:28:35,679
liability in any way possible or like
 

1335
00:28:35,679 --> 00:28:37,379
liability in any way possible or like
they're gonna always protect the driver

1336
00:28:37,379 --> 00:28:37,389
they're gonna always protect the driver
 

1337
00:28:37,389 --> 00:28:39,359
they're gonna always protect the driver
because who's gonna buy a car if it's

1338
00:28:39,359 --> 00:28:39,369
because who's gonna buy a car if it's
 

1339
00:28:39,369 --> 00:28:41,519
because who's gonna buy a car if it's
you know programmed to kill someone kill

1340
00:28:41,519 --> 00:28:41,529
you know programmed to kill someone kill
 

1341
00:28:41,529 --> 00:28:44,970
you know programmed to kill someone kill
kill you instead of someone else so

1342
00:28:44,970 --> 00:28:44,980
kill you instead of someone else so
 

1343
00:28:44,980 --> 00:28:46,799
kill you instead of someone else so
that's what's gonna happen in reality

1344
00:28:46,799 --> 00:28:46,809
that's what's gonna happen in reality
 

1345
00:28:46,809 --> 00:28:49,320
that's what's gonna happen in reality
but what did you mean by like once we

1346
00:28:49,320 --> 00:28:49,330
but what did you mean by like once we
 

1347
00:28:49,330 --> 00:28:50,789
but what did you mean by like once we
have robots at the table like do you

1348
00:28:50,789 --> 00:28:50,799
have robots at the table like do you
 

1349
00:28:50,799 --> 00:28:53,129
have robots at the table like do you
mean when they can help us figure out

1350
00:28:53,129 --> 00:28:53,139
mean when they can help us figure out
 

1351
00:28:53,139 --> 00:28:57,539
mean when they can help us figure out
what to do no I mean when robots are

1352
00:28:57,539 --> 00:28:57,549
what to do no I mean when robots are
 

1353
00:28:57,549 --> 00:29:00,419
what to do no I mean when robots are
part of the ethical decisions so no no

1354
00:29:00,419 --> 00:29:00,429
part of the ethical decisions so no no
 

1355
00:29:00,429 --> 00:29:05,970
part of the ethical decisions so no no
not they help us well oh you mean when

1356
00:29:05,970 --> 00:29:05,980
not they help us well oh you mean when
 

1357
00:29:05,980 --> 00:29:08,279
not they help us well oh you mean when
it's like should I run over a robot or a

1358
00:29:08,279 --> 00:29:08,289
it's like should I run over a robot or a
 

1359
00:29:08,289 --> 00:29:10,889
it's like should I run over a robot or a
person right that kind of thing so what

1360
00:29:10,889 --> 00:29:10,899
person right that kind of thing so what
 

1361
00:29:10,899 --> 00:29:14,489
person right that kind of thing so what
no what no no no so when you it's

1362
00:29:14,489 --> 00:29:14,499
no what no no no so when you it's
 

1363
00:29:14,499 --> 00:29:16,230
no what no no no so when you it's
exactly what you said which is when you

1364
00:29:16,230 --> 00:29:16,240
exactly what you said which is when you
 

1365
00:29:16,240 --> 00:29:18,899
exactly what you said which is when you
have to encode the ethics into an

1366
00:29:18,899 --> 00:29:18,909
have to encode the ethics into an
 

1367
00:29:18,909 --> 00:29:21,810
have to encode the ethics into an
algorithm you start to try to really

1368
00:29:21,810 --> 00:29:21,820
algorithm you start to try to really
 

1369
00:29:21,820 --> 00:29:24,210
algorithm you start to try to really
understand what are the fundamentals of

1370
00:29:24,210 --> 00:29:24,220
understand what are the fundamentals of
 

1371
00:29:24,220 --> 00:29:26,190
understand what are the fundamentals of
the decision making process you make

1372
00:29:26,190 --> 00:29:26,200
the decision making process you make
 

1373
00:29:26,200 --> 00:29:29,810
the decision making process you make
just make certain decisions should you

1374
00:29:29,810 --> 00:29:29,820
just make certain decisions should you
 

1375
00:29:29,820 --> 00:29:32,759
just make certain decisions should you
like capital punishment should you take

1376
00:29:32,759 --> 00:29:32,769
like capital punishment should you take
 

1377
00:29:32,769 --> 00:29:34,769
like capital punishment should you take
a person's life or not to punish them

1378
00:29:34,769 --> 00:29:34,779
a person's life or not to punish them
 

1379
00:29:34,779 --> 00:29:37,879
a person's life or not to punish them
for a certain crime sort of you can use

1380
00:29:37,879 --> 00:29:37,889
for a certain crime sort of you can use
 

1381
00:29:37,889 --> 00:29:40,350
for a certain crime sort of you can use
you can develop an algorithm to make

1382
00:29:40,350 --> 00:29:40,360
you can develop an algorithm to make
 

1383
00:29:40,360 --> 00:29:44,669
you can develop an algorithm to make
that decision right and the hope is that

1384
00:29:44,669 --> 00:29:44,679
that decision right and the hope is that
 

1385
00:29:44,679 --> 00:29:48,539
that decision right and the hope is that
the act of making that algorithm however

1386
00:29:48,539 --> 00:29:48,549
the act of making that algorithm however
 

1387
00:29:48,549 --> 00:29:50,419
the act of making that algorithm however
you make it so there's a few approaches

1388
00:29:50,419 --> 00:29:50,429
you make it so there's a few approaches
 

1389
00:29:50,429 --> 00:29:54,379
you make it so there's a few approaches
will help us actually get to the core of

1390
00:29:54,379 --> 00:29:54,389
will help us actually get to the core of
 

1391
00:29:54,389 --> 00:29:57,840
will help us actually get to the core of
what what is right and what is wrong

1392
00:29:57,840 --> 00:29:57,850
what what is right and what is wrong
 

1393
00:29:57,850 --> 00:30:00,779
what what is right and what is wrong
under our current societal standards

1394
00:30:00,779 --> 00:30:00,789
under our current societal standards
 

1395
00:30:00,789 --> 00:30:02,250
under our current societal standards
isn't that what's happening right now

1396
00:30:02,250 --> 00:30:02,260
isn't that what's happening right now
 

1397
00:30:02,260 --> 00:30:04,650
isn't that what's happening right now
and we're realizing that we don't have a

1398
00:30:04,650 --> 00:30:04,660
and we're realizing that we don't have a
 

1399
00:30:04,660 --> 00:30:06,810
and we're realizing that we don't have a
consensus on what's right and wrong I

1400
00:30:06,810 --> 00:30:06,820
consensus on what's right and wrong I
 

1401
00:30:06,820 --> 00:30:08,820
consensus on what's right and wrong I
mean in politics in general well like

1402
00:30:08,820 --> 00:30:08,830
mean in politics in general well like
 

1403
00:30:08,830 --> 00:30:10,500
mean in politics in general well like
when we're thinking about these trolley

1404
00:30:10,500 --> 00:30:10,510
when we're thinking about these trolley
 

1405
00:30:10,510 --> 00:30:12,810
when we're thinking about these trolley
problems and autonomous vehicles and how

1406
00:30:12,810 --> 00:30:12,820
problems and autonomous vehicles and how
 

1407
00:30:12,820 --> 00:30:14,940
problems and autonomous vehicles and how
to program ethics into machines and how

1408
00:30:14,940 --> 00:30:14,950
to program ethics into machines and how
 

1409
00:30:14,950 --> 00:30:19,590
to program ethics into machines and how
to you know make make AI algorithms fair

1410
00:30:19,590 --> 00:30:19,600
to you know make make AI algorithms fair
 

1411
00:30:19,600 --> 00:30:22,980
to you know make make AI algorithms fair
and equitable where we're realizing that

1412
00:30:22,980 --> 00:30:22,990
and equitable where we're realizing that
 

1413
00:30:22,990 --> 00:30:24,960
and equitable where we're realizing that
this is so complicated and it's

1414
00:30:24,960 --> 00:30:24,970
this is so complicated and it's
 

1415
00:30:24,970 --> 00:30:27,270
this is so complicated and it's
complicated in part because there is

1416
00:30:27,270 --> 00:30:27,280
complicated in part because there is
 

1417
00:30:27,280 --> 00:30:29,700
complicated in part because there is
doesn't seem to be a one right answer in

1418
00:30:29,700 --> 00:30:29,710
doesn't seem to be a one right answer in
 

1419
00:30:29,710 --> 00:30:31,980
doesn't seem to be a one right answer in
any of these cases do you hope for like

1420
00:30:31,980 --> 00:30:31,990
any of these cases do you hope for like
 

1421
00:30:31,990 --> 00:30:33,930
any of these cases do you hope for like
one of the ideas of the moral machine is

1422
00:30:33,930 --> 00:30:33,940
one of the ideas of the moral machine is
 

1423
00:30:33,940 --> 00:30:37,590
one of the ideas of the moral machine is
that crowdsourcing can help us converge

1424
00:30:37,590 --> 00:30:37,600
that crowdsourcing can help us converge
 

1425
00:30:37,600 --> 00:30:39,840
that crowdsourcing can help us converge
towards like democracy can help us

1426
00:30:39,840 --> 00:30:39,850
towards like democracy can help us
 

1427
00:30:39,850 --> 00:30:42,390
towards like democracy can help us
converge towards the right answer do you

1428
00:30:42,390 --> 00:30:42,400
converge towards the right answer do you
 

1429
00:30:42,400 --> 00:30:45,390
converge towards the right answer do you
have a hope for crowdsourcing well yes

1430
00:30:45,390 --> 00:30:45,400
have a hope for crowdsourcing well yes
 

1431
00:30:45,400 --> 00:30:47,640
have a hope for crowdsourcing well yes
and no so I think that in general you

1432
00:30:47,640 --> 00:30:47,650
and no so I think that in general you
 

1433
00:30:47,650 --> 00:30:49,380
and no so I think that in general you
know I have a legal background and

1434
00:30:49,380 --> 00:30:49,390
know I have a legal background and
 

1435
00:30:49,390 --> 00:30:51,480
know I have a legal background and
policymaking is often about trying to

1436
00:30:51,480 --> 00:30:51,490
policymaking is often about trying to
 

1437
00:30:51,490 --> 00:30:53,669
policymaking is often about trying to
suss out you know what rules does this

1438
00:30:53,669 --> 00:30:53,679
suss out you know what rules does this
 

1439
00:30:53,679 --> 00:30:56,070
suss out you know what rules does this
society this particular Society agree on

1440
00:30:56,070 --> 00:30:56,080
society this particular Society agree on
 

1441
00:30:56,080 --> 00:30:57,779
society this particular Society agree on
and then trying to codify that so the

1442
00:30:57,779 --> 00:30:57,789
and then trying to codify that so the
 

1443
00:30:57,789 --> 00:31:00,029
and then trying to codify that so the
law makes these choices all the time and

1444
00:31:00,029 --> 00:31:00,039
law makes these choices all the time and
 

1445
00:31:00,039 --> 00:31:01,350
law makes these choices all the time and
then tries to adapt according to

1446
00:31:01,350 --> 00:31:01,360
then tries to adapt according to
 

1447
00:31:01,360 --> 00:31:04,560
then tries to adapt according to
changing culture but in the case of the

1448
00:31:04,560 --> 00:31:04,570
changing culture but in the case of the
 

1449
00:31:04,570 --> 00:31:06,870
changing culture but in the case of the
moral machine project I don't think that

1450
00:31:06,870 --> 00:31:06,880
moral machine project I don't think that
 

1451
00:31:06,880 --> 00:31:08,370
moral machine project I don't think that
people's choices on that website

1452
00:31:08,370 --> 00:31:08,380
people's choices on that website
 

1453
00:31:08,380 --> 00:31:11,130
people's choices on that website
necessarily necessarily reflect what

1454
00:31:11,130 --> 00:31:11,140
necessarily necessarily reflect what
 

1455
00:31:11,140 --> 00:31:14,730
necessarily necessarily reflect what
laws they would want in place if given I

1456
00:31:14,730 --> 00:31:14,740
laws they would want in place if given I
 

1457
00:31:14,740 --> 00:31:16,320
laws they would want in place if given I
think you would have to ask them a

1458
00:31:16,320 --> 00:31:16,330
think you would have to ask them a
 

1459
00:31:16,330 --> 00:31:18,120
think you would have to ask them a
series of different questions in order

1460
00:31:18,120 --> 00:31:18,130
series of different questions in order
 

1461
00:31:18,130 --> 00:31:20,580
series of different questions in order
to get up what their consensus is I

1462
00:31:20,580 --> 00:31:20,590
to get up what their consensus is I
 

1463
00:31:20,590 --> 00:31:22,799
to get up what their consensus is I
agree but that that has to do more with

1464
00:31:22,799 --> 00:31:22,809
agree but that that has to do more with
 

1465
00:31:22,809 --> 00:31:25,470
agree but that that has to do more with
the artificial nature of I mean they're

1466
00:31:25,470 --> 00:31:25,480
the artificial nature of I mean they're
 

1467
00:31:25,480 --> 00:31:27,330
the artificial nature of I mean they're
showing some cute icons on a screen

1468
00:31:27,330 --> 00:31:27,340
showing some cute icons on a screen
 

1469
00:31:27,340 --> 00:31:31,289
showing some cute icons on a screen
that's that's almost so if you for

1470
00:31:31,289 --> 00:31:31,299
that's that's almost so if you for
 

1471
00:31:31,299 --> 00:31:32,730
that's that's almost so if you for
example we do a lot of work in virtual

1472
00:31:32,730 --> 00:31:32,740
example we do a lot of work in virtual
 

1473
00:31:32,740 --> 00:31:33,390
example we do a lot of work in virtual
reality

1474
00:31:33,390 --> 00:31:33,400
reality
 

1475
00:31:33,400 --> 00:31:36,539
reality
and so if you make if you put those same

1476
00:31:36,539 --> 00:31:36,549
and so if you make if you put those same
 

1477
00:31:36,549 --> 00:31:38,220
and so if you make if you put those same
people into virtual reality where they

1478
00:31:38,220 --> 00:31:38,230
people into virtual reality where they
 

1479
00:31:38,230 --> 00:31:41,070
people into virtual reality where they
have to make that decision they should

1480
00:31:41,070 --> 00:31:41,080
have to make that decision they should
 

1481
00:31:41,080 --> 00:31:43,320
have to make that decision they should
be very different I think I agree with

1482
00:31:43,320 --> 00:31:43,330
be very different I think I agree with
 

1483
00:31:43,330 --> 00:31:45,750
be very different I think I agree with
that that's one aspect and the other

1484
00:31:45,750 --> 00:31:45,760
that that's one aspect and the other
 

1485
00:31:45,760 --> 00:31:47,700
that that's one aspect and the other
aspect is it's a different question to

1486
00:31:47,700 --> 00:31:47,710
aspect is it's a different question to
 

1487
00:31:47,710 --> 00:31:50,580
aspect is it's a different question to
ask someone would you run over the

1488
00:31:50,580 --> 00:31:50,590
ask someone would you run over the
 

1489
00:31:50,590 --> 00:31:52,350
ask someone would you run over the
homeless person or the doctor in this

1490
00:31:52,350 --> 00:31:52,360
homeless person or the doctor in this
 

1491
00:31:52,360 --> 00:31:55,950
homeless person or the doctor in this
scene or do you want cars to always run

1492
00:31:55,950 --> 00:31:55,960
scene or do you want cars to always run
 

1493
00:31:55,960 --> 00:31:59,700
scene or do you want cars to always run
over the homeless people yeah so let's

1494
00:31:59,700 --> 00:31:59,710
over the homeless people yeah so let's
 

1495
00:31:59,710 --> 00:32:02,880
over the homeless people yeah so let's
talk about anthropomorphism do me at the

1496
00:32:02,880 --> 00:32:02,890
talk about anthropomorphism do me at the
 

1497
00:32:02,890 --> 00:32:05,010
talk about anthropomorphism do me at the
prom or fizzell if I can pronounce it

1498
00:32:05,010 --> 00:32:05,020
prom or fizzell if I can pronounce it
 

1499
00:32:05,020 --> 00:32:07,470
prom or fizzell if I can pronounce it
correctly is is one of the most

1500
00:32:07,470 --> 00:32:07,480
correctly is is one of the most
 

1501
00:32:07,480 --> 00:32:09,930
correctly is is one of the most
fascinating phenomena from like both the

1502
00:32:09,930 --> 00:32:09,940
fascinating phenomena from like both the
 

1503
00:32:09,940 --> 00:32:11,070
fascinating phenomena from like both the
engineering perspective

1504
00:32:11,070 --> 00:32:11,080
engineering perspective
 

1505
00:32:11,080 --> 00:32:13,590
engineering perspective
and psychology perspective machine

1506
00:32:13,590 --> 00:32:13,600
and psychology perspective machine
 

1507
00:32:13,600 --> 00:32:15,360
and psychology perspective machine
learning perspective in robotics in

1508
00:32:15,360 --> 00:32:15,370
learning perspective in robotics in
 

1509
00:32:15,370 --> 00:32:19,230
learning perspective in robotics in
general can you step back and define at

1510
00:32:19,230 --> 00:32:19,240
general can you step back and define at
 

1511
00:32:19,240 --> 00:32:23,370
general can you step back and define at
the prom or fizzle how you see it in

1512
00:32:23,370 --> 00:32:23,380
the prom or fizzle how you see it in
 

1513
00:32:23,380 --> 00:32:25,110
the prom or fizzle how you see it in
general terms in your in your work

1514
00:32:25,110 --> 00:32:25,120
general terms in your in your work
 

1515
00:32:25,120 --> 00:32:27,899
general terms in your in your work
sure so anthropomorphism is this

1516
00:32:27,899 --> 00:32:27,909
sure so anthropomorphism is this
 

1517
00:32:27,909 --> 00:32:30,019
sure so anthropomorphism is this
tendency that we have to project

1518
00:32:30,019 --> 00:32:30,029
tendency that we have to project
 

1519
00:32:30,029 --> 00:32:33,180
tendency that we have to project
human-like traits and behaviors and

1520
00:32:33,180 --> 00:32:33,190
human-like traits and behaviors and
 

1521
00:32:33,190 --> 00:32:36,299
human-like traits and behaviors and
qualities onto nonhumans and we often

1522
00:32:36,299 --> 00:32:36,309
qualities onto nonhumans and we often
 

1523
00:32:36,309 --> 00:32:38,399
qualities onto nonhumans and we often
see it with animals like well will

1524
00:32:38,399 --> 00:32:38,409
see it with animals like well will
 

1525
00:32:38,409 --> 00:32:40,649
see it with animals like well will
project emotions on animals that may or

1526
00:32:40,649 --> 00:32:40,659
project emotions on animals that may or
 

1527
00:32:40,659 --> 00:32:42,840
project emotions on animals that may or
may not actually be there okay we often

1528
00:32:42,840 --> 00:32:42,850
may not actually be there okay we often
 

1529
00:32:42,850 --> 00:32:44,159
may not actually be there okay we often
see that we're trying to interpret

1530
00:32:44,159 --> 00:32:44,169
see that we're trying to interpret
 

1531
00:32:44,169 --> 00:32:45,990
see that we're trying to interpret
things according to our own behavior

1532
00:32:45,990 --> 00:32:46,000
things according to our own behavior
 

1533
00:32:46,000 --> 00:32:48,960
things according to our own behavior
when we get it wrong but we do it with

1534
00:32:48,960 --> 00:32:48,970
when we get it wrong but we do it with
 

1535
00:32:48,970 --> 00:32:50,340
when we get it wrong but we do it with
more than just animals we do it with

1536
00:32:50,340 --> 00:32:50,350
more than just animals we do it with
 

1537
00:32:50,350 --> 00:32:53,070
more than just animals we do it with
objects you know teddy bears we see you

1538
00:32:53,070 --> 00:32:53,080
objects you know teddy bears we see you
 

1539
00:32:53,080 --> 00:32:55,940
objects you know teddy bears we see you
know faces in the headlights of cars and

1540
00:32:55,940 --> 00:32:55,950
know faces in the headlights of cars and
 

1541
00:32:55,950 --> 00:32:58,740
know faces in the headlights of cars and
we do it with robots very very extremely

1542
00:32:58,740 --> 00:32:58,750
we do it with robots very very extremely
 

1543
00:32:58,750 --> 00:33:01,200
we do it with robots very very extremely
you think that can be engineered can

1544
00:33:01,200 --> 00:33:01,210
you think that can be engineered can
 

1545
00:33:01,210 --> 00:33:03,539
you think that can be engineered can
that be used to enrich an interaction Oh

1546
00:33:03,539 --> 00:33:03,549
that be used to enrich an interaction Oh
 

1547
00:33:03,549 --> 00:33:06,870
that be used to enrich an interaction Oh
in and they a system in the human oh

1548
00:33:06,870 --> 00:33:06,880
in and they a system in the human oh
 

1549
00:33:06,880 --> 00:33:09,299
in and they a system in the human oh
yeah for sure and do you and do you see

1550
00:33:09,299 --> 00:33:09,309
yeah for sure and do you and do you see
 

1551
00:33:09,309 --> 00:33:12,740
yeah for sure and do you and do you see
it being used that way often like I

1552
00:33:12,740 --> 00:33:12,750
it being used that way often like I
 

1553
00:33:12,750 --> 00:33:18,149
it being used that way often like I
don't I haven't seen whether it's Alexa

1554
00:33:18,149 --> 00:33:18,159
don't I haven't seen whether it's Alexa
 

1555
00:33:18,159 --> 00:33:20,120
don't I haven't seen whether it's Alexa
or any of the smart speaker systems

1556
00:33:20,120 --> 00:33:20,130
or any of the smart speaker systems
 

1557
00:33:20,130 --> 00:33:24,509
or any of the smart speaker systems
often trying to optimize for the ethical

1558
00:33:24,509 --> 00:33:24,519
often trying to optimize for the ethical
 

1559
00:33:24,519 --> 00:33:27,930
often trying to optimize for the ethical
or physician you said you haven't seen I

1560
00:33:27,930 --> 00:33:27,940
or physician you said you haven't seen I
 

1561
00:33:27,940 --> 00:33:29,850
or physician you said you haven't seen I
haven't seen they they keep moving away

1562
00:33:29,850 --> 00:33:29,860
haven't seen they they keep moving away
 

1563
00:33:29,860 --> 00:33:31,649
haven't seen they they keep moving away
from that I think they're afraid of that

1564
00:33:31,649 --> 00:33:31,659
from that I think they're afraid of that
 

1565
00:33:31,659 --> 00:33:35,250
from that I think they're afraid of that
they they actually so I only recently

1566
00:33:35,250 --> 00:33:35,260
they they actually so I only recently
 

1567
00:33:35,260 --> 00:33:36,659
they they actually so I only recently
found out but did you know that Amazon

1568
00:33:36,659 --> 00:33:36,669
found out but did you know that Amazon
 

1569
00:33:36,669 --> 00:33:39,299
found out but did you know that Amazon
has like a whole team of people who are

1570
00:33:39,299 --> 00:33:39,309
has like a whole team of people who are
 

1571
00:33:39,309 --> 00:33:43,730
has like a whole team of people who are
just there to work on Alexis personality

1572
00:33:43,730 --> 00:33:43,740
just there to work on Alexis personality
 

1573
00:33:43,740 --> 00:33:48,120
just there to work on Alexis personality
so I know that depends on UI personality

1574
00:33:48,120 --> 00:33:48,130
so I know that depends on UI personality
 

1575
00:33:48,130 --> 00:33:49,919
so I know that depends on UI personality
I didn't know I didn't know that exact

1576
00:33:49,919 --> 00:33:49,929
I didn't know I didn't know that exact
 

1577
00:33:49,929 --> 00:33:54,210
I didn't know I didn't know that exact
thing but I do know that the how the

1578
00:33:54,210 --> 00:33:54,220
thing but I do know that the how the
 

1579
00:33:54,220 --> 00:33:57,570
thing but I do know that the how the
voice is perceived has worked on a lot

1580
00:33:57,570 --> 00:33:57,580
voice is perceived has worked on a lot
 

1581
00:33:57,580 --> 00:34:00,289
voice is perceived has worked on a lot
whether that if it's a pleasant feeling

1582
00:34:00,289 --> 00:34:00,299
whether that if it's a pleasant feeling
 

1583
00:34:00,299 --> 00:34:02,639
whether that if it's a pleasant feeling
about the voice but that has to do more

1584
00:34:02,639 --> 00:34:02,649
about the voice but that has to do more
 

1585
00:34:02,649 --> 00:34:04,139
about the voice but that has to do more
with the texture of the sound and the

1586
00:34:04,139 --> 00:34:04,149
with the texture of the sound and the
 

1587
00:34:04,149 --> 00:34:07,049
with the texture of the sound and the
audience on what personality is more

1588
00:34:07,049 --> 00:34:07,059
audience on what personality is more
 

1589
00:34:07,059 --> 00:34:10,020
audience on what personality is more
like it's like what's her favorite beer

1590
00:34:10,020 --> 00:34:10,030
like it's like what's her favorite beer
 

1591
00:34:10,030 --> 00:34:12,270
like it's like what's her favorite beer
when you ask her and and the personality

1592
00:34:12,270 --> 00:34:12,280
when you ask her and and the personality
 

1593
00:34:12,280 --> 00:34:14,339
when you ask her and and the personality
team is different for every country to

1594
00:34:14,339 --> 00:34:14,349
team is different for every country to
 

1595
00:34:14,349 --> 00:34:16,169
team is different for every country to
like there's a different personality for

1596
00:34:16,169 --> 00:34:16,179
like there's a different personality for
 

1597
00:34:16,179 --> 00:34:17,820
like there's a different personality for
a German Alexa than there is for

1598
00:34:17,820 --> 00:34:17,830
a German Alexa than there is for
 

1599
00:34:17,830 --> 00:34:20,909
a German Alexa than there is for
American Alexa that's it I think it's

1600
00:34:20,909 --> 00:34:20,919
American Alexa that's it I think it's
 

1601
00:34:20,919 --> 00:34:23,590
American Alexa that's it I think it's
very difficult to

1602
00:34:23,590 --> 00:34:23,600
very difficult to
 

1603
00:34:23,600 --> 00:34:27,330
very difficult to
you know use the are really really

1604
00:34:27,330 --> 00:34:27,340
you know use the are really really
 

1605
00:34:27,340 --> 00:34:30,010
you know use the are really really
harness the anthropomorphism with these

1606
00:34:30,010 --> 00:34:30,020
harness the anthropomorphism with these
 

1607
00:34:30,020 --> 00:34:33,310
harness the anthropomorphism with these
voice assistance because the voice

1608
00:34:33,310 --> 00:34:33,320
voice assistance because the voice
 

1609
00:34:33,320 --> 00:34:36,460
voice assistance because the voice
interface is still very primitive and I

1610
00:34:36,460 --> 00:34:36,470
interface is still very primitive and I
 

1611
00:34:36,470 --> 00:34:38,590
interface is still very primitive and I
think that in order to get people to

1612
00:34:38,590 --> 00:34:38,600
think that in order to get people to
 

1613
00:34:38,600 --> 00:34:41,140
think that in order to get people to
really suspend their disbelief and treat

1614
00:34:41,140 --> 00:34:41,150
really suspend their disbelief and treat
 

1615
00:34:41,150 --> 00:34:43,170
really suspend their disbelief and treat
a robot like it's alive

1616
00:34:43,170 --> 00:34:43,180
a robot like it's alive
 

1617
00:34:43,180 --> 00:34:46,390
a robot like it's alive
less is sometimes more you you want them

1618
00:34:46,390 --> 00:34:46,400
less is sometimes more you you want them
 

1619
00:34:46,400 --> 00:34:48,700
less is sometimes more you you want them
to project onto the robot and you want

1620
00:34:48,700 --> 00:34:48,710
to project onto the robot and you want
 

1621
00:34:48,710 --> 00:34:49,990
to project onto the robot and you want
the robot to not disappoint their

1622
00:34:49,990 --> 00:34:50,000
the robot to not disappoint their
 

1623
00:34:50,000 --> 00:34:51,490
the robot to not disappoint their
expectations for how it's going to

1624
00:34:51,490 --> 00:34:51,500
expectations for how it's going to
 

1625
00:34:51,500 --> 00:34:54,310
expectations for how it's going to
answer or behave in order for them to

1626
00:34:54,310 --> 00:34:54,320
answer or behave in order for them to
 

1627
00:34:54,320 --> 00:34:57,610
answer or behave in order for them to
have this kind of illusion and with

1628
00:34:57,610 --> 00:34:57,620
have this kind of illusion and with
 

1629
00:34:57,620 --> 00:34:59,470
have this kind of illusion and with
Alexa I don't think we're there yet or

1630
00:34:59,470 --> 00:34:59,480
Alexa I don't think we're there yet or
 

1631
00:34:59,480 --> 00:35:02,620
Alexa I don't think we're there yet or
Siri that just they're just not good at

1632
00:35:02,620 --> 00:35:02,630
Siri that just they're just not good at
 

1633
00:35:02,630 --> 00:35:05,010
Siri that just they're just not good at
that but if you look at some of the more

1634
00:35:05,010 --> 00:35:05,020
that but if you look at some of the more
 

1635
00:35:05,020 --> 00:35:07,870
that but if you look at some of the more
animal-like robots like the baby seal

1636
00:35:07,870 --> 00:35:07,880
animal-like robots like the baby seal
 

1637
00:35:07,880 --> 00:35:09,820
animal-like robots like the baby seal
that they use with the dementia patients

1638
00:35:09,820 --> 00:35:09,830
that they use with the dementia patients
 

1639
00:35:09,830 --> 00:35:12,070
that they use with the dementia patients
so much more simple design doesn't try

1640
00:35:12,070 --> 00:35:12,080
so much more simple design doesn't try
 

1641
00:35:12,080 --> 00:35:13,900
so much more simple design doesn't try
to talk to you you can't disappoint you

1642
00:35:13,900 --> 00:35:13,910
to talk to you you can't disappoint you
 

1643
00:35:13,910 --> 00:35:15,220
to talk to you you can't disappoint you
in that way it just makes little

1644
00:35:15,220 --> 00:35:15,230
in that way it just makes little
 

1645
00:35:15,230 --> 00:35:18,190
in that way it just makes little
movements and sounds and people stroke

1646
00:35:18,190 --> 00:35:18,200
movements and sounds and people stroke
 

1647
00:35:18,200 --> 00:35:20,020
movements and sounds and people stroke
it and it responds to their touch and

1648
00:35:20,020 --> 00:35:20,030
it and it responds to their touch and
 

1649
00:35:20,030 --> 00:35:22,300
it and it responds to their touch and
that is like a very effective way to

1650
00:35:22,300 --> 00:35:22,310
that is like a very effective way to
 

1651
00:35:22,310 --> 00:35:26,140
that is like a very effective way to
harness people tendency to kind of treat

1652
00:35:26,140 --> 00:35:26,150
harness people tendency to kind of treat
 

1653
00:35:26,150 --> 00:35:30,000
harness people tendency to kind of treat
the robot like a living thing yeah so

1654
00:35:30,000 --> 00:35:30,010
the robot like a living thing yeah so
 

1655
00:35:30,010 --> 00:35:32,440
the robot like a living thing yeah so
you bring up some interesting ideas in

1656
00:35:32,440 --> 00:35:32,450
you bring up some interesting ideas in
 

1657
00:35:32,450 --> 00:35:36,130
you bring up some interesting ideas in
your paper chapter I guess at the poem

1658
00:35:36,130 --> 00:35:36,140
your paper chapter I guess at the poem
 

1659
00:35:36,140 --> 00:35:37,560
your paper chapter I guess at the poem
Orphic framing human robot interaction

1660
00:35:37,560 --> 00:35:37,570
Orphic framing human robot interaction
 

1661
00:35:37,570 --> 00:35:40,330
Orphic framing human robot interaction
that I read the last time we scheduled

1662
00:35:40,330 --> 00:35:40,340
that I read the last time we scheduled
 

1663
00:35:40,340 --> 00:35:45,580
that I read the last time we scheduled
this a long time what are some good and

1664
00:35:45,580 --> 00:35:45,590
this a long time what are some good and
 

1665
00:35:45,590 --> 00:35:47,500
this a long time what are some good and
bad cases event them for morphism and in

1666
00:35:47,500 --> 00:35:47,510
bad cases event them for morphism and in
 

1667
00:35:47,510 --> 00:35:51,220
bad cases event them for morphism and in
your perspective like one is the good

1668
00:35:51,220 --> 00:35:51,230
your perspective like one is the good
 

1669
00:35:51,230 --> 00:35:53,620
your perspective like one is the good
one is it bad well I just start by

1670
00:35:53,620 --> 00:35:53,630
one is it bad well I just start by
 

1671
00:35:53,630 --> 00:35:55,660
one is it bad well I just start by
saying that you know while design can

1672
00:35:55,660 --> 00:35:55,670
saying that you know while design can
 

1673
00:35:55,670 --> 00:35:57,280
saying that you know while design can
really enhance the end the premiere film

1674
00:35:57,280 --> 00:35:57,290
really enhance the end the premiere film
 

1675
00:35:57,290 --> 00:35:59,920
really enhance the end the premiere film
it doesn't take a lot to get people to

1676
00:35:59,920 --> 00:35:59,930
it doesn't take a lot to get people to
 

1677
00:35:59,930 --> 00:36:01,420
it doesn't take a lot to get people to
treat a robot like it's alive like

1678
00:36:01,420 --> 00:36:01,430
treat a robot like it's alive like
 

1679
00:36:01,430 --> 00:36:04,210
treat a robot like it's alive like
people will over 85% of rumbas have a

1680
00:36:04,210 --> 00:36:04,220
people will over 85% of rumbas have a
 

1681
00:36:04,220 --> 00:36:07,180
people will over 85% of rumbas have a
name which I'm I don't know the numbers

1682
00:36:07,180 --> 00:36:07,190
name which I'm I don't know the numbers
 

1683
00:36:07,190 --> 00:36:08,890
name which I'm I don't know the numbers
for your regular type of vacuum cleaner

1684
00:36:08,890 --> 00:36:08,900
for your regular type of vacuum cleaner
 

1685
00:36:08,900 --> 00:36:11,020
for your regular type of vacuum cleaner
but they're not that high right so

1686
00:36:11,020 --> 00:36:11,030
but they're not that high right so
 

1687
00:36:11,030 --> 00:36:12,460
but they're not that high right so
people will feel bad for the room but

1688
00:36:12,460 --> 00:36:12,470
people will feel bad for the room but
 

1689
00:36:12,470 --> 00:36:14,080
people will feel bad for the room but
when it gets stuck they'll send it in

1690
00:36:14,080 --> 00:36:14,090
when it gets stuck they'll send it in
 

1691
00:36:14,090 --> 00:36:15,460
when it gets stuck they'll send it in
for repair and want to get the same one

1692
00:36:15,460 --> 00:36:15,470
for repair and want to get the same one
 

1693
00:36:15,470 --> 00:36:17,290
for repair and want to get the same one
back and that's that one is not even

1694
00:36:17,290 --> 00:36:17,300
back and that's that one is not even
 

1695
00:36:17,300 --> 00:36:21,130
back and that's that one is not even
designed to like make you do that so I

1696
00:36:21,130 --> 00:36:21,140
designed to like make you do that so I
 

1697
00:36:21,140 --> 00:36:24,130
designed to like make you do that so I
think that some of the cases where it's

1698
00:36:24,130 --> 00:36:24,140
think that some of the cases where it's
 

1699
00:36:24,140 --> 00:36:25,840
think that some of the cases where it's
maybe a little bit concerning that

1700
00:36:25,840 --> 00:36:25,850
maybe a little bit concerning that
 

1701
00:36:25,850 --> 00:36:27,730
maybe a little bit concerning that
anthropomorphism is happening is when

1702
00:36:27,730 --> 00:36:27,740
anthropomorphism is happening is when
 

1703
00:36:27,740 --> 00:36:29,470
anthropomorphism is happening is when
you have something that's supposed to

1704
00:36:29,470 --> 00:36:29,480
you have something that's supposed to
 

1705
00:36:29,480 --> 00:36:30,910
you have something that's supposed to
function like a tool and people are

1706
00:36:30,910 --> 00:36:30,920
function like a tool and people are
 

1707
00:36:30,920 --> 00:36:32,510
function like a tool and people are
using it in the wrong way

1708
00:36:32,510 --> 00:36:32,520
using it in the wrong way
 

1709
00:36:32,520 --> 00:36:34,790
using it in the wrong way
and one of the concerns is military

1710
00:36:34,790 --> 00:36:34,800
and one of the concerns is military
 

1711
00:36:34,800 --> 00:36:43,760
and one of the concerns is military
robots we're so gosh mm like early 2000s

1712
00:36:43,760 --> 00:36:43,770
robots we're so gosh mm like early 2000s
 

1713
00:36:43,770 --> 00:36:45,530
robots we're so gosh mm like early 2000s
which is a long time ago

1714
00:36:45,530 --> 00:36:45,540
which is a long time ago
 

1715
00:36:45,540 --> 00:36:48,500
which is a long time ago
iRobot the room a company made this

1716
00:36:48,500 --> 00:36:48,510
iRobot the room a company made this
 

1717
00:36:48,510 --> 00:36:50,000
iRobot the room a company made this
robot called the pack bot that was

1718
00:36:50,000 --> 00:36:50,010
robot called the pack bot that was
 

1719
00:36:50,010 --> 00:36:53,240
robot called the pack bot that was
deployed in Iraq and and Afghanistan

1720
00:36:53,240 --> 00:36:53,250
deployed in Iraq and and Afghanistan
 

1721
00:36:53,250 --> 00:36:55,670
deployed in Iraq and and Afghanistan
with the bomb disposal units that were

1722
00:36:55,670 --> 00:36:55,680
with the bomb disposal units that were
 

1723
00:36:55,680 --> 00:36:58,790
with the bomb disposal units that were
there and the soldiers became very

1724
00:36:58,790 --> 00:36:58,800
there and the soldiers became very
 

1725
00:36:58,800 --> 00:37:01,580
there and the soldiers became very
emotionally attached to the robots and

1726
00:37:01,580 --> 00:37:01,590
emotionally attached to the robots and
 

1727
00:37:01,590 --> 00:37:05,660
emotionally attached to the robots and
that's you know fine until a soldier

1728
00:37:05,660 --> 00:37:05,670
that's you know fine until a soldier
 

1729
00:37:05,670 --> 00:37:09,080
that's you know fine until a soldier
risks his life to save a robot which you

1730
00:37:09,080 --> 00:37:09,090
risks his life to save a robot which you
 

1731
00:37:09,090 --> 00:37:10,550
risks his life to save a robot which you
really don't want but they were treating

1732
00:37:10,550 --> 00:37:10,560
really don't want but they were treating
 

1733
00:37:10,560 --> 00:37:12,590
really don't want but they were treating
them like pets like they would name them

1734
00:37:12,590 --> 00:37:12,600
them like pets like they would name them
 

1735
00:37:12,600 --> 00:37:14,330
them like pets like they would name them
they would give them funerals with gun

1736
00:37:14,330 --> 00:37:14,340
they would give them funerals with gun
 

1737
00:37:14,340 --> 00:37:16,700
they would give them funerals with gun
salutes they would get really upset and

1738
00:37:16,700 --> 00:37:16,710
salutes they would get really upset and
 

1739
00:37:16,710 --> 00:37:18,710
salutes they would get really upset and
traumatized when the robot got broken so

1740
00:37:18,710 --> 00:37:18,720
traumatized when the robot got broken so
 

1741
00:37:18,720 --> 00:37:22,160
traumatized when the robot got broken so
you in situations where you want a robot

1742
00:37:22,160 --> 00:37:22,170
you in situations where you want a robot
 

1743
00:37:22,170 --> 00:37:24,230
you in situations where you want a robot
to be a tool in particular when it's

1744
00:37:24,230 --> 00:37:24,240
to be a tool in particular when it's
 

1745
00:37:24,240 --> 00:37:25,880
to be a tool in particular when it's
supposed to like do a dangerous job that

1746
00:37:25,880 --> 00:37:25,890
supposed to like do a dangerous job that
 

1747
00:37:25,890 --> 00:37:28,400
supposed to like do a dangerous job that
you don't want a person doing it it can

1748
00:37:28,400 --> 00:37:28,410
you don't want a person doing it it can
 

1749
00:37:28,410 --> 00:37:31,070
you don't want a person doing it it can
be hard when people get emotionally

1750
00:37:31,070 --> 00:37:31,080
be hard when people get emotionally
 

1751
00:37:31,080 --> 00:37:32,060
be hard when people get emotionally
attached to it

1752
00:37:32,060 --> 00:37:32,070
attached to it
 

1753
00:37:32,070 --> 00:37:33,860
attached to it
that's maybe something that you would

1754
00:37:33,860 --> 00:37:33,870
that's maybe something that you would
 

1755
00:37:33,870 --> 00:37:36,470
that's maybe something that you would
want to discourage another case for

1756
00:37:36,470 --> 00:37:36,480
want to discourage another case for
 

1757
00:37:36,480 --> 00:37:39,880
want to discourage another case for
concern is maybe when companies try to

1758
00:37:39,880 --> 00:37:39,890
concern is maybe when companies try to
 

1759
00:37:39,890 --> 00:37:42,020
concern is maybe when companies try to
leverage the emotional attachment to

1760
00:37:42,020 --> 00:37:42,030
leverage the emotional attachment to
 

1761
00:37:42,030 --> 00:37:45,380
leverage the emotional attachment to
exploit people so if it's something

1762
00:37:45,380 --> 00:37:45,390
exploit people so if it's something
 

1763
00:37:45,390 --> 00:37:47,210
exploit people so if it's something
that's not in the consumers interest

1764
00:37:47,210 --> 00:37:47,220
that's not in the consumers interest
 

1765
00:37:47,220 --> 00:37:49,910
that's not in the consumers interest
trying to like sell them products or

1766
00:37:49,910 --> 00:37:49,920
trying to like sell them products or
 

1767
00:37:49,920 --> 00:37:51,740
trying to like sell them products or
services or exploit an emotional

1768
00:37:51,740 --> 00:37:51,750
services or exploit an emotional
 

1769
00:37:51,750 --> 00:37:53,300
services or exploit an emotional
connection to keep them you know paying

1770
00:37:53,300 --> 00:37:53,310
connection to keep them you know paying
 

1771
00:37:53,310 --> 00:37:55,400
connection to keep them you know paying
for a cloud service for a social robot

1772
00:37:55,400 --> 00:37:55,410
for a cloud service for a social robot
 

1773
00:37:55,410 --> 00:37:57,890
for a cloud service for a social robot
or something like that might be I I

1774
00:37:57,890 --> 00:37:57,900
or something like that might be I I
 

1775
00:37:57,900 --> 00:37:59,600
or something like that might be I I
think that's a little bit concerning as

1776
00:37:59,600 --> 00:37:59,610
think that's a little bit concerning as
 

1777
00:37:59,610 --> 00:38:01,700
think that's a little bit concerning as
well yeah the emotional manipulation

1778
00:38:01,700 --> 00:38:01,710
well yeah the emotional manipulation
 

1779
00:38:01,710 --> 00:38:03,530
well yeah the emotional manipulation
which probably happens behind the scenes

1780
00:38:03,530 --> 00:38:03,540
which probably happens behind the scenes
 

1781
00:38:03,540 --> 00:38:06,020
which probably happens behind the scenes
now with some like social networks and

1782
00:38:06,020 --> 00:38:06,030
now with some like social networks and
 

1783
00:38:06,030 --> 00:38:10,280
now with some like social networks and
so on but making it more explicit what's

1784
00:38:10,280 --> 00:38:10,290
so on but making it more explicit what's
 

1785
00:38:10,290 --> 00:38:13,610
so on but making it more explicit what's
your favorite robot like you know a real

1786
00:38:13,610 --> 00:38:13,620
your favorite robot like you know a real
 

1787
00:38:13,620 --> 00:38:18,290
your favorite robot like you know a real
no real real robot which you have felt a

1788
00:38:18,290 --> 00:38:18,300
no real real robot which you have felt a
 

1789
00:38:18,300 --> 00:38:22,400
no real real robot which you have felt a
connection with or not like not not at

1790
00:38:22,400 --> 00:38:22,410
connection with or not like not not at
 

1791
00:38:22,410 --> 00:38:24,380
connection with or not like not not at
the core morphic connection but I mean

1792
00:38:24,380 --> 00:38:24,390
the core morphic connection but I mean
 

1793
00:38:24,390 --> 00:38:28,610
the core morphic connection but I mean
like you just sit back as a damn this is

1794
00:38:28,610 --> 00:38:28,620
like you just sit back as a damn this is
 

1795
00:38:28,620 --> 00:38:32,690
like you just sit back as a damn this is
an impressive system Wow

1796
00:38:32,690 --> 00:38:32,700
an impressive system Wow
 

1797
00:38:32,700 --> 00:38:36,140
an impressive system Wow
so two different robots so the the plio

1798
00:38:36,140 --> 00:38:36,150
so two different robots so the the plio
 

1799
00:38:36,150 --> 00:38:38,510
so two different robots so the the plio
baby dinosaur robot that is no longer

1800
00:38:38,510 --> 00:38:38,520
baby dinosaur robot that is no longer
 

1801
00:38:38,520 --> 00:38:41,960
baby dinosaur robot that is no longer
sold that came out in 2007 that one I

1802
00:38:41,960 --> 00:38:41,970
sold that came out in 2007 that one I
 

1803
00:38:41,970 --> 00:38:44,390
sold that came out in 2007 that one I
was very impressed with it was but but

1804
00:38:44,390 --> 00:38:44,400
was very impressed with it was but but
 

1805
00:38:44,400 --> 00:38:46,250
was very impressed with it was but but
from an anthropomorphic perspective

1806
00:38:46,250 --> 00:38:46,260
from an anthropomorphic perspective
 

1807
00:38:46,260 --> 00:38:47,840
from an anthropomorphic perspective
I was impressed with how much I bonded

1808
00:38:47,840 --> 00:38:47,850
I was impressed with how much I bonded
 

1809
00:38:47,850 --> 00:38:49,820
I was impressed with how much I bonded
with it how much I like wanted to

1810
00:38:49,820 --> 00:38:49,830
with it how much I like wanted to
 

1811
00:38:49,830 --> 00:38:51,860
with it how much I like wanted to
believe that it had this inner life

1812
00:38:51,860 --> 00:38:51,870
believe that it had this inner life
 

1813
00:38:51,870 --> 00:38:53,960
believe that it had this inner life
can you describe Cleo the can you

1814
00:38:53,960 --> 00:38:53,970
can you describe Cleo the can you
 

1815
00:38:53,970 --> 00:38:55,940
can you describe Cleo the can you
describe what what it is how big is it

1816
00:38:55,940 --> 00:38:55,950
describe what what it is how big is it
 

1817
00:38:55,950 --> 00:39:00,470
describe what what it is how big is it
what can actually do ya plio is about

1818
00:39:00,470 --> 00:39:00,480
what can actually do ya plio is about
 

1819
00:39:00,480 --> 00:39:04,610
what can actually do ya plio is about
the size of a small cat it had a lot of

1820
00:39:04,610 --> 00:39:04,620
the size of a small cat it had a lot of
 

1821
00:39:04,620 --> 00:39:06,620
the size of a small cat it had a lot of
like motors that gave it this kind of

1822
00:39:06,620 --> 00:39:06,630
like motors that gave it this kind of
 

1823
00:39:06,630 --> 00:39:09,380
like motors that gave it this kind of
lifelike movement it had things like

1824
00:39:09,380 --> 00:39:09,390
lifelike movement it had things like
 

1825
00:39:09,390 --> 00:39:11,270
lifelike movement it had things like
touch sensors and an infrared camera so

1826
00:39:11,270 --> 00:39:11,280
touch sensors and an infrared camera so
 

1827
00:39:11,280 --> 00:39:12,470
touch sensors and an infrared camera so
it had all these like cool little

1828
00:39:12,470 --> 00:39:12,480
it had all these like cool little
 

1829
00:39:12,480 --> 00:39:14,360
it had all these like cool little
technical features even though it was a

1830
00:39:14,360 --> 00:39:14,370
technical features even though it was a
 

1831
00:39:14,370 --> 00:39:19,250
technical features even though it was a
toy and the thing that really struck me

1832
00:39:19,250 --> 00:39:19,260
toy and the thing that really struck me
 

1833
00:39:19,260 --> 00:39:21,290
toy and the thing that really struck me
about it was that it could mimic pain

1834
00:39:21,290 --> 00:39:21,300
about it was that it could mimic pain
 

1835
00:39:21,300 --> 00:39:24,260
about it was that it could mimic pain
and distress really well so if you held

1836
00:39:24,260 --> 00:39:24,270
and distress really well so if you held
 

1837
00:39:24,270 --> 00:39:26,090
and distress really well so if you held
it up by the tail it had a tilt sensor

1838
00:39:26,090 --> 00:39:26,100
it up by the tail it had a tilt sensor
 

1839
00:39:26,100 --> 00:39:27,860
it up by the tail it had a tilt sensor
that you know told it what direction it

1840
00:39:27,860 --> 00:39:27,870
that you know told it what direction it
 

1841
00:39:27,870 --> 00:39:29,390
that you know told it what direction it
was facing and it would start to squirm

1842
00:39:29,390 --> 00:39:29,400
was facing and it would start to squirm
 

1843
00:39:29,400 --> 00:39:33,020
was facing and it would start to squirm
and cry out if you hit it too hard it

1844
00:39:33,020 --> 00:39:33,030
and cry out if you hit it too hard it
 

1845
00:39:33,030 --> 00:39:35,630
and cry out if you hit it too hard it
would start to cry so it was very

1846
00:39:35,630 --> 00:39:35,640
would start to cry so it was very
 

1847
00:39:35,640 --> 00:39:38,990
would start to cry so it was very
impressive in design and what's the

1848
00:39:38,990 --> 00:39:39,000
impressive in design and what's the
 

1849
00:39:39,000 --> 00:39:41,330
impressive in design and what's the
second robot that you were you said

1850
00:39:41,330 --> 00:39:41,340
second robot that you were you said
 

1851
00:39:41,340 --> 00:39:43,040
second robot that you were you said
there might have been two that you liked

1852
00:39:43,040 --> 00:39:43,050
there might have been two that you liked
 

1853
00:39:43,050 --> 00:39:46,880
there might have been two that you liked
yeah so the Boston Dynamics robots are

1854
00:39:46,880 --> 00:39:46,890
yeah so the Boston Dynamics robots are
 

1855
00:39:46,890 --> 00:39:49,280
yeah so the Boston Dynamics robots are
just impressive feats of engineering

1856
00:39:49,280 --> 00:39:49,290
just impressive feats of engineering
 

1857
00:39:49,290 --> 00:39:51,170
just impressive feats of engineering
have you met them in person

1858
00:39:51,170 --> 00:39:51,180
have you met them in person
 

1859
00:39:51,180 --> 00:39:53,030
have you met them in person
yeah I recently got a chance to go visit

1860
00:39:53,030 --> 00:39:53,040
yeah I recently got a chance to go visit
 

1861
00:39:53,040 --> 00:39:55,070
yeah I recently got a chance to go visit
and I you know I was always one of those

1862
00:39:55,070 --> 00:39:55,080
and I you know I was always one of those
 

1863
00:39:55,080 --> 00:39:56,420
and I you know I was always one of those
people who watched the videos and was

1864
00:39:56,420 --> 00:39:56,430
people who watched the videos and was
 

1865
00:39:56,430 --> 00:39:58,850
people who watched the videos and was
like this is super cool but also it's a

1866
00:39:58,850 --> 00:39:58,860
like this is super cool but also it's a
 

1867
00:39:58,860 --> 00:40:00,740
like this is super cool but also it's a
product video like I don't know how many

1868
00:40:00,740 --> 00:40:00,750
product video like I don't know how many
 

1869
00:40:00,750 --> 00:40:02,570
product video like I don't know how many
times that they had to shoot this to get

1870
00:40:02,570 --> 00:40:02,580
times that they had to shoot this to get
 

1871
00:40:02,580 --> 00:40:05,660
times that they had to shoot this to get
it right but visiting them I you know

1872
00:40:05,660 --> 00:40:05,670
it right but visiting them I you know
 

1873
00:40:05,670 --> 00:40:08,240
it right but visiting them I you know
I'm pretty sure that I was very

1874
00:40:08,240 --> 00:40:08,250
I'm pretty sure that I was very
 

1875
00:40:08,250 --> 00:40:10,520
I'm pretty sure that I was very
impressed let's put it that way yeah in

1876
00:40:10,520 --> 00:40:10,530
impressed let's put it that way yeah in
 

1877
00:40:10,530 --> 00:40:12,970
impressed let's put it that way yeah in
terms of the control I think that was a

1878
00:40:12,970 --> 00:40:12,980
terms of the control I think that was a
 

1879
00:40:12,980 --> 00:40:15,950
terms of the control I think that was a
transformational moment for me when I

1880
00:40:15,950 --> 00:40:15,960
transformational moment for me when I
 

1881
00:40:15,960 --> 00:40:21,710
transformational moment for me when I
met spot many in person because okay

1882
00:40:21,710 --> 00:40:21,720
met spot many in person because okay
 

1883
00:40:21,720 --> 00:40:23,390
met spot many in person because okay
maybe this is a psychology experiment

1884
00:40:23,390 --> 00:40:23,400
maybe this is a psychology experiment
 

1885
00:40:23,400 --> 00:40:25,490
maybe this is a psychology experiment
but I anthropomorphised

1886
00:40:25,490 --> 00:40:25,500
but I anthropomorphised
 

1887
00:40:25,500 --> 00:40:28,910
but I anthropomorphised
the crap out of it so I immediately it

1888
00:40:28,910 --> 00:40:28,920
the crap out of it so I immediately it
 

1889
00:40:28,920 --> 00:40:31,850
the crap out of it so I immediately it
was like my best friend right I mean

1890
00:40:31,850 --> 00:40:31,860
was like my best friend right I mean
 

1891
00:40:31,860 --> 00:40:33,230
was like my best friend right I mean
it's really hard for anyone to watch

1892
00:40:33,230 --> 00:40:33,240
it's really hard for anyone to watch
 

1893
00:40:33,240 --> 00:40:34,970
it's really hard for anyone to watch
spot move and not feel like it has

1894
00:40:34,970 --> 00:40:34,980
spot move and not feel like it has
 

1895
00:40:34,980 --> 00:40:37,310
spot move and not feel like it has
agency yeah did this movement especially

1896
00:40:37,310 --> 00:40:37,320
agency yeah did this movement especially
 

1897
00:40:37,320 --> 00:40:42,020
agency yeah did this movement especially
the arm on spot mini really obvi

1898
00:40:42,020 --> 00:40:42,030
the arm on spot mini really obvi
 

1899
00:40:42,030 --> 00:40:44,690
the arm on spot mini really obvi
obviously looks like a head yeah that

1900
00:40:44,690 --> 00:40:44,700
obviously looks like a head yeah that
 

1901
00:40:44,700 --> 00:40:47,300
obviously looks like a head yeah that
and they say no wouldn't mean it that

1902
00:40:47,300 --> 00:40:47,310
and they say no wouldn't mean it that
 

1903
00:40:47,310 --> 00:40:50,330
and they say no wouldn't mean it that
way but it obviously it looks exactly

1904
00:40:50,330 --> 00:40:50,340
way but it obviously it looks exactly
 

1905
00:40:50,340 --> 00:40:52,700
way but it obviously it looks exactly
like that and so it's almost impossible

1906
00:40:52,700 --> 00:40:52,710
like that and so it's almost impossible
 

1907
00:40:52,710 --> 00:40:56,210
like that and so it's almost impossible
to not think of it as a almost like the

1908
00:40:56,210 --> 00:40:56,220
to not think of it as a almost like the
 

1909
00:40:56,220 --> 00:40:59,010
to not think of it as a almost like the
baby dinosaur but slightly larger

1910
00:40:59,010 --> 00:40:59,020
baby dinosaur but slightly larger
 

1911
00:40:59,020 --> 00:41:01,080
baby dinosaur but slightly larger
and in this movement of the of course

1912
00:41:01,080 --> 00:41:01,090
and in this movement of the of course
 

1913
00:41:01,090 --> 00:41:02,910
and in this movement of the of course
the intelligence is that their whole

1914
00:41:02,910 --> 00:41:02,920
the intelligence is that their whole
 

1915
00:41:02,920 --> 00:41:05,160
the intelligence is that their whole
idea is that it's not supposed to be

1916
00:41:05,160 --> 00:41:05,170
idea is that it's not supposed to be
 

1917
00:41:05,170 --> 00:41:07,530
idea is that it's not supposed to be
intelligent it's a platform on which you

1918
00:41:07,530 --> 00:41:07,540
intelligent it's a platform on which you
 

1919
00:41:07,540 --> 00:41:09,840
intelligent it's a platform on which you
build higher intelligence it's actually

1920
00:41:09,840 --> 00:41:09,850
build higher intelligence it's actually
 

1921
00:41:09,850 --> 00:41:12,150
build higher intelligence it's actually
really really dumb it's just a basic

1922
00:41:12,150 --> 00:41:12,160
really really dumb it's just a basic
 

1923
00:41:12,160 --> 00:41:14,490
really really dumb it's just a basic
movement platform yeah but even dumb

1924
00:41:14,490 --> 00:41:14,500
movement platform yeah but even dumb
 

1925
00:41:14,500 --> 00:41:17,430
movement platform yeah but even dumb
robots can like we can immediately

1926
00:41:17,430 --> 00:41:17,440
robots can like we can immediately
 

1927
00:41:17,440 --> 00:41:19,290
robots can like we can immediately
respond to them in this visceral way

1928
00:41:19,290 --> 00:41:19,300
respond to them in this visceral way
 

1929
00:41:19,300 --> 00:41:22,350
respond to them in this visceral way
what are your thoughts about Sofia the

1930
00:41:22,350 --> 00:41:22,360
what are your thoughts about Sofia the
 

1931
00:41:22,360 --> 00:41:25,890
what are your thoughts about Sofia the
robot this kind of mix of some basic

1932
00:41:25,890 --> 00:41:25,900
robot this kind of mix of some basic
 

1933
00:41:25,900 --> 00:41:28,609
robot this kind of mix of some basic
natural language processing and

1934
00:41:28,609 --> 00:41:28,619
natural language processing and
 

1935
00:41:28,619 --> 00:41:32,400
natural language processing and
basically an art experiment yeah an art

1936
00:41:32,400 --> 00:41:32,410
basically an art experiment yeah an art
 

1937
00:41:32,410 --> 00:41:34,320
basically an art experiment yeah an art
experiment is a good way to characterize

1938
00:41:34,320 --> 00:41:34,330
experiment is a good way to characterize
 

1939
00:41:34,330 --> 00:41:36,480
experiment is a good way to characterize
it I'm much less impressed with Sofia

1940
00:41:36,480 --> 00:41:36,490
it I'm much less impressed with Sofia
 

1941
00:41:36,490 --> 00:41:38,250
it I'm much less impressed with Sofia
than I am with Boston Dynamics she said

1942
00:41:38,250 --> 00:41:38,260
than I am with Boston Dynamics she said
 

1943
00:41:38,260 --> 00:41:40,260
than I am with Boston Dynamics she said
she likes you she says she admires you

1944
00:41:40,260 --> 00:41:40,270
she likes you she says she admires you
 

1945
00:41:40,270 --> 00:41:42,600
she likes you she says she admires you
she yeah she followed me on Twitter at

1946
00:41:42,600 --> 00:41:42,610
she yeah she followed me on Twitter at
 

1947
00:41:42,610 --> 00:41:45,090
she yeah she followed me on Twitter at
some point yeah as she tweets about how

1948
00:41:45,090 --> 00:41:45,100
some point yeah as she tweets about how
 

1949
00:41:45,100 --> 00:41:47,220
some point yeah as she tweets about how
much she likes you so so wouldn't that

1950
00:41:47,220 --> 00:41:47,230
much she likes you so so wouldn't that
 

1951
00:41:47,230 --> 00:41:50,520
much she likes you so so wouldn't that
mean I have to be nicer not I was

1952
00:41:50,520 --> 00:41:50,530
mean I have to be nicer not I was
 

1953
00:41:50,530 --> 00:41:54,390
mean I have to be nicer not I was
emotionally manipulating it no how do

1954
00:41:54,390 --> 00:41:54,400
emotionally manipulating it no how do
 

1955
00:41:54,400 --> 00:41:57,420
emotionally manipulating it no how do
you think of the whole thing that

1956
00:41:57,420 --> 00:41:57,430
you think of the whole thing that
 

1957
00:41:57,430 --> 00:41:59,850
you think of the whole thing that
happened with Sofia is quite a large

1958
00:41:59,850 --> 00:41:59,860
happened with Sofia is quite a large
 

1959
00:41:59,860 --> 00:42:02,820
happened with Sofia is quite a large
number of people kind of immediately had

1960
00:42:02,820 --> 00:42:02,830
number of people kind of immediately had
 

1961
00:42:02,830 --> 00:42:04,530
number of people kind of immediately had
a connection and thought that maybe

1962
00:42:04,530 --> 00:42:04,540
a connection and thought that maybe
 

1963
00:42:04,540 --> 00:42:06,240
a connection and thought that maybe
we're far far more advanced with

1964
00:42:06,240 --> 00:42:06,250
we're far far more advanced with
 

1965
00:42:06,250 --> 00:42:07,710
we're far far more advanced with
robotics than we are all right she

1966
00:42:07,710 --> 00:42:07,720
robotics than we are all right she
 

1967
00:42:07,720 --> 00:42:10,290
robotics than we are all right she
didn't even think much I'm surprised how

1968
00:42:10,290 --> 00:42:10,300
didn't even think much I'm surprised how
 

1969
00:42:10,300 --> 00:42:15,150
didn't even think much I'm surprised how
little people cared that they kind of

1970
00:42:15,150 --> 00:42:15,160
little people cared that they kind of
 

1971
00:42:15,160 --> 00:42:16,800
little people cared that they kind of
assumed that

1972
00:42:16,800 --> 00:42:16,810
assumed that
 

1973
00:42:16,810 --> 00:42:19,920
assumed that
well of course AI can do this yeah and

1974
00:42:19,920 --> 00:42:19,930
well of course AI can do this yeah and
 

1975
00:42:19,930 --> 00:42:23,820
well of course AI can do this yeah and
then they if they assume that I felt

1976
00:42:23,820 --> 00:42:23,830
then they if they assume that I felt
 

1977
00:42:23,830 --> 00:42:27,540
then they if they assume that I felt
they should be more impressed well you

1978
00:42:27,540 --> 00:42:27,550
they should be more impressed well you
 

1979
00:42:27,550 --> 00:42:28,410
they should be more impressed well you
know what I mean like really

1980
00:42:28,410 --> 00:42:28,420
know what I mean like really
 

1981
00:42:28,420 --> 00:42:30,780
know what I mean like really
overestimate where we are and so in

1982
00:42:30,780 --> 00:42:30,790
overestimate where we are and so in
 

1983
00:42:30,790 --> 00:42:32,550
overestimate where we are and so in
something I don't even I don't even

1984
00:42:32,550 --> 00:42:32,560
something I don't even I don't even
 

1985
00:42:32,560 --> 00:42:34,650
something I don't even I don't even
think Sofia was very impressed over it

1986
00:42:34,650 --> 00:42:34,660
think Sofia was very impressed over it
 

1987
00:42:34,660 --> 00:42:36,030
think Sofia was very impressed over it
is very impressive I think she's kind of

1988
00:42:36,030 --> 00:42:36,040
is very impressive I think she's kind of
 

1989
00:42:36,040 --> 00:42:39,030
is very impressive I think she's kind of
a puppet to be honest but yeah I think

1990
00:42:39,030 --> 00:42:39,040
a puppet to be honest but yeah I think
 

1991
00:42:39,040 --> 00:42:41,550
a puppet to be honest but yeah I think
people have are a little bit influenced

1992
00:42:41,550 --> 00:42:41,560
people have are a little bit influenced
 

1993
00:42:41,560 --> 00:42:43,440
people have are a little bit influenced
by science fiction pop culture to think

1994
00:42:43,440 --> 00:42:43,450
by science fiction pop culture to think
 

1995
00:42:43,450 --> 00:42:44,940
by science fiction pop culture to think
that we should be further along than we

1996
00:42:44,940 --> 00:42:44,950
that we should be further along than we
 

1997
00:42:44,950 --> 00:42:48,210
that we should be further along than we
are so what's your favorite robots and

1998
00:42:48,210 --> 00:42:48,220
are so what's your favorite robots and
 

1999
00:42:48,220 --> 00:42:52,980
are so what's your favorite robots and
movies in fiction wall-e wall-e what do

2000
00:42:52,980 --> 00:42:52,990
movies in fiction wall-e wall-e what do
 

2001
00:42:52,990 --> 00:42:55,440
movies in fiction wall-e wall-e what do
you like about wall-e the humor the

2002
00:42:55,440 --> 00:42:55,450
you like about wall-e the humor the
 

2003
00:42:55,450 --> 00:42:59,310
you like about wall-e the humor the
cuteness the the perception control

2004
00:42:59,310 --> 00:42:59,320
cuteness the the perception control
 

2005
00:42:59,320 --> 00:43:01,170
cuteness the the perception control
systems operating and wallahi that makes

2006
00:43:01,170 --> 00:43:01,180
systems operating and wallahi that makes
 

2007
00:43:01,180 --> 00:43:05,580
systems operating and wallahi that makes
it all just in general the design of

2008
00:43:05,580 --> 00:43:05,590
it all just in general the design of
 

2009
00:43:05,590 --> 00:43:08,520
it all just in general the design of
wall-e the robot I think that animators

2010
00:43:08,520 --> 00:43:08,530
wall-e the robot I think that animators
 

2011
00:43:08,530 --> 00:43:11,010
wall-e the robot I think that animators
figured out you know starting in like

2012
00:43:11,010 --> 00:43:11,020
figured out you know starting in like
 

2013
00:43:11,020 --> 00:43:11,370
figured out you know starting in like
Ben

2014
00:43:11,370 --> 00:43:11,380
Ben
 

2015
00:43:11,380 --> 00:43:14,130
Ben
1940's how to create characters that

2016
00:43:14,130 --> 00:43:14,140
1940's how to create characters that
 

2017
00:43:14,140 --> 00:43:18,749
1940's how to create characters that
don't look real but look like something

2018
00:43:18,749 --> 00:43:18,759
don't look real but look like something
 

2019
00:43:18,759 --> 00:43:20,579
don't look real but look like something
that's even better than real that we

2020
00:43:20,579 --> 00:43:20,589
that's even better than real that we
 

2021
00:43:20,589 --> 00:43:22,170
that's even better than real that we
really respond to and think is really

2022
00:43:22,170 --> 00:43:22,180
really respond to and think is really
 

2023
00:43:22,180 --> 00:43:23,789
really respond to and think is really
cute they figured out how to make them

2024
00:43:23,789 --> 00:43:23,799
cute they figured out how to make them
 

2025
00:43:23,799 --> 00:43:25,799
cute they figured out how to make them
move and look in the right way and

2026
00:43:25,799 --> 00:43:25,809
move and look in the right way and
 

2027
00:43:25,809 --> 00:43:28,319
move and look in the right way and
wall-e is just such a great example of

2028
00:43:28,319 --> 00:43:28,329
wall-e is just such a great example of
 

2029
00:43:28,329 --> 00:43:28,829
wall-e is just such a great example of
that

2030
00:43:28,829 --> 00:43:28,839
that
 

2031
00:43:28,839 --> 00:43:31,289
that
you think eyes big eyes or big something

2032
00:43:31,289 --> 00:43:31,299
you think eyes big eyes or big something
 

2033
00:43:31,299 --> 00:43:33,630
you think eyes big eyes or big something
that's kind of AI ish so it's always

2034
00:43:33,630 --> 00:43:33,640
that's kind of AI ish so it's always
 

2035
00:43:33,640 --> 00:43:37,589
that's kind of AI ish so it's always
playing on some aspect of the human face

2036
00:43:37,589 --> 00:43:37,599
playing on some aspect of the human face
 

2037
00:43:37,599 --> 00:43:40,109
playing on some aspect of the human face
right often yeah

2038
00:43:40,109 --> 00:43:40,119
right often yeah
 

2039
00:43:40,119 --> 00:43:43,410
right often yeah
so big eyes well I think one of the one

2040
00:43:43,410 --> 00:43:43,420
so big eyes well I think one of the one
 

2041
00:43:43,420 --> 00:43:45,509
so big eyes well I think one of the one
of the first like animations to really

2042
00:43:45,509 --> 00:43:45,519
of the first like animations to really
 

2043
00:43:45,519 --> 00:43:47,549
of the first like animations to really
play with this was Bambi and they

2044
00:43:47,549 --> 00:43:47,559
play with this was Bambi and they
 

2045
00:43:47,559 --> 00:43:49,289
play with this was Bambi and they
weren't originally gonna do that they

2046
00:43:49,289 --> 00:43:49,299
weren't originally gonna do that they
 

2047
00:43:49,299 --> 00:43:50,910
weren't originally gonna do that they
were originally trying to make the deer

2048
00:43:50,910 --> 00:43:50,920
were originally trying to make the deer
 

2049
00:43:50,920 --> 00:43:52,769
were originally trying to make the deer
look as lifelike as possible like they

2050
00:43:52,769 --> 00:43:52,779
look as lifelike as possible like they
 

2051
00:43:52,779 --> 00:43:54,450
look as lifelike as possible like they
brought deer into the studio and had a

2052
00:43:54,450 --> 00:43:54,460
brought deer into the studio and had a
 

2053
00:43:54,460 --> 00:43:56,370
brought deer into the studio and had a
little zoo there so the animators could

2054
00:43:56,370 --> 00:43:56,380
little zoo there so the animators could
 

2055
00:43:56,380 --> 00:43:58,200
little zoo there so the animators could
work with them and then at some point

2056
00:43:58,200 --> 00:43:58,210
work with them and then at some point
 

2057
00:43:58,210 --> 00:44:00,390
work with them and then at some point
they were like hmm if we make really big

2058
00:44:00,390 --> 00:44:00,400
they were like hmm if we make really big
 

2059
00:44:00,400 --> 00:44:02,490
they were like hmm if we make really big
eyes and like a small nose and like big

2060
00:44:02,490 --> 00:44:02,500
eyes and like a small nose and like big
 

2061
00:44:02,500 --> 00:44:04,200
eyes and like a small nose and like big
cheeks kind of more like a baby face

2062
00:44:04,200 --> 00:44:04,210
cheeks kind of more like a baby face
 

2063
00:44:04,210 --> 00:44:06,509
cheeks kind of more like a baby face
then people like it even better than if

2064
00:44:06,509 --> 00:44:06,519
then people like it even better than if
 

2065
00:44:06,519 --> 00:44:11,480
then people like it even better than if
it looks real do you think the future of

2066
00:44:11,480 --> 00:44:11,490
it looks real do you think the future of
 

2067
00:44:11,490 --> 00:44:14,720
it looks real do you think the future of
things I collects are in the home has

2068
00:44:14,720 --> 00:44:14,730
things I collects are in the home has
 

2069
00:44:14,730 --> 00:44:17,640
things I collects are in the home has
possibility to take advantage of that to

2070
00:44:17,640 --> 00:44:17,650
possibility to take advantage of that to
 

2071
00:44:17,650 --> 00:44:22,319
possibility to take advantage of that to
build on that to create these systems

2072
00:44:22,319 --> 00:44:22,329
build on that to create these systems
 

2073
00:44:22,329 --> 00:44:25,230
build on that to create these systems
that are better than real that created

2074
00:44:25,230 --> 00:44:25,240
that are better than real that created
 

2075
00:44:25,240 --> 00:44:27,690
that are better than real that created
closed human connection I can pretty

2076
00:44:27,690 --> 00:44:27,700
closed human connection I can pretty
 

2077
00:44:27,700 --> 00:44:29,400
closed human connection I can pretty
much guarantee you without having any

2078
00:44:29,400 --> 00:44:29,410
much guarantee you without having any
 

2079
00:44:29,410 --> 00:44:32,370
much guarantee you without having any
knowledge that those companies are

2080
00:44:32,370 --> 00:44:32,380
knowledge that those companies are
 

2081
00:44:32,380 --> 00:44:35,640
knowledge that those companies are
working on that on that design behind

2082
00:44:35,640 --> 00:44:35,650
working on that on that design behind
 

2083
00:44:35,650 --> 00:44:38,009
working on that on that design behind
the scenes like pretty sure I totally

2084
00:44:38,009 --> 00:44:38,019
the scenes like pretty sure I totally
 

2085
00:44:38,019 --> 00:44:40,140
the scenes like pretty sure I totally
disagree with you really so that's what

2086
00:44:40,140 --> 00:44:40,150
disagree with you really so that's what
 

2087
00:44:40,150 --> 00:44:42,359
disagree with you really so that's what
I'm interested in I'd like to build such

2088
00:44:42,359 --> 00:44:42,369
I'm interested in I'd like to build such
 

2089
00:44:42,369 --> 00:44:44,160
I'm interested in I'd like to build such
a company I know a lot of those folks

2090
00:44:44,160 --> 00:44:44,170
a company I know a lot of those folks
 

2091
00:44:44,170 --> 00:44:46,079
a company I know a lot of those folks
and they're afraid of that because you

2092
00:44:46,079 --> 00:44:46,089
and they're afraid of that because you
 

2093
00:44:46,089 --> 00:44:47,849
and they're afraid of that because you
don't well how do you make money off of

2094
00:44:47,849 --> 00:44:47,859
don't well how do you make money off of
 

2095
00:44:47,859 --> 00:44:51,870
don't well how do you make money off of
it well but even just like making a lexa

2096
00:44:51,870 --> 00:44:51,880
it well but even just like making a lexa
 

2097
00:44:51,880 --> 00:44:53,339
it well but even just like making a lexa
look a little bit more interesting than

2098
00:44:53,339 --> 00:44:53,349
look a little bit more interesting than
 

2099
00:44:53,349 --> 00:44:56,029
look a little bit more interesting than
just like a cylinder would do so much

2100
00:44:56,029 --> 00:44:56,039
just like a cylinder would do so much
 

2101
00:44:56,039 --> 00:44:59,490
just like a cylinder would do so much
it's it's an interesting thought but I

2102
00:44:59,490 --> 00:44:59,500
it's it's an interesting thought but I
 

2103
00:44:59,500 --> 00:45:02,579
it's it's an interesting thought but I
don't think people are from Amazon

2104
00:45:02,579 --> 00:45:02,589
don't think people are from Amazon
 

2105
00:45:02,589 --> 00:45:03,930
don't think people are from Amazon
perspective looking for that kind of

2106
00:45:03,930 --> 00:45:03,940
perspective looking for that kind of
 

2107
00:45:03,940 --> 00:45:07,200
perspective looking for that kind of
connection they want you to be addicted

2108
00:45:07,200 --> 00:45:07,210
connection they want you to be addicted
 

2109
00:45:07,210 --> 00:45:09,749
connection they want you to be addicted
to the services provided by Alexa not to

2110
00:45:09,749 --> 00:45:09,759
to the services provided by Alexa not to
 

2111
00:45:09,759 --> 00:45:14,249
to the services provided by Alexa not to
the device so the the device itself it's

2112
00:45:14,249 --> 00:45:14,259
the device so the the device itself it's
 

2113
00:45:14,259 --> 00:45:17,549
the device so the the device itself it's
felt that you can lose a lot because if

2114
00:45:17,549 --> 00:45:17,559
felt that you can lose a lot because if
 

2115
00:45:17,559 --> 00:45:20,400
felt that you can lose a lot because if
you create a connection and then if

2116
00:45:20,400 --> 00:45:20,410
you create a connection and then if
 

2117
00:45:20,410 --> 00:45:22,589
you create a connection and then if
there's it creates more opportunity for

2118
00:45:22,589 --> 00:45:22,599
there's it creates more opportunity for
 

2119
00:45:22,599 --> 00:45:25,020
there's it creates more opportunity for
frustration for

2120
00:45:25,020 --> 00:45:25,030
frustration for
 

2121
00:45:25,030 --> 00:45:28,020
frustration for
for negative stuff then it does for

2122
00:45:28,020 --> 00:45:28,030
for negative stuff then it does for
 

2123
00:45:28,030 --> 00:45:30,030
for negative stuff then it does for
positive stuff is I think the way they

2124
00:45:30,030 --> 00:45:30,040
positive stuff is I think the way they
 

2125
00:45:30,040 --> 00:45:31,800
positive stuff is I think the way they
think about it that's interesting

2126
00:45:31,800 --> 00:45:31,810
think about it that's interesting
 

2127
00:45:31,810 --> 00:45:34,070
think about it that's interesting
like I agree that there is it's very

2128
00:45:34,070 --> 00:45:34,080
like I agree that there is it's very
 

2129
00:45:34,080 --> 00:45:36,480
like I agree that there is it's very
difficult to get right and you have to

2130
00:45:36,480 --> 00:45:36,490
difficult to get right and you have to
 

2131
00:45:36,490 --> 00:45:38,070
difficult to get right and you have to
get it exactly right otherwise you wind

2132
00:45:38,070 --> 00:45:38,080
get it exactly right otherwise you wind
 

2133
00:45:38,080 --> 00:45:41,720
get it exactly right otherwise you wind
up with Microsoft's Clippy okay easy now

2134
00:45:41,720 --> 00:45:41,730
up with Microsoft's Clippy okay easy now
 

2135
00:45:41,730 --> 00:45:44,550
up with Microsoft's Clippy okay easy now
what's your problem with Clippy oh you

2136
00:45:44,550 --> 00:45:44,560
what's your problem with Clippy oh you
 

2137
00:45:44,560 --> 00:45:45,960
what's your problem with Clippy oh you
like clip these clothes your friends

2138
00:45:45,960 --> 00:45:45,970
like clip these clothes your friends
 

2139
00:45:45,970 --> 00:45:49,650
like clip these clothes your friends
yeah I'll just I just I just talked to

2140
00:45:49,650 --> 00:45:49,660
yeah I'll just I just I just talked to
 

2141
00:45:49,660 --> 00:45:51,030
yeah I'll just I just I just talked to
the would just had this argument and

2142
00:45:51,030 --> 00:45:51,040
the would just had this argument and
 

2143
00:45:51,040 --> 00:45:53,460
the would just had this argument and
they Microsoft CTO and they and he said

2144
00:45:53,460 --> 00:45:53,470
they Microsoft CTO and they and he said
 

2145
00:45:53,470 --> 00:45:55,910
they Microsoft CTO and they and he said
he said he's not bringing Clippy back

2146
00:45:55,910 --> 00:45:55,920
he said he's not bringing Clippy back
 

2147
00:45:55,920 --> 00:45:58,380
he said he's not bringing Clippy back
they're not bringing Clippy back and

2148
00:45:58,380 --> 00:45:58,390
they're not bringing Clippy back and
 

2149
00:45:58,390 --> 00:46:00,540
they're not bringing Clippy back and
that's very disappointing is I think it

2150
00:46:00,540 --> 00:46:00,550
that's very disappointing is I think it
 

2151
00:46:00,550 --> 00:46:05,340
that's very disappointing is I think it
was clip II was the greatest assistance

2152
00:46:05,340 --> 00:46:05,350
was clip II was the greatest assistance
 

2153
00:46:05,350 --> 00:46:07,890
was clip II was the greatest assistance
we've ever built it was a horrible

2154
00:46:07,890 --> 00:46:07,900
we've ever built it was a horrible
 

2155
00:46:07,900 --> 00:46:09,750
we've ever built it was a horrible
attempt of course but it's the best

2156
00:46:09,750 --> 00:46:09,760
attempt of course but it's the best
 

2157
00:46:09,760 --> 00:46:12,000
attempt of course but it's the best
we've ever done because it was in real

2158
00:46:12,000 --> 00:46:12,010
we've ever done because it was in real
 

2159
00:46:12,010 --> 00:46:14,490
we've ever done because it was in real
attempt you haven't like a actual

2160
00:46:14,490 --> 00:46:14,500
attempt you haven't like a actual
 

2161
00:46:14,500 --> 00:46:17,820
attempt you haven't like a actual
personality and I mean it was obviously

2162
00:46:17,820 --> 00:46:17,830
personality and I mean it was obviously
 

2163
00:46:17,830 --> 00:46:20,970
personality and I mean it was obviously
technology was way not there at the time

2164
00:46:20,970 --> 00:46:20,980
technology was way not there at the time
 

2165
00:46:20,980 --> 00:46:24,150
technology was way not there at the time
of being able to be a recommender system

2166
00:46:24,150 --> 00:46:24,160
of being able to be a recommender system
 

2167
00:46:24,160 --> 00:46:26,690
of being able to be a recommender system
for assisting you in anything and typing

2168
00:46:26,690 --> 00:46:26,700
for assisting you in anything and typing
 

2169
00:46:26,700 --> 00:46:29,490
for assisting you in anything and typing
in Word or any kind of other application

2170
00:46:29,490 --> 00:46:29,500
in Word or any kind of other application
 

2171
00:46:29,500 --> 00:46:31,290
in Word or any kind of other application
but still was an attempt of personality

2172
00:46:31,290 --> 00:46:31,300
but still was an attempt of personality
 

2173
00:46:31,300 --> 00:46:33,480
but still was an attempt of personality
that was legitimate I'm sure I thought

2174
00:46:33,480 --> 00:46:33,490
that was legitimate I'm sure I thought
 

2175
00:46:33,490 --> 00:46:37,110
that was legitimate I'm sure I thought
was brave yes oh yes okay you know

2176
00:46:37,110 --> 00:46:37,120
was brave yes oh yes okay you know
 

2177
00:46:37,120 --> 00:46:38,400
was brave yes oh yes okay you know
you've convinced me I'll be slightly

2178
00:46:38,400 --> 00:46:38,410
you've convinced me I'll be slightly
 

2179
00:46:38,410 --> 00:46:40,740
you've convinced me I'll be slightly
less hard unclick and I know I have like

2180
00:46:40,740 --> 00:46:40,750
less hard unclick and I know I have like
 

2181
00:46:40,750 --> 00:46:42,960
less hard unclick and I know I have like
an army of people behind me who also

2182
00:46:42,960 --> 00:46:42,970
an army of people behind me who also
 

2183
00:46:42,970 --> 00:46:45,480
an army of people behind me who also
miss Clippy so really I want to meet

2184
00:46:45,480 --> 00:46:45,490
miss Clippy so really I want to meet
 

2185
00:46:45,490 --> 00:46:47,370
miss Clippy so really I want to meet
these people who are these people it's

2186
00:46:47,370 --> 00:46:47,380
these people who are these people it's
 

2187
00:46:47,380 --> 00:46:50,730
these people who are these people it's
the people who like to hate stuff when

2188
00:46:50,730 --> 00:46:50,740
the people who like to hate stuff when
 

2189
00:46:50,740 --> 00:46:53,370
the people who like to hate stuff when
it's there and and miss it when it's

2190
00:46:53,370 --> 00:46:53,380
it's there and and miss it when it's
 

2191
00:46:53,380 --> 00:46:53,570
it's there and and miss it when it's
gone

2192
00:46:53,570 --> 00:46:53,580
gone
 

2193
00:46:53,580 --> 00:46:56,690
gone
[Laughter]

2194
00:46:56,690 --> 00:46:56,700
[Laughter]
 

2195
00:46:56,700 --> 00:46:58,350
[Laughter]
exactly

2196
00:46:58,350 --> 00:46:58,360
exactly
 

2197
00:46:58,360 --> 00:47:04,380
exactly
alright so Anki and Gebo the two

2198
00:47:04,380 --> 00:47:04,390
alright so Anki and Gebo the two
 

2199
00:47:04,390 --> 00:47:07,350
alright so Anki and Gebo the two
companies two amazing companies social

2200
00:47:07,350 --> 00:47:07,360
companies two amazing companies social
 

2201
00:47:07,360 --> 00:47:09,630
companies two amazing companies social
robotics companies that have recently

2202
00:47:09,630 --> 00:47:09,640
robotics companies that have recently
 

2203
00:47:09,640 --> 00:47:13,500
robotics companies that have recently
been closed down yeah why do you think

2204
00:47:13,500 --> 00:47:13,510
been closed down yeah why do you think
 

2205
00:47:13,510 --> 00:47:15,420
been closed down yeah why do you think
it's so hard to create a personal

2206
00:47:15,420 --> 00:47:15,430
it's so hard to create a personal
 

2207
00:47:15,430 --> 00:47:17,490
it's so hard to create a personal
robotics company so making a business

2208
00:47:17,490 --> 00:47:17,500
robotics company so making a business
 

2209
00:47:17,500 --> 00:47:20,970
robotics company so making a business
out of essentially something that people

2210
00:47:20,970 --> 00:47:20,980
out of essentially something that people
 

2211
00:47:20,980 --> 00:47:23,250
out of essentially something that people
would anthropomorphize have a deep

2212
00:47:23,250 --> 00:47:23,260
would anthropomorphize have a deep
 

2213
00:47:23,260 --> 00:47:25,350
would anthropomorphize have a deep
connection with why is it so hard to

2214
00:47:25,350 --> 00:47:25,360
connection with why is it so hard to
 

2215
00:47:25,360 --> 00:47:27,660
connection with why is it so hard to
make it work the business case not there

2216
00:47:27,660 --> 00:47:27,670
make it work the business case not there
 

2217
00:47:27,670 --> 00:47:30,720
make it work the business case not there
or what is it I think it's a number of

2218
00:47:30,720 --> 00:47:30,730
or what is it I think it's a number of
 

2219
00:47:30,730 --> 00:47:33,660
or what is it I think it's a number of
different things I don't think it's

2220
00:47:33,660 --> 00:47:33,670
different things I don't think it's
 

2221
00:47:33,670 --> 00:47:36,210
different things I don't think it's
going to be this way forever I think at

2222
00:47:36,210 --> 00:47:36,220
going to be this way forever I think at
 

2223
00:47:36,220 --> 00:47:38,340
going to be this way forever I think at
this current point in time it

2224
00:47:38,340 --> 00:47:38,350
this current point in time it
 

2225
00:47:38,350 --> 00:47:42,120
this current point in time it
so much work to build something that

2226
00:47:42,120 --> 00:47:42,130
so much work to build something that
 

2227
00:47:42,130 --> 00:47:45,810
so much work to build something that
only barely meets people's like minimal

2228
00:47:45,810 --> 00:47:45,820
only barely meets people's like minimal
 

2229
00:47:45,820 --> 00:47:48,510
only barely meets people's like minimal
expectations because of science fiction

2230
00:47:48,510 --> 00:47:48,520
expectations because of science fiction
 

2231
00:47:48,520 --> 00:47:50,130
expectations because of science fiction
and pop-culture giving people this idea

2232
00:47:50,130 --> 00:47:50,140
and pop-culture giving people this idea
 

2233
00:47:50,140 --> 00:47:51,720
and pop-culture giving people this idea
that we should be further than we

2234
00:47:51,720 --> 00:47:51,730
that we should be further than we
 

2235
00:47:51,730 --> 00:47:53,340
that we should be further than we
already are like when people think about

2236
00:47:53,340 --> 00:47:53,350
already are like when people think about
 

2237
00:47:53,350 --> 00:47:55,650
already are like when people think about
a robot assistant in the home they think

2238
00:47:55,650 --> 00:47:55,660
a robot assistant in the home they think
 

2239
00:47:55,660 --> 00:47:57,660
a robot assistant in the home they think
about Rosie from the Jetsons or

2240
00:47:57,660 --> 00:47:57,670
about Rosie from the Jetsons or
 

2241
00:47:57,670 --> 00:48:01,140
about Rosie from the Jetsons or
something like that and on key and and

2242
00:48:01,140 --> 00:48:01,150
something like that and on key and and
 

2243
00:48:01,150 --> 00:48:03,000
something like that and on key and and
giba did such a beautiful job with the

2244
00:48:03,000 --> 00:48:03,010
giba did such a beautiful job with the
 

2245
00:48:03,010 --> 00:48:05,280
giba did such a beautiful job with the
design and getting that interaction just

2246
00:48:05,280 --> 00:48:05,290
design and getting that interaction just
 

2247
00:48:05,290 --> 00:48:08,400
design and getting that interaction just
right but I think people just wanted

2248
00:48:08,400 --> 00:48:08,410
right but I think people just wanted
 

2249
00:48:08,410 --> 00:48:09,990
right but I think people just wanted
more they wanted more functionality I

2250
00:48:09,990 --> 00:48:10,000
more they wanted more functionality I
 

2251
00:48:10,000 --> 00:48:11,490
more they wanted more functionality I
think you're also right that you know

2252
00:48:11,490 --> 00:48:11,500
think you're also right that you know
 

2253
00:48:11,500 --> 00:48:13,620
think you're also right that you know
the business case isn't really there

2254
00:48:13,620 --> 00:48:13,630
the business case isn't really there
 

2255
00:48:13,630 --> 00:48:15,810
the business case isn't really there
because there hasn't been a killer

2256
00:48:15,810 --> 00:48:15,820
because there hasn't been a killer
 

2257
00:48:15,820 --> 00:48:18,330
because there hasn't been a killer
application that's useful enough to get

2258
00:48:18,330 --> 00:48:18,340
application that's useful enough to get
 

2259
00:48:18,340 --> 00:48:21,000
application that's useful enough to get
people to adopt the technology in great

2260
00:48:21,000 --> 00:48:21,010
people to adopt the technology in great
 

2261
00:48:21,010 --> 00:48:23,520
people to adopt the technology in great
numbers I think what we did see from the

2262
00:48:23,520 --> 00:48:23,530
numbers I think what we did see from the
 

2263
00:48:23,530 --> 00:48:25,800
numbers I think what we did see from the
people who did you know get geebo is a

2264
00:48:25,800 --> 00:48:25,810
people who did you know get geebo is a
 

2265
00:48:25,810 --> 00:48:28,110
people who did you know get geebo is a
lot of them became very emotionally

2266
00:48:28,110 --> 00:48:28,120
lot of them became very emotionally
 

2267
00:48:28,120 --> 00:48:31,440
lot of them became very emotionally
attached to it but that's not I mean

2268
00:48:31,440 --> 00:48:31,450
attached to it but that's not I mean
 

2269
00:48:31,450 --> 00:48:33,270
attached to it but that's not I mean
it's kind of like the Palm Pilot back in

2270
00:48:33,270 --> 00:48:33,280
it's kind of like the Palm Pilot back in
 

2271
00:48:33,280 --> 00:48:34,680
it's kind of like the Palm Pilot back in
the day most people are like why do I

2272
00:48:34,680 --> 00:48:34,690
the day most people are like why do I
 

2273
00:48:34,690 --> 00:48:36,510
the day most people are like why do I
need this why would I they don't see how

2274
00:48:36,510 --> 00:48:36,520
need this why would I they don't see how
 

2275
00:48:36,520 --> 00:48:38,700
need this why would I they don't see how
they would benefit from it until they

2276
00:48:38,700 --> 00:48:38,710
they would benefit from it until they
 

2277
00:48:38,710 --> 00:48:40,800
they would benefit from it until they
you know have it or some other company

2278
00:48:40,800 --> 00:48:40,810
you know have it or some other company
 

2279
00:48:40,810 --> 00:48:42,890
you know have it or some other company
comes in and makes it a little better

2280
00:48:42,890 --> 00:48:42,900
comes in and makes it a little better
 

2281
00:48:42,900 --> 00:48:45,840
comes in and makes it a little better
yet like how how far away are we do you

2282
00:48:45,840 --> 00:48:45,850
yet like how how far away are we do you
 

2283
00:48:45,850 --> 00:48:47,820
yet like how how far away are we do you
think I mean how hard is this problem

2284
00:48:47,820 --> 00:48:47,830
think I mean how hard is this problem
 

2285
00:48:47,830 --> 00:48:49,740
think I mean how hard is this problem
it's a good question and I think it has

2286
00:48:49,740 --> 00:48:49,750
it's a good question and I think it has
 

2287
00:48:49,750 --> 00:48:51,060
it's a good question and I think it has
a lot to do with people's expectations

2288
00:48:51,060 --> 00:48:51,070
a lot to do with people's expectations
 

2289
00:48:51,070 --> 00:48:53,820
a lot to do with people's expectations
and those keep shifting depending on

2290
00:48:53,820 --> 00:48:53,830
and those keep shifting depending on
 

2291
00:48:53,830 --> 00:48:56,400
and those keep shifting depending on
what science fiction that is popular but

2292
00:48:56,400 --> 00:48:56,410
what science fiction that is popular but
 

2293
00:48:56,410 --> 00:48:58,650
what science fiction that is popular but
also it's two things it's people's

2294
00:48:58,650 --> 00:48:58,660
also it's two things it's people's
 

2295
00:48:58,660 --> 00:49:01,530
also it's two things it's people's
expectation and people's need for an

2296
00:49:01,530 --> 00:49:01,540
expectation and people's need for an
 

2297
00:49:01,540 --> 00:49:04,710
expectation and people's need for an
emotional connection yeah and then I

2298
00:49:04,710 --> 00:49:04,720
emotional connection yeah and then I
 

2299
00:49:04,720 --> 00:49:08,190
emotional connection yeah and then I
believe the need is pretty high yes but

2300
00:49:08,190 --> 00:49:08,200
believe the need is pretty high yes but
 

2301
00:49:08,200 --> 00:49:09,690
believe the need is pretty high yes but
I don't think we're aware of it

2302
00:49:09,690 --> 00:49:09,700
I don't think we're aware of it
 

2303
00:49:09,700 --> 00:49:12,690
I don't think we're aware of it
that's right there's like it I really

2304
00:49:12,690 --> 00:49:12,700
that's right there's like it I really
 

2305
00:49:12,700 --> 00:49:15,270
that's right there's like it I really
think we're this is like the life as we

2306
00:49:15,270 --> 00:49:15,280
think we're this is like the life as we
 

2307
00:49:15,280 --> 00:49:17,490
think we're this is like the life as we
know it so we've just kind of gotten

2308
00:49:17,490 --> 00:49:17,500
know it so we've just kind of gotten
 

2309
00:49:17,500 --> 00:49:20,820
know it so we've just kind of gotten
used to it of really I hate to be dark

2310
00:49:20,820 --> 00:49:20,830
used to it of really I hate to be dark
 

2311
00:49:20,830 --> 00:49:24,330
used to it of really I hate to be dark
because I have close friends but we've

2312
00:49:24,330 --> 00:49:24,340
because I have close friends but we've
 

2313
00:49:24,340 --> 00:49:27,720
because I have close friends but we've
gotten used to really never being close

2314
00:49:27,720 --> 00:49:27,730
gotten used to really never being close
 

2315
00:49:27,730 --> 00:49:31,800
gotten used to really never being close
to anyone all right and we're deeply I

2316
00:49:31,800 --> 00:49:31,810
to anyone all right and we're deeply I
 

2317
00:49:31,810 --> 00:49:33,810
to anyone all right and we're deeply I
believe okay this is hypotheses I think

2318
00:49:33,810 --> 00:49:33,820
believe okay this is hypotheses I think
 

2319
00:49:33,820 --> 00:49:35,940
believe okay this is hypotheses I think
we're deeply lonely all of us even those

2320
00:49:35,940 --> 00:49:35,950
we're deeply lonely all of us even those
 

2321
00:49:35,950 --> 00:49:38,100
we're deeply lonely all of us even those
in deep fulfilling relationships in fact

2322
00:49:38,100 --> 00:49:38,110
in deep fulfilling relationships in fact
 

2323
00:49:38,110 --> 00:49:40,020
in deep fulfilling relationships in fact
what makes us relationship fulfilling I

2324
00:49:40,020 --> 00:49:40,030
what makes us relationship fulfilling I
 

2325
00:49:40,030 --> 00:49:42,540
what makes us relationship fulfilling I
think is that they at least tap into

2326
00:49:42,540 --> 00:49:42,550
think is that they at least tap into
 

2327
00:49:42,550 --> 00:49:45,150
think is that they at least tap into
that deep loneliness a little bit but I

2328
00:49:45,150 --> 00:49:45,160
that deep loneliness a little bit but I
 

2329
00:49:45,160 --> 00:49:47,610
that deep loneliness a little bit but I
feel like there's more opportunity to

2330
00:49:47,610 --> 00:49:47,620
feel like there's more opportunity to
 

2331
00:49:47,620 --> 00:49:50,400
feel like there's more opportunity to
explore that that doesn't interfere with

2332
00:49:50,400 --> 00:49:50,410
explore that that doesn't interfere with
 

2333
00:49:50,410 --> 00:49:51,600
explore that that doesn't interfere with
the human relationship

2334
00:49:51,600 --> 00:49:51,610
the human relationship
 

2335
00:49:51,610 --> 00:49:55,500
the human relationship
you have it expands more on the that

2336
00:49:55,500 --> 00:49:55,510
you have it expands more on the that
 

2337
00:49:55,510 --> 00:49:57,870
you have it expands more on the that
yeah the the rich deep unexplored

2338
00:49:57,870 --> 00:49:57,880
yeah the the rich deep unexplored
 

2339
00:49:57,880 --> 00:50:00,800
yeah the the rich deep unexplored
complexity that's all of us weird apes

2340
00:50:00,800 --> 00:50:00,810
complexity that's all of us weird apes
 

2341
00:50:00,810 --> 00:50:04,290
complexity that's all of us weird apes
okay right do you think it's possible to

2342
00:50:04,290 --> 00:50:04,300
okay right do you think it's possible to
 

2343
00:50:04,300 --> 00:50:06,680
okay right do you think it's possible to
fall in love with a robot oh yeah

2344
00:50:06,680 --> 00:50:06,690
fall in love with a robot oh yeah
 

2345
00:50:06,690 --> 00:50:08,250
fall in love with a robot oh yeah
totally

2346
00:50:08,250 --> 00:50:08,260
totally
 

2347
00:50:08,260 --> 00:50:11,370
totally
do you think it's possible to have a

2348
00:50:11,370 --> 00:50:11,380
do you think it's possible to have a
 

2349
00:50:11,380 --> 00:50:12,720
do you think it's possible to have a
long-term committed monogamous

2350
00:50:12,720 --> 00:50:12,730
long-term committed monogamous
 

2351
00:50:12,730 --> 00:50:13,800
long-term committed monogamous
relationship

2352
00:50:13,800 --> 00:50:13,810
relationship
 

2353
00:50:13,810 --> 00:50:16,380
relationship
oh the robot well yeah there are lots of

2354
00:50:16,380 --> 00:50:16,390
oh the robot well yeah there are lots of
 

2355
00:50:16,390 --> 00:50:18,090
oh the robot well yeah there are lots of
different types of long-term committed

2356
00:50:18,090 --> 00:50:18,100
different types of long-term committed
 

2357
00:50:18,100 --> 00:50:20,730
different types of long-term committed
monogamous relationships I think

2358
00:50:20,730 --> 00:50:20,740
monogamous relationships I think
 

2359
00:50:20,740 --> 00:50:23,430
monogamous relationships I think
monogamous implies like you're not going

2360
00:50:23,430 --> 00:50:23,440
monogamous implies like you're not going
 

2361
00:50:23,440 --> 00:50:27,210
monogamous implies like you're not going
to see other humans and sexually or like

2362
00:50:27,210 --> 00:50:27,220
to see other humans and sexually or like
 

2363
00:50:27,220 --> 00:50:29,520
to see other humans and sexually or like
you basically on Facebook have to say

2364
00:50:29,520 --> 00:50:29,530
you basically on Facebook have to say
 

2365
00:50:29,530 --> 00:50:31,520
you basically on Facebook have to say
I'm in a relationship with this person

2366
00:50:31,520 --> 00:50:31,530
I'm in a relationship with this person
 

2367
00:50:31,530 --> 00:50:34,620
I'm in a relationship with this person
this robot I just don't like again I

2368
00:50:34,620 --> 00:50:34,630
this robot I just don't like again I
 

2369
00:50:34,630 --> 00:50:36,540
this robot I just don't like again I
think this is comparing robots to humans

2370
00:50:36,540 --> 00:50:36,550
think this is comparing robots to humans
 

2371
00:50:36,550 --> 00:50:39,300
think this is comparing robots to humans
when I would rather compare them to pets

2372
00:50:39,300 --> 00:50:39,310
when I would rather compare them to pets
 

2373
00:50:39,310 --> 00:50:42,780
when I would rather compare them to pets
like you get a robot it fulfills you

2374
00:50:42,780 --> 00:50:42,790
like you get a robot it fulfills you
 

2375
00:50:42,790 --> 00:50:47,010
like you get a robot it fulfills you
know this loneliness that you have in us

2376
00:50:47,010 --> 00:50:47,020
know this loneliness that you have in us
 

2377
00:50:47,020 --> 00:50:48,990
know this loneliness that you have in us
maybe not the same way as a pet maybe in

2378
00:50:48,990 --> 00:50:49,000
maybe not the same way as a pet maybe in
 

2379
00:50:49,000 --> 00:50:51,290
maybe not the same way as a pet maybe in
a different way that is even you know

2380
00:50:51,290 --> 00:50:51,300
a different way that is even you know
 

2381
00:50:51,300 --> 00:50:54,540
a different way that is even you know
supplemental in a different way but you

2382
00:50:54,540 --> 00:50:54,550
supplemental in a different way but you
 

2383
00:50:54,550 --> 00:50:56,070
supplemental in a different way but you
know I'm not saying that people won't

2384
00:50:56,070 --> 00:50:56,080
know I'm not saying that people won't
 

2385
00:50:56,080 --> 00:50:58,590
know I'm not saying that people won't
like do this be like oh I want to marry

2386
00:50:58,590 --> 00:50:58,600
like do this be like oh I want to marry
 

2387
00:50:58,600 --> 00:51:01,050
like do this be like oh I want to marry
my robot or I want to have like a you

2388
00:51:01,050 --> 00:51:01,060
my robot or I want to have like a you
 

2389
00:51:01,060 --> 00:51:02,970
my robot or I want to have like a you
know sexual relation monogamous

2390
00:51:02,970 --> 00:51:02,980
know sexual relation monogamous
 

2391
00:51:02,980 --> 00:51:05,940
know sexual relation monogamous
relationship with my robot but I don't

2392
00:51:05,940 --> 00:51:05,950
relationship with my robot but I don't
 

2393
00:51:05,950 --> 00:51:07,860
relationship with my robot but I don't
think that that's the main use case for

2394
00:51:07,860 --> 00:51:07,870
think that that's the main use case for
 

2395
00:51:07,870 --> 00:51:10,830
think that that's the main use case for
them well you think that there's still a

2396
00:51:10,830 --> 00:51:10,840
them well you think that there's still a
 

2397
00:51:10,840 --> 00:51:18,530
them well you think that there's still a
gap between human and pet so between

2398
00:51:18,530 --> 00:51:18,540
gap between human and pet so between
 

2399
00:51:18,540 --> 00:51:24,000
gap between human and pet so between
husband and pet there's a relation

2400
00:51:24,000 --> 00:51:24,010
husband and pet there's a relation
 

2401
00:51:24,010 --> 00:51:26,280
husband and pet there's a relation
earring so that that's a gap that can be

2402
00:51:26,280 --> 00:51:26,290
earring so that that's a gap that can be
 

2403
00:51:26,290 --> 00:51:28,950
earring so that that's a gap that can be
closed but I think it could be closed

2404
00:51:28,950 --> 00:51:28,960
closed but I think it could be closed
 

2405
00:51:28,960 --> 00:51:31,440
closed but I think it could be closed
someday but why would we close that like

2406
00:51:31,440 --> 00:51:31,450
someday but why would we close that like
 

2407
00:51:31,450 --> 00:51:33,150
someday but why would we close that like
I I think it's so boring to think about

2408
00:51:33,150 --> 00:51:33,160
I I think it's so boring to think about
 

2409
00:51:33,160 --> 00:51:35,130
I I think it's so boring to think about
recreating things that we already have

2410
00:51:35,130 --> 00:51:35,140
recreating things that we already have
 

2411
00:51:35,140 --> 00:51:36,960
recreating things that we already have
when we could when we could create

2412
00:51:36,960 --> 00:51:36,970
when we could when we could create
 

2413
00:51:36,970 --> 00:51:42,630
when we could when we could create
something that's different I know you're

2414
00:51:42,630 --> 00:51:42,640
something that's different I know you're
 

2415
00:51:42,640 --> 00:51:43,950
something that's different I know you're
thinking about the people who like don't

2416
00:51:43,950 --> 00:51:43,960
thinking about the people who like don't
 

2417
00:51:43,960 --> 00:51:45,960
thinking about the people who like don't
have a husband and like what could we

2418
00:51:45,960 --> 00:51:45,970
have a husband and like what could we
 

2419
00:51:45,970 --> 00:51:50,040
have a husband and like what could we
give them yeah but but let's I guess

2420
00:51:50,040 --> 00:51:50,050
give them yeah but but let's I guess
 

2421
00:51:50,050 --> 00:51:54,480
give them yeah but but let's I guess
what I'm getting at is maybe not so like

2422
00:51:54,480 --> 00:51:54,490
what I'm getting at is maybe not so like
 

2423
00:51:54,490 --> 00:51:59,760
what I'm getting at is maybe not so like
the movie her yeah right so a better

2424
00:51:59,760 --> 00:51:59,770
the movie her yeah right so a better
 

2425
00:51:59,770 --> 00:52:02,550
the movie her yeah right so a better
husband well may be better in some ways

2426
00:52:02,550 --> 00:52:02,560
husband well may be better in some ways
 

2427
00:52:02,560 --> 00:52:05,130
husband well may be better in some ways
like it's I I do think that robots are

2428
00:52:05,130 --> 00:52:05,140
like it's I I do think that robots are
 

2429
00:52:05,140 --> 00:52:05,580
like it's I I do think that robots are
going to

2430
00:52:05,580 --> 00:52:05,590
going to
 

2431
00:52:05,590 --> 00:52:07,680
going to
continued to be a different type of

2432
00:52:07,680 --> 00:52:07,690
continued to be a different type of
 

2433
00:52:07,690 --> 00:52:10,110
continued to be a different type of
relationship even if we get them like

2434
00:52:10,110 --> 00:52:10,120
relationship even if we get them like
 

2435
00:52:10,120 --> 00:52:12,870
relationship even if we get them like
very human looking or when you know the

2436
00:52:12,870 --> 00:52:12,880
very human looking or when you know the
 

2437
00:52:12,880 --> 00:52:14,640
very human looking or when you know the
voice interactions we have with them

2438
00:52:14,640 --> 00:52:14,650
voice interactions we have with them
 

2439
00:52:14,650 --> 00:52:16,830
voice interactions we have with them
feel very like natural and human like I

2440
00:52:16,830 --> 00:52:16,840
feel very like natural and human like I
 

2441
00:52:16,840 --> 00:52:19,470
feel very like natural and human like I
think they're still gonna be differences

2442
00:52:19,470 --> 00:52:19,480
think they're still gonna be differences
 

2443
00:52:19,480 --> 00:52:21,240
think they're still gonna be differences
and there were in that movie too like

2444
00:52:21,240 --> 00:52:21,250
and there were in that movie too like
 

2445
00:52:21,250 --> 00:52:22,710
and there were in that movie too like
towards the end yeah it goes off the

2446
00:52:22,710 --> 00:52:22,720
towards the end yeah it goes off the
 

2447
00:52:22,720 --> 00:52:24,630
towards the end yeah it goes off the
rails it's just a movie so that your

2448
00:52:24,630 --> 00:52:24,640
rails it's just a movie so that your
 

2449
00:52:24,640 --> 00:52:29,250
rails it's just a movie so that your
intuition is that that because because

2450
00:52:29,250 --> 00:52:29,260
intuition is that that because because
 

2451
00:52:29,260 --> 00:52:31,980
intuition is that that because because
you kind of said two things right so one

2452
00:52:31,980 --> 00:52:31,990
you kind of said two things right so one
 

2453
00:52:31,990 --> 00:52:36,050
you kind of said two things right so one
is why would you want to basically

2454
00:52:36,050 --> 00:52:36,060
is why would you want to basically
 

2455
00:52:36,060 --> 00:52:39,510
is why would you want to basically
replicate the husband Yeah right and the

2456
00:52:39,510 --> 00:52:39,520
replicate the husband Yeah right and the
 

2457
00:52:39,520 --> 00:52:42,450
replicate the husband Yeah right and the
other is kind of implying that it's kind

2458
00:52:42,450 --> 00:52:42,460
other is kind of implying that it's kind
 

2459
00:52:42,460 --> 00:52:45,780
other is kind of implying that it's kind
of hard to do so you like anytime you

2460
00:52:45,780 --> 00:52:45,790
of hard to do so you like anytime you
 

2461
00:52:45,790 --> 00:52:47,910
of hard to do so you like anytime you
try you might build something very

2462
00:52:47,910 --> 00:52:47,920
try you might build something very
 

2463
00:52:47,920 --> 00:52:50,450
try you might build something very
impressive but it'll be different I

2464
00:52:50,450 --> 00:52:50,460
impressive but it'll be different I
 

2465
00:52:50,460 --> 00:52:53,490
impressive but it'll be different I
guess my question is about human nature

2466
00:52:53,490 --> 00:52:53,500
guess my question is about human nature
 

2467
00:52:53,500 --> 00:52:58,950
guess my question is about human nature
it's like how hard is it to satisfy that

2468
00:52:58,950 --> 00:52:58,960
it's like how hard is it to satisfy that
 

2469
00:52:58,960 --> 00:53:01,980
it's like how hard is it to satisfy that
role of the husband so removing any of

2470
00:53:01,980 --> 00:53:01,990
role of the husband so removing any of
 

2471
00:53:01,990 --> 00:53:05,820
role of the husband so removing any of
the sexual stuff aside is the is more

2472
00:53:05,820 --> 00:53:05,830
the sexual stuff aside is the is more
 

2473
00:53:05,830 --> 00:53:08,220
the sexual stuff aside is the is more
like the mystery detention the dance of

2474
00:53:08,220 --> 00:53:08,230
like the mystery detention the dance of
 

2475
00:53:08,230 --> 00:53:10,860
like the mystery detention the dance of
relationships you think with robots

2476
00:53:10,860 --> 00:53:10,870
relationships you think with robots
 

2477
00:53:10,870 --> 00:53:13,710
relationships you think with robots
that's difficult to build what's you I

2478
00:53:13,710 --> 00:53:13,720
that's difficult to build what's you I
 

2479
00:53:13,720 --> 00:53:18,750
that's difficult to build what's you I
think that well it also depends I'm not

2480
00:53:18,750 --> 00:53:18,760
think that well it also depends I'm not
 

2481
00:53:18,760 --> 00:53:21,720
think that well it also depends I'm not
reading about robots now in 50 years in

2482
00:53:21,720 --> 00:53:21,730
reading about robots now in 50 years in
 

2483
00:53:21,730 --> 00:53:24,600
reading about robots now in 50 years in
like indefinite amount of time where I'm

2484
00:53:24,600 --> 00:53:24,610
like indefinite amount of time where I'm
 

2485
00:53:24,610 --> 00:53:26,220
like indefinite amount of time where I'm
thinking abilities five or ten years

2486
00:53:26,220 --> 00:53:26,230
thinking abilities five or ten years
 

2487
00:53:26,230 --> 00:53:28,650
thinking abilities five or ten years
five or ten years I think that robots at

2488
00:53:28,650 --> 00:53:28,660
five or ten years I think that robots at
 

2489
00:53:28,660 --> 00:53:32,280
five or ten years I think that robots at
best will be like a more similar to the

2490
00:53:32,280 --> 00:53:32,290
best will be like a more similar to the
 

2491
00:53:32,290 --> 00:53:34,110
best will be like a more similar to the
relationship we have with our pets than

2492
00:53:34,110 --> 00:53:34,120
relationship we have with our pets than
 

2493
00:53:34,120 --> 00:53:35,280
relationship we have with our pets than
relationship that we have with other

2494
00:53:35,280 --> 00:53:35,290
relationship that we have with other
 

2495
00:53:35,290 --> 00:53:38,430
relationship that we have with other
people I got it so what do you think it

2496
00:53:38,430 --> 00:53:38,440
people I got it so what do you think it
 

2497
00:53:38,440 --> 00:53:42,180
people I got it so what do you think it
takes to build a system that exhibits

2498
00:53:42,180 --> 00:53:42,190
takes to build a system that exhibits
 

2499
00:53:42,190 --> 00:53:43,590
takes to build a system that exhibits
greater and greater levels of

2500
00:53:43,590 --> 00:53:43,600
greater and greater levels of
 

2501
00:53:43,600 --> 00:53:45,660
greater and greater levels of
intelligence like it impresses us with

2502
00:53:45,660 --> 00:53:45,670
intelligence like it impresses us with
 

2503
00:53:45,670 --> 00:53:48,330
intelligence like it impresses us with
its intelligence you know a Roomba so

2504
00:53:48,330 --> 00:53:48,340
its intelligence you know a Roomba so
 

2505
00:53:48,340 --> 00:53:49,830
its intelligence you know a Roomba so
you talk about ethical moral ization

2506
00:53:49,830 --> 00:53:49,840
you talk about ethical moral ization
 

2507
00:53:49,840 --> 00:53:53,310
you talk about ethical moral ization
that doesn't i think intelligence is not

2508
00:53:53,310 --> 00:53:53,320
that doesn't i think intelligence is not
 

2509
00:53:53,320 --> 00:53:54,900
that doesn't i think intelligence is not
required if i can tell us probably gets

2510
00:53:54,900 --> 00:53:54,910
required if i can tell us probably gets
 

2511
00:53:54,910 --> 00:53:57,260
required if i can tell us probably gets
in the way sometimes like you mentioned

2512
00:53:57,260 --> 00:53:57,270
in the way sometimes like you mentioned
 

2513
00:53:57,270 --> 00:54:02,220
in the way sometimes like you mentioned
but what do you think it takes to create

2514
00:54:02,220 --> 00:54:02,230
but what do you think it takes to create
 

2515
00:54:02,230 --> 00:54:05,610
but what do you think it takes to create
a system where we sense that it has a

2516
00:54:05,610 --> 00:54:05,620
a system where we sense that it has a
 

2517
00:54:05,620 --> 00:54:08,630
a system where we sense that it has a
human level intelligence something that

2518
00:54:08,630 --> 00:54:08,640
human level intelligence something that
 

2519
00:54:08,640 --> 00:54:11,370
human level intelligence something that
obviously something conversational human

2520
00:54:11,370 --> 00:54:11,380
obviously something conversational human
 

2521
00:54:11,380 --> 00:54:14,010
obviously something conversational human
level intelligence that problem is it'd

2522
00:54:14,010 --> 00:54:14,020
level intelligence that problem is it'd
 

2523
00:54:14,020 --> 00:54:15,420
level intelligence that problem is it'd
be interesting to sort of hear your

2524
00:54:15,420 --> 00:54:15,430
be interesting to sort of hear your
 

2525
00:54:15,430 --> 00:54:17,940
be interesting to sort of hear your
perspective not

2526
00:54:17,940 --> 00:54:17,950
perspective not
 

2527
00:54:17,950 --> 00:54:19,770
perspective not
just purely that talked to a lot of

2528
00:54:19,770 --> 00:54:19,780
just purely that talked to a lot of
 

2529
00:54:19,780 --> 00:54:22,200
just purely that talked to a lot of
people how hard is the conversational

2530
00:54:22,200 --> 00:54:22,210
people how hard is the conversational
 

2531
00:54:22,210 --> 00:54:24,660
people how hard is the conversational
agents yeah how hard is it to pass a

2532
00:54:24,660 --> 00:54:24,670
agents yeah how hard is it to pass a
 

2533
00:54:24,670 --> 00:54:25,410
agents yeah how hard is it to pass a
Turing test

2534
00:54:25,410 --> 00:54:25,420
Turing test
 

2535
00:54:25,420 --> 00:54:30,750
Turing test
but my sense is it's it's easier than

2536
00:54:30,750 --> 00:54:30,760
but my sense is it's it's easier than
 

2537
00:54:30,760 --> 00:54:33,089
but my sense is it's it's easier than
just solving it's easier than solving

2538
00:54:33,089 --> 00:54:33,099
just solving it's easier than solving
 

2539
00:54:33,099 --> 00:54:34,740
just solving it's easier than solving
the pure and natural language processing

2540
00:54:34,740 --> 00:54:34,750
the pure and natural language processing
 

2541
00:54:34,750 --> 00:54:37,589
the pure and natural language processing
problem because I feel like you can

2542
00:54:37,589 --> 00:54:37,599
problem because I feel like you can
 

2543
00:54:37,599 --> 00:54:42,089
problem because I feel like you can
cheat yeah so yeah so how hard is it to

2544
00:54:42,089 --> 00:54:42,099
cheat yeah so yeah so how hard is it to
 

2545
00:54:42,099 --> 00:54:44,490
cheat yeah so yeah so how hard is it to
pass the Turing test any of you I well I

2546
00:54:44,490 --> 00:54:44,500
pass the Turing test any of you I well I
 

2547
00:54:44,500 --> 00:54:46,770
pass the Turing test any of you I well I
think again it's all about expectation

2548
00:54:46,770 --> 00:54:46,780
think again it's all about expectation
 

2549
00:54:46,780 --> 00:54:48,660
think again it's all about expectation
management if you set up people's

2550
00:54:48,660 --> 00:54:48,670
management if you set up people's
 

2551
00:54:48,670 --> 00:54:50,609
management if you set up people's
expectations to think that they're

2552
00:54:50,609 --> 00:54:50,619
expectations to think that they're
 

2553
00:54:50,619 --> 00:54:53,310
expectations to think that they're
communicating with what was it a 13 year

2554
00:54:53,310 --> 00:54:53,320
communicating with what was it a 13 year
 

2555
00:54:53,320 --> 00:54:54,810
communicating with what was it a 13 year
old boy from the Ukraine yeah that's

2556
00:54:54,810 --> 00:54:54,820
old boy from the Ukraine yeah that's
 

2557
00:54:54,820 --> 00:54:55,410
old boy from the Ukraine yeah that's
right

2558
00:54:55,410 --> 00:54:55,420
right
 

2559
00:54:55,420 --> 00:54:57,030
right
then they're not going to expect perfect

2560
00:54:57,030 --> 00:54:57,040
then they're not going to expect perfect
 

2561
00:54:57,040 --> 00:54:58,710
then they're not going to expect perfect
English they're not going to expect

2562
00:54:58,710 --> 00:54:58,720
English they're not going to expect
 

2563
00:54:58,720 --> 00:55:00,450
English they're not going to expect
perfect you know understanding of

2564
00:55:00,450 --> 00:55:00,460
perfect you know understanding of
 

2565
00:55:00,460 --> 00:55:02,310
perfect you know understanding of
concepts or even like being on the same

2566
00:55:02,310 --> 00:55:02,320
concepts or even like being on the same
 

2567
00:55:02,320 --> 00:55:05,160
concepts or even like being on the same
wavelength in terms of like conversation

2568
00:55:05,160 --> 00:55:05,170
wavelength in terms of like conversation
 

2569
00:55:05,170 --> 00:55:08,280
wavelength in terms of like conversation
flow so it's much easier to pass in that

2570
00:55:08,280 --> 00:55:08,290
flow so it's much easier to pass in that
 

2571
00:55:08,290 --> 00:55:13,020
flow so it's much easier to pass in that
case do you think you kind of alluded

2572
00:55:13,020 --> 00:55:13,030
case do you think you kind of alluded
 

2573
00:55:13,030 --> 00:55:15,450
case do you think you kind of alluded
this to with audio do you think it needs

2574
00:55:15,450 --> 00:55:15,460
this to with audio do you think it needs
 

2575
00:55:15,460 --> 00:55:18,810
this to with audio do you think it needs
to have a body I think that we

2576
00:55:18,810 --> 00:55:18,820
to have a body I think that we
 

2577
00:55:18,820 --> 00:55:22,500
to have a body I think that we
definitely have so we treat physical

2578
00:55:22,500 --> 00:55:22,510
definitely have so we treat physical
 

2579
00:55:22,510 --> 00:55:25,140
definitely have so we treat physical
things with more social agency because

2580
00:55:25,140 --> 00:55:25,150
things with more social agency because
 

2581
00:55:25,150 --> 00:55:26,970
things with more social agency because
we're very physical creatures I think a

2582
00:55:26,970 --> 00:55:26,980
we're very physical creatures I think a
 

2583
00:55:26,980 --> 00:55:33,900
we're very physical creatures I think a
body can be useful does it get in the

2584
00:55:33,900 --> 00:55:33,910
body can be useful does it get in the
 

2585
00:55:33,910 --> 00:55:37,200
body can be useful does it get in the
way is there negative aspects like yeah

2586
00:55:37,200 --> 00:55:37,210
way is there negative aspects like yeah
 

2587
00:55:37,210 --> 00:55:39,329
way is there negative aspects like yeah
there can be so if you're trying to

2588
00:55:39,329 --> 00:55:39,339
there can be so if you're trying to
 

2589
00:55:39,339 --> 00:55:40,859
there can be so if you're trying to
create a body that's too similar to

2590
00:55:40,859 --> 00:55:40,869
create a body that's too similar to
 

2591
00:55:40,869 --> 00:55:42,329
create a body that's too similar to
something that people are familiar with

2592
00:55:42,329 --> 00:55:42,339
something that people are familiar with
 

2593
00:55:42,339 --> 00:55:44,520
something that people are familiar with
like I have this robot cat at home that

2594
00:55:44,520 --> 00:55:44,530
like I have this robot cat at home that
 

2595
00:55:44,530 --> 00:55:48,270
like I have this robot cat at home that
Hasbro makes and it's very disturbing to

2596
00:55:48,270 --> 00:55:48,280
Hasbro makes and it's very disturbing to
 

2597
00:55:48,280 --> 00:55:50,760
Hasbro makes and it's very disturbing to
watch because I'm constantly assuming

2598
00:55:50,760 --> 00:55:50,770
watch because I'm constantly assuming
 

2599
00:55:50,770 --> 00:55:52,650
watch because I'm constantly assuming
that it's gonna move like a real cat and

2600
00:55:52,650 --> 00:55:52,660
that it's gonna move like a real cat and
 

2601
00:55:52,660 --> 00:55:54,270
that it's gonna move like a real cat and
it doesn't because it's like a 100

2602
00:55:54,270 --> 00:55:54,280
it doesn't because it's like a 100
 

2603
00:55:54,280 --> 00:55:57,839
it doesn't because it's like a 100
dollar piece of technology so it's very

2604
00:55:57,839 --> 00:55:57,849
dollar piece of technology so it's very
 

2605
00:55:57,849 --> 00:56:01,559
dollar piece of technology so it's very
like disappointing and it's very hard to

2606
00:56:01,559 --> 00:56:01,569
like disappointing and it's very hard to
 

2607
00:56:01,569 --> 00:56:04,530
like disappointing and it's very hard to
treat it like it's alive so you can get

2608
00:56:04,530 --> 00:56:04,540
treat it like it's alive so you can get
 

2609
00:56:04,540 --> 00:56:06,300
treat it like it's alive so you can get
a lot wrong with the body too but you

2610
00:56:06,300 --> 00:56:06,310
a lot wrong with the body too but you
 

2611
00:56:06,310 --> 00:56:09,240
a lot wrong with the body too but you
can also use tricks same as you know the

2612
00:56:09,240 --> 00:56:09,250
can also use tricks same as you know the
 

2613
00:56:09,250 --> 00:56:10,800
can also use tricks same as you know the
expectation management of the 13 year

2614
00:56:10,800 --> 00:56:10,810
expectation management of the 13 year
 

2615
00:56:10,810 --> 00:56:12,569
expectation management of the 13 year
old boy from the Ukraine if you pick an

2616
00:56:12,569 --> 00:56:12,579
old boy from the Ukraine if you pick an
 

2617
00:56:12,579 --> 00:56:14,099
old boy from the Ukraine if you pick an
animal that people aren't intimately

2618
00:56:14,099 --> 00:56:14,109
animal that people aren't intimately
 

2619
00:56:14,109 --> 00:56:16,140
animal that people aren't intimately
familiar with like the baby dinosaur

2620
00:56:16,140 --> 00:56:16,150
familiar with like the baby dinosaur
 

2621
00:56:16,150 --> 00:56:17,730
familiar with like the baby dinosaur
like the baby seal that people have

2622
00:56:17,730 --> 00:56:17,740
like the baby seal that people have
 

2623
00:56:17,740 --> 00:56:20,280
like the baby seal that people have
never actually held in their arms you

2624
00:56:20,280 --> 00:56:20,290
never actually held in their arms you
 

2625
00:56:20,290 --> 00:56:21,839
never actually held in their arms you
can get away with much more because they

2626
00:56:21,839 --> 00:56:21,849
can get away with much more because they
 

2627
00:56:21,849 --> 00:56:23,880
can get away with much more because they
don't have these preformed expectations

2628
00:56:23,880 --> 00:56:23,890
don't have these preformed expectations
 

2629
00:56:23,890 --> 00:56:26,520
don't have these preformed expectations
yeah I'm thinking a TED talk or

2630
00:56:26,520 --> 00:56:26,530
yeah I'm thinking a TED talk or
 

2631
00:56:26,530 --> 00:56:28,730
yeah I'm thinking a TED talk or
something that clicked for me that

2632
00:56:28,730 --> 00:56:28,740
something that clicked for me that
 

2633
00:56:28,740 --> 00:56:30,990
something that clicked for me that
nobody actually knows what a dinosaur

2634
00:56:30,990 --> 00:56:31,000
nobody actually knows what a dinosaur
 

2635
00:56:31,000 --> 00:56:32,210
nobody actually knows what a dinosaur
looks

2636
00:56:32,210 --> 00:56:32,220
looks
 

2637
00:56:32,220 --> 00:56:34,589
looks
so you can actually get away with a lot

2638
00:56:34,589 --> 00:56:34,599
so you can actually get away with a lot
 

2639
00:56:34,599 --> 00:56:37,380
so you can actually get away with a lot
more that was great

2640
00:56:37,380 --> 00:56:37,390
more that was great
 

2641
00:56:37,390 --> 00:56:40,859
more that was great
do you think he needs so what do you

2642
00:56:40,859 --> 00:56:40,869
do you think he needs so what do you
 

2643
00:56:40,869 --> 00:56:45,650
do you think he needs so what do you
think about consciousness and mortality

2644
00:56:45,650 --> 00:56:45,660
think about consciousness and mortality
 

2645
00:56:45,660 --> 00:56:50,549
think about consciousness and mortality
being displayed in a robot so not

2646
00:56:50,549 --> 00:56:50,559
being displayed in a robot so not
 

2647
00:56:50,559 --> 00:56:55,109
being displayed in a robot so not
actually having consciousness but having

2648
00:56:55,109 --> 00:56:55,119
actually having consciousness but having
 

2649
00:56:55,119 --> 00:56:57,240
actually having consciousness but having
these kind of human elements that are

2650
00:56:57,240 --> 00:56:57,250
these kind of human elements that are
 

2651
00:56:57,250 --> 00:57:00,569
these kind of human elements that are
much more than just the interaction much

2652
00:57:00,569 --> 00:57:00,579
much more than just the interaction much
 

2653
00:57:00,579 --> 00:57:02,760
much more than just the interaction much
more than just like you mentioned with a

2654
00:57:02,760 --> 00:57:02,770
more than just like you mentioned with a
 

2655
00:57:02,770 --> 00:57:05,700
more than just like you mentioned with a
dinosaur moving kind of interesting ways

2656
00:57:05,700 --> 00:57:05,710
dinosaur moving kind of interesting ways
 

2657
00:57:05,710 --> 00:57:08,460
dinosaur moving kind of interesting ways
but really being worried about its own

2658
00:57:08,460 --> 00:57:08,470
but really being worried about its own
 

2659
00:57:08,470 --> 00:57:13,500
but really being worried about its own
death and really acting as if it's aware

2660
00:57:13,500 --> 00:57:13,510
death and really acting as if it's aware
 

2661
00:57:13,510 --> 00:57:15,779
death and really acting as if it's aware
and self-aware and identity have you

2662
00:57:15,779 --> 00:57:15,789
and self-aware and identity have you
 

2663
00:57:15,789 --> 00:57:18,029
and self-aware and identity have you
seen that done in robotics what do you

2664
00:57:18,029 --> 00:57:18,039
seen that done in robotics what do you
 

2665
00:57:18,039 --> 00:57:20,849
seen that done in robotics what do you
think about doing that I think it does

2666
00:57:20,849 --> 00:57:20,859
think about doing that I think it does
 

2667
00:57:20,859 --> 00:57:23,839
think about doing that I think it does
is that a is that a powerful good thing

2668
00:57:23,839 --> 00:57:23,849
is that a is that a powerful good thing
 

2669
00:57:23,849 --> 00:57:27,120
is that a is that a powerful good thing
well it's a I think it can be a design

2670
00:57:27,120 --> 00:57:27,130
well it's a I think it can be a design
 

2671
00:57:27,130 --> 00:57:28,589
well it's a I think it can be a design
tool that you can use for different

2672
00:57:28,589 --> 00:57:28,599
tool that you can use for different
 

2673
00:57:28,599 --> 00:57:30,059
tool that you can use for different
purposes so I can't say whether it's

2674
00:57:30,059 --> 00:57:30,069
purposes so I can't say whether it's
 

2675
00:57:30,069 --> 00:57:32,039
purposes so I can't say whether it's
inherently good or bad but I do think it

2676
00:57:32,039 --> 00:57:32,049
inherently good or bad but I do think it
 

2677
00:57:32,049 --> 00:57:35,549
inherently good or bad but I do think it
can be a powerful tool the fact that the

2678
00:57:35,549 --> 00:57:35,559
can be a powerful tool the fact that the
 

2679
00:57:35,559 --> 00:57:37,700
can be a powerful tool the fact that the
you know Clio

2680
00:57:37,700 --> 00:57:37,710
you know Clio
 

2681
00:57:37,710 --> 00:57:40,650
you know Clio
mimics distress when you quote-unquote

2682
00:57:40,650 --> 00:57:40,660
mimics distress when you quote-unquote
 

2683
00:57:40,660 --> 00:57:44,000
mimics distress when you quote-unquote
would hurt it his is a really powerful

2684
00:57:44,000 --> 00:57:44,010
would hurt it his is a really powerful
 

2685
00:57:44,010 --> 00:57:47,640
would hurt it his is a really powerful
tool to get people to engage with it in

2686
00:57:47,640 --> 00:57:47,650
tool to get people to engage with it in
 

2687
00:57:47,650 --> 00:57:50,430
tool to get people to engage with it in
a certain way I had a research partner

2688
00:57:50,430 --> 00:57:50,440
a certain way I had a research partner
 

2689
00:57:50,440 --> 00:57:52,260
a certain way I had a research partner
that I did some of the empathy work with

2690
00:57:52,260 --> 00:57:52,270
that I did some of the empathy work with
 

2691
00:57:52,270 --> 00:57:54,599
that I did some of the empathy work with
named Kailash Nandi and he had built a

2692
00:57:54,599 --> 00:57:54,609
named Kailash Nandi and he had built a
 

2693
00:57:54,609 --> 00:57:56,849
named Kailash Nandi and he had built a
robot for himself that had like a life

2694
00:57:56,849 --> 00:57:56,859
robot for himself that had like a life
 

2695
00:57:56,859 --> 00:57:59,039
robot for himself that had like a life
span and that would stop working after a

2696
00:57:59,039 --> 00:57:59,049
span and that would stop working after a
 

2697
00:57:59,049 --> 00:58:01,079
span and that would stop working after a
certain amount of time just because he

2698
00:58:01,079 --> 00:58:01,089
certain amount of time just because he
 

2699
00:58:01,089 --> 00:58:02,460
certain amount of time just because he
was interested in like whether he

2700
00:58:02,460 --> 00:58:02,470
was interested in like whether he
 

2701
00:58:02,470 --> 00:58:04,339
was interested in like whether he
himself would treat it differently and

2702
00:58:04,339 --> 00:58:04,349
himself would treat it differently and
 

2703
00:58:04,349 --> 00:58:07,680
himself would treat it differently and
we know from you know Tamagotchis those

2704
00:58:07,680 --> 00:58:07,690
we know from you know Tamagotchis those
 

2705
00:58:07,690 --> 00:58:10,170
we know from you know Tamagotchis those
like those little games that that we

2706
00:58:10,170 --> 00:58:10,180
like those little games that that we
 

2707
00:58:10,180 --> 00:58:11,549
like those little games that that we
used to have that we're extremely

2708
00:58:11,549 --> 00:58:11,559
used to have that we're extremely
 

2709
00:58:11,559 --> 00:58:13,230
used to have that we're extremely
primitive that like people respond to

2710
00:58:13,230 --> 00:58:13,240
primitive that like people respond to
 

2711
00:58:13,240 --> 00:58:16,589
primitive that like people respond to
like this idea of mortality and you know

2712
00:58:16,589 --> 00:58:16,599
like this idea of mortality and you know
 

2713
00:58:16,599 --> 00:58:18,990
like this idea of mortality and you know
you can get people to do a lot with

2714
00:58:18,990 --> 00:58:19,000
you can get people to do a lot with
 

2715
00:58:19,000 --> 00:58:21,029
you can get people to do a lot with
little design tricks like that now

2716
00:58:21,029 --> 00:58:21,039
little design tricks like that now
 

2717
00:58:21,039 --> 00:58:22,079
little design tricks like that now
whether it's a good thing depends on

2718
00:58:22,079 --> 00:58:22,089
whether it's a good thing depends on
 

2719
00:58:22,089 --> 00:58:23,630
whether it's a good thing depends on
what you're trying to get them to do

2720
00:58:23,630 --> 00:58:23,640
what you're trying to get them to do
 

2721
00:58:23,640 --> 00:58:27,480
what you're trying to get them to do
have a deeper relationship have a deeper

2722
00:58:27,480 --> 00:58:27,490
have a deeper relationship have a deeper
 

2723
00:58:27,490 --> 00:58:29,609
have a deeper relationship have a deeper
connection sign a relationship if it's

2724
00:58:29,609 --> 00:58:29,619
connection sign a relationship if it's
 

2725
00:58:29,619 --> 00:58:32,010
connection sign a relationship if it's
for their own benefit that sounds great

2726
00:58:32,010 --> 00:58:32,020
for their own benefit that sounds great
 

2727
00:58:32,020 --> 00:58:37,319
for their own benefit that sounds great
okay a lot of other reasons I see so

2728
00:58:37,319 --> 00:58:37,329
okay a lot of other reasons I see so
 

2729
00:58:37,329 --> 00:58:38,460
okay a lot of other reasons I see so
what kind of stuff are you worried about

2730
00:58:38,460 --> 00:58:38,470
what kind of stuff are you worried about
 

2731
00:58:38,470 --> 00:58:40,589
what kind of stuff are you worried about
so is this a mostly about manipulation

2732
00:58:40,589 --> 00:58:40,599
so is this a mostly about manipulation
 

2733
00:58:40,599 --> 00:58:42,839
so is this a mostly about manipulation
of your emotions for like advertisement

2734
00:58:42,839 --> 00:58:42,849
of your emotions for like advertisement
 

2735
00:58:42,849 --> 00:58:43,769
of your emotions for like advertisement
so on things like that

2736
00:58:43,769 --> 00:58:43,779
so on things like that
 

2737
00:58:43,779 --> 00:58:45,450
so on things like that
yeah or data collect

2738
00:58:45,450 --> 00:58:45,460
yeah or data collect
 

2739
00:58:45,460 --> 00:58:47,640
yeah or data collect
I mean you could think of governments

2740
00:58:47,640 --> 00:58:47,650
I mean you could think of governments
 

2741
00:58:47,650 --> 00:58:50,790
I mean you could think of governments
misusing this to extract information

2742
00:58:50,790 --> 00:58:50,800
misusing this to extract information
 

2743
00:58:50,800 --> 00:58:55,079
misusing this to extract information
from people it's you know just just like

2744
00:58:55,079 --> 00:58:55,089
from people it's you know just just like
 

2745
00:58:55,089 --> 00:58:57,000
from people it's you know just just like
any other technological tool just raises

2746
00:58:57,000 --> 00:58:57,010
any other technological tool just raises
 

2747
00:58:57,010 --> 00:58:58,670
any other technological tool just raises
a lot of questions

2748
00:58:58,670 --> 00:58:58,680
a lot of questions
 

2749
00:58:58,680 --> 00:59:01,200
a lot of questions
what's if you if you look at Facebook if

2750
00:59:01,200 --> 00:59:01,210
what's if you if you look at Facebook if
 

2751
00:59:01,210 --> 00:59:02,700
what's if you if you look at Facebook if
you look at Twitter and social networks

2752
00:59:02,700 --> 00:59:02,710
you look at Twitter and social networks
 

2753
00:59:02,710 --> 00:59:03,750
you look at Twitter and social networks
there's a lot of concern of data

2754
00:59:03,750 --> 00:59:03,760
there's a lot of concern of data
 

2755
00:59:03,760 --> 00:59:09,390
there's a lot of concern of data
collection now how what's from the legal

2756
00:59:09,390 --> 00:59:09,400
collection now how what's from the legal
 

2757
00:59:09,400 --> 00:59:13,220
collection now how what's from the legal
perspective or in general how do we

2758
00:59:13,220 --> 00:59:13,230
perspective or in general how do we
 

2759
00:59:13,230 --> 00:59:17,310
perspective or in general how do we
prevent the violation of sort of these

2760
00:59:17,310 --> 00:59:17,320
prevent the violation of sort of these
 

2761
00:59:17,320 --> 00:59:19,470
prevent the violation of sort of these
companies crossing a line it's a gray

2762
00:59:19,470 --> 00:59:19,480
companies crossing a line it's a gray
 

2763
00:59:19,480 --> 00:59:21,450
companies crossing a line it's a gray
area but crossing a line they shouldn't

2764
00:59:21,450 --> 00:59:21,460
area but crossing a line they shouldn't
 

2765
00:59:21,460 --> 00:59:23,880
area but crossing a line they shouldn't
in terms of manipulating like we're

2766
00:59:23,880 --> 00:59:23,890
in terms of manipulating like we're
 

2767
00:59:23,890 --> 00:59:25,829
in terms of manipulating like we're
talking about a manipulating our emotion

2768
00:59:25,829 --> 00:59:25,839
talking about a manipulating our emotion
 

2769
00:59:25,839 --> 00:59:29,220
talking about a manipulating our emotion
manipulating our behavior using tactics

2770
00:59:29,220 --> 00:59:29,230
manipulating our behavior using tactics
 

2771
00:59:29,230 --> 00:59:32,820
manipulating our behavior using tactics
that are not so savory yeah it's it's

2772
00:59:32,820 --> 00:59:32,830
that are not so savory yeah it's it's
 

2773
00:59:32,830 --> 00:59:36,930
that are not so savory yeah it's it's
really difficult because we are starting

2774
00:59:36,930 --> 00:59:36,940
really difficult because we are starting
 

2775
00:59:36,940 --> 00:59:39,240
really difficult because we are starting
to create technology that relies on data

2776
00:59:39,240 --> 00:59:39,250
to create technology that relies on data
 

2777
00:59:39,250 --> 00:59:42,390
to create technology that relies on data
collection to provide functionality and

2778
00:59:42,390 --> 00:59:42,400
collection to provide functionality and
 

2779
00:59:42,400 --> 00:59:45,270
collection to provide functionality and
there's not a lot of incentive even on

2780
00:59:45,270 --> 00:59:45,280
there's not a lot of incentive even on
 

2781
00:59:45,280 --> 00:59:47,040
there's not a lot of incentive even on
the consumer side to curb that because

2782
00:59:47,040 --> 00:59:47,050
the consumer side to curb that because
 

2783
00:59:47,050 --> 00:59:48,750
the consumer side to curb that because
the other problem is that the harms

2784
00:59:48,750 --> 00:59:48,760
the other problem is that the harms
 

2785
00:59:48,760 --> 00:59:51,630
the other problem is that the harms
aren't tangible they're not really

2786
00:59:51,630 --> 00:59:51,640
aren't tangible they're not really
 

2787
00:59:51,640 --> 00:59:54,060
aren't tangible they're not really
apparent to a lot of people because they

2788
00:59:54,060 --> 00:59:54,070
apparent to a lot of people because they
 

2789
00:59:54,070 --> 00:59:55,710
apparent to a lot of people because they
kind of trickle down on a societal level

2790
00:59:55,710 --> 00:59:55,720
kind of trickle down on a societal level
 

2791
00:59:55,720 --> 00:59:57,660
kind of trickle down on a societal level
and then suddenly we're living in like

2792
00:59:57,660 --> 00:59:57,670
and then suddenly we're living in like
 

2793
00:59:57,670 --> 01:00:02,420
and then suddenly we're living in like
1984 which you know sounds extreme but

2794
01:00:02,420 --> 01:00:02,430
1984 which you know sounds extreme but
 

2795
01:00:02,430 --> 01:00:05,790
1984 which you know sounds extreme but
that book was very prescient and I'm not

2796
01:00:05,790 --> 01:00:05,800
that book was very prescient and I'm not
 

2797
01:00:05,800 --> 01:00:09,599
that book was very prescient and I'm not
worried about you know these systems you

2798
01:00:09,599 --> 01:00:09,609
worried about you know these systems you
 

2799
01:00:09,609 --> 01:00:13,050
worried about you know these systems you
know I I I have you know Amazon's echo

2800
01:00:13,050 --> 01:00:13,060
know I I I have you know Amazon's echo
 

2801
01:00:13,060 --> 01:00:16,020
know I I I have you know Amazon's echo
at home and and you know tell Alexa all

2802
01:00:16,020 --> 01:00:16,030
at home and and you know tell Alexa all
 

2803
01:00:16,030 --> 01:00:18,930
at home and and you know tell Alexa all
sorts of stuff and and it helps me

2804
01:00:18,930 --> 01:00:18,940
sorts of stuff and and it helps me
 

2805
01:00:18,940 --> 01:00:22,079
sorts of stuff and and it helps me
because you know Alexa knows what you

2806
01:00:22,079 --> 01:00:22,089
because you know Alexa knows what you
 

2807
01:00:22,089 --> 01:00:24,030
because you know Alexa knows what you
know brand of diaper we use and so I can

2808
01:00:24,030 --> 01:00:24,040
know brand of diaper we use and so I can
 

2809
01:00:24,040 --> 01:00:25,680
know brand of diaper we use and so I can
just easily order it again so I don't

2810
01:00:25,680 --> 01:00:25,690
just easily order it again so I don't
 

2811
01:00:25,690 --> 01:00:27,599
just easily order it again so I don't
have any incentive to like ask a

2812
01:00:27,599 --> 01:00:27,609
have any incentive to like ask a
 

2813
01:00:27,609 --> 01:00:30,030
have any incentive to like ask a
lawmaker to curb that but when I think

2814
01:00:30,030 --> 01:00:30,040
lawmaker to curb that but when I think
 

2815
01:00:30,040 --> 01:00:33,300
lawmaker to curb that but when I think
about that data then being used against

2816
01:00:33,300 --> 01:00:33,310
about that data then being used against
 

2817
01:00:33,310 --> 01:00:35,310
about that data then being used against
you know low income people to target

2818
01:00:35,310 --> 01:00:35,320
you know low income people to target
 

2819
01:00:35,320 --> 01:00:37,710
you know low income people to target
them for you know scammy loans or

2820
01:00:37,710 --> 01:00:37,720
them for you know scammy loans or
 

2821
01:00:37,720 --> 01:00:40,320
them for you know scammy loans or
education programs that's then a

2822
01:00:40,320 --> 01:00:40,330
education programs that's then a
 

2823
01:00:40,330 --> 01:00:43,320
education programs that's then a
societal effect that I think is very

2824
01:00:43,320 --> 01:00:43,330
societal effect that I think is very
 

2825
01:00:43,330 --> 01:00:46,109
societal effect that I think is very
severe and you know legislators should

2826
01:00:46,109 --> 01:00:46,119
severe and you know legislators should
 

2827
01:00:46,119 --> 01:00:48,240
severe and you know legislators should
be thinking about well yeah there's the

2828
01:00:48,240 --> 01:00:48,250
be thinking about well yeah there's the
 

2829
01:00:48,250 --> 01:00:52,349
be thinking about well yeah there's the
the Garrett gray area is the removing

2830
01:00:52,349 --> 01:00:52,359
the Garrett gray area is the removing
 

2831
01:00:52,359 --> 01:00:55,099
the Garrett gray area is the removing
ourselves from consideration of like

2832
01:00:55,099 --> 01:00:55,109
ourselves from consideration of like
 

2833
01:00:55,109 --> 01:00:58,219
ourselves from consideration of like
of explicitly defining objectives and

2834
01:00:58,219 --> 01:00:58,229
of explicitly defining objectives and
 

2835
01:00:58,229 --> 01:01:00,349
of explicitly defining objectives and
more saying well we want to maximize

2836
01:01:00,349 --> 01:01:00,359
more saying well we want to maximize
 

2837
01:01:00,359 --> 01:01:03,979
more saying well we want to maximize
engagement in our social network yeah

2838
01:01:03,979 --> 01:01:03,989
engagement in our social network yeah
 

2839
01:01:03,989 --> 01:01:07,279
engagement in our social network yeah
and and then just because you're not

2840
01:01:07,279 --> 01:01:07,289
and and then just because you're not
 

2841
01:01:07,289 --> 01:01:09,199
and and then just because you're not
actually doing a bad thing it makes

2842
01:01:09,199 --> 01:01:09,209
actually doing a bad thing it makes
 

2843
01:01:09,209 --> 01:01:10,039
actually doing a bad thing it makes
sense

2844
01:01:10,039 --> 01:01:10,049
sense
 

2845
01:01:10,049 --> 01:01:12,289
sense
you want people to to keep a

2846
01:01:12,289 --> 01:01:12,299
you want people to to keep a
 

2847
01:01:12,299 --> 01:01:14,209
you want people to to keep a
conversation going to have more

2848
01:01:14,209 --> 01:01:14,219
conversation going to have more
 

2849
01:01:14,219 --> 01:01:16,699
conversation going to have more
conversations to keep coming back again

2850
01:01:16,699 --> 01:01:16,709
conversations to keep coming back again
 

2851
01:01:16,709 --> 01:01:18,910
conversations to keep coming back again
and again to have conversations and

2852
01:01:18,910 --> 01:01:18,920
and again to have conversations and
 

2853
01:01:18,920 --> 01:01:22,519
and again to have conversations and
whatever happens after that you're kind

2854
01:01:22,519 --> 01:01:22,529
whatever happens after that you're kind
 

2855
01:01:22,529 --> 01:01:24,729
whatever happens after that you're kind
of not exactly directly responsible

2856
01:01:24,729 --> 01:01:24,739
of not exactly directly responsible
 

2857
01:01:24,739 --> 01:01:27,920
of not exactly directly responsible
you're only indirectly responsible so

2858
01:01:27,920 --> 01:01:27,930
you're only indirectly responsible so
 

2859
01:01:27,930 --> 01:01:30,249
you're only indirectly responsible so
it's I think it's a really hard problem

2860
01:01:30,249 --> 01:01:30,259
it's I think it's a really hard problem
 

2861
01:01:30,259 --> 01:01:33,949
it's I think it's a really hard problem
do I are you optimistic about us ever

2862
01:01:33,949 --> 01:01:33,959
do I are you optimistic about us ever
 

2863
01:01:33,959 --> 01:01:37,819
do I are you optimistic about us ever
being able to solve it you mean the

2864
01:01:37,819 --> 01:01:37,829
being able to solve it you mean the
 

2865
01:01:37,829 --> 01:01:41,150
being able to solve it you mean the
problem of capitalists like because the

2866
01:01:41,150 --> 01:01:41,160
problem of capitalists like because the
 

2867
01:01:41,160 --> 01:01:43,729
problem of capitalists like because the
problem is that the companies are acting

2868
01:01:43,729 --> 01:01:43,739
problem is that the companies are acting
 

2869
01:01:43,739 --> 01:01:45,650
problem is that the companies are acting
in the company's interests and not in

2870
01:01:45,650 --> 01:01:45,660
in the company's interests and not in
 

2871
01:01:45,660 --> 01:01:47,269
in the company's interests and not in
people's interest and when those

2872
01:01:47,269 --> 01:01:47,279
people's interest and when those
 

2873
01:01:47,279 --> 01:01:50,289
people's interest and when those
interests are aligned that's great but

2874
01:01:50,289 --> 01:01:50,299
interests are aligned that's great but
 

2875
01:01:50,299 --> 01:01:52,880
interests are aligned that's great but
the completely free market doesn't seem

2876
01:01:52,880 --> 01:01:52,890
the completely free market doesn't seem
 

2877
01:01:52,890 --> 01:01:54,049
the completely free market doesn't seem
to work because of this information

2878
01:01:54,049 --> 01:01:54,059
to work because of this information
 

2879
01:01:54,059 --> 01:01:56,859
to work because of this information
asymmetry but it's hard to know how to

2880
01:01:56,859 --> 01:01:56,869
asymmetry but it's hard to know how to
 

2881
01:01:56,869 --> 01:01:59,209
asymmetry but it's hard to know how to
so say you would try to do the right

2882
01:01:59,209 --> 01:01:59,219
so say you would try to do the right
 

2883
01:01:59,219 --> 01:02:01,430
so say you would try to do the right
thing I guess I guess what I'm trying to

2884
01:02:01,430 --> 01:02:01,440
thing I guess I guess what I'm trying to
 

2885
01:02:01,440 --> 01:02:03,229
thing I guess I guess what I'm trying to
say is I'm it's not obvious for these

2886
01:02:03,229 --> 01:02:03,239
say is I'm it's not obvious for these
 

2887
01:02:03,239 --> 01:02:06,529
say is I'm it's not obvious for these
companies what the good thing for

2888
01:02:06,529 --> 01:02:06,539
companies what the good thing for
 

2889
01:02:06,539 --> 01:02:08,900
companies what the good thing for
society is to do like I don't think they

2890
01:02:08,900 --> 01:02:08,910
society is to do like I don't think they
 

2891
01:02:08,910 --> 01:02:13,039
society is to do like I don't think they
sit there and with I don't know whether

2892
01:02:13,039 --> 01:02:13,049
sit there and with I don't know whether
 

2893
01:02:13,049 --> 01:02:15,140
sit there and with I don't know whether
it with a glass of wine and a cat like

2894
01:02:15,140 --> 01:02:15,150
it with a glass of wine and a cat like
 

2895
01:02:15,150 --> 01:02:18,499
it with a glass of wine and a cat like
petting a cat evil cat and and there's

2896
01:02:18,499 --> 01:02:18,509
petting a cat evil cat and and there's
 

2897
01:02:18,509 --> 01:02:20,509
petting a cat evil cat and and there's
two decisions and one of them is good

2898
01:02:20,509 --> 01:02:20,519
two decisions and one of them is good
 

2899
01:02:20,519 --> 01:02:22,729
two decisions and one of them is good
for society one is good for the for the

2900
01:02:22,729 --> 01:02:22,739
for society one is good for the for the
 

2901
01:02:22,739 --> 01:02:25,219
for society one is good for the for the
profit and they choose the profit I

2902
01:02:25,219 --> 01:02:25,229
profit and they choose the profit I
 

2903
01:02:25,229 --> 01:02:27,109
profit and they choose the profit I
think they actually there's a lot of

2904
01:02:27,109 --> 01:02:27,119
think they actually there's a lot of
 

2905
01:02:27,119 --> 01:02:29,719
think they actually there's a lot of
money to be made by doing the the right

2906
01:02:29,719 --> 01:02:29,729
money to be made by doing the the right
 

2907
01:02:29,729 --> 01:02:33,049
money to be made by doing the the right
thing for society like that because

2908
01:02:33,049 --> 01:02:33,059
thing for society like that because
 

2909
01:02:33,059 --> 01:02:36,799
thing for society like that because
Google Facebook have so much cash that

2910
01:02:36,799 --> 01:02:36,809
Google Facebook have so much cash that
 

2911
01:02:36,809 --> 01:02:38,689
Google Facebook have so much cash that
day actually was especially Facebook was

2912
01:02:38,689 --> 01:02:38,699
day actually was especially Facebook was
 

2913
01:02:38,699 --> 01:02:40,430
day actually was especially Facebook was
significantly benefit for making

2914
01:02:40,430 --> 01:02:40,440
significantly benefit for making
 

2915
01:02:40,440 --> 01:02:42,019
significantly benefit for making
decisions that are good for society it's

2916
01:02:42,019 --> 01:02:42,029
decisions that are good for society it's
 

2917
01:02:42,029 --> 01:02:45,259
decisions that are good for society it's
good for their brand right so but I

2918
01:02:45,259 --> 01:02:45,269
good for their brand right so but I
 

2919
01:02:45,269 --> 01:02:47,449
good for their brand right so but I
don't know if they know what society

2920
01:02:47,449 --> 01:02:47,459
don't know if they know what society
 

2921
01:02:47,459 --> 01:02:51,019
don't know if they know what society
that's the we I don't think we know

2922
01:02:51,019 --> 01:02:51,029
that's the we I don't think we know
 

2923
01:02:51,029 --> 01:02:55,059
that's the we I don't think we know
what's good for society in terms of how

2924
01:02:55,059 --> 01:02:55,069
what's good for society in terms of how
 

2925
01:02:55,069 --> 01:02:57,650
what's good for society in terms of how
yeah how we manage the conversation on

2926
01:02:57,650 --> 01:02:57,660
yeah how we manage the conversation on
 

2927
01:02:57,660 --> 01:03:03,109
yeah how we manage the conversation on
Twitter or how we design will talk about

2928
01:03:03,109 --> 01:03:03,119
Twitter or how we design will talk about
 

2929
01:03:03,119 --> 01:03:05,710
Twitter or how we design will talk about
robots like

2930
01:03:05,710 --> 01:03:05,720
robots like
 

2931
01:03:05,720 --> 01:03:08,080
robots like
should we emotionally manipulate you

2932
01:03:08,080 --> 01:03:08,090
should we emotionally manipulate you
 

2933
01:03:08,090 --> 01:03:10,330
should we emotionally manipulate you
into having a deep connection with Alexa

2934
01:03:10,330 --> 01:03:10,340
into having a deep connection with Alexa
 

2935
01:03:10,340 --> 01:03:15,520
into having a deep connection with Alexa
or not yeah yeah you have optimism that

2936
01:03:15,520 --> 01:03:15,530
or not yeah yeah you have optimism that
 

2937
01:03:15,530 --> 01:03:16,720
or not yeah yeah you have optimism that
we'll be able to solve some of these

2938
01:03:16,720 --> 01:03:16,730
we'll be able to solve some of these
 

2939
01:03:16,730 --> 01:03:20,050
we'll be able to solve some of these
questions well I'm gonna say something

2940
01:03:20,050 --> 01:03:20,060
questions well I'm gonna say something
 

2941
01:03:20,060 --> 01:03:22,150
questions well I'm gonna say something
that's controversial like in my circles

2942
01:03:22,150 --> 01:03:22,160
that's controversial like in my circles
 

2943
01:03:22,160 --> 01:03:24,270
that's controversial like in my circles
which is that I don't think that

2944
01:03:24,270 --> 01:03:24,280
which is that I don't think that
 

2945
01:03:24,280 --> 01:03:26,740
which is that I don't think that
companies who are reaching out to

2946
01:03:26,740 --> 01:03:26,750
companies who are reaching out to
 

2947
01:03:26,750 --> 01:03:28,210
companies who are reaching out to
ethicists and trying to create

2948
01:03:28,210 --> 01:03:28,220
ethicists and trying to create
 

2949
01:03:28,220 --> 01:03:30,250
ethicists and trying to create
interdisciplinary ethics boards I don't

2950
01:03:30,250 --> 01:03:30,260
interdisciplinary ethics boards I don't
 

2951
01:03:30,260 --> 01:03:31,750
interdisciplinary ethics boards I don't
think that that's totally just trying to

2952
01:03:31,750 --> 01:03:31,760
think that that's totally just trying to
 

2953
01:03:31,760 --> 01:03:34,330
think that that's totally just trying to
whitewash the problem and and and so

2954
01:03:34,330 --> 01:03:34,340
whitewash the problem and and and so
 

2955
01:03:34,340 --> 01:03:35,200
whitewash the problem and and and so
that they look like they've done

2956
01:03:35,200 --> 01:03:35,210
that they look like they've done
 

2957
01:03:35,210 --> 01:03:36,400
that they look like they've done
something I think that a lot of

2958
01:03:36,400 --> 01:03:36,410
something I think that a lot of
 

2959
01:03:36,410 --> 01:03:40,090
something I think that a lot of
companies actually do like you say care

2960
01:03:40,090 --> 01:03:40,100
companies actually do like you say care
 

2961
01:03:40,100 --> 01:03:41,680
companies actually do like you say care
about what the right answer is they

2962
01:03:41,680 --> 01:03:41,690
about what the right answer is they
 

2963
01:03:41,690 --> 01:03:43,390
about what the right answer is they
don't know what that is and they're

2964
01:03:43,390 --> 01:03:43,400
don't know what that is and they're
 

2965
01:03:43,400 --> 01:03:45,220
don't know what that is and they're
trying to find people to help them find

2966
01:03:45,220 --> 01:03:45,230
trying to find people to help them find
 

2967
01:03:45,230 --> 01:03:48,070
trying to find people to help them find
them not in every case but I think I you

2968
01:03:48,070 --> 01:03:48,080
them not in every case but I think I you
 

2969
01:03:48,080 --> 01:03:49,810
them not in every case but I think I you
know it's much too easy to just vilify

2970
01:03:49,810 --> 01:03:49,820
know it's much too easy to just vilify
 

2971
01:03:49,820 --> 01:03:51,670
know it's much too easy to just vilify
the companies as like you said sitting

2972
01:03:51,670 --> 01:03:51,680
the companies as like you said sitting
 

2973
01:03:51,680 --> 01:03:54,460
the companies as like you said sitting
there with their cat going her 1 million

2974
01:03:54,460 --> 01:03:54,470
there with their cat going her 1 million
 

2975
01:03:54,470 --> 01:03:57,490
there with their cat going her 1 million
dollars that's not what happens a lot of

2976
01:03:57,490 --> 01:03:57,500
dollars that's not what happens a lot of
 

2977
01:03:57,500 --> 01:03:59,860
dollars that's not what happens a lot of
people are well-meaning even within

2978
01:03:59,860 --> 01:03:59,870
people are well-meaning even within
 

2979
01:03:59,870 --> 01:04:04,450
people are well-meaning even within
companies I think that what we do

2980
01:04:04,450 --> 01:04:04,460
companies I think that what we do
 

2981
01:04:04,460 --> 01:04:08,250
companies I think that what we do
absolutely need is more

2982
01:04:08,250 --> 01:04:08,260
absolutely need is more
 

2983
01:04:08,260 --> 01:04:10,540
absolutely need is more
interdisciplinarity both within

2984
01:04:10,540 --> 01:04:10,550
interdisciplinarity both within
 

2985
01:04:10,550 --> 01:04:12,610
interdisciplinarity both within
companies but also within the

2986
01:04:12,610 --> 01:04:12,620
companies but also within the
 

2987
01:04:12,620 --> 01:04:16,330
companies but also within the
policy-making space because we're you

2988
01:04:16,330 --> 01:04:16,340
policy-making space because we're you
 

2989
01:04:16,340 --> 01:04:18,280
policy-making space because we're you
know we've hurdled into the world where

2990
01:04:18,280 --> 01:04:18,290
know we've hurdled into the world where
 

2991
01:04:18,290 --> 01:04:22,180
know we've hurdled into the world where
technological progress is much faster it

2992
01:04:22,180 --> 01:04:22,190
technological progress is much faster it
 

2993
01:04:22,190 --> 01:04:24,100
technological progress is much faster it
seems much faster than it was and things

2994
01:04:24,100 --> 01:04:24,110
seems much faster than it was and things
 

2995
01:04:24,110 --> 01:04:26,170
seems much faster than it was and things
are getting very complex and you need

2996
01:04:26,170 --> 01:04:26,180
are getting very complex and you need
 

2997
01:04:26,180 --> 01:04:28,240
are getting very complex and you need
people who understand the technology but

2998
01:04:28,240 --> 01:04:28,250
people who understand the technology but
 

2999
01:04:28,250 --> 01:04:30,160
people who understand the technology but
also people who understand what the

3000
01:04:30,160 --> 01:04:30,170
also people who understand what the
 

3001
01:04:30,170 --> 01:04:32,860
also people who understand what the
societal implications are and people who

3002
01:04:32,860 --> 01:04:32,870
societal implications are and people who
 

3003
01:04:32,870 --> 01:04:34,330
societal implications are and people who
are thinking about this in a more

3004
01:04:34,330 --> 01:04:34,340
are thinking about this in a more
 

3005
01:04:34,340 --> 01:04:36,580
are thinking about this in a more
systematic way to be talking to each

3006
01:04:36,580 --> 01:04:36,590
systematic way to be talking to each
 

3007
01:04:36,590 --> 01:04:39,310
systematic way to be talking to each
other there's no other solution I think

3008
01:04:39,310 --> 01:04:39,320
other there's no other solution I think
 

3009
01:04:39,320 --> 01:04:41,620
other there's no other solution I think
you've also done work on intellectual

3010
01:04:41,620 --> 01:04:41,630
you've also done work on intellectual
 

3011
01:04:41,630 --> 01:04:44,710
you've also done work on intellectual
property so if you look at the

3012
01:04:44,710 --> 01:04:44,720
property so if you look at the
 

3013
01:04:44,720 --> 01:04:46,270
property so if you look at the
algorithms these companies are using

3014
01:04:46,270 --> 01:04:46,280
algorithms these companies are using
 

3015
01:04:46,280 --> 01:04:48,880
algorithms these companies are using
like YouTube Twitter Facebook so on and

3016
01:04:48,880 --> 01:04:48,890
like YouTube Twitter Facebook so on and
 

3017
01:04:48,890 --> 01:04:52,150
like YouTube Twitter Facebook so on and
that's kind of the those are mostly

3018
01:04:52,150 --> 01:04:52,160
that's kind of the those are mostly
 

3019
01:04:52,160 --> 01:04:55,180
that's kind of the those are mostly
secretive in the recommender systems

3020
01:04:55,180 --> 01:04:55,190
secretive in the recommender systems
 

3021
01:04:55,190 --> 01:04:58,240
secretive in the recommender systems
behind behind these algorithms do you do

3022
01:04:58,240 --> 01:04:58,250
behind behind these algorithms do you do
 

3023
01:04:58,250 --> 01:05:00,280
behind behind these algorithms do you do
you think about it IP and transparency

3024
01:05:00,280 --> 01:05:00,290
you think about it IP and transparency
 

3025
01:05:00,290 --> 01:05:03,640
you think about it IP and transparency
about how goes like this like what the

3026
01:05:03,640 --> 01:05:03,650
about how goes like this like what the
 

3027
01:05:03,650 --> 01:05:05,400
about how goes like this like what the
responsibility these companies to

3028
01:05:05,400 --> 01:05:05,410
responsibility these companies to
 

3029
01:05:05,410 --> 01:05:07,840
responsibility these companies to
open-source the algorithms or at least

3030
01:05:07,840 --> 01:05:07,850
open-source the algorithms or at least
 

3031
01:05:07,850 --> 01:05:11,500
open-source the algorithms or at least
reveal to the public what's how these

3032
01:05:11,500 --> 01:05:11,510
reveal to the public what's how these
 

3033
01:05:11,510 --> 01:05:14,140
reveal to the public what's how these
algorithms work so I personally don't

3034
01:05:14,140 --> 01:05:14,150
algorithms work so I personally don't
 

3035
01:05:14,150 --> 01:05:15,430
algorithms work so I personally don't
work on that there are a lot of people

3036
01:05:15,430 --> 01:05:15,440
work on that there are a lot of people
 

3037
01:05:15,440 --> 01:05:17,020
work on that there are a lot of people
who do though and there are a lot of

3038
01:05:17,020 --> 01:05:17,030
who do though and there are a lot of
 

3039
01:05:17,030 --> 01:05:19,089
who do though and there are a lot of
people calling for transparency in fact

3040
01:05:19,089 --> 01:05:19,099
people calling for transparency in fact
 

3041
01:05:19,099 --> 01:05:21,239
people calling for transparency in fact
Europe's even trying to legislate

3042
01:05:21,239 --> 01:05:21,249
Europe's even trying to legislate
 

3043
01:05:21,249 --> 01:05:23,109
Europe's even trying to legislate
transparency maybe they even have at

3044
01:05:23,109 --> 01:05:23,119
transparency maybe they even have at
 

3045
01:05:23,119 --> 01:05:25,839
transparency maybe they even have at
this point where like if if an

3046
01:05:25,839 --> 01:05:25,849
this point where like if if an
 

3047
01:05:25,849 --> 01:05:28,420
this point where like if if an
algorithmic system makes some sort of

3048
01:05:28,420 --> 01:05:28,430
algorithmic system makes some sort of
 

3049
01:05:28,430 --> 01:05:29,920
algorithmic system makes some sort of
decision that affects someone's life

3050
01:05:29,920 --> 01:05:29,930
decision that affects someone's life
 

3051
01:05:29,930 --> 01:05:32,289
decision that affects someone's life
that you need to be able to see how that

3052
01:05:32,289 --> 01:05:32,299
that you need to be able to see how that
 

3053
01:05:32,299 --> 01:05:38,380
that you need to be able to see how that
decision was made I you know it's it's a

3054
01:05:38,380 --> 01:05:38,390
decision was made I you know it's it's a
 

3055
01:05:38,390 --> 01:05:39,880
decision was made I you know it's it's a
it's a tricky balance because obviously

3056
01:05:39,880 --> 01:05:39,890
it's a tricky balance because obviously
 

3057
01:05:39,890 --> 01:05:41,710
it's a tricky balance because obviously
companies need to have you know some

3058
01:05:41,710 --> 01:05:41,720
companies need to have you know some
 

3059
01:05:41,720 --> 01:05:43,359
companies need to have you know some
sort of competitive advantage and you

3060
01:05:43,359 --> 01:05:43,369
sort of competitive advantage and you
 

3061
01:05:43,369 --> 01:05:45,219
sort of competitive advantage and you
can't take all that away or you stifle

3062
01:05:45,219 --> 01:05:45,229
can't take all that away or you stifle
 

3063
01:05:45,229 --> 01:05:48,670
can't take all that away or you stifle
innovation but yeah for some of the ways

3064
01:05:48,670 --> 01:05:48,680
innovation but yeah for some of the ways
 

3065
01:05:48,680 --> 01:05:49,960
innovation but yeah for some of the ways
that these systems are already being

3066
01:05:49,960 --> 01:05:49,970
that these systems are already being
 

3067
01:05:49,970 --> 01:05:52,329
that these systems are already being
used I think it it is pretty important

3068
01:05:52,329 --> 01:05:52,339
used I think it it is pretty important
 

3069
01:05:52,339 --> 01:05:54,450
used I think it it is pretty important
that people understand how they work

3070
01:05:54,450 --> 01:05:54,460
that people understand how they work
 

3071
01:05:54,460 --> 01:05:56,529
that people understand how they work
what are your thoughts in general on

3072
01:05:56,529 --> 01:05:56,539
what are your thoughts in general on
 

3073
01:05:56,539 --> 01:05:58,839
what are your thoughts in general on
intellectual property in this weird age

3074
01:05:58,839 --> 01:05:58,849
intellectual property in this weird age
 

3075
01:05:58,849 --> 01:06:02,710
intellectual property in this weird age
of software AI robotics oh that it's

3076
01:06:02,710 --> 01:06:02,720
of software AI robotics oh that it's
 

3077
01:06:02,720 --> 01:06:05,049
of software AI robotics oh that it's
broken I mean the system is just broken

3078
01:06:05,049 --> 01:06:05,059
broken I mean the system is just broken
 

3079
01:06:05,059 --> 01:06:08,529
broken I mean the system is just broken
so did can you describe I actually I

3080
01:06:08,529 --> 01:06:08,539
so did can you describe I actually I
 

3081
01:06:08,539 --> 01:06:09,969
so did can you describe I actually I
don't even know what intellectual

3082
01:06:09,969 --> 01:06:09,979
don't even know what intellectual
 

3083
01:06:09,979 --> 01:06:13,690
don't even know what intellectual
property is in the space of software

3084
01:06:13,690 --> 01:06:13,700
property is in the space of software
 

3085
01:06:13,700 --> 01:06:17,979
property is in the space of software
what it means to I mean I so I believe I

3086
01:06:17,979 --> 01:06:17,989
what it means to I mean I so I believe I
 

3087
01:06:17,989 --> 01:06:19,839
what it means to I mean I so I believe I
have a patent on a piece of software

3088
01:06:19,839 --> 01:06:19,849
have a patent on a piece of software
 

3089
01:06:19,849 --> 01:06:22,690
have a patent on a piece of software
from my PhD you believe you don't know

3090
01:06:22,690 --> 01:06:22,700
from my PhD you believe you don't know
 

3091
01:06:22,700 --> 01:06:24,549
from my PhD you believe you don't know
no we went through a whole process yeah

3092
01:06:24,549 --> 01:06:24,559
no we went through a whole process yeah
 

3093
01:06:24,559 --> 01:06:26,170
no we went through a whole process yeah
I do

3094
01:06:26,170 --> 01:06:26,180
I do
 

3095
01:06:26,180 --> 01:06:28,150
I do
the spam emails like will frame your

3096
01:06:28,150 --> 01:06:28,160
the spam emails like will frame your
 

3097
01:06:28,160 --> 01:06:32,349
the spam emails like will frame your
patent for you yes much like a thesis so

3098
01:06:32,349 --> 01:06:32,359
patent for you yes much like a thesis so
 

3099
01:06:32,359 --> 01:06:38,140
patent for you yes much like a thesis so
uh but that's useless right or not what

3100
01:06:38,140 --> 01:06:38,150
uh but that's useless right or not what
 

3101
01:06:38,150 --> 01:06:40,809
uh but that's useless right or not what
word is IP stand in this age what what

3102
01:06:40,809 --> 01:06:40,819
word is IP stand in this age what what
 

3103
01:06:40,819 --> 01:06:42,819
word is IP stand in this age what what
is what's the right way to do it what's

3104
01:06:42,819 --> 01:06:42,829
is what's the right way to do it what's
 

3105
01:06:42,829 --> 01:06:44,620
is what's the right way to do it what's
the right way to protect and own ideas

3106
01:06:44,620 --> 01:06:44,630
the right way to protect and own ideas
 

3107
01:06:44,630 --> 01:06:48,039
the right way to protect and own ideas
and why don't when it's just code and in

3108
01:06:48,039 --> 01:06:48,049
and why don't when it's just code and in
 

3109
01:06:48,049 --> 01:06:51,370
and why don't when it's just code and in
this mishmash of something that feels

3110
01:06:51,370 --> 01:06:51,380
this mishmash of something that feels
 

3111
01:06:51,380 --> 01:06:53,769
this mishmash of something that feels
much softer than a piece of machinery

3112
01:06:53,769 --> 01:06:53,779
much softer than a piece of machinery
 

3113
01:06:53,779 --> 01:06:57,190
much softer than a piece of machinery
yeah idea I mean it's hard because you

3114
01:06:57,190 --> 01:06:57,200
yeah idea I mean it's hard because you
 

3115
01:06:57,200 --> 01:06:58,239
yeah idea I mean it's hard because you
know there are different types of

3116
01:06:58,239 --> 01:06:58,249
know there are different types of
 

3117
01:06:58,249 --> 01:06:59,529
know there are different types of
intellectual property and they're kind

3118
01:06:59,529 --> 01:06:59,539
intellectual property and they're kind
 

3119
01:06:59,539 --> 01:07:01,120
intellectual property and they're kind
of these blunt instruments they're

3120
01:07:01,120 --> 01:07:01,130
of these blunt instruments they're
 

3121
01:07:01,130 --> 01:07:03,190
of these blunt instruments they're
they're like it's like patent law is

3122
01:07:03,190 --> 01:07:03,200
they're like it's like patent law is
 

3123
01:07:03,200 --> 01:07:04,749
they're like it's like patent law is
like a wrench like it works really well

3124
01:07:04,749 --> 01:07:04,759
like a wrench like it works really well
 

3125
01:07:04,759 --> 01:07:06,489
like a wrench like it works really well
for an industry like the pharmaceutical

3126
01:07:06,489 --> 01:07:06,499
for an industry like the pharmaceutical
 

3127
01:07:06,499 --> 01:07:08,049
for an industry like the pharmaceutical
industry but when you try and apply it

3128
01:07:08,049 --> 01:07:08,059
industry but when you try and apply it
 

3129
01:07:08,059 --> 01:07:10,539
industry but when you try and apply it
to something else it's like I don't know

3130
01:07:10,539 --> 01:07:10,549
to something else it's like I don't know
 

3131
01:07:10,549 --> 01:07:11,859
to something else it's like I don't know
I'll just like hit this thing with the

3132
01:07:11,859 --> 01:07:11,869
I'll just like hit this thing with the
 

3133
01:07:11,869 --> 01:07:15,700
I'll just like hit this thing with the
wrench and hope it works so software you

3134
01:07:15,700 --> 01:07:15,710
wrench and hope it works so software you
 

3135
01:07:15,710 --> 01:07:16,809
wrench and hope it works so software you
know software you have a couple

3136
01:07:16,809 --> 01:07:16,819
know software you have a couple
 

3137
01:07:16,819 --> 01:07:20,049
know software you have a couple
different options software like any code

3138
01:07:20,049 --> 01:07:20,059
different options software like any code
 

3139
01:07:20,059 --> 01:07:23,019
different options software like any code
that's written down in some tangible

3140
01:07:23,019 --> 01:07:23,029
that's written down in some tangible
 

3141
01:07:23,029 --> 01:07:26,529
that's written down in some tangible
form is automatically copyrighted so you

3142
01:07:26,529 --> 01:07:26,539
form is automatically copyrighted so you
 

3143
01:07:26,539 --> 01:07:27,910
form is automatically copyrighted so you
have that protection but that doesn't do

3144
01:07:27,910 --> 01:07:27,920
have that protection but that doesn't do
 

3145
01:07:27,920 --> 01:07:30,700
have that protection but that doesn't do
much because if someone takes the basic

3146
01:07:30,700 --> 01:07:30,710
much because if someone takes the basic
 

3147
01:07:30,710 --> 01:07:32,529
much because if someone takes the basic
idea that the

3148
01:07:32,529 --> 01:07:32,539
idea that the
 

3149
01:07:32,539 --> 01:07:35,529
idea that the
code is executing and just does it in a

3150
01:07:35,529 --> 01:07:35,539
code is executing and just does it in a
 

3151
01:07:35,539 --> 01:07:38,140
code is executing and just does it in a
slightly different way they can get

3152
01:07:38,140 --> 01:07:38,150
slightly different way they can get
 

3153
01:07:38,150 --> 01:07:39,909
slightly different way they can get
around the copyright so that's not a lot

3154
01:07:39,909 --> 01:07:39,919
around the copyright so that's not a lot
 

3155
01:07:39,919 --> 01:07:41,880
around the copyright so that's not a lot
of protection then you can patent

3156
01:07:41,880 --> 01:07:41,890
of protection then you can patent
 

3157
01:07:41,890 --> 01:07:46,419
of protection then you can patent
software but that's kind I mean getting

3158
01:07:46,419 --> 01:07:46,429
software but that's kind I mean getting
 

3159
01:07:46,429 --> 01:07:47,859
software but that's kind I mean getting
a patent cost I don't know if you

3160
01:07:47,859 --> 01:07:47,869
a patent cost I don't know if you
 

3161
01:07:47,869 --> 01:07:50,349
a patent cost I don't know if you
remember what yours costs or like was it

3162
01:07:50,349 --> 01:07:50,359
remember what yours costs or like was it
 

3163
01:07:50,359 --> 01:07:52,630
remember what yours costs or like was it
an institution yes during university

3164
01:07:52,630 --> 01:07:52,640
an institution yes during university
 

3165
01:07:52,640 --> 01:07:55,209
an institution yes during university
yeah they it was insane there's so many

3166
01:07:55,209 --> 01:07:55,219
yeah they it was insane there's so many
 

3167
01:07:55,219 --> 01:07:58,209
yeah they it was insane there's so many
lawyers so many meetings and it made me

3168
01:07:58,209 --> 01:07:58,219
lawyers so many meetings and it made me
 

3169
01:07:58,219 --> 01:08:00,009
lawyers so many meetings and it made me
feel like it must have been hundreds of

3170
01:08:00,009 --> 01:08:00,019
feel like it must have been hundreds of
 

3171
01:08:00,019 --> 01:08:02,979
feel like it must have been hundreds of
thousands of dollars yeah crazy it's

3172
01:08:02,979 --> 01:08:02,989
thousands of dollars yeah crazy it's
 

3173
01:08:02,989 --> 01:08:05,259
thousands of dollars yeah crazy it's
it's insane the costs of getting a

3174
01:08:05,259 --> 01:08:05,269
it's insane the costs of getting a
 

3175
01:08:05,269 --> 01:08:06,669
it's insane the costs of getting a
patent and so this idea of like

3176
01:08:06,669 --> 01:08:06,679
patent and so this idea of like
 

3177
01:08:06,679 --> 01:08:08,559
patent and so this idea of like
protecting the like inventor in their

3178
01:08:08,559 --> 01:08:08,569
protecting the like inventor in their
 

3179
01:08:08,569 --> 01:08:10,359
protecting the like inventor in their
own garage like came up with a great

3180
01:08:10,359 --> 01:08:10,369
own garage like came up with a great
 

3181
01:08:10,369 --> 01:08:12,519
own garage like came up with a great
idea is kind of that's the thing of the

3182
01:08:12,519 --> 01:08:12,529
idea is kind of that's the thing of the
 

3183
01:08:12,529 --> 01:08:14,799
idea is kind of that's the thing of the
past it's all just companies trying to

3184
01:08:14,799 --> 01:08:14,809
past it's all just companies trying to
 

3185
01:08:14,809 --> 01:08:17,680
past it's all just companies trying to
protect things and it costs a lot of

3186
01:08:17,680 --> 01:08:17,690
protect things and it costs a lot of
 

3187
01:08:17,690 --> 01:08:20,349
protect things and it costs a lot of
money and then with code it's oftentimes

3188
01:08:20,349 --> 01:08:20,359
money and then with code it's oftentimes
 

3189
01:08:20,359 --> 01:08:23,049
money and then with code it's oftentimes
like you know by the time the patent is

3190
01:08:23,049 --> 01:08:23,059
like you know by the time the patent is
 

3191
01:08:23,059 --> 01:08:24,729
like you know by the time the patent is
issued which can take like five years

3192
01:08:24,729 --> 01:08:24,739
issued which can take like five years
 

3193
01:08:24,739 --> 01:08:27,039
issued which can take like five years
you probably your code is obsolete at

3194
01:08:27,039 --> 01:08:27,049
you probably your code is obsolete at
 

3195
01:08:27,049 --> 01:08:29,890
you probably your code is obsolete at
that point so it's it's a very again a

3196
01:08:29,890 --> 01:08:29,900
that point so it's it's a very again a
 

3197
01:08:29,900 --> 01:08:32,079
that point so it's it's a very again a
very blunt instrument that doesn't work

3198
01:08:32,079 --> 01:08:32,089
very blunt instrument that doesn't work
 

3199
01:08:32,089 --> 01:08:34,959
very blunt instrument that doesn't work
well for that industry and so you know

3200
01:08:34,959 --> 01:08:34,969
well for that industry and so you know
 

3201
01:08:34,969 --> 01:08:36,789
well for that industry and so you know
at this point we should really have

3202
01:08:36,789 --> 01:08:36,799
at this point we should really have
 

3203
01:08:36,799 --> 01:08:38,859
at this point we should really have
something better but we don't do like

3204
01:08:38,859 --> 01:08:38,869
something better but we don't do like
 

3205
01:08:38,869 --> 01:08:40,720
something better but we don't do like
open source yeah it's open so it's good

3206
01:08:40,720 --> 01:08:40,730
open source yeah it's open so it's good
 

3207
01:08:40,730 --> 01:08:42,669
open source yeah it's open so it's good
for society you think all of us should

3208
01:08:42,669 --> 01:08:42,679
for society you think all of us should
 

3209
01:08:42,679 --> 01:08:46,030
for society you think all of us should
open source code well so at the Media

3210
01:08:46,030 --> 01:08:46,040
open source code well so at the Media
 

3211
01:08:46,040 --> 01:08:49,240
open source code well so at the Media
Lab at MIT we have an open source

3212
01:08:49,240 --> 01:08:49,250
Lab at MIT we have an open source
 

3213
01:08:49,250 --> 01:08:51,099
Lab at MIT we have an open source
default because what we've noticed is

3214
01:08:51,099 --> 01:08:51,109
default because what we've noticed is
 

3215
01:08:51,109 --> 01:08:52,959
default because what we've noticed is
that people will come in there like

3216
01:08:52,959 --> 01:08:52,969
that people will come in there like
 

3217
01:08:52,969 --> 01:08:54,970
that people will come in there like
write some code and they'll be like how

3218
01:08:54,970 --> 01:08:54,980
write some code and they'll be like how
 

3219
01:08:54,980 --> 01:08:57,280
write some code and they'll be like how
do I protect this and we're like mmm

3220
01:08:57,280 --> 01:08:57,290
do I protect this and we're like mmm
 

3221
01:08:57,290 --> 01:08:58,660
do I protect this and we're like mmm
like that's not your problem right now

3222
01:08:58,660 --> 01:08:58,670
like that's not your problem right now
 

3223
01:08:58,670 --> 01:08:59,709
like that's not your problem right now
your problem isn't that someone's gonna

3224
01:08:59,709 --> 01:08:59,719
your problem isn't that someone's gonna
 

3225
01:08:59,719 --> 01:09:01,539
your problem isn't that someone's gonna
steal your project your problem is

3226
01:09:01,539 --> 01:09:01,549
steal your project your problem is
 

3227
01:09:01,549 --> 01:09:03,700
steal your project your problem is
getting people to use it at all like

3228
01:09:03,700 --> 01:09:03,710
getting people to use it at all like
 

3229
01:09:03,710 --> 01:09:05,769
getting people to use it at all like
there's so much stuff out there like we

3230
01:09:05,769 --> 01:09:05,779
there's so much stuff out there like we
 

3231
01:09:05,779 --> 01:09:06,669
there's so much stuff out there like we
don't even know if you're gonna get

3232
01:09:06,669 --> 01:09:06,679
don't even know if you're gonna get
 

3233
01:09:06,679 --> 01:09:08,319
don't even know if you're gonna get
traction for your work and so open

3234
01:09:08,319 --> 01:09:08,329
traction for your work and so open
 

3235
01:09:08,329 --> 01:09:11,709
traction for your work and so open
sourcing can sometimes help you know get

3236
01:09:11,709 --> 01:09:11,719
sourcing can sometimes help you know get
 

3237
01:09:11,719 --> 01:09:13,510
sourcing can sometimes help you know get
people's work out there but ensure that

3238
01:09:13,510 --> 01:09:13,520
people's work out there but ensure that
 

3239
01:09:13,520 --> 01:09:15,999
people's work out there but ensure that
they get attribution for it for the work

3240
01:09:15,999 --> 01:09:16,009
they get attribution for it for the work
 

3241
01:09:16,009 --> 01:09:18,129
they get attribution for it for the work
that they've done so I like I'm a fan of

3242
01:09:18,129 --> 01:09:18,139
that they've done so I like I'm a fan of
 

3243
01:09:18,139 --> 01:09:20,589
that they've done so I like I'm a fan of
it in a lot of contexts obviously it's

3244
01:09:20,589 --> 01:09:20,599
it in a lot of contexts obviously it's
 

3245
01:09:20,599 --> 01:09:23,950
it in a lot of contexts obviously it's
not like a one-size-fits-all solution so

3246
01:09:23,950 --> 01:09:23,960
not like a one-size-fits-all solution so
 

3247
01:09:23,960 --> 01:09:26,979
not like a one-size-fits-all solution so
what I gleaned from your Twitter is your

3248
01:09:26,979 --> 01:09:26,989
what I gleaned from your Twitter is your
 

3249
01:09:26,989 --> 01:09:32,200
what I gleaned from your Twitter is your
mom I saw a quote a reference to baby

3250
01:09:32,200 --> 01:09:32,210
mom I saw a quote a reference to baby
 

3251
01:09:32,210 --> 01:09:36,669
mom I saw a quote a reference to baby
bot what have you learned about robotics

3252
01:09:36,669 --> 01:09:36,679
bot what have you learned about robotics
 

3253
01:09:36,679 --> 01:09:41,939
bot what have you learned about robotics
and AI from raising a human baby bot

3254
01:09:41,939 --> 01:09:41,949
and AI from raising a human baby bot
 

3255
01:09:41,949 --> 01:09:45,789
and AI from raising a human baby bot
well I think that my child has made it

3256
01:09:45,789 --> 01:09:45,799
well I think that my child has made it
 

3257
01:09:45,799 --> 01:09:46,910
well I think that my child has made it
more apparent and

3258
01:09:46,910 --> 01:09:46,920
more apparent and
 

3259
01:09:46,920 --> 01:09:48,470
more apparent and
that the systems we're currently

3260
01:09:48,470 --> 01:09:48,480
that the systems we're currently
 

3261
01:09:48,480 --> 01:09:50,780
that the systems we're currently
creating aren't like human intelligence

3262
01:09:50,780 --> 01:09:50,790
creating aren't like human intelligence
 

3263
01:09:50,790 --> 01:09:52,999
creating aren't like human intelligence
like it there's not a lot to compare

3264
01:09:52,999 --> 01:09:53,009
like it there's not a lot to compare
 

3265
01:09:53,009 --> 01:09:56,360
like it there's not a lot to compare
there it's just you he has learned and

3266
01:09:56,360 --> 01:09:56,370
there it's just you he has learned and
 

3267
01:09:56,370 --> 01:09:58,459
there it's just you he has learned and
developed in such a different way than a

3268
01:09:58,459 --> 01:09:58,469
developed in such a different way than a
 

3269
01:09:58,469 --> 01:10:01,700
developed in such a different way than a
lot of the AI systems were creating that

3270
01:10:01,700 --> 01:10:01,710
lot of the AI systems were creating that
 

3271
01:10:01,710 --> 01:10:03,470
lot of the AI systems were creating that
that's not really interesting to me to

3272
01:10:03,470 --> 01:10:03,480
that's not really interesting to me to
 

3273
01:10:03,480 --> 01:10:07,669
that's not really interesting to me to
compare but what is interesting to me is

3274
01:10:07,669 --> 01:10:07,679
compare but what is interesting to me is
 

3275
01:10:07,679 --> 01:10:10,520
compare but what is interesting to me is
how these systems are going to shape the

3276
01:10:10,520 --> 01:10:10,530
how these systems are going to shape the
 

3277
01:10:10,530 --> 01:10:12,200
how these systems are going to shape the
world that he grows up in and so I'm

3278
01:10:12,200 --> 01:10:12,210
world that he grows up in and so I'm
 

3279
01:10:12,210 --> 01:10:15,380
world that he grows up in and so I'm
like even more concerned about kind of

3280
01:10:15,380 --> 01:10:15,390
like even more concerned about kind of
 

3281
01:10:15,390 --> 01:10:17,270
like even more concerned about kind of
the societal effects of developing

3282
01:10:17,270 --> 01:10:17,280
the societal effects of developing
 

3283
01:10:17,280 --> 01:10:20,150
the societal effects of developing
systems that you know rely on massive

3284
01:10:20,150 --> 01:10:20,160
systems that you know rely on massive
 

3285
01:10:20,160 --> 01:10:22,430
systems that you know rely on massive
amounts of data collection for example

3286
01:10:22,430 --> 01:10:22,440
amounts of data collection for example
 

3287
01:10:22,440 --> 01:10:25,459
amounts of data collection for example
so is you going to be allowed to use

3288
01:10:25,459 --> 01:10:25,469
so is you going to be allowed to use
 

3289
01:10:25,469 --> 01:10:30,590
so is you going to be allowed to use
like Facebook or Facebook is over kids

3290
01:10:30,590 --> 01:10:30,600
like Facebook or Facebook is over kids
 

3291
01:10:30,600 --> 01:10:32,720
like Facebook or Facebook is over kids
don't use that at snapchat what do they

3292
01:10:32,720 --> 01:10:32,730
don't use that at snapchat what do they
 

3293
01:10:32,730 --> 01:10:34,910
don't use that at snapchat what do they
use Instagram Jets over to I don't know

3294
01:10:34,910 --> 01:10:34,920
use Instagram Jets over to I don't know
 

3295
01:10:34,920 --> 01:10:36,770
use Instagram Jets over to I don't know
I just heard that tick tock is over

3296
01:10:36,770 --> 01:10:36,780
I just heard that tick tock is over
 

3297
01:10:36,780 --> 01:10:38,630
I just heard that tick tock is over
which I've never even seen so I don't

3298
01:10:38,630 --> 01:10:38,640
which I've never even seen so I don't
 

3299
01:10:38,640 --> 01:10:41,479
which I've never even seen so I don't
know no we're old we don't know twitch

3300
01:10:41,479 --> 01:10:41,489
know no we're old we don't know twitch
 

3301
01:10:41,489 --> 01:10:44,000
know no we're old we don't know twitch
and you just I'm gonna start gaming and

3302
01:10:44,000 --> 01:10:44,010
and you just I'm gonna start gaming and
 

3303
01:10:44,010 --> 01:10:47,990
and you just I'm gonna start gaming and
streaming my my gameplay so what do you

3304
01:10:47,990 --> 01:10:48,000
streaming my my gameplay so what do you
 

3305
01:10:48,000 --> 01:10:51,470
streaming my my gameplay so what do you
see is the future of personal robotic

3306
01:10:51,470 --> 01:10:51,480
see is the future of personal robotic
 

3307
01:10:51,480 --> 01:10:53,300
see is the future of personal robotic
social robotics interaction with our

3308
01:10:53,300 --> 01:10:53,310
social robotics interaction with our
 

3309
01:10:53,310 --> 01:10:55,120
social robotics interaction with our
robots like what are you excited about

3310
01:10:55,120 --> 01:10:55,130
robots like what are you excited about
 

3311
01:10:55,130 --> 01:10:57,560
robots like what are you excited about
if you were to sort of philosophize

3312
01:10:57,560 --> 01:10:57,570
if you were to sort of philosophize
 

3313
01:10:57,570 --> 01:10:59,479
if you were to sort of philosophize
about what might happen the next 5-10

3314
01:10:59,479 --> 01:10:59,489
about what might happen the next 5-10
 

3315
01:10:59,489 --> 01:11:03,050
about what might happen the next 5-10
years that would be cool to see oh I

3316
01:11:03,050 --> 01:11:03,060
years that would be cool to see oh I
 

3317
01:11:03,060 --> 01:11:05,630
years that would be cool to see oh I
really hope that we get kind of a home

3318
01:11:05,630 --> 01:11:05,640
really hope that we get kind of a home
 

3319
01:11:05,640 --> 01:11:07,939
really hope that we get kind of a home
robot that makes it that's a social

3320
01:11:07,939 --> 01:11:07,949
robot that makes it that's a social
 

3321
01:11:07,949 --> 01:11:12,080
robot that makes it that's a social
robot and not just Alexa like it's you

3322
01:11:12,080 --> 01:11:12,090
robot and not just Alexa like it's you
 

3323
01:11:12,090 --> 01:11:14,479
robot and not just Alexa like it's you
know I really loved the Anki products

3324
01:11:14,479 --> 01:11:14,489
know I really loved the Anki products
 

3325
01:11:14,489 --> 01:11:17,720
know I really loved the Anki products
I thought Gebo was had some really great

3326
01:11:17,720 --> 01:11:17,730
I thought Gebo was had some really great
 

3327
01:11:17,730 --> 01:11:20,240
I thought Gebo was had some really great
aspect so I'm hoping that a company

3328
01:11:20,240 --> 01:11:20,250
aspect so I'm hoping that a company
 

3329
01:11:20,250 --> 01:11:24,320
aspect so I'm hoping that a company
cracks that meet you so okay it was

3330
01:11:24,320 --> 01:11:24,330
cracks that meet you so okay it was
 

3331
01:11:24,330 --> 01:11:27,080
cracks that meet you so okay it was
wonderful talking today likewise thank

3332
01:11:27,080 --> 01:11:27,090
wonderful talking today likewise thank
 

3333
01:11:27,090 --> 01:11:29,380
wonderful talking today likewise thank
you so much it's fun

3334
01:11:29,380 --> 01:11:29,390
you so much it's fun
 

3335
01:11:29,390 --> 01:11:30,460
you so much it's fun
thanks for listening to this

3336
01:11:30,460 --> 01:11:30,470
thanks for listening to this
 

3337
01:11:30,470 --> 01:11:32,560
thanks for listening to this
conversation with Kate darling and thank

3338
01:11:32,560 --> 01:11:32,570
conversation with Kate darling and thank
 

3339
01:11:32,570 --> 01:11:34,990
conversation with Kate darling and thank
you to our sponsors expressvpn and

3340
01:11:34,990 --> 01:11:35,000
you to our sponsors expressvpn and
 

3341
01:11:35,000 --> 01:11:37,420
you to our sponsors expressvpn and
master class please consider supporting

3342
01:11:37,420 --> 01:11:37,430
master class please consider supporting
 

3343
01:11:37,430 --> 01:11:39,670
master class please consider supporting
the podcast by signing up to master

3344
01:11:39,670 --> 01:11:39,680
the podcast by signing up to master
 

3345
01:11:39,680 --> 01:11:42,310
the podcast by signing up to master
class and master class comm slash flex

3346
01:11:42,310 --> 01:11:42,320
class and master class comm slash flex
 

3347
01:11:42,320 --> 01:11:45,670
class and master class comm slash flex
and getting expressvpn at expressvpn

3348
01:11:45,670 --> 01:11:45,680
and getting expressvpn at expressvpn
 

3349
01:11:45,680 --> 01:11:49,990
and getting expressvpn at expressvpn
comm / lex pod if you enjoy this podcast

3350
01:11:49,990 --> 01:11:50,000
comm / lex pod if you enjoy this podcast
 

3351
01:11:50,000 --> 01:11:52,420
comm / lex pod if you enjoy this podcast
subscribe on youtube review it with five

3352
01:11:52,420 --> 01:11:52,430
subscribe on youtube review it with five
 

3353
01:11:52,430 --> 01:11:54,580
subscribe on youtube review it with five
stars on Apple podcast supported on

3354
01:11:54,580 --> 01:11:54,590
stars on Apple podcast supported on
 

3355
01:11:54,590 --> 01:11:56,470
stars on Apple podcast supported on
patreon or simply connect with me on

3356
01:11:56,470 --> 01:11:56,480
patreon or simply connect with me on
 

3357
01:11:56,480 --> 01:12:00,370
patreon or simply connect with me on
Twitter at Lex Friedman and now let me

3358
01:12:00,370 --> 01:12:00,380
Twitter at Lex Friedman and now let me
 

3359
01:12:00,380 --> 01:12:02,500
Twitter at Lex Friedman and now let me
leave you with some tweets from Kate

3360
01:12:02,500 --> 01:12:02,510
leave you with some tweets from Kate
 

3361
01:12:02,510 --> 01:12:06,580
leave you with some tweets from Kate
darling first tweet is the pandemic has

3362
01:12:06,580 --> 01:12:06,590
darling first tweet is the pandemic has
 

3363
01:12:06,590 --> 01:12:09,820
darling first tweet is the pandemic has
fundamentally changed Who I am I now

3364
01:12:09,820 --> 01:12:09,830
fundamentally changed Who I am I now
 

3365
01:12:09,830 --> 01:12:12,040
fundamentally changed Who I am I now
drink the leftover milk in the bottom of

3366
01:12:12,040 --> 01:12:12,050
drink the leftover milk in the bottom of
 

3367
01:12:12,050 --> 01:12:15,850
drink the leftover milk in the bottom of
the cereal bowl second tweet is I came

3368
01:12:15,850 --> 01:12:15,860
the cereal bowl second tweet is I came
 

3369
01:12:15,860 --> 01:12:18,160
the cereal bowl second tweet is I came
on here to complain that I had a really

3370
01:12:18,160 --> 01:12:18,170
on here to complain that I had a really
 

3371
01:12:18,170 --> 01:12:20,440
on here to complain that I had a really
bad day and saw that a bunch of you are

3372
01:12:20,440 --> 01:12:20,450
bad day and saw that a bunch of you are
 

3373
01:12:20,450 --> 01:12:24,220
bad day and saw that a bunch of you are
hurting - love - everyone thank you for

3374
01:12:24,220 --> 01:12:24,230
hurting - love - everyone thank you for
 

3375
01:12:24,230 --> 01:12:33,390
hurting - love - everyone thank you for
listening and hope to see you next time

3376
01:12:33,390 --> 01:12:33,400

 

3377
01:12:33,400 --> 01:12:35,460

you


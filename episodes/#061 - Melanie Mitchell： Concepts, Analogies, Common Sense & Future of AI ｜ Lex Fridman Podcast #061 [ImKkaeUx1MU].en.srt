1
00:00:00,030 --> 00:00:01,730

the following is a conversation with

2
00:00:01,730 --> 00:00:01,740
the following is a conversation with
 

3
00:00:01,740 --> 00:00:04,039
the following is a conversation with
Melanie Mitchell she's the professor of

4
00:00:04,039 --> 00:00:04,049
Melanie Mitchell she's the professor of
 

5
00:00:04,049 --> 00:00:05,450
Melanie Mitchell she's the professor of
computer science at Portland State

6
00:00:05,450 --> 00:00:05,460
computer science at Portland State
 

7
00:00:05,460 --> 00:00:08,360
computer science at Portland State
University and an external professor at

8
00:00:08,360 --> 00:00:08,370
University and an external professor at
 

9
00:00:08,370 --> 00:00:11,000
University and an external professor at
Santa Fe Institute she has worked on and

10
00:00:11,000 --> 00:00:11,010
Santa Fe Institute she has worked on and
 

11
00:00:11,010 --> 00:00:12,530
Santa Fe Institute she has worked on and
written about artificial intelligence

12
00:00:12,530 --> 00:00:12,540
written about artificial intelligence
 

13
00:00:12,540 --> 00:00:14,839
written about artificial intelligence
from fascinating perspectives including

14
00:00:14,839 --> 00:00:14,849
from fascinating perspectives including
 

15
00:00:14,849 --> 00:00:17,660
from fascinating perspectives including
adaptive complex systems genetic

16
00:00:17,660 --> 00:00:17,670
adaptive complex systems genetic
 

17
00:00:17,670 --> 00:00:20,060
adaptive complex systems genetic
algorithms and the copycat cognitive

18
00:00:20,060 --> 00:00:20,070
algorithms and the copycat cognitive
 

19
00:00:20,070 --> 00:00:22,189
algorithms and the copycat cognitive
architecture which places the process of

20
00:00:22,189 --> 00:00:22,199
architecture which places the process of
 

21
00:00:22,199 --> 00:00:24,590
architecture which places the process of
analogy making at the core of human

22
00:00:24,590 --> 00:00:24,600
analogy making at the core of human
 

23
00:00:24,600 --> 00:00:27,650
analogy making at the core of human
cognition from her doctoral work with

24
00:00:27,650 --> 00:00:27,660
cognition from her doctoral work with
 

25
00:00:27,660 --> 00:00:30,200
cognition from her doctoral work with
her advisers Douglas Hofstadter and John

26
00:00:30,200 --> 00:00:30,210
her advisers Douglas Hofstadter and John
 

27
00:00:30,210 --> 00:00:32,840
her advisers Douglas Hofstadter and John
Holland - today she has contributed a

28
00:00:32,840 --> 00:00:32,850
Holland - today she has contributed a
 

29
00:00:32,850 --> 00:00:34,790
Holland - today she has contributed a
lot of important ideas to the field of

30
00:00:34,790 --> 00:00:34,800
lot of important ideas to the field of
 

31
00:00:34,800 --> 00:00:37,400
lot of important ideas to the field of
AI including her recent book simply

32
00:00:37,400 --> 00:00:37,410
AI including her recent book simply
 

33
00:00:37,410 --> 00:00:40,310
AI including her recent book simply
called artificial intelligence a guide

34
00:00:40,310 --> 00:00:40,320
called artificial intelligence a guide
 

35
00:00:40,320 --> 00:00:43,670
called artificial intelligence a guide
for thinking humans this is the

36
00:00:43,670 --> 00:00:43,680
for thinking humans this is the
 

37
00:00:43,680 --> 00:00:46,100
for thinking humans this is the
artificial intelligence podcast if you

38
00:00:46,100 --> 00:00:46,110
artificial intelligence podcast if you
 

39
00:00:46,110 --> 00:00:48,500
artificial intelligence podcast if you
enjoy it subscribe on YouTube give it

40
00:00:48,500 --> 00:00:48,510
enjoy it subscribe on YouTube give it
 

41
00:00:48,510 --> 00:00:50,900
enjoy it subscribe on YouTube give it
five stars on Apple podcast supported on

42
00:00:50,900 --> 00:00:50,910
five stars on Apple podcast supported on
 

43
00:00:50,910 --> 00:00:52,880
five stars on Apple podcast supported on
patreon or simply connect with me on

44
00:00:52,880 --> 00:00:52,890
patreon or simply connect with me on
 

45
00:00:52,890 --> 00:00:56,959
patreon or simply connect with me on
Twitter at Lex Friedman spelled Fri D ma

46
00:00:56,959 --> 00:00:56,969
Twitter at Lex Friedman spelled Fri D ma
 

47
00:00:56,969 --> 00:00:59,990
Twitter at Lex Friedman spelled Fri D ma
n I recently started doing ads at the

48
00:00:59,990 --> 00:01:00,000
n I recently started doing ads at the
 

49
00:01:00,000 --> 00:01:02,119
n I recently started doing ads at the
end of the introduction I'll do one or

50
00:01:02,119 --> 00:01:02,129
end of the introduction I'll do one or
 

51
00:01:02,129 --> 00:01:03,529
end of the introduction I'll do one or
two minutes after introducing the

52
00:01:03,529 --> 00:01:03,539
two minutes after introducing the
 

53
00:01:03,539 --> 00:01:05,660
two minutes after introducing the
episode and never any ads in the middle

54
00:01:05,660 --> 00:01:05,670
episode and never any ads in the middle
 

55
00:01:05,670 --> 00:01:06,980
episode and never any ads in the middle
that can break the flow of the

56
00:01:06,980 --> 00:01:06,990
that can break the flow of the
 

57
00:01:06,990 --> 00:01:09,320
that can break the flow of the
conversation I hope that works for you

58
00:01:09,320 --> 00:01:09,330
conversation I hope that works for you
 

59
00:01:09,330 --> 00:01:11,060
conversation I hope that works for you
it doesn't hurt the listening experience

60
00:01:11,060 --> 00:01:11,070
it doesn't hurt the listening experience
 

61
00:01:11,070 --> 00:01:13,789
it doesn't hurt the listening experience
I provide time stamps for the start of

62
00:01:13,789 --> 00:01:13,799
I provide time stamps for the start of
 

63
00:01:13,799 --> 00:01:15,950
I provide time stamps for the start of
the conversation but it helps if you

64
00:01:15,950 --> 00:01:15,960
the conversation but it helps if you
 

65
00:01:15,960 --> 00:01:17,690
the conversation but it helps if you
listen to the ad and support this

66
00:01:17,690 --> 00:01:17,700
listen to the ad and support this
 

67
00:01:17,700 --> 00:01:19,700
listen to the ad and support this
podcast by trying out the product the

68
00:01:19,700 --> 00:01:19,710
podcast by trying out the product the
 

69
00:01:19,710 --> 00:01:22,620
podcast by trying out the product the
service being advertised

70
00:01:22,620 --> 00:01:22,630
service being advertised
 

71
00:01:22,630 --> 00:01:24,990
service being advertised
this show is presented by cash app the

72
00:01:24,990 --> 00:01:25,000
this show is presented by cash app the
 

73
00:01:25,000 --> 00:01:26,640
this show is presented by cash app the
number one finance app in the App Store

74
00:01:26,640 --> 00:01:26,650
number one finance app in the App Store
 

75
00:01:26,650 --> 00:01:29,160
number one finance app in the App Store
I personally use cash app to send money

76
00:01:29,160 --> 00:01:29,170
I personally use cash app to send money
 

77
00:01:29,170 --> 00:01:31,469
I personally use cash app to send money
to friends but you can also use it to

78
00:01:31,469 --> 00:01:31,479
to friends but you can also use it to
 

79
00:01:31,479 --> 00:01:34,020
to friends but you can also use it to
buy sell and deposit Bitcoin in just

80
00:01:34,020 --> 00:01:34,030
buy sell and deposit Bitcoin in just
 

81
00:01:34,030 --> 00:01:36,780
buy sell and deposit Bitcoin in just
seconds cash app also has a new

82
00:01:36,780 --> 00:01:36,790
seconds cash app also has a new
 

83
00:01:36,790 --> 00:01:39,030
seconds cash app also has a new
investing feature you can buy fractions

84
00:01:39,030 --> 00:01:39,040
investing feature you can buy fractions
 

85
00:01:39,040 --> 00:01:41,639
investing feature you can buy fractions
of a stock say $1 worth no matter what

86
00:01:41,639 --> 00:01:41,649
of a stock say $1 worth no matter what
 

87
00:01:41,649 --> 00:01:44,130
of a stock say $1 worth no matter what
the stock price is brokerage services

88
00:01:44,130 --> 00:01:44,140
the stock price is brokerage services
 

89
00:01:44,140 --> 00:01:46,050
the stock price is brokerage services
are provided by cash app investing a

90
00:01:46,050 --> 00:01:46,060
are provided by cash app investing a
 

91
00:01:46,060 --> 00:01:49,260
are provided by cash app investing a
subsidiary of square and member s IBC

92
00:01:49,260 --> 00:01:49,270
subsidiary of square and member s IBC
 

93
00:01:49,270 --> 00:01:51,600
subsidiary of square and member s IBC
I'm excited to be working with cash app

94
00:01:51,600 --> 00:01:51,610
I'm excited to be working with cash app
 

95
00:01:51,610 --> 00:01:53,160
I'm excited to be working with cash app
to support one of my favorite

96
00:01:53,160 --> 00:01:53,170
to support one of my favorite
 

97
00:01:53,170 --> 00:01:55,680
to support one of my favorite
organizations called first best known

98
00:01:55,680 --> 00:01:55,690
organizations called first best known
 

99
00:01:55,690 --> 00:01:57,419
organizations called first best known
for their first robotics and Lego

100
00:01:57,419 --> 00:01:57,429
for their first robotics and Lego
 

101
00:01:57,429 --> 00:02:00,120
for their first robotics and Lego
competitions they educate and inspire

102
00:02:00,120 --> 00:02:00,130
competitions they educate and inspire
 

103
00:02:00,130 --> 00:02:02,580
competitions they educate and inspire
hundreds of thousands of students in

104
00:02:02,580 --> 00:02:02,590
hundreds of thousands of students in
 

105
00:02:02,590 --> 00:02:05,160
hundreds of thousands of students in
over 110 countries and have a perfect

106
00:02:05,160 --> 00:02:05,170
over 110 countries and have a perfect
 

107
00:02:05,170 --> 00:02:07,320
over 110 countries and have a perfect
rating and charity navigator which means

108
00:02:07,320 --> 00:02:07,330
rating and charity navigator which means
 

109
00:02:07,330 --> 00:02:09,660
rating and charity navigator which means
that donated money is used to maximum

110
00:02:09,660 --> 00:02:09,670
that donated money is used to maximum
 

111
00:02:09,670 --> 00:02:12,870
that donated money is used to maximum
effectiveness when you get cash app from

112
00:02:12,870 --> 00:02:12,880
effectiveness when you get cash app from
 

113
00:02:12,880 --> 00:02:15,210
effectiveness when you get cash app from
the App Store or Google Play and use

114
00:02:15,210 --> 00:02:15,220
the App Store or Google Play and use
 

115
00:02:15,220 --> 00:02:18,240
the App Store or Google Play and use
code Lex podcast you'll get ten dollars

116
00:02:18,240 --> 00:02:18,250
code Lex podcast you'll get ten dollars
 

117
00:02:18,250 --> 00:02:20,070
code Lex podcast you'll get ten dollars
in cash up will also donate ten dollars

118
00:02:20,070 --> 00:02:20,080
in cash up will also donate ten dollars
 

119
00:02:20,080 --> 00:02:23,130
in cash up will also donate ten dollars
the first which again is an organization

120
00:02:23,130 --> 00:02:23,140
the first which again is an organization
 

121
00:02:23,140 --> 00:02:25,050
the first which again is an organization
that I've personally seen inspire girls

122
00:02:25,050 --> 00:02:25,060
that I've personally seen inspire girls
 

123
00:02:25,060 --> 00:02:27,300
that I've personally seen inspire girls
and boys to dream of engineering a

124
00:02:27,300 --> 00:02:27,310
and boys to dream of engineering a
 

125
00:02:27,310 --> 00:02:30,090
and boys to dream of engineering a
better world and now here's my

126
00:02:30,090 --> 00:02:30,100
better world and now here's my
 

127
00:02:30,100 --> 00:02:33,530
better world and now here's my
conversation with Melanie Mitchell

128
00:02:33,530 --> 00:02:33,540
conversation with Melanie Mitchell
 

129
00:02:33,540 --> 00:02:35,960
conversation with Melanie Mitchell
the name of your new book is artificial

130
00:02:35,960 --> 00:02:35,970
the name of your new book is artificial
 

131
00:02:35,970 --> 00:02:38,210
the name of your new book is artificial
intelligence subtitle a guide for

132
00:02:38,210 --> 00:02:38,220
intelligence subtitle a guide for
 

133
00:02:38,220 --> 00:02:40,729
intelligence subtitle a guide for
thinking humans the name of this podcast

134
00:02:40,729 --> 00:02:40,739
thinking humans the name of this podcast
 

135
00:02:40,739 --> 00:02:43,250
thinking humans the name of this podcast
is artificial intelligence so let me

136
00:02:43,250 --> 00:02:43,260
is artificial intelligence so let me
 

137
00:02:43,260 --> 00:02:44,809
is artificial intelligence so let me
take a step back and ask the old

138
00:02:44,809 --> 00:02:44,819
take a step back and ask the old
 

139
00:02:44,819 --> 00:02:47,080
take a step back and ask the old
Shakespeare question about roses and

140
00:02:47,080 --> 00:02:47,090
Shakespeare question about roses and
 

141
00:02:47,090 --> 00:02:50,390
Shakespeare question about roses and
what do you think of the term artificial

142
00:02:50,390 --> 00:02:50,400
what do you think of the term artificial
 

143
00:02:50,400 --> 00:02:53,720
what do you think of the term artificial
intelligence for our big and complicated

144
00:02:53,720 --> 00:02:53,730
intelligence for our big and complicated
 

145
00:02:53,730 --> 00:02:56,000
intelligence for our big and complicated
and interesting field I'm not crazy

146
00:02:56,000 --> 00:02:56,010
and interesting field I'm not crazy
 

147
00:02:56,010 --> 00:02:59,210
and interesting field I'm not crazy
about the term I think it has a few

148
00:02:59,210 --> 00:02:59,220
about the term I think it has a few
 

149
00:02:59,220 --> 00:03:03,619
about the term I think it has a few
problems because it it's means so many

150
00:03:03,619 --> 00:03:03,629
problems because it it's means so many
 

151
00:03:03,629 --> 00:03:05,470
problems because it it's means so many
different things to different people and

152
00:03:05,470 --> 00:03:05,480
different things to different people and
 

153
00:03:05,480 --> 00:03:07,430
different things to different people and
intelligence is one of those words that

154
00:03:07,430 --> 00:03:07,440
intelligence is one of those words that
 

155
00:03:07,440 --> 00:03:09,890
intelligence is one of those words that
isn't very clearly defined either

156
00:03:09,890 --> 00:03:09,900
isn't very clearly defined either
 

157
00:03:09,900 --> 00:03:12,380
isn't very clearly defined either
there's so many different kinds of

158
00:03:12,380 --> 00:03:12,390
there's so many different kinds of
 

159
00:03:12,390 --> 00:03:16,240
there's so many different kinds of
intelligence degrees of intelligence

160
00:03:16,240 --> 00:03:16,250
intelligence degrees of intelligence
 

161
00:03:16,250 --> 00:03:19,580
intelligence degrees of intelligence
approaches to intelligence John McCarthy

162
00:03:19,580 --> 00:03:19,590
approaches to intelligence John McCarthy
 

163
00:03:19,590 --> 00:03:21,589
approaches to intelligence John McCarthy
was the one who came up with the term

164
00:03:21,589 --> 00:03:21,599
was the one who came up with the term
 

165
00:03:21,599 --> 00:03:23,660
was the one who came up with the term
artificial intelligence and what from

166
00:03:23,660 --> 00:03:23,670
artificial intelligence and what from
 

167
00:03:23,670 --> 00:03:26,140
artificial intelligence and what from
what I read he called it that to

168
00:03:26,140 --> 00:03:26,150
what I read he called it that to
 

169
00:03:26,150 --> 00:03:28,910
what I read he called it that to
differentiate it from cybernetics which

170
00:03:28,910 --> 00:03:28,920
differentiate it from cybernetics which
 

171
00:03:28,920 --> 00:03:32,449
differentiate it from cybernetics which
was another related movement at the time

172
00:03:32,449 --> 00:03:32,459
was another related movement at the time
 

173
00:03:32,459 --> 00:03:36,740
was another related movement at the time
and he later regretted calling it

174
00:03:36,740 --> 00:03:36,750
and he later regretted calling it
 

175
00:03:36,750 --> 00:03:39,830
and he later regretted calling it
artificial intelligence Herbert Simon

176
00:03:39,830 --> 00:03:39,840
artificial intelligence Herbert Simon
 

177
00:03:39,840 --> 00:03:42,379
artificial intelligence Herbert Simon
was pushing for calling it complex

178
00:03:42,379 --> 00:03:42,389
was pushing for calling it complex
 

179
00:03:42,389 --> 00:03:46,940
was pushing for calling it complex
information processing which got nixed

180
00:03:46,940 --> 00:03:46,950
information processing which got nixed
 

181
00:03:46,950 --> 00:03:51,409
information processing which got nixed
but you know probably is equally vague I

182
00:03:51,409 --> 00:03:51,419
but you know probably is equally vague I
 

183
00:03:51,419 --> 00:03:54,020
but you know probably is equally vague I
guess is it the intelligence or the

184
00:03:54,020 --> 00:03:54,030
guess is it the intelligence or the
 

185
00:03:54,030 --> 00:03:56,509
guess is it the intelligence or the
artificial in terms of words that it's

186
00:03:56,509 --> 00:03:56,519
artificial in terms of words that it's
 

187
00:03:56,519 --> 00:03:58,339
artificial in terms of words that it's
the most problematic you would you say

188
00:03:58,339 --> 00:03:58,349
the most problematic you would you say
 

189
00:03:58,349 --> 00:04:01,159
the most problematic you would you say
yeah I think it's a little of both but

190
00:04:01,159 --> 00:04:01,169
yeah I think it's a little of both but
 

191
00:04:01,169 --> 00:04:04,449
yeah I think it's a little of both but
you know it has some good size because I

192
00:04:04,449 --> 00:04:04,459
you know it has some good size because I
 

193
00:04:04,459 --> 00:04:06,830
you know it has some good size because I
personally was attracted to the field

194
00:04:06,830 --> 00:04:06,840
personally was attracted to the field
 

195
00:04:06,840 --> 00:04:08,659
personally was attracted to the field
because I was interested in phenom

196
00:04:08,659 --> 00:04:08,669
because I was interested in phenom
 

197
00:04:08,669 --> 00:04:11,750
because I was interested in phenom
phenomenons of intelligence and if it

198
00:04:11,750 --> 00:04:11,760
phenomenons of intelligence and if it
 

199
00:04:11,760 --> 00:04:12,979
phenomenons of intelligence and if it
was called complex information

200
00:04:12,979 --> 00:04:12,989
was called complex information
 

201
00:04:12,989 --> 00:04:14,809
was called complex information
processing maybe I'd be doing something

202
00:04:14,809 --> 00:04:14,819
processing maybe I'd be doing something
 

203
00:04:14,819 --> 00:04:16,580
processing maybe I'd be doing something
wholly different now what do you think

204
00:04:16,580 --> 00:04:16,590
wholly different now what do you think
 

205
00:04:16,590 --> 00:04:19,159
wholly different now what do you think
of I've heard the term used cognitive

206
00:04:19,159 --> 00:04:19,169
of I've heard the term used cognitive
 

207
00:04:19,169 --> 00:04:21,879
of I've heard the term used cognitive
systems for example so using cognitive

208
00:04:21,879 --> 00:04:21,889
systems for example so using cognitive
 

209
00:04:21,889 --> 00:04:26,260
systems for example so using cognitive
yeah I mean cognitive has certain

210
00:04:26,260 --> 00:04:26,270
yeah I mean cognitive has certain
 

211
00:04:26,270 --> 00:04:28,879
yeah I mean cognitive has certain
associations with it and people like to

212
00:04:28,879 --> 00:04:28,889
associations with it and people like to
 

213
00:04:28,889 --> 00:04:31,100
associations with it and people like to
separate things like cognition and

214
00:04:31,100 --> 00:04:31,110
separate things like cognition and
 

215
00:04:31,110 --> 00:04:32,779
separate things like cognition and
perception which I don't actually think

216
00:04:32,779 --> 00:04:32,789
perception which I don't actually think
 

217
00:04:32,789 --> 00:04:35,529
perception which I don't actually think
are separate but often people talk about

218
00:04:35,529 --> 00:04:35,539
are separate but often people talk about
 

219
00:04:35,539 --> 00:04:38,210
are separate but often people talk about
cognition is being different from sort

220
00:04:38,210 --> 00:04:38,220
cognition is being different from sort
 

221
00:04:38,220 --> 00:04:41,480
cognition is being different from sort
of other aspects of intelligence it's

222
00:04:41,480 --> 00:04:41,490
of other aspects of intelligence it's
 

223
00:04:41,490 --> 00:04:43,640
of other aspects of intelligence it's
sort of higher level so to you cognition

224
00:04:43,640 --> 00:04:43,650
sort of higher level so to you cognition
 

225
00:04:43,650 --> 00:04:45,649
sort of higher level so to you cognition
is this broad beautiful mess of things

226
00:04:45,649 --> 00:04:45,659
is this broad beautiful mess of things
 

227
00:04:45,659 --> 00:04:46,670
is this broad beautiful mess of things
that's in calm

228
00:04:46,670 --> 00:04:46,680
that's in calm
 

229
00:04:46,680 --> 00:04:50,390
that's in calm
the whole thing memory yeah I I think

230
00:04:50,390 --> 00:04:50,400
the whole thing memory yeah I I think
 

231
00:04:50,400 --> 00:04:53,270
the whole thing memory yeah I I think
it's hard to draw lines like that when I

232
00:04:53,270 --> 00:04:53,280
it's hard to draw lines like that when I
 

233
00:04:53,280 --> 00:04:55,219
it's hard to draw lines like that when I
was coming out of grad school in the

234
00:04:55,219 --> 00:04:55,229
was coming out of grad school in the
 

235
00:04:55,229 --> 00:04:57,490
was coming out of grad school in the
night in 1990 which is when I graduated

236
00:04:57,490 --> 00:04:57,500
night in 1990 which is when I graduated
 

237
00:04:57,500 --> 00:05:00,400
night in 1990 which is when I graduated
that was during one of the AI winters

238
00:05:00,400 --> 00:05:00,410
that was during one of the AI winters
 

239
00:05:00,410 --> 00:05:04,700
that was during one of the AI winters
and I was advised to not put AI

240
00:05:04,700 --> 00:05:04,710
and I was advised to not put AI
 

241
00:05:04,710 --> 00:05:06,890
and I was advised to not put AI
artificial intelligence on my CV but

242
00:05:06,890 --> 00:05:06,900
artificial intelligence on my CV but
 

243
00:05:06,900 --> 00:05:10,340
artificial intelligence on my CV but
instead call it intelligent systems so

244
00:05:10,340 --> 00:05:10,350
instead call it intelligent systems so
 

245
00:05:10,350 --> 00:05:14,080
instead call it intelligent systems so
that was kind of a euphemism I guess

246
00:05:14,080 --> 00:05:14,090
that was kind of a euphemism I guess
 

247
00:05:14,090 --> 00:05:18,529
that was kind of a euphemism I guess
what about the stick briefly on on terms

248
00:05:18,529 --> 00:05:18,539
what about the stick briefly on on terms
 

249
00:05:18,539 --> 00:05:22,550
what about the stick briefly on on terms
and words the idea of artificial general

250
00:05:22,550 --> 00:05:22,560
and words the idea of artificial general
 

251
00:05:22,560 --> 00:05:27,710
and words the idea of artificial general
intelligence or or like beyond Laocoon

252
00:05:27,710 --> 00:05:27,720
intelligence or or like beyond Laocoon
 

253
00:05:27,720 --> 00:05:29,810
intelligence or or like beyond Laocoon
prefers human level intelligence sort of

254
00:05:29,810 --> 00:05:29,820
prefers human level intelligence sort of
 

255
00:05:29,820 --> 00:05:34,779
prefers human level intelligence sort of
starting to talk about ideas that that

256
00:05:34,779 --> 00:05:34,789
starting to talk about ideas that that
 

257
00:05:34,789 --> 00:05:37,010
starting to talk about ideas that that
achieve higher and higher levels of

258
00:05:37,010 --> 00:05:37,020
achieve higher and higher levels of
 

259
00:05:37,020 --> 00:05:38,779
achieve higher and higher levels of
intelligence and somehow artificial

260
00:05:38,779 --> 00:05:38,789
intelligence and somehow artificial
 

261
00:05:38,789 --> 00:05:41,480
intelligence and somehow artificial
intelligence seems to be a term used

262
00:05:41,480 --> 00:05:41,490
intelligence seems to be a term used
 

263
00:05:41,490 --> 00:05:44,150
intelligence seems to be a term used
more for the narrow very specific

264
00:05:44,150 --> 00:05:44,160
more for the narrow very specific
 

265
00:05:44,160 --> 00:05:46,219
more for the narrow very specific
applications of AI and sort of the

266
00:05:46,219 --> 00:05:46,229
applications of AI and sort of the
 

267
00:05:46,229 --> 00:05:50,930
applications of AI and sort of the
there's the what set of terms appeal to

268
00:05:50,930 --> 00:05:50,940
there's the what set of terms appeal to
 

269
00:05:50,940 --> 00:05:53,420
there's the what set of terms appeal to
you to describe the thing that perhaps

270
00:05:53,420 --> 00:05:53,430
you to describe the thing that perhaps
 

271
00:05:53,430 --> 00:05:56,480
you to describe the thing that perhaps
would strive to create people have been

272
00:05:56,480 --> 00:05:56,490
would strive to create people have been
 

273
00:05:56,490 --> 00:05:57,860
would strive to create people have been
struggling with this for the whole

274
00:05:57,860 --> 00:05:57,870
struggling with this for the whole
 

275
00:05:57,870 --> 00:06:00,830
struggling with this for the whole
history of the field and defining

276
00:06:00,830 --> 00:06:00,840
history of the field and defining
 

277
00:06:00,840 --> 00:06:02,629
history of the field and defining
exactly what it is that we're talking

278
00:06:02,629 --> 00:06:02,639
exactly what it is that we're talking
 

279
00:06:02,639 --> 00:06:04,640
exactly what it is that we're talking
about you know John Searle had this

280
00:06:04,640 --> 00:06:04,650
about you know John Searle had this
 

281
00:06:04,650 --> 00:06:07,339
about you know John Searle had this
distinction between strong AI and weak

282
00:06:07,339 --> 00:06:07,349
distinction between strong AI and weak
 

283
00:06:07,349 --> 00:06:10,580
distinction between strong AI and weak
AI and weak AI could be generally AI but

284
00:06:10,580 --> 00:06:10,590
AI and weak AI could be generally AI but
 

285
00:06:10,590 --> 00:06:14,750
AI and weak AI could be generally AI but
his idea was strong AI was the view that

286
00:06:14,750 --> 00:06:14,760
his idea was strong AI was the view that
 

287
00:06:14,760 --> 00:06:18,860
his idea was strong AI was the view that
a machine is actually thinking that as

288
00:06:18,860 --> 00:06:18,870
a machine is actually thinking that as
 

289
00:06:18,870 --> 00:06:23,950
a machine is actually thinking that as
opposed to simulating thinking or

290
00:06:23,950 --> 00:06:23,960
opposed to simulating thinking or
 

291
00:06:23,960 --> 00:06:28,100
opposed to simulating thinking or
carrying out intelligent processes that

292
00:06:28,100 --> 00:06:28,110
carrying out intelligent processes that
 

293
00:06:28,110 --> 00:06:31,150
carrying out intelligent processes that
we would call intelligent

294
00:06:31,150 --> 00:06:31,160
we would call intelligent
 

295
00:06:31,160 --> 00:06:34,390
we would call intelligent
high level if you look at the founding

296
00:06:34,390 --> 00:06:34,400
high level if you look at the founding
 

297
00:06:34,400 --> 00:06:36,580
high level if you look at the founding
of the field of McCarthy in sterlin and

298
00:06:36,580 --> 00:06:36,590
of the field of McCarthy in sterlin and
 

299
00:06:36,590 --> 00:06:40,840
of the field of McCarthy in sterlin and
so on are we closer to having a better

300
00:06:40,840 --> 00:06:40,850
so on are we closer to having a better
 

301
00:06:40,850 --> 00:06:46,750
so on are we closer to having a better
sense of that line between narrow weak

302
00:06:46,750 --> 00:06:46,760
sense of that line between narrow weak
 

303
00:06:46,760 --> 00:06:51,520
sense of that line between narrow weak
AI and strong AI yes I think we're

304
00:06:51,520 --> 00:06:51,530
AI and strong AI yes I think we're
 

305
00:06:51,530 --> 00:06:55,780
AI and strong AI yes I think we're
closer to having a better idea of what

306
00:06:55,780 --> 00:06:55,790
closer to having a better idea of what
 

307
00:06:55,790 --> 00:07:00,970
closer to having a better idea of what
that line is early on for example a lot

308
00:07:00,970 --> 00:07:00,980
that line is early on for example a lot
 

309
00:07:00,980 --> 00:07:03,490
that line is early on for example a lot
of people thought that playing chess

310
00:07:03,490 --> 00:07:03,500
of people thought that playing chess
 

311
00:07:03,500 --> 00:07:07,030
of people thought that playing chess
would be you couldn't play chess if you

312
00:07:07,030 --> 00:07:07,040
would be you couldn't play chess if you
 

313
00:07:07,040 --> 00:07:09,910
would be you couldn't play chess if you
didn't have sort of general human level

314
00:07:09,910 --> 00:07:09,920
didn't have sort of general human level
 

315
00:07:09,920 --> 00:07:12,310
didn't have sort of general human level
intelligence and of course once

316
00:07:12,310 --> 00:07:12,320
intelligence and of course once
 

317
00:07:12,320 --> 00:07:14,110
intelligence and of course once
computers were able to play chess better

318
00:07:14,110 --> 00:07:14,120
computers were able to play chess better
 

319
00:07:14,120 --> 00:07:18,120
computers were able to play chess better
than humans that revised that view and

320
00:07:18,120 --> 00:07:18,130
than humans that revised that view and
 

321
00:07:18,130 --> 00:07:21,610
than humans that revised that view and
people said ok well maybe now we have to

322
00:07:21,610 --> 00:07:21,620
people said ok well maybe now we have to
 

323
00:07:21,620 --> 00:07:24,490
people said ok well maybe now we have to
revise what we think of intelligence as

324
00:07:24,490 --> 00:07:24,500
revise what we think of intelligence as
 

325
00:07:24,500 --> 00:07:27,540
revise what we think of intelligence as
or and and so that's kind of been a

326
00:07:27,540 --> 00:07:27,550
or and and so that's kind of been a
 

327
00:07:27,550 --> 00:07:29,560
or and and so that's kind of been a
theme throughout the history of the

328
00:07:29,560 --> 00:07:29,570
theme throughout the history of the
 

329
00:07:29,570 --> 00:07:32,530
theme throughout the history of the
field is that once a machine can do some

330
00:07:32,530 --> 00:07:32,540
field is that once a machine can do some
 

331
00:07:32,540 --> 00:07:36,340
field is that once a machine can do some
task we then have to look back and say

332
00:07:36,340 --> 00:07:36,350
task we then have to look back and say
 

333
00:07:36,350 --> 00:07:38,800
task we then have to look back and say
oh well that changes my understanding of

334
00:07:38,800 --> 00:07:38,810
oh well that changes my understanding of
 

335
00:07:38,810 --> 00:07:40,270
oh well that changes my understanding of
what intelligence is because I don't

336
00:07:40,270 --> 00:07:40,280
what intelligence is because I don't
 

337
00:07:40,280 --> 00:07:43,060
what intelligence is because I don't
think that machine is intelligent at

338
00:07:43,060 --> 00:07:43,070
think that machine is intelligent at
 

339
00:07:43,070 --> 00:07:44,140
think that machine is intelligent at
least that's not what I want to call

340
00:07:44,140 --> 00:07:44,150
least that's not what I want to call
 

341
00:07:44,150 --> 00:07:46,450
least that's not what I want to call
intelligence do you think that line

342
00:07:46,450 --> 00:07:46,460
intelligence do you think that line
 

343
00:07:46,460 --> 00:07:49,080
intelligence do you think that line
moves forever or will we eventually

344
00:07:49,080 --> 00:07:49,090
moves forever or will we eventually
 

345
00:07:49,090 --> 00:07:51,490
moves forever or will we eventually
really feel as a civilization like we

346
00:07:51,490 --> 00:07:51,500
really feel as a civilization like we
 

347
00:07:51,500 --> 00:07:54,130
really feel as a civilization like we
cross the line if it's possible it's

348
00:07:54,130 --> 00:07:54,140
cross the line if it's possible it's
 

349
00:07:54,140 --> 00:07:56,140
cross the line if it's possible it's
hard to predict but I don't see any

350
00:07:56,140 --> 00:07:56,150
hard to predict but I don't see any
 

351
00:07:56,150 --> 00:07:58,860
hard to predict but I don't see any
reason why we couldn't in principle

352
00:07:58,860 --> 00:07:58,870
reason why we couldn't in principle
 

353
00:07:58,870 --> 00:08:00,820
reason why we couldn't in principle
create something that we would consider

354
00:08:00,820 --> 00:08:00,830
create something that we would consider
 

355
00:08:00,830 --> 00:08:05,050
create something that we would consider
intelligent I don't know how we will

356
00:08:05,050 --> 00:08:05,060
intelligent I don't know how we will
 

357
00:08:05,060 --> 00:08:09,550
intelligent I don't know how we will
know for sure maybe our own view of what

358
00:08:09,550 --> 00:08:09,560
know for sure maybe our own view of what
 

359
00:08:09,560 --> 00:08:12,010
know for sure maybe our own view of what
intelligence is will be refined more and

360
00:08:12,010 --> 00:08:12,020
intelligence is will be refined more and
 

361
00:08:12,020 --> 00:08:14,110
intelligence is will be refined more and
more until we finally figure out what we

362
00:08:14,110 --> 00:08:14,120
more until we finally figure out what we
 

363
00:08:14,120 --> 00:08:18,100
more until we finally figure out what we
mean when we talk about it but I I think

364
00:08:18,100 --> 00:08:18,110
mean when we talk about it but I I think
 

365
00:08:18,110 --> 00:08:22,330
mean when we talk about it but I I think
eventually we will create machines in a

366
00:08:22,330 --> 00:08:22,340
eventually we will create machines in a
 

367
00:08:22,340 --> 00:08:24,670
eventually we will create machines in a
sense that have intelligence they may

368
00:08:24,670 --> 00:08:24,680
sense that have intelligence they may
 

369
00:08:24,680 --> 00:08:26,740
sense that have intelligence they may
not be the kinds of machines we have now

370
00:08:26,740 --> 00:08:26,750
not be the kinds of machines we have now
 

371
00:08:26,750 --> 00:08:30,310
not be the kinds of machines we have now
and one of the things that that's going

372
00:08:30,310 --> 00:08:30,320
and one of the things that that's going
 

373
00:08:30,320 --> 00:08:34,029
and one of the things that that's going
to produce is is making us sort of

374
00:08:34,029 --> 00:08:34,039
to produce is is making us sort of
 

375
00:08:34,039 --> 00:08:37,290
to produce is is making us sort of
understand our own machine like

376
00:08:37,290 --> 00:08:37,300
understand our own machine like
 

377
00:08:37,300 --> 00:08:41,490
understand our own machine like
qualities that we in a sense are

378
00:08:41,490 --> 00:08:41,500
qualities that we in a sense are
 

379
00:08:41,500 --> 00:08:44,950
qualities that we in a sense are
mechanical in the sense that like an

380
00:08:44,950 --> 00:08:44,960
mechanical in the sense that like an
 

381
00:08:44,960 --> 00:08:47,770
mechanical in the sense that like an
eles cells are kind of mechanical they

382
00:08:47,770 --> 00:08:47,780
eles cells are kind of mechanical they
 

383
00:08:47,780 --> 00:08:50,890
eles cells are kind of mechanical they
part they have algorithms they process

384
00:08:50,890 --> 00:08:50,900
part they have algorithms they process
 

385
00:08:50,900 --> 00:08:54,400
part they have algorithms they process
information by and somehow out of this

386
00:08:54,400 --> 00:08:54,410
information by and somehow out of this
 

387
00:08:54,410 --> 00:08:59,080
information by and somehow out of this
mass of cells we get this emergent

388
00:08:59,080 --> 00:08:59,090
mass of cells we get this emergent
 

389
00:08:59,090 --> 00:09:01,390
mass of cells we get this emergent
property that we call intelligence but

390
00:09:01,390 --> 00:09:01,400
property that we call intelligence but
 

391
00:09:01,400 --> 00:09:06,520
property that we call intelligence but
underlying it is really just cellular

392
00:09:06,520 --> 00:09:06,530
underlying it is really just cellular
 

393
00:09:06,530 --> 00:09:09,010
underlying it is really just cellular
processing and and lots and lots and

394
00:09:09,010 --> 00:09:09,020
processing and and lots and lots and
 

395
00:09:09,020 --> 00:09:11,350
processing and and lots and lots and
lots of it do you think we'll be able to

396
00:09:11,350 --> 00:09:11,360
lots of it do you think we'll be able to
 

397
00:09:11,360 --> 00:09:13,320
lots of it do you think we'll be able to
do you think it's possible to create

398
00:09:13,320 --> 00:09:13,330
do you think it's possible to create
 

399
00:09:13,330 --> 00:09:15,400
do you think it's possible to create
intelligence without understanding our

400
00:09:15,400 --> 00:09:15,410
intelligence without understanding our
 

401
00:09:15,410 --> 00:09:17,740
intelligence without understanding our
own mind you said sort of in that

402
00:09:17,740 --> 00:09:17,750
own mind you said sort of in that
 

403
00:09:17,750 --> 00:09:19,150
own mind you said sort of in that
process we'll understand more and more

404
00:09:19,150 --> 00:09:19,160
process we'll understand more and more
 

405
00:09:19,160 --> 00:09:22,060
process we'll understand more and more
but do you think it's possible to sort

406
00:09:22,060 --> 00:09:22,070
but do you think it's possible to sort
 

407
00:09:22,070 --> 00:09:23,920
but do you think it's possible to sort
of create without really fully

408
00:09:23,920 --> 00:09:23,930
of create without really fully
 

409
00:09:23,930 --> 00:09:26,860
of create without really fully
understanding from a mechanistic

410
00:09:26,860 --> 00:09:26,870
understanding from a mechanistic
 

411
00:09:26,870 --> 00:09:28,630
understanding from a mechanistic
perspective sort of from a functional

412
00:09:28,630 --> 00:09:28,640
perspective sort of from a functional
 

413
00:09:28,640 --> 00:09:31,180
perspective sort of from a functional
perspective how our mysterious mind

414
00:09:31,180 --> 00:09:31,190
perspective how our mysterious mind
 

415
00:09:31,190 --> 00:09:35,500
perspective how our mysterious mind
works if I had to bet on it I would say

416
00:09:35,500 --> 00:09:35,510
works if I had to bet on it I would say
 

417
00:09:35,510 --> 00:09:38,830
works if I had to bet on it I would say
no we we we do have to understand our

418
00:09:38,830 --> 00:09:38,840
no we we we do have to understand our
 

419
00:09:38,840 --> 00:09:41,470
no we we we do have to understand our
own minds at least to some significant

420
00:09:41,470 --> 00:09:41,480
own minds at least to some significant
 

421
00:09:41,480 --> 00:09:45,160
own minds at least to some significant
extent but it I think that's a really

422
00:09:45,160 --> 00:09:45,170
extent but it I think that's a really
 

423
00:09:45,170 --> 00:09:47,590
extent but it I think that's a really
big open question I've been very

424
00:09:47,590 --> 00:09:47,600
big open question I've been very
 

425
00:09:47,600 --> 00:09:49,810
big open question I've been very
surprised at how far kind of brute force

426
00:09:49,810 --> 00:09:49,820
surprised at how far kind of brute force
 

427
00:09:49,820 --> 00:09:53,770
surprised at how far kind of brute force
approaches based on say big data and

428
00:09:53,770 --> 00:09:53,780
approaches based on say big data and
 

429
00:09:53,780 --> 00:09:57,640
approaches based on say big data and
huge networks can can take us I wouldn't

430
00:09:57,640 --> 00:09:57,650
huge networks can can take us I wouldn't
 

431
00:09:57,650 --> 00:10:00,550
huge networks can can take us I wouldn't
have expected that and they have nothing

432
00:10:00,550 --> 00:10:00,560
have expected that and they have nothing
 

433
00:10:00,560 --> 00:10:03,250
have expected that and they have nothing
to do with the way our minds work so

434
00:10:03,250 --> 00:10:03,260
to do with the way our minds work so
 

435
00:10:03,260 --> 00:10:05,530
to do with the way our minds work so
that's been surprising to me so it could

436
00:10:05,530 --> 00:10:05,540
that's been surprising to me so it could
 

437
00:10:05,540 --> 00:10:07,630
that's been surprising to me so it could
be wrong to explore the psychological

438
00:10:07,630 --> 00:10:07,640
be wrong to explore the psychological
 

439
00:10:07,640 --> 00:10:10,120
be wrong to explore the psychological
and the philosophical do you think we're

440
00:10:10,120 --> 00:10:10,130
and the philosophical do you think we're
 

441
00:10:10,130 --> 00:10:13,930
and the philosophical do you think we're
okay as a species with something that's

442
00:10:13,930 --> 00:10:13,940
okay as a species with something that's
 

443
00:10:13,940 --> 00:10:16,540
okay as a species with something that's
more intelligent than us do you think

444
00:10:16,540 --> 00:10:16,550
more intelligent than us do you think
 

445
00:10:16,550 --> 00:10:18,910
more intelligent than us do you think
perhaps the reason we're pushing that

446
00:10:18,910 --> 00:10:18,920
perhaps the reason we're pushing that
 

447
00:10:18,920 --> 00:10:21,460
perhaps the reason we're pushing that
line farther and farther is we're afraid

448
00:10:21,460 --> 00:10:21,470
line farther and farther is we're afraid
 

449
00:10:21,470 --> 00:10:23,830
line farther and farther is we're afraid
of acknowledging that there's something

450
00:10:23,830 --> 00:10:23,840
of acknowledging that there's something
 

451
00:10:23,840 --> 00:10:28,140
of acknowledging that there's something
stronger better smarter than us humans

452
00:10:28,140 --> 00:10:28,150
stronger better smarter than us humans
 

453
00:10:28,150 --> 00:10:30,490
stronger better smarter than us humans
well I'm not sure we can define

454
00:10:30,490 --> 00:10:30,500
well I'm not sure we can define
 

455
00:10:30,500 --> 00:10:32,890
well I'm not sure we can define
intelligence that way because you know

456
00:10:32,890 --> 00:10:32,900
intelligence that way because you know
 

457
00:10:32,900 --> 00:10:37,980
intelligence that way because you know
smarter then is with with respect to

458
00:10:37,980 --> 00:10:37,990
smarter then is with with respect to
 

459
00:10:37,990 --> 00:10:41,140
smarter then is with with respect to
what what you know computers are already

460
00:10:41,140 --> 00:10:41,150
what what you know computers are already
 

461
00:10:41,150 --> 00:10:43,030
what what you know computers are already
smarter than us in some areas they could

462
00:10:43,030 --> 00:10:43,040
smarter than us in some areas they could
 

463
00:10:43,040 --> 00:10:45,670
smarter than us in some areas they could
multiply much better than we can they

464
00:10:45,670 --> 00:10:45,680
multiply much better than we can they
 

465
00:10:45,680 --> 00:10:49,420
multiply much better than we can they
they can figure out driving routes to

466
00:10:49,420 --> 00:10:49,430
they can figure out driving routes to
 

467
00:10:49,430 --> 00:10:51,700
they can figure out driving routes to
take much faster and better than we can

468
00:10:51,700 --> 00:10:51,710
take much faster and better than we can
 

469
00:10:51,710 --> 00:10:53,500
take much faster and better than we can
they have a lot more information to draw

470
00:10:53,500 --> 00:10:53,510
they have a lot more information to draw
 

471
00:10:53,510 --> 00:10:55,450
they have a lot more information to draw
on they know about you know traffic

472
00:10:55,450 --> 00:10:55,460
on they know about you know traffic
 

473
00:10:55,460 --> 00:10:58,420
on they know about you know traffic
conditions and all that stuff so

474
00:10:58,420 --> 00:10:58,430
conditions and all that stuff so
 

475
00:10:58,430 --> 00:11:02,470
conditions and all that stuff so
for any given particular task sometimes

476
00:11:02,470 --> 00:11:02,480
for any given particular task sometimes
 

477
00:11:02,480 --> 00:11:04,480
for any given particular task sometimes
computers are much better than we are

478
00:11:04,480 --> 00:11:04,490
computers are much better than we are
 

479
00:11:04,490 --> 00:11:06,940
computers are much better than we are
and we're totally happy with that right

480
00:11:06,940 --> 00:11:06,950
and we're totally happy with that right
 

481
00:11:06,950 --> 00:11:08,769
and we're totally happy with that right
I'm totally happy with that I don't

482
00:11:08,769 --> 00:11:08,779
I'm totally happy with that I don't
 

483
00:11:08,779 --> 00:11:11,320
I'm totally happy with that I don't
doesn't bother me at all I guess the

484
00:11:11,320 --> 00:11:11,330
doesn't bother me at all I guess the
 

485
00:11:11,330 --> 00:11:13,960
doesn't bother me at all I guess the
question is you know what which things

486
00:11:13,960 --> 00:11:13,970
question is you know what which things
 

487
00:11:13,970 --> 00:11:17,440
question is you know what which things
about our intelligence would we feel

488
00:11:17,440 --> 00:11:17,450
about our intelligence would we feel
 

489
00:11:17,450 --> 00:11:22,600
about our intelligence would we feel
very sad or or upset that machine's had

490
00:11:22,600 --> 00:11:22,610
very sad or or upset that machine's had
 

491
00:11:22,610 --> 00:11:25,090
very sad or or upset that machine's had
been able to recreate so in the book I

492
00:11:25,090 --> 00:11:25,100
been able to recreate so in the book I
 

493
00:11:25,100 --> 00:11:27,730
been able to recreate so in the book I
talk about my former PhD advisor Douglas

494
00:11:27,730 --> 00:11:27,740
talk about my former PhD advisor Douglas
 

495
00:11:27,740 --> 00:11:30,940
talk about my former PhD advisor Douglas
Hofstadter who encountered a music

496
00:11:30,940 --> 00:11:30,950
Hofstadter who encountered a music
 

497
00:11:30,950 --> 00:11:35,290
Hofstadter who encountered a music
generation program and that was really

498
00:11:35,290 --> 00:11:35,300
generation program and that was really
 

499
00:11:35,300 --> 00:11:37,990
generation program and that was really
the line for him that if a machine could

500
00:11:37,990 --> 00:11:38,000
the line for him that if a machine could
 

501
00:11:38,000 --> 00:11:41,850
the line for him that if a machine could
create beautiful music that would be

502
00:11:41,850 --> 00:11:41,860
create beautiful music that would be
 

503
00:11:41,860 --> 00:11:45,370
create beautiful music that would be
terrifying for him because that is

504
00:11:45,370 --> 00:11:45,380
terrifying for him because that is
 

505
00:11:45,380 --> 00:11:48,010
terrifying for him because that is
something he feels is really at the core

506
00:11:48,010 --> 00:11:48,020
something he feels is really at the core
 

507
00:11:48,020 --> 00:11:50,470
something he feels is really at the core
of what it is to be human creating

508
00:11:50,470 --> 00:11:50,480
of what it is to be human creating
 

509
00:11:50,480 --> 00:11:53,800
of what it is to be human creating
beautiful music art literature I you

510
00:11:53,800 --> 00:11:53,810
beautiful music art literature I you
 

511
00:11:53,810 --> 00:11:56,860
beautiful music art literature I you
know I don't think he doesn't like the

512
00:11:56,860 --> 00:11:56,870
know I don't think he doesn't like the
 

513
00:11:56,870 --> 00:12:03,010
know I don't think he doesn't like the
fact that machines can recognize spoken

514
00:12:03,010 --> 00:12:03,020
fact that machines can recognize spoken
 

515
00:12:03,020 --> 00:12:05,530
fact that machines can recognize spoken
language really well like he doesn't he

516
00:12:05,530 --> 00:12:05,540
language really well like he doesn't he
 

517
00:12:05,540 --> 00:12:08,440
language really well like he doesn't he
personally doesn't like using speech

518
00:12:08,440 --> 00:12:08,450
personally doesn't like using speech
 

519
00:12:08,450 --> 00:12:10,660
personally doesn't like using speech
recognition I don't think it bothers him

520
00:12:10,660 --> 00:12:10,670
recognition I don't think it bothers him
 

521
00:12:10,670 --> 00:12:12,519
recognition I don't think it bothers him
to his core because it's like okay

522
00:12:12,519 --> 00:12:12,529
to his core because it's like okay
 

523
00:12:12,529 --> 00:12:15,910
to his core because it's like okay
that's not at the core of humanity but

524
00:12:15,910 --> 00:12:15,920
that's not at the core of humanity but
 

525
00:12:15,920 --> 00:12:17,320
that's not at the core of humanity but
it may be different for every person

526
00:12:17,320 --> 00:12:17,330
it may be different for every person
 

527
00:12:17,330 --> 00:12:23,320
it may be different for every person
what what really they feel would usurp

528
00:12:23,320 --> 00:12:23,330
what what really they feel would usurp
 

529
00:12:23,330 --> 00:12:26,019
what what really they feel would usurp
their humanity and I think maybe it's a

530
00:12:26,019 --> 00:12:26,029
their humanity and I think maybe it's a
 

531
00:12:26,029 --> 00:12:27,910
their humanity and I think maybe it's a
generational thing also maybe our

532
00:12:27,910 --> 00:12:27,920
generational thing also maybe our
 

533
00:12:27,920 --> 00:12:31,170
generational thing also maybe our
children or our children's children will

534
00:12:31,170 --> 00:12:31,180
children or our children's children will
 

535
00:12:31,180 --> 00:12:34,720
children or our children's children will
be adapted they'll adapt to these new

536
00:12:34,720 --> 00:12:34,730
be adapted they'll adapt to these new
 

537
00:12:34,730 --> 00:12:37,750
be adapted they'll adapt to these new
devices that can do all these tasks and

538
00:12:37,750 --> 00:12:37,760
devices that can do all these tasks and
 

539
00:12:37,760 --> 00:12:40,120
devices that can do all these tasks and
and say yes this thing is smarter than

540
00:12:40,120 --> 00:12:40,130
and say yes this thing is smarter than
 

541
00:12:40,130 --> 00:12:43,420
and say yes this thing is smarter than
me in all these areas but that's great

542
00:12:43,420 --> 00:12:43,430
me in all these areas but that's great
 

543
00:12:43,430 --> 00:12:47,710
me in all these areas but that's great
because it helps me looking at the broad

544
00:12:47,710 --> 00:12:47,720
because it helps me looking at the broad
 

545
00:12:47,720 --> 00:12:51,040
because it helps me looking at the broad
history of our species why do you think

546
00:12:51,040 --> 00:12:51,050
history of our species why do you think
 

547
00:12:51,050 --> 00:12:52,990
history of our species why do you think
so many humans have dreamed of creating

548
00:12:52,990 --> 00:12:53,000
so many humans have dreamed of creating
 

549
00:12:53,000 --> 00:12:54,610
so many humans have dreamed of creating
artificial life and artificial

550
00:12:54,610 --> 00:12:54,620
artificial life and artificial
 

551
00:12:54,620 --> 00:12:56,260
artificial life and artificial
intelligence throughout the history of

552
00:12:56,260 --> 00:12:56,270
intelligence throughout the history of
 

553
00:12:56,270 --> 00:12:58,900
intelligence throughout the history of
our civilization so not just this

554
00:12:58,900 --> 00:12:58,910
our civilization so not just this
 

555
00:12:58,910 --> 00:13:01,389
our civilization so not just this
century or the 20th century but really

556
00:13:01,389 --> 00:13:01,399
century or the 20th century but really
 

557
00:13:01,399 --> 00:13:03,970
century or the 20th century but really
many throughout many centuries that

558
00:13:03,970 --> 00:13:03,980
many throughout many centuries that
 

559
00:13:03,980 --> 00:13:07,269
many throughout many centuries that
preceded it that's a really good

560
00:13:07,269 --> 00:13:07,279
preceded it that's a really good
 

561
00:13:07,279 --> 00:13:09,390
preceded it that's a really good
question and I have wondered about that

562
00:13:09,390 --> 00:13:09,400
question and I have wondered about that
 

563
00:13:09,400 --> 00:13:12,190
question and I have wondered about that
because I'm I myself

564
00:13:12,190 --> 00:13:12,200
because I'm I myself
 

565
00:13:12,200 --> 00:13:16,700
because I'm I myself
you know was driven by curiosity about

566
00:13:16,700 --> 00:13:16,710
you know was driven by curiosity about
 

567
00:13:16,710 --> 00:13:19,580
you know was driven by curiosity about
my own thought processes and thought it

568
00:13:19,580 --> 00:13:19,590
my own thought processes and thought it
 

569
00:13:19,590 --> 00:13:21,440
my own thought processes and thought it
would be fantastic to be able to get a

570
00:13:21,440 --> 00:13:21,450
would be fantastic to be able to get a
 

571
00:13:21,450 --> 00:13:24,140
would be fantastic to be able to get a
computer to mimic some of my thought

572
00:13:24,140 --> 00:13:24,150
computer to mimic some of my thought
 

573
00:13:24,150 --> 00:13:27,830
computer to mimic some of my thought
process season I'm not sure why we're so

574
00:13:27,830 --> 00:13:27,840
process season I'm not sure why we're so
 

575
00:13:27,840 --> 00:13:35,540
process season I'm not sure why we're so
driven I think we want to understand

576
00:13:35,540 --> 00:13:35,550
driven I think we want to understand
 

577
00:13:35,550 --> 00:13:40,150
driven I think we want to understand
ourselves better and we also want

578
00:13:40,150 --> 00:13:40,160
ourselves better and we also want
 

579
00:13:40,160 --> 00:13:44,900
ourselves better and we also want
machines to do things for us but I don't

580
00:13:44,900 --> 00:13:44,910
machines to do things for us but I don't
 

581
00:13:44,910 --> 00:13:46,160
machines to do things for us but I don't
know there's something more to it

582
00:13:46,160 --> 00:13:46,170
know there's something more to it
 

583
00:13:46,170 --> 00:13:48,620
know there's something more to it
because it's so deep in in the kind of

584
00:13:48,620 --> 00:13:48,630
because it's so deep in in the kind of
 

585
00:13:48,630 --> 00:13:53,120
because it's so deep in in the kind of
Mythology or the dose of our species and

586
00:13:53,120 --> 00:13:53,130
Mythology or the dose of our species and
 

587
00:13:53,130 --> 00:13:55,010
Mythology or the dose of our species and
I don't think other species have this

588
00:13:55,010 --> 00:13:55,020
I don't think other species have this
 

589
00:13:55,020 --> 00:13:58,070
I don't think other species have this
drive so I don't know if you were to

590
00:13:58,070 --> 00:13:58,080
drive so I don't know if you were to
 

591
00:13:58,080 --> 00:13:59,990
drive so I don't know if you were to
sort of psychoanalyze yourself and

592
00:13:59,990 --> 00:14:00,000
sort of psychoanalyze yourself and
 

593
00:14:00,000 --> 00:14:02,720
sort of psychoanalyze yourself and
you're in your own interest in AI are

594
00:14:02,720 --> 00:14:02,730
you're in your own interest in AI are
 

595
00:14:02,730 --> 00:14:06,740
you're in your own interest in AI are
you what excites you about creating

596
00:14:06,740 --> 00:14:06,750
you what excites you about creating
 

597
00:14:06,750 --> 00:14:08,720
you what excites you about creating
intelligence you said understanding our

598
00:14:08,720 --> 00:14:08,730
intelligence you said understanding our
 

599
00:14:08,730 --> 00:14:09,680
intelligence you said understanding our
own selves

600
00:14:09,680 --> 00:14:09,690
own selves
 

601
00:14:09,690 --> 00:14:11,560
own selves
yeah I think that's what drives me

602
00:14:11,560 --> 00:14:11,570
yeah I think that's what drives me
 

603
00:14:11,570 --> 00:14:17,720
yeah I think that's what drives me
particularly I'm really interested in

604
00:14:17,720 --> 00:14:17,730
particularly I'm really interested in
 

605
00:14:17,730 --> 00:14:24,200
particularly I'm really interested in
human intelligence but I'm all I'm also

606
00:14:24,200 --> 00:14:24,210
human intelligence but I'm all I'm also
 

607
00:14:24,210 --> 00:14:25,730
human intelligence but I'm all I'm also
interested in the sort of the phenomenon

608
00:14:25,730 --> 00:14:25,740
interested in the sort of the phenomenon
 

609
00:14:25,740 --> 00:14:28,580
interested in the sort of the phenomenon
of intelligence more generally and I

610
00:14:28,580 --> 00:14:28,590
of intelligence more generally and I
 

611
00:14:28,590 --> 00:14:29,780
of intelligence more generally and I
don't think humans are the only thing

612
00:14:29,780 --> 00:14:29,790
don't think humans are the only thing
 

613
00:14:29,790 --> 00:14:30,770
don't think humans are the only thing
with intelligence

614
00:14:30,770 --> 00:14:30,780
with intelligence
 

615
00:14:30,780 --> 00:14:34,640
with intelligence
you know I or even animals that I think

616
00:14:34,640 --> 00:14:34,650
you know I or even animals that I think
 

617
00:14:34,650 --> 00:14:39,800
you know I or even animals that I think
intelligence is a concept that

618
00:14:39,800 --> 00:14:39,810
intelligence is a concept that
 

619
00:14:39,810 --> 00:14:43,220
intelligence is a concept that
encompasses a lot of complex systems and

620
00:14:43,220 --> 00:14:43,230
encompasses a lot of complex systems and
 

621
00:14:43,230 --> 00:14:46,730
encompasses a lot of complex systems and
if you think of things like insect

622
00:14:46,730 --> 00:14:46,740
if you think of things like insect
 

623
00:14:46,740 --> 00:14:50,960
if you think of things like insect
colonies or cellular processes or the

624
00:14:50,960 --> 00:14:50,970
colonies or cellular processes or the
 

625
00:14:50,970 --> 00:14:52,790
colonies or cellular processes or the
immune system or all kinds of different

626
00:14:52,790 --> 00:14:52,800
immune system or all kinds of different
 

627
00:14:52,800 --> 00:14:56,870
immune system or all kinds of different
biological or even societal processes

628
00:14:56,870 --> 00:14:56,880
biological or even societal processes
 

629
00:14:56,880 --> 00:14:59,840
biological or even societal processes
have as an emergent property some

630
00:14:59,840 --> 00:14:59,850
have as an emergent property some
 

631
00:14:59,850 --> 00:15:01,190
have as an emergent property some
aspects of what we would call

632
00:15:01,190 --> 00:15:01,200
aspects of what we would call
 

633
00:15:01,200 --> 00:15:03,410
aspects of what we would call
intelligence you know they have memory

634
00:15:03,410 --> 00:15:03,420
intelligence you know they have memory
 

635
00:15:03,420 --> 00:15:05,450
intelligence you know they have memory
they do in process information they have

636
00:15:05,450 --> 00:15:05,460
they do in process information they have
 

637
00:15:05,460 --> 00:15:08,060
they do in process information they have
goals they accomplish their goals etc

638
00:15:08,060 --> 00:15:08,070
goals they accomplish their goals etc
 

639
00:15:08,070 --> 00:15:12,050
goals they accomplish their goals etc
and to me that the question of what is

640
00:15:12,050 --> 00:15:12,060
and to me that the question of what is
 

641
00:15:12,060 --> 00:15:15,610
and to me that the question of what is
this thing we're talking about here was

642
00:15:15,610 --> 00:15:15,620
this thing we're talking about here was
 

643
00:15:15,620 --> 00:15:18,470
this thing we're talking about here was
really fascinating to me and and

644
00:15:18,470 --> 00:15:18,480
really fascinating to me and and
 

645
00:15:18,480 --> 00:15:21,170
really fascinating to me and and
exploring it using computers seem to be

646
00:15:21,170 --> 00:15:21,180
exploring it using computers seem to be
 

647
00:15:21,180 --> 00:15:24,080
exploring it using computers seem to be
a good way to approach the question so

648
00:15:24,080 --> 00:15:24,090
a good way to approach the question so
 

649
00:15:24,090 --> 00:15:25,129
a good way to approach the question so
do you think kind of

650
00:15:25,129 --> 00:15:25,139
do you think kind of
 

651
00:15:25,139 --> 00:15:26,869
do you think kind of
intelligence do you think of our

652
00:15:26,869 --> 00:15:26,879
intelligence do you think of our
 

653
00:15:26,879 --> 00:15:29,119
intelligence do you think of our
universes a kind of hierarchy of complex

654
00:15:29,119 --> 00:15:29,129
universes a kind of hierarchy of complex
 

655
00:15:29,129 --> 00:15:31,309
universes a kind of hierarchy of complex
systems and then intelligence is just

656
00:15:31,309 --> 00:15:31,319
systems and then intelligence is just
 

657
00:15:31,319 --> 00:15:34,340
systems and then intelligence is just
the property of any you can look at any

658
00:15:34,340 --> 00:15:34,350
the property of any you can look at any
 

659
00:15:34,350 --> 00:15:38,749
the property of any you can look at any
level and every level has some aspect of

660
00:15:38,749 --> 00:15:38,759
level and every level has some aspect of
 

661
00:15:38,759 --> 00:15:40,129
level and every level has some aspect of
intelligence so we're just like one

662
00:15:40,129 --> 00:15:40,139
intelligence so we're just like one
 

663
00:15:40,139 --> 00:15:42,379
intelligence so we're just like one
little speck in that giant hierarchy of

664
00:15:42,379 --> 00:15:42,389
little speck in that giant hierarchy of
 

665
00:15:42,389 --> 00:15:45,019
little speck in that giant hierarchy of
complex systems I don't know if I would

666
00:15:45,019 --> 00:15:45,029
complex systems I don't know if I would
 

667
00:15:45,029 --> 00:15:48,340
complex systems I don't know if I would
say any system like that has

668
00:15:48,340 --> 00:15:48,350
say any system like that has
 

669
00:15:48,350 --> 00:15:51,379
say any system like that has
intelligence but I guess what I want to

670
00:15:51,379 --> 00:15:51,389
intelligence but I guess what I want to
 

671
00:15:51,389 --> 00:15:54,530
intelligence but I guess what I want to
I don't have a good enough definition of

672
00:15:54,530 --> 00:15:54,540
I don't have a good enough definition of
 

673
00:15:54,540 --> 00:15:57,319
I don't have a good enough definition of
intelligence to say that so let me let

674
00:15:57,319 --> 00:15:57,329
intelligence to say that so let me let
 

675
00:15:57,329 --> 00:15:58,970
intelligence to say that so let me let
me do sort of multiple choice I guess

676
00:15:58,970 --> 00:15:58,980
me do sort of multiple choice I guess
 

677
00:15:58,980 --> 00:15:59,979
me do sort of multiple choice I guess
though

678
00:15:59,979 --> 00:15:59,989
though
 

679
00:15:59,989 --> 00:16:03,139
though
so you said ant colonies so our ant

680
00:16:03,139 --> 00:16:03,149
so you said ant colonies so our ant
 

681
00:16:03,149 --> 00:16:07,039
so you said ant colonies so our ant
colonies intelligent are the bacteria in

682
00:16:07,039 --> 00:16:07,049
colonies intelligent are the bacteria in
 

683
00:16:07,049 --> 00:16:09,889
colonies intelligent are the bacteria in
our body in intelligent and then look

684
00:16:09,889 --> 00:16:09,899
our body in intelligent and then look
 

685
00:16:09,899 --> 00:16:13,849
our body in intelligent and then look
going to the physics world molecules and

686
00:16:13,849 --> 00:16:13,859
going to the physics world molecules and
 

687
00:16:13,859 --> 00:16:17,379
going to the physics world molecules and
the behavior at the quantum level of of

688
00:16:17,379 --> 00:16:17,389
the behavior at the quantum level of of
 

689
00:16:17,389 --> 00:16:20,299
the behavior at the quantum level of of
electrons and so on is are those kinds

690
00:16:20,299 --> 00:16:20,309
electrons and so on is are those kinds
 

691
00:16:20,309 --> 00:16:22,280
electrons and so on is are those kinds
of systems do they possess intelligence

692
00:16:22,280 --> 00:16:22,290
of systems do they possess intelligence
 

693
00:16:22,290 --> 00:16:25,819
of systems do they possess intelligence
like words where's the line that feels

694
00:16:25,819 --> 00:16:25,829
like words where's the line that feels
 

695
00:16:25,829 --> 00:16:28,309
like words where's the line that feels
compelling to you I don't know I mean I

696
00:16:28,309 --> 00:16:28,319
compelling to you I don't know I mean I
 

697
00:16:28,319 --> 00:16:31,159
compelling to you I don't know I mean I
think intelligence is a continuum and I

698
00:16:31,159 --> 00:16:31,169
think intelligence is a continuum and I
 

699
00:16:31,169 --> 00:16:34,909
think intelligence is a continuum and I
think that the ability to in some sense

700
00:16:34,909 --> 00:16:34,919
think that the ability to in some sense
 

701
00:16:34,919 --> 00:16:40,669
think that the ability to in some sense
have intention have a goal have a some

702
00:16:40,669 --> 00:16:40,679
have intention have a goal have a some
 

703
00:16:40,679 --> 00:16:44,720
have intention have a goal have a some
kind of self-awareness is part of it

704
00:16:44,720 --> 00:16:44,730
kind of self-awareness is part of it
 

705
00:16:44,730 --> 00:16:48,199
kind of self-awareness is part of it
so I'm not sure if you know it's hard to

706
00:16:48,199 --> 00:16:48,209
so I'm not sure if you know it's hard to
 

707
00:16:48,209 --> 00:16:50,479
so I'm not sure if you know it's hard to
know where to draw that line I think

708
00:16:50,479 --> 00:16:50,489
know where to draw that line I think
 

709
00:16:50,489 --> 00:16:52,850
know where to draw that line I think
that's kind of a mystery but I wouldn't

710
00:16:52,850 --> 00:16:52,860
that's kind of a mystery but I wouldn't
 

711
00:16:52,860 --> 00:16:56,449
that's kind of a mystery but I wouldn't
say that say that you know this the

712
00:16:56,449 --> 00:16:56,459
say that say that you know this the
 

713
00:16:56,459 --> 00:16:59,479
say that say that you know this the
planets orbiting the Sun her is an

714
00:16:59,479 --> 00:16:59,489
planets orbiting the Sun her is an
 

715
00:16:59,489 --> 00:17:02,689
planets orbiting the Sun her is an
intelligent system I mean I would find

716
00:17:02,689 --> 00:17:02,699
intelligent system I mean I would find
 

717
00:17:02,699 --> 00:17:05,090
intelligent system I mean I would find
that maybe not the right term to

718
00:17:05,090 --> 00:17:05,100
that maybe not the right term to
 

719
00:17:05,100 --> 00:17:07,250
that maybe not the right term to
describe that and this is you know

720
00:17:07,250 --> 00:17:07,260
describe that and this is you know
 

721
00:17:07,260 --> 00:17:09,199
describe that and this is you know
there's all this debate in the field of

722
00:17:09,199 --> 00:17:09,209
there's all this debate in the field of
 

723
00:17:09,209 --> 00:17:11,329
there's all this debate in the field of
like what's what's the right way to

724
00:17:11,329 --> 00:17:11,339
like what's what's the right way to
 

725
00:17:11,339 --> 00:17:13,189
like what's what's the right way to
define intelligence what's the right way

726
00:17:13,189 --> 00:17:13,199
define intelligence what's the right way
 

727
00:17:13,199 --> 00:17:15,710
define intelligence what's the right way
to model intelligence should we think

728
00:17:15,710 --> 00:17:15,720
to model intelligence should we think
 

729
00:17:15,720 --> 00:17:17,210
to model intelligence should we think
about computation should we think about

730
00:17:17,210 --> 00:17:17,220
about computation should we think about
 

731
00:17:17,220 --> 00:17:20,389
about computation should we think about
dynamics and should we think about you

732
00:17:20,389 --> 00:17:20,399
dynamics and should we think about you
 

733
00:17:20,399 --> 00:17:23,329
dynamics and should we think about you
know free energy and all of that stuff

734
00:17:23,329 --> 00:17:23,339
know free energy and all of that stuff
 

735
00:17:23,339 --> 00:17:26,990
know free energy and all of that stuff
and I think that it's it's a fantastic

736
00:17:26,990 --> 00:17:27,000
and I think that it's it's a fantastic
 

737
00:17:27,000 --> 00:17:28,639
and I think that it's it's a fantastic
time to be in the field because there's

738
00:17:28,639 --> 00:17:28,649
time to be in the field because there's
 

739
00:17:28,649 --> 00:17:31,039
time to be in the field because there's
so many questions and so much we don't

740
00:17:31,039 --> 00:17:31,049
so many questions and so much we don't
 

741
00:17:31,049 --> 00:17:33,950
so many questions and so much we don't
understand there's so much work to do so

742
00:17:33,950 --> 00:17:33,960
understand there's so much work to do so
 

743
00:17:33,960 --> 00:17:37,100
understand there's so much work to do so
are we are we the most special kind of

744
00:17:37,100 --> 00:17:37,110
are we are we the most special kind of
 

745
00:17:37,110 --> 00:17:38,450
are we are we the most special kind of
intelligence

746
00:17:38,450 --> 00:17:38,460
intelligence
 

747
00:17:38,460 --> 00:17:41,630
intelligence
this kind of you said there's a bunch of

748
00:17:41,630 --> 00:17:41,640
this kind of you said there's a bunch of
 

749
00:17:41,640 --> 00:17:43,520
this kind of you said there's a bunch of
different elements and characteristics

750
00:17:43,520 --> 00:17:43,530
different elements and characteristics
 

751
00:17:43,530 --> 00:17:49,940
different elements and characteristics
of intelligent systems and colonies are

752
00:17:49,940 --> 00:17:49,950
of intelligent systems and colonies are
 

753
00:17:49,950 --> 00:17:52,190
of intelligent systems and colonies are
his human intelligence the thing in our

754
00:17:52,190 --> 00:17:52,200
his human intelligence the thing in our
 

755
00:17:52,200 --> 00:17:54,260
his human intelligence the thing in our
brain is that the most interesting kind

756
00:17:54,260 --> 00:17:54,270
brain is that the most interesting kind
 

757
00:17:54,270 --> 00:17:56,270
brain is that the most interesting kind
of intelligence in this continuum

758
00:17:56,270 --> 00:17:56,280
of intelligence in this continuum
 

759
00:17:56,280 --> 00:17:58,450
of intelligence in this continuum
well it's interesting to us because

760
00:17:58,450 --> 00:17:58,460
well it's interesting to us because
 

761
00:17:58,460 --> 00:18:02,420
well it's interesting to us because
because it is us I mean interesting to

762
00:18:02,420 --> 00:18:02,430
because it is us I mean interesting to
 

763
00:18:02,430 --> 00:18:05,630
because it is us I mean interesting to
me yes and because I'm part of the you

764
00:18:05,630 --> 00:18:05,640
me yes and because I'm part of the you
 

765
00:18:05,640 --> 00:18:07,610
me yes and because I'm part of the you
know human but to understanding the

766
00:18:07,610 --> 00:18:07,620
know human but to understanding the
 

767
00:18:07,620 --> 00:18:08,990
know human but to understanding the
fundamentals of intelligence what I'm

768
00:18:08,990 --> 00:18:09,000
fundamentals of intelligence what I'm
 

769
00:18:09,000 --> 00:18:11,090
fundamentals of intelligence what I'm
yeah yeah Jerry is studying the human is

770
00:18:11,090 --> 00:18:11,100
yeah yeah Jerry is studying the human is
 

771
00:18:11,100 --> 00:18:12,950
yeah yeah Jerry is studying the human is
sort of if everything we've talked about

772
00:18:12,950 --> 00:18:12,960
sort of if everything we've talked about
 

773
00:18:12,960 --> 00:18:15,070
sort of if everything we've talked about
will you talk about in your book what

774
00:18:15,070 --> 00:18:15,080
will you talk about in your book what
 

775
00:18:15,080 --> 00:18:18,980
will you talk about in your book what
just the AI field this notion yes it's

776
00:18:18,980 --> 00:18:18,990
just the AI field this notion yes it's
 

777
00:18:18,990 --> 00:18:21,350
just the AI field this notion yes it's
hard to define but it's usually talking

778
00:18:21,350 --> 00:18:21,360
hard to define but it's usually talking
 

779
00:18:21,360 --> 00:18:23,630
hard to define but it's usually talking
about something that's very akin to

780
00:18:23,630 --> 00:18:23,640
about something that's very akin to
 

781
00:18:23,640 --> 00:18:25,970
about something that's very akin to
human intelligence to me it is the most

782
00:18:25,970 --> 00:18:25,980
human intelligence to me it is the most
 

783
00:18:25,980 --> 00:18:28,010
human intelligence to me it is the most
interesting because it's the most

784
00:18:28,010 --> 00:18:28,020
interesting because it's the most
 

785
00:18:28,020 --> 00:18:31,210
interesting because it's the most
complex I think it's the most self-aware

786
00:18:31,210 --> 00:18:31,220
complex I think it's the most self-aware
 

787
00:18:31,220 --> 00:18:34,490
complex I think it's the most self-aware
it's the only system at least that I

788
00:18:34,490 --> 00:18:34,500
it's the only system at least that I
 

789
00:18:34,500 --> 00:18:36,710
it's the only system at least that I
know of that reflects on its own

790
00:18:36,710 --> 00:18:36,720
know of that reflects on its own
 

791
00:18:36,720 --> 00:18:39,650
know of that reflects on its own
intelligence and you talk about the

792
00:18:39,650 --> 00:18:39,660
intelligence and you talk about the
 

793
00:18:39,660 --> 00:18:43,340
intelligence and you talk about the
history of AI and us in terms of

794
00:18:43,340 --> 00:18:43,350
history of AI and us in terms of
 

795
00:18:43,350 --> 00:18:45,170
history of AI and us in terms of
creating artificial intelligence being

796
00:18:45,170 --> 00:18:45,180
creating artificial intelligence being
 

797
00:18:45,180 --> 00:18:48,740
creating artificial intelligence being
terrible at predicting the future or the

798
00:18:48,740 --> 00:18:48,750
terrible at predicting the future or the
 

799
00:18:48,750 --> 00:18:53,300
terrible at predicting the future or the
Iowa tech in general so why do you think

800
00:18:53,300 --> 00:18:53,310
Iowa tech in general so why do you think
 

801
00:18:53,310 --> 00:18:55,850
Iowa tech in general so why do you think
we're so bad at predicting the future

802
00:18:55,850 --> 00:18:55,860
we're so bad at predicting the future
 

803
00:18:55,860 --> 00:19:00,290
we're so bad at predicting the future
are we hopelessly bad so no matter what

804
00:19:00,290 --> 00:19:00,300
are we hopelessly bad so no matter what
 

805
00:19:00,300 --> 00:19:02,570
are we hopelessly bad so no matter what
well there's this decade or the next few

806
00:19:02,570 --> 00:19:02,580
well there's this decade or the next few
 

807
00:19:02,580 --> 00:19:03,980
well there's this decade or the next few
decades every time I make a prediction

808
00:19:03,980 --> 00:19:03,990
decades every time I make a prediction
 

809
00:19:03,990 --> 00:19:06,860
decades every time I make a prediction
there's just no way of doing it well or

810
00:19:06,860 --> 00:19:06,870
there's just no way of doing it well or
 

811
00:19:06,870 --> 00:19:09,680
there's just no way of doing it well or
as the field matures we'll be better and

812
00:19:09,680 --> 00:19:09,690
as the field matures we'll be better and
 

813
00:19:09,690 --> 00:19:11,840
as the field matures we'll be better and
better at it I believe as the field

814
00:19:11,840 --> 00:19:11,850
better at it I believe as the field
 

815
00:19:11,850 --> 00:19:14,210
better at it I believe as the field
matures we will be better and I think

816
00:19:14,210 --> 00:19:14,220
matures we will be better and I think
 

817
00:19:14,220 --> 00:19:15,500
matures we will be better and I think
the reason that we've had so much

818
00:19:15,500 --> 00:19:15,510
the reason that we've had so much
 

819
00:19:15,510 --> 00:19:17,600
the reason that we've had so much
trouble is that we have so little

820
00:19:17,600 --> 00:19:17,610
trouble is that we have so little
 

821
00:19:17,610 --> 00:19:20,500
trouble is that we have so little
understanding of our own intelligence so

822
00:19:20,500 --> 00:19:20,510
understanding of our own intelligence so
 

823
00:19:20,510 --> 00:19:26,720
understanding of our own intelligence so
there's the famous story about Marvin

824
00:19:26,720 --> 00:19:26,730
there's the famous story about Marvin
 

825
00:19:26,730 --> 00:19:31,070
there's the famous story about Marvin
Minsky assigning computer vision as a

826
00:19:31,070 --> 00:19:31,080
Minsky assigning computer vision as a
 

827
00:19:31,080 --> 00:19:34,310
Minsky assigning computer vision as a
summer project to his undergrad students

828
00:19:34,310 --> 00:19:34,320
summer project to his undergrad students
 

829
00:19:34,320 --> 00:19:35,960
summer project to his undergrad students
and I believe that's actually a true

830
00:19:35,960 --> 00:19:35,970
and I believe that's actually a true
 

831
00:19:35,970 --> 00:19:38,270
and I believe that's actually a true
story ya know there's a there's a

832
00:19:38,270 --> 00:19:38,280
story ya know there's a there's a
 

833
00:19:38,280 --> 00:19:40,430
story ya know there's a there's a
write-up on it everyone should read it's

834
00:19:40,430 --> 00:19:40,440
write-up on it everyone should read it's
 

835
00:19:40,440 --> 00:19:42,790
write-up on it everyone should read it's
like a I think it's like a proposal

836
00:19:42,790 --> 00:19:42,800
like a I think it's like a proposal
 

837
00:19:42,800 --> 00:19:46,220
like a I think it's like a proposal
this describes everything done in that

838
00:19:46,220 --> 00:19:46,230
this describes everything done in that
 

839
00:19:46,230 --> 00:19:48,890
this describes everything done in that
project is hilarious because that I mean

840
00:19:48,890 --> 00:19:48,900
project is hilarious because that I mean
 

841
00:19:48,900 --> 00:19:50,750
project is hilarious because that I mean
you can explain it but for my sort of

842
00:19:50,750 --> 00:19:50,760
you can explain it but for my sort of
 

843
00:19:50,760 --> 00:19:51,890
you can explain it but for my sort of
recollection it described

844
00:19:51,890 --> 00:19:51,900
recollection it described
 

845
00:19:51,900 --> 00:19:53,390
recollection it described
is basically all the fundamental

846
00:19:53,390 --> 00:19:53,400
is basically all the fundamental
 

847
00:19:53,400 --> 00:19:55,370
is basically all the fundamental
problems of computer vision many of

848
00:19:55,370 --> 00:19:55,380
problems of computer vision many of
 

849
00:19:55,380 --> 00:19:57,260
problems of computer vision many of
which they still haven't been solved

850
00:19:57,260 --> 00:19:57,270
which they still haven't been solved
 

851
00:19:57,270 --> 00:19:59,660
which they still haven't been solved
yeah and and I don't know how far they

852
00:19:59,660 --> 00:19:59,670
yeah and and I don't know how far they
 

853
00:19:59,670 --> 00:20:02,810
yeah and and I don't know how far they
really expected to get but I think that

854
00:20:02,810 --> 00:20:02,820
really expected to get but I think that
 

855
00:20:02,820 --> 00:20:04,580
really expected to get but I think that
and and they're really you know Marvin

856
00:20:04,580 --> 00:20:04,590
and and they're really you know Marvin
 

857
00:20:04,590 --> 00:20:06,530
and and they're really you know Marvin
Minsky is super smart guy and very

858
00:20:06,530 --> 00:20:06,540
Minsky is super smart guy and very
 

859
00:20:06,540 --> 00:20:10,460
Minsky is super smart guy and very
sophisticated thinker but I think that

860
00:20:10,460 --> 00:20:10,470
sophisticated thinker but I think that
 

861
00:20:10,470 --> 00:20:13,520
sophisticated thinker but I think that
no one really understands or understood

862
00:20:13,520 --> 00:20:13,530
no one really understands or understood
 

863
00:20:13,530 --> 00:20:17,210
no one really understands or understood
still doesn't understand how complicated

864
00:20:17,210 --> 00:20:17,220
still doesn't understand how complicated
 

865
00:20:17,220 --> 00:20:21,580
still doesn't understand how complicated
how complex the things that we do are

866
00:20:21,580 --> 00:20:21,590
how complex the things that we do are
 

867
00:20:21,590 --> 00:20:24,440
how complex the things that we do are
because they're so invisible to us you

868
00:20:24,440 --> 00:20:24,450
because they're so invisible to us you
 

869
00:20:24,450 --> 00:20:26,960
because they're so invisible to us you
know to us vision being able to look out

870
00:20:26,960 --> 00:20:26,970
know to us vision being able to look out
 

871
00:20:26,970 --> 00:20:28,490
know to us vision being able to look out
at the world and describe what we see

872
00:20:28,490 --> 00:20:28,500
at the world and describe what we see
 

873
00:20:28,500 --> 00:20:32,210
at the world and describe what we see
that's just immediate it feels like it's

874
00:20:32,210 --> 00:20:32,220
that's just immediate it feels like it's
 

875
00:20:32,220 --> 00:20:34,310
that's just immediate it feels like it's
no work at all so it didn't seem like it

876
00:20:34,310 --> 00:20:34,320
no work at all so it didn't seem like it
 

877
00:20:34,320 --> 00:20:36,500
no work at all so it didn't seem like it
would be that hard but there's so much

878
00:20:36,500 --> 00:20:36,510
would be that hard but there's so much
 

879
00:20:36,510 --> 00:20:37,780
would be that hard but there's so much
going on

880
00:20:37,780 --> 00:20:37,790
going on
 

881
00:20:37,790 --> 00:20:40,640
going on
unconsciously sort of invisible to us

882
00:20:40,640 --> 00:20:40,650
unconsciously sort of invisible to us
 

883
00:20:40,650 --> 00:20:47,030
unconsciously sort of invisible to us
that I think we overestimate how easy it

884
00:20:47,030 --> 00:20:47,040
that I think we overestimate how easy it
 

885
00:20:47,040 --> 00:20:49,520
that I think we overestimate how easy it
will be to get computers to do it and

886
00:20:49,520 --> 00:20:49,530
will be to get computers to do it and
 

887
00:20:49,530 --> 00:20:53,180
will be to get computers to do it and
sort of for me to ask an unfair question

888
00:20:53,180 --> 00:20:53,190
sort of for me to ask an unfair question
 

889
00:20:53,190 --> 00:20:55,880
sort of for me to ask an unfair question
you've done research you've thought

890
00:20:55,880 --> 00:20:55,890
you've done research you've thought
 

891
00:20:55,890 --> 00:20:58,190
you've done research you've thought
about many different branches of AI and

892
00:20:58,190 --> 00:20:58,200
about many different branches of AI and
 

893
00:20:58,200 --> 00:21:01,190
about many different branches of AI and
through this book widespread looking at

894
00:21:01,190 --> 00:21:01,200
through this book widespread looking at
 

895
00:21:01,200 --> 00:21:06,140
through this book widespread looking at
where AI has been where it is today what

896
00:21:06,140 --> 00:21:06,150
where AI has been where it is today what
 

897
00:21:06,150 --> 00:21:08,990
where AI has been where it is today what
if you were to make a prediction how

898
00:21:08,990 --> 00:21:09,000
if you were to make a prediction how
 

899
00:21:09,000 --> 00:21:11,390
if you were to make a prediction how
many years from now would we as a

900
00:21:11,390 --> 00:21:11,400
many years from now would we as a
 

901
00:21:11,400 --> 00:21:15,380
many years from now would we as a
society create something that you would

902
00:21:15,380 --> 00:21:15,390
society create something that you would
 

903
00:21:15,390 --> 00:21:19,600
society create something that you would
say achieved human level intelligence or

904
00:21:19,600 --> 00:21:19,610
say achieved human level intelligence or
 

905
00:21:19,610 --> 00:21:23,570
say achieved human level intelligence or
superhuman level intelligence that is an

906
00:21:23,570 --> 00:21:23,580
superhuman level intelligence that is an
 

907
00:21:23,580 --> 00:21:25,790
superhuman level intelligence that is an
unfair question a prediction that will

908
00:21:25,790 --> 00:21:25,800
unfair question a prediction that will
 

909
00:21:25,800 --> 00:21:29,060
unfair question a prediction that will
most likely be wrong so but it's just

910
00:21:29,060 --> 00:21:29,070
most likely be wrong so but it's just
 

911
00:21:29,070 --> 00:21:32,390
most likely be wrong so but it's just
your notion because okay I'll say I'll

912
00:21:32,390 --> 00:21:32,400
your notion because okay I'll say I'll
 

913
00:21:32,400 --> 00:21:34,610
your notion because okay I'll say I'll
say more than a hundred years more than

914
00:21:34,610 --> 00:21:34,620
say more than a hundred years more than
 

915
00:21:34,620 --> 00:21:36,350
say more than a hundred years more than
a hundred years and there I quoted

916
00:21:36,350 --> 00:21:36,360
a hundred years and there I quoted
 

917
00:21:36,360 --> 00:21:38,780
a hundred years and there I quoted
somebody in my book who said that human

918
00:21:38,780 --> 00:21:38,790
somebody in my book who said that human
 

919
00:21:38,790 --> 00:21:41,300
somebody in my book who said that human
level intelligence is a hundred Nobel

920
00:21:41,300 --> 00:21:41,310
level intelligence is a hundred Nobel
 

921
00:21:41,310 --> 00:21:45,560
level intelligence is a hundred Nobel
Prizes away which I like because it's a

922
00:21:45,560 --> 00:21:45,570
Prizes away which I like because it's a
 

923
00:21:45,570 --> 00:21:48,170
Prizes away which I like because it's a
it's a nice way to to sort of it's a

924
00:21:48,170 --> 00:21:48,180
it's a nice way to to sort of it's a
 

925
00:21:48,180 --> 00:21:52,190
it's a nice way to to sort of it's a
nice unit for prediction and it's like

926
00:21:52,190 --> 00:21:52,200
nice unit for prediction and it's like
 

927
00:21:52,200 --> 00:21:55,940
nice unit for prediction and it's like
that many fantastic discoveries have to

928
00:21:55,940 --> 00:21:55,950
that many fantastic discoveries have to
 

929
00:21:55,950 --> 00:21:57,530
that many fantastic discoveries have to
be made and of course there's no Nobel

930
00:21:57,530 --> 00:21:57,540
be made and of course there's no Nobel
 

931
00:21:57,540 --> 00:22:02,790
be made and of course there's no Nobel
Prize in

932
00:22:02,790 --> 00:22:02,800

 

933
00:22:02,800 --> 00:22:05,490

if we look at that hundred years your

934
00:22:05,490 --> 00:22:05,500
if we look at that hundred years your
 

935
00:22:05,500 --> 00:22:06,500
if we look at that hundred years your
senses

936
00:22:06,500 --> 00:22:06,510
senses
 

937
00:22:06,510 --> 00:22:10,410
senses
really the journey to intelligence has

938
00:22:10,410 --> 00:22:10,420
really the journey to intelligence has
 

939
00:22:10,420 --> 00:22:14,490
really the journey to intelligence has
to go through something something more

940
00:22:14,490 --> 00:22:14,500
to go through something something more
 

941
00:22:14,500 --> 00:22:16,650
to go through something something more
complicated as again to our own

942
00:22:16,650 --> 00:22:16,660
complicated as again to our own
 

943
00:22:16,660 --> 00:22:20,370
complicated as again to our own
cognitive systems understanding them

944
00:22:20,370 --> 00:22:20,380
cognitive systems understanding them
 

945
00:22:20,380 --> 00:22:22,770
cognitive systems understanding them
being able to create them in in the

946
00:22:22,770 --> 00:22:22,780
being able to create them in in the
 

947
00:22:22,780 --> 00:22:25,350
being able to create them in in the
artificial systems as opposed to sort of

948
00:22:25,350 --> 00:22:25,360
artificial systems as opposed to sort of
 

949
00:22:25,360 --> 00:22:27,330
artificial systems as opposed to sort of
taking the machine learning approaches

950
00:22:27,330 --> 00:22:27,340
taking the machine learning approaches
 

951
00:22:27,340 --> 00:22:30,680
taking the machine learning approaches
of today and really scaling them and

952
00:22:30,680 --> 00:22:30,690
of today and really scaling them and
 

953
00:22:30,690 --> 00:22:32,790
of today and really scaling them and
scaling them and scaling them

954
00:22:32,790 --> 00:22:32,800
scaling them and scaling them
 

955
00:22:32,800 --> 00:22:34,470
scaling them and scaling them
exponentially with both computing

956
00:22:34,470 --> 00:22:34,480
exponentially with both computing
 

957
00:22:34,480 --> 00:22:38,600
exponentially with both computing
hardware and and data that would be my

958
00:22:38,600 --> 00:22:38,610
hardware and and data that would be my
 

959
00:22:38,610 --> 00:22:41,310
hardware and and data that would be my
that would be my guess

960
00:22:41,310 --> 00:22:41,320
that would be my guess
 

961
00:22:41,320 --> 00:22:46,500
that would be my guess
you know I think that in in the the sort

962
00:22:46,500 --> 00:22:46,510
you know I think that in in the the sort
 

963
00:22:46,510 --> 00:22:49,350
you know I think that in in the the sort
of going along in the narrow AI that

964
00:22:49,350 --> 00:22:49,360
of going along in the narrow AI that
 

965
00:22:49,360 --> 00:22:52,470
of going along in the narrow AI that
these current the current approaches

966
00:22:52,470 --> 00:22:52,480
these current the current approaches
 

967
00:22:52,480 --> 00:22:55,170
these current the current approaches
will get better you know I think there's

968
00:22:55,170 --> 00:22:55,180
will get better you know I think there's
 

969
00:22:55,180 --> 00:22:57,720
will get better you know I think there's
some fundamental limits to how far

970
00:22:57,720 --> 00:22:57,730
some fundamental limits to how far
 

971
00:22:57,730 --> 00:23:00,090
some fundamental limits to how far
they're gonna get I might be wrong but

972
00:23:00,090 --> 00:23:00,100
they're gonna get I might be wrong but
 

973
00:23:00,100 --> 00:23:03,230
they're gonna get I might be wrong but
that's what I think but and there's some

974
00:23:03,230 --> 00:23:03,240
that's what I think but and there's some
 

975
00:23:03,240 --> 00:23:05,720
that's what I think but and there's some
fundamental weaknesses that they have

976
00:23:05,720 --> 00:23:05,730
fundamental weaknesses that they have
 

977
00:23:05,730 --> 00:23:10,110
fundamental weaknesses that they have
that I talked about in the book that

978
00:23:10,110 --> 00:23:10,120
that I talked about in the book that
 

979
00:23:10,120 --> 00:23:12,980
that I talked about in the book that
that just comes from this approach of

980
00:23:12,980 --> 00:23:12,990
that just comes from this approach of
 

981
00:23:12,990 --> 00:23:21,170
that just comes from this approach of
supervised learning we require requiring

982
00:23:21,170 --> 00:23:21,180

 

983
00:23:21,180 --> 00:23:26,390

sort of feed-forward networks and so on

984
00:23:26,390 --> 00:23:26,400
sort of feed-forward networks and so on
 

985
00:23:26,400 --> 00:23:29,220
sort of feed-forward networks and so on
it it's just I don't think it's a

986
00:23:29,220 --> 00:23:29,230
it it's just I don't think it's a
 

987
00:23:29,230 --> 00:23:33,000
it it's just I don't think it's a
sustainable approach to understanding

988
00:23:33,000 --> 00:23:33,010
sustainable approach to understanding
 

989
00:23:33,010 --> 00:23:35,880
sustainable approach to understanding
the world yeah I'm I'm personally torn

990
00:23:35,880 --> 00:23:35,890
the world yeah I'm I'm personally torn
 

991
00:23:35,890 --> 00:23:38,310
the world yeah I'm I'm personally torn
on it sort of I've everything read about

992
00:23:38,310 --> 00:23:38,320
on it sort of I've everything read about
 

993
00:23:38,320 --> 00:23:40,650
on it sort of I've everything read about
in the book and sort of we're talking

994
00:23:40,650 --> 00:23:40,660
in the book and sort of we're talking
 

995
00:23:40,660 --> 00:23:43,950
in the book and sort of we're talking
about now I agreed I agree with you but

996
00:23:43,950 --> 00:23:43,960
about now I agreed I agree with you but
 

997
00:23:43,960 --> 00:23:46,620
about now I agreed I agree with you but
I'm more and more depending on the day

998
00:23:46,620 --> 00:23:46,630
I'm more and more depending on the day
 

999
00:23:46,630 --> 00:23:49,530
I'm more and more depending on the day
first of all I'm deeply surprised by the

1000
00:23:49,530 --> 00:23:49,540
first of all I'm deeply surprised by the
 

1001
00:23:49,540 --> 00:23:51,570
first of all I'm deeply surprised by the
successful machine learning and deep

1002
00:23:51,570 --> 00:23:51,580
successful machine learning and deep
 

1003
00:23:51,580 --> 00:23:53,160
successful machine learning and deep
learning in general and from the very

1004
00:23:53,160 --> 00:23:53,170
learning in general and from the very
 

1005
00:23:53,170 --> 00:23:55,260
learning in general and from the very
beginning that when I was it's really

1006
00:23:55,260 --> 00:23:55,270
beginning that when I was it's really
 

1007
00:23:55,270 --> 00:23:57,420
beginning that when I was it's really
been many focus of work I'm just

1008
00:23:57,420 --> 00:23:57,430
been many focus of work I'm just
 

1009
00:23:57,430 --> 00:23:58,800
been many focus of work I'm just
surprised how far it gets

1010
00:23:58,800 --> 00:23:58,810
surprised how far it gets
 

1011
00:23:58,810 --> 00:24:02,550
surprised how far it gets
and I'm also think we're really early on

1012
00:24:02,550 --> 00:24:02,560
and I'm also think we're really early on
 

1013
00:24:02,560 --> 00:24:07,560
and I'm also think we're really early on
in these efforts of these narrow AI so I

1014
00:24:07,560 --> 00:24:07,570
in these efforts of these narrow AI so I
 

1015
00:24:07,570 --> 00:24:09,240
in these efforts of these narrow AI so I
think there will be a lot of surprise

1016
00:24:09,240 --> 00:24:09,250
think there will be a lot of surprise
 

1017
00:24:09,250 --> 00:24:11,330
think there will be a lot of surprise
off how far it gets

1018
00:24:11,330 --> 00:24:11,340
off how far it gets
 

1019
00:24:11,340 --> 00:24:14,480
off how far it gets
I think will be extremely impressed like

1020
00:24:14,480 --> 00:24:14,490
I think will be extremely impressed like
 

1021
00:24:14,490 --> 00:24:16,489
I think will be extremely impressed like
my senses everything I've seen so far

1022
00:24:16,489 --> 00:24:16,499
my senses everything I've seen so far
 

1023
00:24:16,499 --> 00:24:18,470
my senses everything I've seen so far
and we'll talk about autonomous driving

1024
00:24:18,470 --> 00:24:18,480
and we'll talk about autonomous driving
 

1025
00:24:18,480 --> 00:24:20,950
and we'll talk about autonomous driving
and so on I think we can get really far

1026
00:24:20,950 --> 00:24:20,960
and so on I think we can get really far
 

1027
00:24:20,960 --> 00:24:24,019
and so on I think we can get really far
but I also have a sense that we will

1028
00:24:24,019 --> 00:24:24,029
but I also have a sense that we will
 

1029
00:24:24,029 --> 00:24:27,019
but I also have a sense that we will
discover just like you said is that even

1030
00:24:27,019 --> 00:24:27,029
discover just like you said is that even
 

1031
00:24:27,029 --> 00:24:29,810
discover just like you said is that even
though we'll get really far in order to

1032
00:24:29,810 --> 00:24:29,820
though we'll get really far in order to
 

1033
00:24:29,820 --> 00:24:31,129
though we'll get really far in order to
create something like our own

1034
00:24:31,129 --> 00:24:31,139
create something like our own
 

1035
00:24:31,139 --> 00:24:32,690
create something like our own
intelligence is actually much farther

1036
00:24:32,690 --> 00:24:32,700
intelligence is actually much farther
 

1037
00:24:32,700 --> 00:24:33,799
intelligence is actually much farther
than we realized

1038
00:24:33,799 --> 00:24:33,809
than we realized
 

1039
00:24:33,809 --> 00:24:36,409
than we realized
right I think these methods are a lot

1040
00:24:36,409 --> 00:24:36,419
right I think these methods are a lot
 

1041
00:24:36,419 --> 00:24:37,789
right I think these methods are a lot
more powerful than people give them

1042
00:24:37,789 --> 00:24:37,799
more powerful than people give them
 

1043
00:24:37,799 --> 00:24:39,470
more powerful than people give them
credit for actually so that of course

1044
00:24:39,470 --> 00:24:39,480
credit for actually so that of course
 

1045
00:24:39,480 --> 00:24:41,659
credit for actually so that of course
there's the media hype but I think

1046
00:24:41,659 --> 00:24:41,669
there's the media hype but I think
 

1047
00:24:41,669 --> 00:24:43,220
there's the media hype but I think
there's a lot of researchers in the

1048
00:24:43,220 --> 00:24:43,230
there's a lot of researchers in the
 

1049
00:24:43,230 --> 00:24:46,039
there's a lot of researchers in the
community especially like not undergrads

1050
00:24:46,039 --> 00:24:46,049
community especially like not undergrads
 

1051
00:24:46,049 --> 00:24:48,169
community especially like not undergrads
right but like people who've been in AI

1052
00:24:48,169 --> 00:24:48,179
right but like people who've been in AI
 

1053
00:24:48,179 --> 00:24:50,299
right but like people who've been in AI
they're skeptical about how far deep

1054
00:24:50,299 --> 00:24:50,309
they're skeptical about how far deep
 

1055
00:24:50,309 --> 00:24:52,539
they're skeptical about how far deep
learning yet and I'm more and more

1056
00:24:52,539 --> 00:24:52,549
learning yet and I'm more and more
 

1057
00:24:52,549 --> 00:24:54,799
learning yet and I'm more and more
thinking that it can actually get

1058
00:24:54,799 --> 00:24:54,809
thinking that it can actually get
 

1059
00:24:54,809 --> 00:24:57,379
thinking that it can actually get
farther than I realize it's certainly

1060
00:24:57,379 --> 00:24:57,389
farther than I realize it's certainly
 

1061
00:24:57,389 --> 00:24:59,539
farther than I realize it's certainly
possible one thing that surprised me

1062
00:24:59,539 --> 00:24:59,549
possible one thing that surprised me
 

1063
00:24:59,549 --> 00:25:01,549
possible one thing that surprised me
when I was writing the book is how far

1064
00:25:01,549 --> 00:25:01,559
when I was writing the book is how far
 

1065
00:25:01,559 --> 00:25:03,409
when I was writing the book is how far
apart different people are in the field

1066
00:25:03,409 --> 00:25:03,419
apart different people are in the field
 

1067
00:25:03,419 --> 00:25:07,310
apart different people are in the field
are artisan their opinion of how how far

1068
00:25:07,310 --> 00:25:07,320
are artisan their opinion of how how far
 

1069
00:25:07,320 --> 00:25:08,810
are artisan their opinion of how how far
the field has come and what is

1070
00:25:08,810 --> 00:25:08,820
the field has come and what is
 

1071
00:25:08,820 --> 00:25:10,340
the field has come and what is
accomplished and what's what's gonna

1072
00:25:10,340 --> 00:25:10,350
accomplished and what's what's gonna
 

1073
00:25:10,350 --> 00:25:12,619
accomplished and what's what's gonna
happen next what's your sense of the

1074
00:25:12,619 --> 00:25:12,629
happen next what's your sense of the
 

1075
00:25:12,629 --> 00:25:14,739
happen next what's your sense of the
different who are the different people

1076
00:25:14,739 --> 00:25:14,749
different who are the different people
 

1077
00:25:14,749 --> 00:25:19,129
different who are the different people
groups mindsets thoughts in the

1078
00:25:19,129 --> 00:25:19,139
groups mindsets thoughts in the
 

1079
00:25:19,139 --> 00:25:22,909
groups mindsets thoughts in the
community about where AI is today yeah

1080
00:25:22,909 --> 00:25:22,919
community about where AI is today yeah
 

1081
00:25:22,919 --> 00:25:24,560
community about where AI is today yeah
they're all over the place so so there's

1082
00:25:24,560 --> 00:25:24,570
they're all over the place so so there's
 

1083
00:25:24,570 --> 00:25:27,580
they're all over the place so so there's
there's kind of the the singularity

1084
00:25:27,580 --> 00:25:27,590
there's kind of the the singularity
 

1085
00:25:27,590 --> 00:25:31,100
there's kind of the the singularity
transhumanism group I don't know exactly

1086
00:25:31,100 --> 00:25:31,110
transhumanism group I don't know exactly
 

1087
00:25:31,110 --> 00:25:33,470
transhumanism group I don't know exactly
how to characterize that approach which

1088
00:25:33,470 --> 00:25:33,480
how to characterize that approach which
 

1089
00:25:33,480 --> 00:25:35,269
how to characterize that approach which
is there as well yeah the sort of

1090
00:25:35,269 --> 00:25:35,279
is there as well yeah the sort of
 

1091
00:25:35,279 --> 00:25:38,779
is there as well yeah the sort of
exponential exponential progress we're

1092
00:25:38,779 --> 00:25:38,789
exponential exponential progress we're
 

1093
00:25:38,789 --> 00:25:43,519
exponential exponential progress we're
on the sort of almost at the the hugely

1094
00:25:43,519 --> 00:25:43,529
on the sort of almost at the the hugely
 

1095
00:25:43,529 --> 00:25:45,700
on the sort of almost at the the hugely
accelerating part of the exponential and

1096
00:25:45,700 --> 00:25:45,710
accelerating part of the exponential and
 

1097
00:25:45,710 --> 00:25:50,239
accelerating part of the exponential and
by in the next 30 years we're going to

1098
00:25:50,239 --> 00:25:50,249
by in the next 30 years we're going to
 

1099
00:25:50,249 --> 00:25:53,899
by in the next 30 years we're going to
see super intelligent AI and all that

1100
00:25:53,899 --> 00:25:53,909
see super intelligent AI and all that
 

1101
00:25:53,909 --> 00:25:55,279
see super intelligent AI and all that
and we'll be able to upload our brains

1102
00:25:55,279 --> 00:25:55,289
and we'll be able to upload our brains
 

1103
00:25:55,289 --> 00:25:59,539
and we'll be able to upload our brains
and that so there's that kind of extreme

1104
00:25:59,539 --> 00:25:59,549
and that so there's that kind of extreme
 

1105
00:25:59,549 --> 00:26:01,999
and that so there's that kind of extreme
view that most I think most people who

1106
00:26:01,999 --> 00:26:02,009
view that most I think most people who
 

1107
00:26:02,009 --> 00:26:05,180
view that most I think most people who
work in AI don't have they disagree with

1108
00:26:05,180 --> 00:26:05,190
work in AI don't have they disagree with
 

1109
00:26:05,190 --> 00:26:08,440
work in AI don't have they disagree with
that but there are people who who are

1110
00:26:08,440 --> 00:26:08,450
that but there are people who who are
 

1111
00:26:08,450 --> 00:26:11,989
that but there are people who who are
maybe don't aren't you know singularity

1112
00:26:11,989 --> 00:26:11,999
maybe don't aren't you know singularity
 

1113
00:26:11,999 --> 00:26:15,499
maybe don't aren't you know singularity
people but but they're they do think

1114
00:26:15,499 --> 00:26:15,509
people but but they're they do think
 

1115
00:26:15,509 --> 00:26:17,149
people but but they're they do think
that the current approach of deep

1116
00:26:17,149 --> 00:26:17,159
that the current approach of deep
 

1117
00:26:17,159 --> 00:26:20,600
that the current approach of deep
learning is going to scale and is going

1118
00:26:20,600 --> 00:26:20,610
learning is going to scale and is going
 

1119
00:26:20,610 --> 00:26:23,840
learning is going to scale and is going
to kind of go all the way basically and

1120
00:26:23,840 --> 00:26:23,850
to kind of go all the way basically and
 

1121
00:26:23,850 --> 00:26:25,220
to kind of go all the way basically and
take us to

1122
00:26:25,220 --> 00:26:25,230
take us to
 

1123
00:26:25,230 --> 00:26:27,080
take us to
i or human-level AI or whatever you

1124
00:26:27,080 --> 00:26:27,090
i or human-level AI or whatever you
 

1125
00:26:27,090 --> 00:26:29,810
i or human-level AI or whatever you
want to call it and there's quite a few

1126
00:26:29,810 --> 00:26:29,820
want to call it and there's quite a few
 

1127
00:26:29,820 --> 00:26:34,009
want to call it and there's quite a few
of them and a lot of them like a lot of

1128
00:26:34,009 --> 00:26:34,019
of them and a lot of them like a lot of
 

1129
00:26:34,019 --> 00:26:38,060
of them and a lot of them like a lot of
the people I've met who work at big tech

1130
00:26:38,060 --> 00:26:38,070
the people I've met who work at big tech
 

1131
00:26:38,070 --> 00:26:40,700
the people I've met who work at big tech
companies in AI groups kind of have this

1132
00:26:40,700 --> 00:26:40,710
companies in AI groups kind of have this
 

1133
00:26:40,710 --> 00:26:45,680
companies in AI groups kind of have this
view that we're really not that far you

1134
00:26:45,680 --> 00:26:45,690
view that we're really not that far you
 

1135
00:26:45,690 --> 00:26:47,539
view that we're really not that far you
know just to linger on that point sort

1136
00:26:47,539 --> 00:26:47,549
know just to linger on that point sort
 

1137
00:26:47,549 --> 00:26:49,879
know just to linger on that point sort
of if I can take as an example like

1138
00:26:49,879 --> 00:26:49,889
of if I can take as an example like
 

1139
00:26:49,889 --> 00:26:51,529
of if I can take as an example like
Yannick kun I don't know if you know

1140
00:26:51,529 --> 00:26:51,539
Yannick kun I don't know if you know
 

1141
00:26:51,539 --> 00:26:53,810
Yannick kun I don't know if you know
about his work and so a few points

1142
00:26:53,810 --> 00:26:53,820
about his work and so a few points
 

1143
00:26:53,820 --> 00:26:56,120
about his work and so a few points
unless I do he believes that there's a

1144
00:26:56,120 --> 00:26:56,130
unless I do he believes that there's a
 

1145
00:26:56,130 --> 00:26:58,430
unless I do he believes that there's a
bunch of breakthroughs like fundamental

1146
00:26:58,430 --> 00:26:58,440
bunch of breakthroughs like fundamental
 

1147
00:26:58,440 --> 00:27:00,049
bunch of breakthroughs like fundamental
like Nobel Prizes there's yeah he did

1148
00:27:00,049 --> 00:27:00,059
like Nobel Prizes there's yeah he did
 

1149
00:27:00,059 --> 00:27:02,930
like Nobel Prizes there's yeah he did
still write but I think he thinks those

1150
00:27:02,930 --> 00:27:02,940
still write but I think he thinks those
 

1151
00:27:02,940 --> 00:27:04,549
still write but I think he thinks those
breakthroughs will be built on top of

1152
00:27:04,549 --> 00:27:04,559
breakthroughs will be built on top of
 

1153
00:27:04,559 --> 00:27:06,950
breakthroughs will be built on top of
deep learning right and then there's

1154
00:27:06,950 --> 00:27:06,960
deep learning right and then there's
 

1155
00:27:06,960 --> 00:27:09,169
deep learning right and then there's
some people who think we need to kind of

1156
00:27:09,169 --> 00:27:09,179
some people who think we need to kind of
 

1157
00:27:09,179 --> 00:27:12,230
some people who think we need to kind of
put deep learning to the side a little

1158
00:27:12,230 --> 00:27:12,240
put deep learning to the side a little
 

1159
00:27:12,240 --> 00:27:15,440
put deep learning to the side a little
bit as just one module that's helpful in

1160
00:27:15,440 --> 00:27:15,450
bit as just one module that's helpful in
 

1161
00:27:15,450 --> 00:27:18,259
bit as just one module that's helpful in
the bigger cognitive framework right so

1162
00:27:18,259 --> 00:27:18,269
the bigger cognitive framework right so
 

1163
00:27:18,269 --> 00:27:21,470
the bigger cognitive framework right so
so I think some what I understand yan

1164
00:27:21,470 --> 00:27:21,480
so I think some what I understand yan
 

1165
00:27:21,480 --> 00:27:25,610
so I think some what I understand yan
laocon is rightly saying supervised

1166
00:27:25,610 --> 00:27:25,620
laocon is rightly saying supervised
 

1167
00:27:25,620 --> 00:27:28,430
laocon is rightly saying supervised
learning is not sustainable we have to

1168
00:27:28,430 --> 00:27:28,440
learning is not sustainable we have to
 

1169
00:27:28,440 --> 00:27:29,840
learning is not sustainable we have to
figure out how to do unsupervised

1170
00:27:29,840 --> 00:27:29,850
figure out how to do unsupervised
 

1171
00:27:29,850 --> 00:27:33,039
figure out how to do unsupervised
learning that that's going to be the key

1172
00:27:33,039 --> 00:27:33,049
learning that that's going to be the key
 

1173
00:27:33,049 --> 00:27:37,340
learning that that's going to be the key
and you know I think that's probably

1174
00:27:37,340 --> 00:27:37,350
and you know I think that's probably
 

1175
00:27:37,350 --> 00:27:37,940
and you know I think that's probably
true

1176
00:27:37,940 --> 00:27:37,950
true
 

1177
00:27:37,950 --> 00:27:40,940
true
I think unsupervised learning is going

1178
00:27:40,940 --> 00:27:40,950
I think unsupervised learning is going
 

1179
00:27:40,950 --> 00:27:44,750
I think unsupervised learning is going
to be harder than people think I mean

1180
00:27:44,750 --> 00:27:44,760
to be harder than people think I mean
 

1181
00:27:44,760 --> 00:27:47,240
to be harder than people think I mean
the way that we humans do it then

1182
00:27:47,240 --> 00:27:47,250
the way that we humans do it then
 

1183
00:27:47,250 --> 00:27:50,779
the way that we humans do it then
there's the opposing view you know that

1184
00:27:50,779 --> 00:27:50,789
there's the opposing view you know that
 

1185
00:27:50,789 --> 00:27:54,430
there's the opposing view you know that
there's a the the Gary Marcus kind of

1186
00:27:54,430 --> 00:27:54,440
there's a the the Gary Marcus kind of
 

1187
00:27:54,440 --> 00:27:57,350
there's a the the Gary Marcus kind of
hybrid view or where deep learning is

1188
00:27:57,350 --> 00:27:57,360
hybrid view or where deep learning is
 

1189
00:27:57,360 --> 00:27:59,269
hybrid view or where deep learning is
one part but we need to bring back kind

1190
00:27:59,269 --> 00:27:59,279
one part but we need to bring back kind
 

1191
00:27:59,279 --> 00:28:02,930
one part but we need to bring back kind
of these symbolic approaches and combine

1192
00:28:02,930 --> 00:28:02,940
of these symbolic approaches and combine
 

1193
00:28:02,940 --> 00:28:05,000
of these symbolic approaches and combine
them of course no one knows how to do

1194
00:28:05,000 --> 00:28:05,010
them of course no one knows how to do
 

1195
00:28:05,010 --> 00:28:07,460
them of course no one knows how to do
that very well which is the more

1196
00:28:07,460 --> 00:28:07,470
that very well which is the more
 

1197
00:28:07,470 --> 00:28:10,460
that very well which is the more
important part right to emphasize and

1198
00:28:10,460 --> 00:28:10,470
important part right to emphasize and
 

1199
00:28:10,470 --> 00:28:11,779
important part right to emphasize and
how do they how do they fit together

1200
00:28:11,779 --> 00:28:11,789
how do they how do they fit together
 

1201
00:28:11,789 --> 00:28:14,029
how do they how do they fit together
what's what's the foundation what's the

1202
00:28:14,029 --> 00:28:14,039
what's what's the foundation what's the
 

1203
00:28:14,039 --> 00:28:16,039
what's what's the foundation what's the
thing that's on top yeah the cake was

1204
00:28:16,039 --> 00:28:16,049
thing that's on top yeah the cake was
 

1205
00:28:16,049 --> 00:28:19,940
thing that's on top yeah the cake was
the icing right yeah then there's people

1206
00:28:19,940 --> 00:28:19,950
the icing right yeah then there's people
 

1207
00:28:19,950 --> 00:28:21,879
the icing right yeah then there's people
pushing different different things

1208
00:28:21,879 --> 00:28:21,889
pushing different different things
 

1209
00:28:21,889 --> 00:28:24,620
pushing different different things
there's the people the causality people

1210
00:28:24,620 --> 00:28:24,630
there's the people the causality people
 

1211
00:28:24,630 --> 00:28:27,860
there's the people the causality people
who say you know deep learning as its

1212
00:28:27,860 --> 00:28:27,870
who say you know deep learning as its
 

1213
00:28:27,870 --> 00:28:30,830
who say you know deep learning as its
formulated a completely lacks any notion

1214
00:28:30,830 --> 00:28:30,840
formulated a completely lacks any notion
 

1215
00:28:30,840 --> 00:28:35,119
formulated a completely lacks any notion
of causality and that's dooms it and

1216
00:28:35,119 --> 00:28:35,129
of causality and that's dooms it and
 

1217
00:28:35,129 --> 00:28:36,950
of causality and that's dooms it and
therefore we have to somehow give it

1218
00:28:36,950 --> 00:28:36,960
therefore we have to somehow give it
 

1219
00:28:36,960 --> 00:28:40,560
therefore we have to somehow give it
some kind of notion of cause

1220
00:28:40,560 --> 00:28:40,570
some kind of notion of cause
 

1221
00:28:40,570 --> 00:28:46,350
some kind of notion of cause
there's a lot of push from the more

1222
00:28:46,350 --> 00:28:46,360
there's a lot of push from the more
 

1223
00:28:46,360 --> 00:28:51,690
there's a lot of push from the more
cognitive science crowd saying we have

1224
00:28:51,690 --> 00:28:51,700
cognitive science crowd saying we have
 

1225
00:28:51,700 --> 00:28:54,180
cognitive science crowd saying we have
to look at developmental learning we

1226
00:28:54,180 --> 00:28:54,190
to look at developmental learning we
 

1227
00:28:54,190 --> 00:28:56,940
to look at developmental learning we
have to look at how babies learn we have

1228
00:28:56,940 --> 00:28:56,950
have to look at how babies learn we have
 

1229
00:28:56,950 --> 00:29:01,259
have to look at how babies learn we have
to look at intuitive physics all these

1230
00:29:01,259 --> 00:29:01,269
to look at intuitive physics all these
 

1231
00:29:01,269 --> 00:29:03,360
to look at intuitive physics all these
things we know about physics and it's

1232
00:29:03,360 --> 00:29:03,370
things we know about physics and it's
 

1233
00:29:03,370 --> 00:29:06,480
things we know about physics and it's
somebody kind of quipped we also have to

1234
00:29:06,480 --> 00:29:06,490
somebody kind of quipped we also have to
 

1235
00:29:06,490 --> 00:29:08,310
somebody kind of quipped we also have to
teach machines intuitive metaphysics

1236
00:29:08,310 --> 00:29:08,320
teach machines intuitive metaphysics
 

1237
00:29:08,320 --> 00:29:15,180
teach machines intuitive metaphysics
which means like objects exist causality

1238
00:29:15,180 --> 00:29:15,190
which means like objects exist causality
 

1239
00:29:15,190 --> 00:29:18,149
which means like objects exist causality
exists you know these things that maybe

1240
00:29:18,149 --> 00:29:18,159
exists you know these things that maybe
 

1241
00:29:18,159 --> 00:29:20,610
exists you know these things that maybe
were born with I don't know that that

1242
00:29:20,610 --> 00:29:20,620
were born with I don't know that that
 

1243
00:29:20,620 --> 00:29:22,830
were born with I don't know that that
they don't have the machines don't have

1244
00:29:22,830 --> 00:29:22,840
they don't have the machines don't have
 

1245
00:29:22,840 --> 00:29:24,769
they don't have the machines don't have
any of that you know they look at a

1246
00:29:24,769 --> 00:29:24,779
any of that you know they look at a
 

1247
00:29:24,779 --> 00:29:28,580
any of that you know they look at a
group of pixels and they maybe they get

1248
00:29:28,580 --> 00:29:28,590
group of pixels and they maybe they get
 

1249
00:29:28,590 --> 00:29:33,389
group of pixels and they maybe they get
10 million examples but they they can't

1250
00:29:33,389 --> 00:29:33,399
10 million examples but they they can't
 

1251
00:29:33,399 --> 00:29:35,519
10 million examples but they they can't
necessarily learn that there are objects

1252
00:29:35,519 --> 00:29:35,529
necessarily learn that there are objects
 

1253
00:29:35,529 --> 00:29:39,269
necessarily learn that there are objects
in the world so there's just a lot of

1254
00:29:39,269 --> 00:29:39,279
in the world so there's just a lot of
 

1255
00:29:39,279 --> 00:29:41,850
in the world so there's just a lot of
pieces of the puzzle that people are

1256
00:29:41,850 --> 00:29:41,860
pieces of the puzzle that people are
 

1257
00:29:41,860 --> 00:29:45,629
pieces of the puzzle that people are
promoting and with different opinions of

1258
00:29:45,629 --> 00:29:45,639
promoting and with different opinions of
 

1259
00:29:45,639 --> 00:29:47,730
promoting and with different opinions of
like how how how important they are and

1260
00:29:47,730 --> 00:29:47,740
like how how how important they are and
 

1261
00:29:47,740 --> 00:29:50,909
like how how how important they are and
how close we are to the you know we'll

1262
00:29:50,909 --> 00:29:50,919
how close we are to the you know we'll
 

1263
00:29:50,919 --> 00:29:52,680
how close we are to the you know we'll
put them all together to create general

1264
00:29:52,680 --> 00:29:52,690
put them all together to create general
 

1265
00:29:52,690 --> 00:29:55,759
put them all together to create general
intelligence looking at this broad field

1266
00:29:55,759 --> 00:29:55,769
intelligence looking at this broad field
 

1267
00:29:55,769 --> 00:29:58,169
intelligence looking at this broad field
what do you take away from it who is the

1268
00:29:58,169 --> 00:29:58,179
what do you take away from it who is the
 

1269
00:29:58,179 --> 00:30:00,659
what do you take away from it who is the
most impressive is that the cognitive

1270
00:30:00,659 --> 00:30:00,669
most impressive is that the cognitive
 

1271
00:30:00,669 --> 00:30:05,190
most impressive is that the cognitive
folks Gary Marcus camp the yawn camp son

1272
00:30:05,190 --> 00:30:05,200
folks Gary Marcus camp the yawn camp son
 

1273
00:30:05,200 --> 00:30:07,169
folks Gary Marcus camp the yawn camp son
supervising their self supervise there's

1274
00:30:07,169 --> 00:30:07,179
supervising their self supervise there's
 

1275
00:30:07,179 --> 00:30:09,090
supervising their self supervise there's
the supervisor and then there's the

1276
00:30:09,090 --> 00:30:09,100
the supervisor and then there's the
 

1277
00:30:09,100 --> 00:30:10,049
the supervisor and then there's the
engineers who are actually building

1278
00:30:10,049 --> 00:30:10,059
engineers who are actually building
 

1279
00:30:10,059 --> 00:30:12,600
engineers who are actually building
systems you have sort of the Andrey

1280
00:30:12,600 --> 00:30:12,610
systems you have sort of the Andrey
 

1281
00:30:12,610 --> 00:30:17,039
systems you have sort of the Andrey
Carpathia Tesla building actual you know

1282
00:30:17,039 --> 00:30:17,049
Carpathia Tesla building actual you know
 

1283
00:30:17,049 --> 00:30:18,810
Carpathia Tesla building actual you know
it's not philosophy it's real writing

1284
00:30:18,810 --> 00:30:18,820
it's not philosophy it's real writing
 

1285
00:30:18,820 --> 00:30:20,249
it's not philosophy it's real writing
systems that operate in the real world

1286
00:30:20,249 --> 00:30:20,259
systems that operate in the real world
 

1287
00:30:20,259 --> 00:30:22,499
systems that operate in the real world
what yeah what do you take away from all

1288
00:30:22,499 --> 00:30:22,509
what yeah what do you take away from all
 

1289
00:30:22,509 --> 00:30:24,299
what yeah what do you take away from all
all this beautiful yeah I don't know if

1290
00:30:24,299 --> 00:30:24,309
all this beautiful yeah I don't know if
 

1291
00:30:24,309 --> 00:30:26,399
all this beautiful yeah I don't know if
you know these these different views are

1292
00:30:26,399 --> 00:30:26,409
you know these these different views are
 

1293
00:30:26,409 --> 00:30:30,649
you know these these different views are
not necessarily mutually exclusive and I

1294
00:30:30,649 --> 00:30:30,659
not necessarily mutually exclusive and I
 

1295
00:30:30,659 --> 00:30:35,070
not necessarily mutually exclusive and I
think people like Jung McCune agrees

1296
00:30:35,070 --> 00:30:35,080
think people like Jung McCune agrees
 

1297
00:30:35,080 --> 00:30:37,909
think people like Jung McCune agrees
with the developmental psychology

1298
00:30:37,909 --> 00:30:37,919
with the developmental psychology
 

1299
00:30:37,919 --> 00:30:43,440
with the developmental psychology
causality intuitive physics etc but he

1300
00:30:43,440 --> 00:30:43,450
causality intuitive physics etc but he
 

1301
00:30:43,450 --> 00:30:46,110
causality intuitive physics etc but he
still thinks that it's learning like

1302
00:30:46,110 --> 00:30:46,120
still thinks that it's learning like
 

1303
00:30:46,120 --> 00:30:48,269
still thinks that it's learning like
end-to-end learning is the way to go

1304
00:30:48,269 --> 00:30:48,279
end-to-end learning is the way to go
 

1305
00:30:48,279 --> 00:30:50,220
end-to-end learning is the way to go
we'll take us perhaps all the way yeah

1306
00:30:50,220 --> 00:30:50,230
we'll take us perhaps all the way yeah
 

1307
00:30:50,230 --> 00:30:52,230
we'll take us perhaps all the way yeah
and that we don't need there's no sort

1308
00:30:52,230 --> 00:30:52,240
and that we don't need there's no sort
 

1309
00:30:52,240 --> 00:30:53,280
and that we don't need there's no sort
of innate

1310
00:30:53,280 --> 00:30:53,290
of innate
 

1311
00:30:53,290 --> 00:30:57,220
of innate
stuff that has to get built in this is

1312
00:30:57,220 --> 00:30:57,230
stuff that has to get built in this is
 

1313
00:30:57,230 --> 00:30:59,650
stuff that has to get built in this is
you know it's because no it's a hard

1314
00:30:59,650 --> 00:30:59,660
you know it's because no it's a hard
 

1315
00:30:59,660 --> 00:31:00,850
you know it's because no it's a hard
problem

1316
00:31:00,850 --> 00:31:00,860
problem
 

1317
00:31:00,860 --> 00:31:04,420
problem
I personally you know I'm very

1318
00:31:04,420 --> 00:31:04,430
I personally you know I'm very
 

1319
00:31:04,430 --> 00:31:06,700
I personally you know I'm very
sympathetic to the cognitive science

1320
00:31:06,700 --> 00:31:06,710
sympathetic to the cognitive science
 

1321
00:31:06,710 --> 00:31:08,200
sympathetic to the cognitive science
side because that's kind of where I came

1322
00:31:08,200 --> 00:31:08,210
side because that's kind of where I came
 

1323
00:31:08,210 --> 00:31:11,260
side because that's kind of where I came
in to the field I've become more and

1324
00:31:11,260 --> 00:31:11,270
in to the field I've become more and
 

1325
00:31:11,270 --> 00:31:15,370
in to the field I've become more and
more sort of an embodiment adherent

1326
00:31:15,370 --> 00:31:15,380
more sort of an embodiment adherent
 

1327
00:31:15,380 --> 00:31:16,960
more sort of an embodiment adherent
saying that you know without having a

1328
00:31:16,960 --> 00:31:16,970
saying that you know without having a
 

1329
00:31:16,970 --> 00:31:20,590
saying that you know without having a
body it's gonna be very hard to learn

1330
00:31:20,590 --> 00:31:20,600
body it's gonna be very hard to learn
 

1331
00:31:20,600 --> 00:31:23,640
body it's gonna be very hard to learn
what we need to learn about the world

1332
00:31:23,640 --> 00:31:23,650
what we need to learn about the world
 

1333
00:31:23,650 --> 00:31:25,780
what we need to learn about the world
that's definitely something like I'd

1334
00:31:25,780 --> 00:31:25,790
that's definitely something like I'd
 

1335
00:31:25,790 --> 00:31:28,840
that's definitely something like I'd
love to talk about in a little bit to

1336
00:31:28,840 --> 00:31:28,850
love to talk about in a little bit to
 

1337
00:31:28,850 --> 00:31:32,080
love to talk about in a little bit to
step into the cognitive world then if

1338
00:31:32,080 --> 00:31:32,090
step into the cognitive world then if
 

1339
00:31:32,090 --> 00:31:33,220
step into the cognitive world then if
you don't mind because you've done so

1340
00:31:33,220 --> 00:31:33,230
you don't mind because you've done so
 

1341
00:31:33,230 --> 00:31:35,170
you don't mind because you've done so
many interesting things if you look to

1342
00:31:35,170 --> 00:31:35,180
many interesting things if you look to
 

1343
00:31:35,180 --> 00:31:39,280
many interesting things if you look to
copycat taking a couple of decades step

1344
00:31:39,280 --> 00:31:39,290
copycat taking a couple of decades step
 

1345
00:31:39,290 --> 00:31:39,820
copycat taking a couple of decades step
back

1346
00:31:39,820 --> 00:31:39,830
back
 

1347
00:31:39,830 --> 00:31:43,420
back
you'd Douglas Hofstadter and others have

1348
00:31:43,420 --> 00:31:43,430
you'd Douglas Hofstadter and others have
 

1349
00:31:43,430 --> 00:31:46,780
you'd Douglas Hofstadter and others have
created and developed copycat more than

1350
00:31:46,780 --> 00:31:46,790
created and developed copycat more than
 

1351
00:31:46,790 --> 00:31:47,650
created and developed copycat more than
thirty years ago

1352
00:31:47,650 --> 00:31:47,660
thirty years ago
 

1353
00:31:47,660 --> 00:31:52,060
thirty years ago
ah that's painful here what is it what

1354
00:31:52,060 --> 00:31:52,070
ah that's painful here what is it what
 

1355
00:31:52,070 --> 00:31:55,590
ah that's painful here what is it what
is what is copycat it's a program that

1356
00:31:55,590 --> 00:31:55,600
is what is copycat it's a program that
 

1357
00:31:55,600 --> 00:32:00,190
is what is copycat it's a program that
makes analogies in an idealized domain

1358
00:32:00,190 --> 00:32:00,200
makes analogies in an idealized domain
 

1359
00:32:00,200 --> 00:32:03,760
makes analogies in an idealized domain
idealized world of letter strings so as

1360
00:32:03,760 --> 00:32:03,770
idealized world of letter strings so as
 

1361
00:32:03,770 --> 00:32:05,770
idealized world of letter strings so as
you say thirty years ago Wow

1362
00:32:05,770 --> 00:32:05,780
you say thirty years ago Wow
 

1363
00:32:05,780 --> 00:32:08,190
you say thirty years ago Wow
so I started working on it when I

1364
00:32:08,190 --> 00:32:08,200
so I started working on it when I
 

1365
00:32:08,200 --> 00:32:18,310
so I started working on it when I
started grad school in 1984 Wow and it's

1366
00:32:18,310 --> 00:32:18,320
started grad school in 1984 Wow and it's
 

1367
00:32:18,320 --> 00:32:21,550
started grad school in 1984 Wow and it's
based on Doug Hofstadter's ideas that

1368
00:32:21,550 --> 00:32:21,560
based on Doug Hofstadter's ideas that
 

1369
00:32:21,560 --> 00:32:25,780
based on Doug Hofstadter's ideas that
about that analogy is really a core

1370
00:32:25,780 --> 00:32:25,790
about that analogy is really a core
 

1371
00:32:25,790 --> 00:32:31,090
about that analogy is really a core
aspect of thinking I remember he has a

1372
00:32:31,090 --> 00:32:31,100
aspect of thinking I remember he has a
 

1373
00:32:31,100 --> 00:32:34,750
aspect of thinking I remember he has a
really nice quote in in in the book by

1374
00:32:34,750 --> 00:32:34,760
really nice quote in in in the book by
 

1375
00:32:34,760 --> 00:32:37,120
really nice quote in in in the book by
by himself and Emmanuel Sanders called

1376
00:32:37,120 --> 00:32:37,130
by himself and Emmanuel Sanders called
 

1377
00:32:37,130 --> 00:32:39,070
by himself and Emmanuel Sanders called
surfaces and essences I don't know if

1378
00:32:39,070 --> 00:32:39,080
surfaces and essences I don't know if
 

1379
00:32:39,080 --> 00:32:40,270
surfaces and essences I don't know if
you've seen that book but it's it's

1380
00:32:40,270 --> 00:32:40,280
you've seen that book but it's it's
 

1381
00:32:40,280 --> 00:32:45,310
you've seen that book but it's it's
about analogy he says without concepts

1382
00:32:45,310 --> 00:32:45,320
about analogy he says without concepts
 

1383
00:32:45,320 --> 00:32:47,430
about analogy he says without concepts
there can be no thought and without

1384
00:32:47,430 --> 00:32:47,440
there can be no thought and without
 

1385
00:32:47,440 --> 00:32:51,280
there can be no thought and without
analogies there can be no concepts so

1386
00:32:51,280 --> 00:32:51,290
analogies there can be no concepts so
 

1387
00:32:51,290 --> 00:32:53,140
analogies there can be no concepts so
the view is that analogy is not just

1388
00:32:53,140 --> 00:32:53,150
the view is that analogy is not just
 

1389
00:32:53,150 --> 00:32:55,150
the view is that analogy is not just
this kind of reasoning technique where

1390
00:32:55,150 --> 00:32:55,160
this kind of reasoning technique where
 

1391
00:32:55,160 --> 00:32:59,980
this kind of reasoning technique where
we go you know shoe is to foot as glove

1392
00:32:59,980 --> 00:32:59,990
we go you know shoe is to foot as glove
 

1393
00:32:59,990 --> 00:33:02,440
we go you know shoe is to foot as glove
as to what you know these kinds of

1394
00:33:02,440 --> 00:33:02,450
as to what you know these kinds of
 

1395
00:33:02,450 --> 00:33:04,300
as to what you know these kinds of
things that we have on IQ tests or

1396
00:33:04,300 --> 00:33:04,310
things that we have on IQ tests or
 

1397
00:33:04,310 --> 00:33:06,640
things that we have on IQ tests or
whatever that but that it's much deeper

1398
00:33:06,640 --> 00:33:06,650
whatever that but that it's much deeper
 

1399
00:33:06,650 --> 00:33:10,750
whatever that but that it's much deeper
much more pervasive in everything we do

1400
00:33:10,750 --> 00:33:10,760
much more pervasive in everything we do
 

1401
00:33:10,760 --> 00:33:13,750
much more pervasive in everything we do
in everything our language our thinking

1402
00:33:13,750 --> 00:33:13,760
in everything our language our thinking
 

1403
00:33:13,760 --> 00:33:17,290
in everything our language our thinking
our perception so we so he had a view

1404
00:33:17,290 --> 00:33:17,300
our perception so we so he had a view
 

1405
00:33:17,300 --> 00:33:20,500
our perception so we so he had a view
that was a very active perception idea

1406
00:33:20,500 --> 00:33:20,510
that was a very active perception idea
 

1407
00:33:20,510 --> 00:33:24,820
that was a very active perception idea
so the idea was that instead of having

1408
00:33:24,820 --> 00:33:24,830
so the idea was that instead of having
 

1409
00:33:24,830 --> 00:33:29,830
so the idea was that instead of having
kind of what a passive network in which

1410
00:33:29,830 --> 00:33:29,840
kind of what a passive network in which
 

1411
00:33:29,840 --> 00:33:32,890
kind of what a passive network in which
you have input that's being processed

1412
00:33:32,890 --> 00:33:32,900
you have input that's being processed
 

1413
00:33:32,900 --> 00:33:35,560
you have input that's being processed
through these feed-forward layers and

1414
00:33:35,560 --> 00:33:35,570
through these feed-forward layers and
 

1415
00:33:35,570 --> 00:33:37,180
through these feed-forward layers and
then there's an output at the end that

1416
00:33:37,180 --> 00:33:37,190
then there's an output at the end that
 

1417
00:33:37,190 --> 00:33:40,320
then there's an output at the end that
perception is really a dynamic process

1418
00:33:40,320 --> 00:33:40,330
perception is really a dynamic process
 

1419
00:33:40,330 --> 00:33:42,700
perception is really a dynamic process
you know we're like our eyes are moving

1420
00:33:42,700 --> 00:33:42,710
you know we're like our eyes are moving
 

1421
00:33:42,710 --> 00:33:44,020
you know we're like our eyes are moving
around and they're getting information

1422
00:33:44,020 --> 00:33:44,030
around and they're getting information
 

1423
00:33:44,030 --> 00:33:47,490
around and they're getting information
and that information is feeding back to

1424
00:33:47,490 --> 00:33:47,500
and that information is feeding back to
 

1425
00:33:47,500 --> 00:33:50,890
and that information is feeding back to
what we look at next influences what we

1426
00:33:50,890 --> 00:33:50,900
what we look at next influences what we
 

1427
00:33:50,900 --> 00:33:52,780
what we look at next influences what we
look at next and how we look at it and

1428
00:33:52,780 --> 00:33:52,790
look at next and how we look at it and
 

1429
00:33:52,790 --> 00:33:56,320
look at next and how we look at it and
so copycat was trying to do that kind of

1430
00:33:56,320 --> 00:33:56,330
so copycat was trying to do that kind of
 

1431
00:33:56,330 --> 00:33:58,510
so copycat was trying to do that kind of
simulate that kind of idea where you

1432
00:33:58,510 --> 00:33:58,520
simulate that kind of idea where you
 

1433
00:33:58,520 --> 00:34:03,430
simulate that kind of idea where you
have these agents it's kind of an agent

1434
00:34:03,430 --> 00:34:03,440
have these agents it's kind of an agent
 

1435
00:34:03,440 --> 00:34:05,050
have these agents it's kind of an agent
based system and you have these agents

1436
00:34:05,050 --> 00:34:05,060
based system and you have these agents
 

1437
00:34:05,060 --> 00:34:08,610
based system and you have these agents
that are picking things to look at and

1438
00:34:08,610 --> 00:34:08,620
that are picking things to look at and
 

1439
00:34:08,620 --> 00:34:10,540
that are picking things to look at and
deciding whether they were interesting

1440
00:34:10,540 --> 00:34:10,550
deciding whether they were interesting
 

1441
00:34:10,550 --> 00:34:12,790
deciding whether they were interesting
or not whether they should be looked at

1442
00:34:12,790 --> 00:34:12,800
or not whether they should be looked at
 

1443
00:34:12,800 --> 00:34:14,860
or not whether they should be looked at
more and and that would influence other

1444
00:34:14,860 --> 00:34:14,870
more and and that would influence other
 

1445
00:34:14,870 --> 00:34:17,740
more and and that would influence other
agents how do they interact so they

1446
00:34:17,740 --> 00:34:17,750
agents how do they interact so they
 

1447
00:34:17,750 --> 00:34:20,020
agents how do they interact so they
interacted through this global kind of

1448
00:34:20,020 --> 00:34:20,030
interacted through this global kind of
 

1449
00:34:20,030 --> 00:34:22,480
interacted through this global kind of
what we call the workspace so this

1450
00:34:22,480 --> 00:34:22,490
what we call the workspace so this
 

1451
00:34:22,490 --> 00:34:24,430
what we call the workspace so this
actually inspired by the old blackboard

1452
00:34:24,430 --> 00:34:24,440
actually inspired by the old blackboard
 

1453
00:34:24,440 --> 00:34:27,070
actually inspired by the old blackboard
systems where you'd have agents that

1454
00:34:27,070 --> 00:34:27,080
systems where you'd have agents that
 

1455
00:34:27,080 --> 00:34:29,740
systems where you'd have agents that
post information on a blackboard a

1456
00:34:29,740 --> 00:34:29,750
post information on a blackboard a
 

1457
00:34:29,750 --> 00:34:31,990
post information on a blackboard a
common blackboard this is like old very

1458
00:34:31,990 --> 00:34:32,000
common blackboard this is like old very
 

1459
00:34:32,000 --> 00:34:34,240
common blackboard this is like old very
old fashioned a set is that we're

1460
00:34:34,240 --> 00:34:34,250
old fashioned a set is that we're
 

1461
00:34:34,250 --> 00:34:36,490
old fashioned a set is that we're
talking about like in physical space is

1462
00:34:36,490 --> 00:34:36,500
talking about like in physical space is
 

1463
00:34:36,500 --> 00:34:38,200
talking about like in physical space is
a computer program computer programs

1464
00:34:38,200 --> 00:34:38,210
a computer program computer programs
 

1465
00:34:38,210 --> 00:34:41,530
a computer program computer programs
agents posting concepts on a blackboard

1466
00:34:41,530 --> 00:34:41,540
agents posting concepts on a blackboard
 

1467
00:34:41,540 --> 00:34:44,610
agents posting concepts on a blackboard
yeah we called it a workspace and it

1468
00:34:44,610 --> 00:34:44,620
yeah we called it a workspace and it
 

1469
00:34:44,620 --> 00:34:47,520
yeah we called it a workspace and it
it's the workspace is a data structure

1470
00:34:47,520 --> 00:34:47,530
it's the workspace is a data structure
 

1471
00:34:47,530 --> 00:34:50,500
it's the workspace is a data structure
the agents are little pieces of code

1472
00:34:50,500 --> 00:34:50,510
the agents are little pieces of code
 

1473
00:34:50,510 --> 00:34:52,990
the agents are little pieces of code
that you can think of them as detect

1474
00:34:52,990 --> 00:34:53,000
that you can think of them as detect
 

1475
00:34:53,000 --> 00:34:55,180
that you can think of them as detect
little detectors or little filters then

1476
00:34:55,180 --> 00:34:55,190
little detectors or little filters then
 

1477
00:34:55,190 --> 00:34:57,310
little detectors or little filters then
say I'm gonna pick this place to look

1478
00:34:57,310 --> 00:34:57,320
say I'm gonna pick this place to look
 

1479
00:34:57,320 --> 00:34:58,990
say I'm gonna pick this place to look
and I'm gonna look for a certain thing

1480
00:34:58,990 --> 00:34:59,000
and I'm gonna look for a certain thing
 

1481
00:34:59,000 --> 00:35:01,300
and I'm gonna look for a certain thing
and it's just the thing I I think is

1482
00:35:01,300 --> 00:35:01,310
and it's just the thing I I think is
 

1483
00:35:01,310 --> 00:35:03,370
and it's just the thing I I think is
important is it there so it's almost

1484
00:35:03,370 --> 00:35:03,380
important is it there so it's almost
 

1485
00:35:03,380 --> 00:35:06,580
important is it there so it's almost
like you know a convolution in way

1486
00:35:06,580 --> 00:35:06,590
like you know a convolution in way
 

1487
00:35:06,590 --> 00:35:09,730
like you know a convolution in way
except a little bit more general and

1488
00:35:09,730 --> 00:35:09,740
except a little bit more general and
 

1489
00:35:09,740 --> 00:35:12,100
except a little bit more general and
saying and then highlighting it on the

1490
00:35:12,100 --> 00:35:12,110
saying and then highlighting it on the
 

1491
00:35:12,110 --> 00:35:14,980
saying and then highlighting it on the
on the work in the workspace wasn't once

1492
00:35:14,980 --> 00:35:14,990
on the work in the workspace wasn't once
 

1493
00:35:14,990 --> 00:35:17,170
on the work in the workspace wasn't once
it's in the workspace how do the things

1494
00:35:17,170 --> 00:35:17,180
it's in the workspace how do the things
 

1495
00:35:17,180 --> 00:35:18,670
it's in the workspace how do the things
they're highlighted relate to each other

1496
00:35:18,670 --> 00:35:18,680
they're highlighted relate to each other
 

1497
00:35:18,680 --> 00:35:19,380
they're highlighted relate to each other
like what

1498
00:35:19,380 --> 00:35:19,390
like what
 

1499
00:35:19,390 --> 00:35:21,509
like what
so there's different kinds of agents

1500
00:35:21,509 --> 00:35:21,519
so there's different kinds of agents
 

1501
00:35:21,519 --> 00:35:22,920
so there's different kinds of agents
that can build connections between

1502
00:35:22,920 --> 00:35:22,930
that can build connections between
 

1503
00:35:22,930 --> 00:35:24,690
that can build connections between
different things so just to give you a

1504
00:35:24,690 --> 00:35:24,700
different things so just to give you a
 

1505
00:35:24,700 --> 00:35:27,180
different things so just to give you a
concrete example what copycat did was it

1506
00:35:27,180 --> 00:35:27,190
concrete example what copycat did was it
 

1507
00:35:27,190 --> 00:35:29,250
concrete example what copycat did was it
made analogies between strings of

1508
00:35:29,250 --> 00:35:29,260
made analogies between strings of
 

1509
00:35:29,260 --> 00:35:33,990
made analogies between strings of
letters so here's an example ABC changes

1510
00:35:33,990 --> 00:35:34,000
letters so here's an example ABC changes
 

1511
00:35:34,000 --> 00:35:39,420
letters so here's an example ABC changes
to a BD what does ijk change to and the

1512
00:35:39,420 --> 00:35:39,430
to a BD what does ijk change to and the
 

1513
00:35:39,430 --> 00:35:41,190
to a BD what does ijk change to and the
program had some prior knowledge about

1514
00:35:41,190 --> 00:35:41,200
program had some prior knowledge about
 

1515
00:35:41,200 --> 00:35:43,440
program had some prior knowledge about
the alphabet new the sequence of the

1516
00:35:43,440 --> 00:35:43,450
the alphabet new the sequence of the
 

1517
00:35:43,450 --> 00:35:47,579
the alphabet new the sequence of the
alphabet it you know had a concept of

1518
00:35:47,579 --> 00:35:47,589
alphabet it you know had a concept of
 

1519
00:35:47,589 --> 00:35:49,500
alphabet it you know had a concept of
letter successor of letter it had

1520
00:35:49,500 --> 00:35:49,510
letter successor of letter it had
 

1521
00:35:49,510 --> 00:35:51,450
letter successor of letter it had
concepts of sameness so it has some

1522
00:35:51,450 --> 00:35:51,460
concepts of sameness so it has some
 

1523
00:35:51,460 --> 00:35:55,559
concepts of sameness so it has some
innate things programmed in but then it

1524
00:35:55,559 --> 00:35:55,569
innate things programmed in but then it
 

1525
00:35:55,569 --> 00:36:01,370
innate things programmed in but then it
could do things like say discover that

1526
00:36:01,370 --> 00:36:01,380
could do things like say discover that
 

1527
00:36:01,380 --> 00:36:04,970
could do things like say discover that
ABC is a group of letters in succession

1528
00:36:04,970 --> 00:36:04,980
ABC is a group of letters in succession
 

1529
00:36:04,980 --> 00:36:10,160
ABC is a group of letters in succession
hmm and then it an agent can mark that

1530
00:36:10,160 --> 00:36:10,170
hmm and then it an agent can mark that
 

1531
00:36:10,170 --> 00:36:14,059
hmm and then it an agent can mark that
so the idea that there could be a

1532
00:36:14,059 --> 00:36:14,069
so the idea that there could be a
 

1533
00:36:14,069 --> 00:36:17,130
so the idea that there could be a
sequence of letters is that a new

1534
00:36:17,130 --> 00:36:17,140
sequence of letters is that a new
 

1535
00:36:17,140 --> 00:36:18,599
sequence of letters is that a new
concept that's formed or if that's a

1536
00:36:18,599 --> 00:36:18,609
concept that's formed or if that's a
 

1537
00:36:18,609 --> 00:36:20,690
concept that's formed or if that's a
concept that's a concept that's innate

1538
00:36:20,690 --> 00:36:20,700
concept that's a concept that's innate
 

1539
00:36:20,700 --> 00:36:24,289
concept that's a concept that's innate
sort of can you form new concepts or all

1540
00:36:24,289 --> 00:36:24,299
sort of can you form new concepts or all
 

1541
00:36:24,299 --> 00:36:28,589
sort of can you form new concepts or all
so in this program all the concepts of

1542
00:36:28,589 --> 00:36:28,599
so in this program all the concepts of
 

1543
00:36:28,599 --> 00:36:30,839
so in this program all the concepts of
the program were innate so cuz because

1544
00:36:30,839 --> 00:36:30,849
the program were innate so cuz because
 

1545
00:36:30,849 --> 00:36:33,690
the program were innate so cuz because
we weren't I mean obviously that limits

1546
00:36:33,690 --> 00:36:33,700
we weren't I mean obviously that limits
 

1547
00:36:33,700 --> 00:36:36,299
we weren't I mean obviously that limits
it quite up quite a bit but what we were

1548
00:36:36,299 --> 00:36:36,309
it quite up quite a bit but what we were
 

1549
00:36:36,309 --> 00:36:37,920
it quite up quite a bit but what we were
trying to do is say suppose you have

1550
00:36:37,920 --> 00:36:37,930
trying to do is say suppose you have
 

1551
00:36:37,930 --> 00:36:42,180
trying to do is say suppose you have
some innate concepts how do you flexibly

1552
00:36:42,180 --> 00:36:42,190
some innate concepts how do you flexibly
 

1553
00:36:42,190 --> 00:36:45,120
some innate concepts how do you flexibly
apply them to new situations right and

1554
00:36:45,120 --> 00:36:45,130
apply them to new situations right and
 

1555
00:36:45,130 --> 00:36:48,359
apply them to new situations right and
how do you make analogies let's step

1556
00:36:48,359 --> 00:36:48,369
how do you make analogies let's step
 

1557
00:36:48,369 --> 00:36:49,740
how do you make analogies let's step
back for a second so I really like that

1558
00:36:49,740 --> 00:36:49,750
back for a second so I really like that
 

1559
00:36:49,750 --> 00:36:52,529
back for a second so I really like that
quote that he said without concepts

1560
00:36:52,529 --> 00:36:52,539
quote that he said without concepts
 

1561
00:36:52,539 --> 00:36:54,150
quote that he said without concepts
there can be no thought and without

1562
00:36:54,150 --> 00:36:54,160
there can be no thought and without
 

1563
00:36:54,160 --> 00:36:56,670
there can be no thought and without
analogies that can be no concepts you

1564
00:36:56,670 --> 00:36:56,680
analogies that can be no concepts you
 

1565
00:36:56,680 --> 00:36:58,740
analogies that can be no concepts you
know in a Santa Fe presentation you said

1566
00:36:58,740 --> 00:36:58,750
know in a Santa Fe presentation you said
 

1567
00:36:58,750 --> 00:37:00,180
know in a Santa Fe presentation you said
that it should be one of the mantras of

1568
00:37:00,180 --> 00:37:00,190
that it should be one of the mantras of
 

1569
00:37:00,190 --> 00:37:03,269
that it should be one of the mantras of
AI yes and that you all see yourself

1570
00:37:03,269 --> 00:37:03,279
AI yes and that you all see yourself
 

1571
00:37:03,279 --> 00:37:06,509
AI yes and that you all see yourself
said how to form and fluidly use concept

1572
00:37:06,509 --> 00:37:06,519
said how to form and fluidly use concept
 

1573
00:37:06,519 --> 00:37:09,049
said how to form and fluidly use concept
is the most important open problem in AI

1574
00:37:09,049 --> 00:37:09,059
is the most important open problem in AI
 

1575
00:37:09,059 --> 00:37:13,740
is the most important open problem in AI
yes how to form and fluidly use concepts

1576
00:37:13,740 --> 00:37:13,750
yes how to form and fluidly use concepts
 

1577
00:37:13,750 --> 00:37:16,740
yes how to form and fluidly use concepts
is the most important open problem in AI

1578
00:37:16,740 --> 00:37:16,750
is the most important open problem in AI
 

1579
00:37:16,750 --> 00:37:20,730
is the most important open problem in AI
so let's what is the concept and what is

1580
00:37:20,730 --> 00:37:20,740
so let's what is the concept and what is
 

1581
00:37:20,740 --> 00:37:24,950
so let's what is the concept and what is
an analogy a concept is in some sense a

1582
00:37:24,950 --> 00:37:24,960
an analogy a concept is in some sense a
 

1583
00:37:24,960 --> 00:37:28,829
an analogy a concept is in some sense a
fundamental unit of thought so say we

1584
00:37:28,829 --> 00:37:28,839
fundamental unit of thought so say we
 

1585
00:37:28,839 --> 00:37:31,890
fundamental unit of thought so say we
have a concept

1586
00:37:31,890 --> 00:37:31,900
have a concept
 

1587
00:37:31,900 --> 00:37:40,950
have a concept
of a dog okay and a concept is embedded

1588
00:37:40,950 --> 00:37:40,960
of a dog okay and a concept is embedded
 

1589
00:37:40,960 --> 00:37:45,480
of a dog okay and a concept is embedded
in a whole space of concepts so that

1590
00:37:45,480 --> 00:37:45,490
in a whole space of concepts so that
 

1591
00:37:45,490 --> 00:37:47,760
in a whole space of concepts so that
there's certain concepts that are closer

1592
00:37:47,760 --> 00:37:47,770
there's certain concepts that are closer
 

1593
00:37:47,770 --> 00:37:50,550
there's certain concepts that are closer
to it or farther away from it are these

1594
00:37:50,550 --> 00:37:50,560
to it or farther away from it are these
 

1595
00:37:50,560 --> 00:37:52,320
to it or farther away from it are these
concepts are they really like

1596
00:37:52,320 --> 00:37:52,330
concepts are they really like
 

1597
00:37:52,330 --> 00:37:54,270
concepts are they really like
fundamental like we mention innate look

1598
00:37:54,270 --> 00:37:54,280
fundamental like we mention innate look
 

1599
00:37:54,280 --> 00:37:57,000
fundamental like we mention innate look
almost like XE o matic like very basic

1600
00:37:57,000 --> 00:37:57,010
almost like XE o matic like very basic
 

1601
00:37:57,010 --> 00:37:58,290
almost like XE o matic like very basic
and then there's other stuff built on

1602
00:37:58,290 --> 00:37:58,300
and then there's other stuff built on
 

1603
00:37:58,300 --> 00:38:00,420
and then there's other stuff built on
top of it or just include everything is

1604
00:38:00,420 --> 00:38:00,430
top of it or just include everything is
 

1605
00:38:00,430 --> 00:38:04,560
top of it or just include everything is
are they're complicated like you can

1606
00:38:04,560 --> 00:38:04,570
are they're complicated like you can
 

1607
00:38:04,570 --> 00:38:07,170
are they're complicated like you can
certainly have form new concepts right I

1608
00:38:07,170 --> 00:38:07,180
certainly have form new concepts right I
 

1609
00:38:07,180 --> 00:38:08,490
certainly have form new concepts right I
guess that's the question I'm asked yeah

1610
00:38:08,490 --> 00:38:08,500
guess that's the question I'm asked yeah
 

1611
00:38:08,500 --> 00:38:11,570
guess that's the question I'm asked yeah
can you form new concepts that our

1612
00:38:11,570 --> 00:38:11,580
can you form new concepts that our
 

1613
00:38:11,580 --> 00:38:14,010
can you form new concepts that our
company complex combinations of other

1614
00:38:14,010 --> 00:38:14,020
company complex combinations of other
 

1615
00:38:14,020 --> 00:38:16,500
company complex combinations of other
ago yes absolutely and that's kind of

1616
00:38:16,500 --> 00:38:16,510
ago yes absolutely and that's kind of
 

1617
00:38:16,510 --> 00:38:20,280
ago yes absolutely and that's kind of
what we we do you know learning and then

1618
00:38:20,280 --> 00:38:20,290
what we we do you know learning and then
 

1619
00:38:20,290 --> 00:38:23,130
what we we do you know learning and then
what's the role of analogies in that so

1620
00:38:23,130 --> 00:38:23,140
what's the role of analogies in that so
 

1621
00:38:23,140 --> 00:38:28,350
what's the role of analogies in that so
analogy is when you recognize that one

1622
00:38:28,350 --> 00:38:28,360
analogy is when you recognize that one
 

1623
00:38:28,360 --> 00:38:32,700
analogy is when you recognize that one
situation is essentially the same as

1624
00:38:32,700 --> 00:38:32,710
situation is essentially the same as
 

1625
00:38:32,710 --> 00:38:37,230
situation is essentially the same as
another situation and essentially is

1626
00:38:37,230 --> 00:38:37,240
another situation and essentially is
 

1627
00:38:37,240 --> 00:38:38,910
another situation and essentially is
kind of the key word there and because

1628
00:38:38,910 --> 00:38:38,920
kind of the key word there and because
 

1629
00:38:38,920 --> 00:38:44,850
kind of the key word there and because
it's not the same so if I say last week

1630
00:38:44,850 --> 00:38:44,860
it's not the same so if I say last week
 

1631
00:38:44,860 --> 00:38:48,930
it's not the same so if I say last week
I did a podcast interview in actually

1632
00:38:48,930 --> 00:38:48,940
I did a podcast interview in actually
 

1633
00:38:48,940 --> 00:38:52,760
I did a podcast interview in actually
like three days ago in Washington DC and

1634
00:38:52,760 --> 00:38:52,770
like three days ago in Washington DC and
 

1635
00:38:52,770 --> 00:38:55,830
like three days ago in Washington DC and
that situation was very similar to this

1636
00:38:55,830 --> 00:38:55,840
that situation was very similar to this
 

1637
00:38:55,840 --> 00:38:57,960
that situation was very similar to this
situation although it wasn't exactly the

1638
00:38:57,960 --> 00:38:57,970
situation although it wasn't exactly the
 

1639
00:38:57,970 --> 00:38:59,310
situation although it wasn't exactly the
same you know it was a different person

1640
00:38:59,310 --> 00:38:59,320
same you know it was a different person
 

1641
00:38:59,320 --> 00:39:01,170
same you know it was a different person
sitting across from me we had different

1642
00:39:01,170 --> 00:39:01,180
sitting across from me we had different
 

1643
00:39:01,180 --> 00:39:03,870
sitting across from me we had different
kinds of microphones the questions were

1644
00:39:03,870 --> 00:39:03,880
kinds of microphones the questions were
 

1645
00:39:03,880 --> 00:39:04,380
kinds of microphones the questions were
different

1646
00:39:04,380 --> 00:39:04,390
different
 

1647
00:39:04,390 --> 00:39:06,330
different
the building was different there's all

1648
00:39:06,330 --> 00:39:06,340
the building was different there's all
 

1649
00:39:06,340 --> 00:39:07,920
the building was different there's all
kinds of different things but really it

1650
00:39:07,920 --> 00:39:07,930
kinds of different things but really it
 

1651
00:39:07,930 --> 00:39:13,740
kinds of different things but really it
was analogous or I can say so by doing a

1652
00:39:13,740 --> 00:39:13,750
was analogous or I can say so by doing a
 

1653
00:39:13,750 --> 00:39:15,660
was analogous or I can say so by doing a
podcast interview that's kind of a

1654
00:39:15,660 --> 00:39:15,670
podcast interview that's kind of a
 

1655
00:39:15,670 --> 00:39:17,460
podcast interview that's kind of a
constant it's a new concept you know I

1656
00:39:17,460 --> 00:39:17,470
constant it's a new concept you know I
 

1657
00:39:17,470 --> 00:39:24,330
constant it's a new concept you know I
never had that concept before I mean and

1658
00:39:24,330 --> 00:39:24,340
never had that concept before I mean and
 

1659
00:39:24,340 --> 00:39:27,630
never had that concept before I mean and
I can make an analogy with it like being

1660
00:39:27,630 --> 00:39:27,640
I can make an analogy with it like being
 

1661
00:39:27,640 --> 00:39:30,090
I can make an analogy with it like being
interviewed for a news article in a

1662
00:39:30,090 --> 00:39:30,100
interviewed for a news article in a
 

1663
00:39:30,100 --> 00:39:34,440
interviewed for a news article in a
newspaper and I can say well you kind of

1664
00:39:34,440 --> 00:39:34,450
newspaper and I can say well you kind of
 

1665
00:39:34,450 --> 00:39:37,320
newspaper and I can say well you kind of
play the same role that the the

1666
00:39:37,320 --> 00:39:37,330
play the same role that the the
 

1667
00:39:37,330 --> 00:39:40,320
play the same role that the the
newspaper the reporter played it's not

1668
00:39:40,320 --> 00:39:40,330
newspaper the reporter played it's not
 

1669
00:39:40,330 --> 00:39:42,600
newspaper the reporter played it's not
exactly the same because maybe they

1670
00:39:42,600 --> 00:39:42,610
exactly the same because maybe they
 

1671
00:39:42,610 --> 00:39:44,340
exactly the same because maybe they
actually emailed me some written

1672
00:39:44,340 --> 00:39:44,350
actually emailed me some written
 

1673
00:39:44,350 --> 00:39:45,660
actually emailed me some written
questions rather than

1674
00:39:45,660 --> 00:39:45,670
questions rather than
 

1675
00:39:45,670 --> 00:39:49,069
questions rather than
and the writing the written questions

1676
00:39:49,069 --> 00:39:49,079
and the writing the written questions
 

1677
00:39:49,079 --> 00:39:52,259
and the writing the written questions
play the you know are analogous to your

1678
00:39:52,259 --> 00:39:52,269
play the you know are analogous to your
 

1679
00:39:52,269 --> 00:39:53,999
play the you know are analogous to your
spoken questions you know there's just

1680
00:39:53,999 --> 00:39:54,009
spoken questions you know there's just
 

1681
00:39:54,009 --> 00:39:55,650
spoken questions you know there's just
all kinds of this somehow probably

1682
00:39:55,650 --> 00:39:55,660
all kinds of this somehow probably
 

1683
00:39:55,660 --> 00:39:57,809
all kinds of this somehow probably
connects to conversations you have over

1684
00:39:57,809 --> 00:39:57,819
connects to conversations you have over
 

1685
00:39:57,819 --> 00:39:59,279
connects to conversations you have over
Thanksgiving dinner just general

1686
00:39:59,279 --> 00:39:59,289
Thanksgiving dinner just general
 

1687
00:39:59,289 --> 00:40:01,499
Thanksgiving dinner just general
conversations you could there's like a

1688
00:40:01,499 --> 00:40:01,509
conversations you could there's like a
 

1689
00:40:01,509 --> 00:40:03,870
conversations you could there's like a
thread you can probably take that just

1690
00:40:03,870 --> 00:40:03,880
thread you can probably take that just
 

1691
00:40:03,880 --> 00:40:06,479
thread you can probably take that just
stretches out in all aspects of life

1692
00:40:06,479 --> 00:40:06,489
stretches out in all aspects of life
 

1693
00:40:06,489 --> 00:40:09,059
stretches out in all aspects of life
that connect to this podcast I mean sure

1694
00:40:09,059 --> 00:40:09,069
that connect to this podcast I mean sure
 

1695
00:40:09,069 --> 00:40:12,239
that connect to this podcast I mean sure
conversations between humans sure and

1696
00:40:12,239 --> 00:40:12,249
conversations between humans sure and
 

1697
00:40:12,249 --> 00:40:16,799
conversations between humans sure and
and if I go and tell a friend of mine

1698
00:40:16,799 --> 00:40:16,809
and if I go and tell a friend of mine
 

1699
00:40:16,809 --> 00:40:19,529
and if I go and tell a friend of mine
about this podcast interview my friend

1700
00:40:19,529 --> 00:40:19,539
about this podcast interview my friend
 

1701
00:40:19,539 --> 00:40:21,900
about this podcast interview my friend
might say oh the same thing happened to

1702
00:40:21,900 --> 00:40:21,910
might say oh the same thing happened to
 

1703
00:40:21,910 --> 00:40:24,120
might say oh the same thing happened to
me you know let's say you know you ask

1704
00:40:24,120 --> 00:40:24,130
me you know let's say you know you ask
 

1705
00:40:24,130 --> 00:40:27,599
me you know let's say you know you ask
me some really hard question and I have

1706
00:40:27,599 --> 00:40:27,609
me some really hard question and I have
 

1707
00:40:27,609 --> 00:40:29,910
me some really hard question and I have
trouble answering it my friend could say

1708
00:40:29,910 --> 00:40:29,920
trouble answering it my friend could say
 

1709
00:40:29,920 --> 00:40:31,950
trouble answering it my friend could say
the same thing happened to me but it was

1710
00:40:31,950 --> 00:40:31,960
the same thing happened to me but it was
 

1711
00:40:31,960 --> 00:40:34,170
the same thing happened to me but it was
like it wasn't a podcast interview it

1712
00:40:34,170 --> 00:40:34,180
like it wasn't a podcast interview it
 

1713
00:40:34,180 --> 00:40:38,569
like it wasn't a podcast interview it
wasn't it was a completely different

1714
00:40:38,569 --> 00:40:38,579
wasn't it was a completely different
 

1715
00:40:38,579 --> 00:40:42,210
wasn't it was a completely different
situation and yet my friend is seen

1716
00:40:42,210 --> 00:40:42,220
situation and yet my friend is seen
 

1717
00:40:42,220 --> 00:40:44,370
situation and yet my friend is seen
essentially this the same thing you know

1718
00:40:44,370 --> 00:40:44,380
essentially this the same thing you know
 

1719
00:40:44,380 --> 00:40:46,529
essentially this the same thing you know
we say that very fluidly the same thing

1720
00:40:46,529 --> 00:40:46,539
we say that very fluidly the same thing
 

1721
00:40:46,539 --> 00:40:49,440
we say that very fluidly the same thing
happened to me essentially the same

1722
00:40:49,440 --> 00:40:49,450
happened to me essentially the same
 

1723
00:40:49,450 --> 00:40:51,029
happened to me essentially the same
thing we don't even say that right

1724
00:40:51,029 --> 00:40:51,039
thing we don't even say that right
 

1725
00:40:51,039 --> 00:40:54,239
thing we don't even say that right
things they imply it yes yeah and the

1726
00:40:54,239 --> 00:40:54,249
things they imply it yes yeah and the
 

1727
00:40:54,249 --> 00:40:56,819
things they imply it yes yeah and the
view that kind of what went into say

1728
00:40:56,819 --> 00:40:56,829
view that kind of what went into say
 

1729
00:40:56,829 --> 00:40:58,999
view that kind of what went into say
coffee cat that that whole thing is that

1730
00:40:58,999 --> 00:40:59,009
coffee cat that that whole thing is that
 

1731
00:40:59,009 --> 00:41:02,039
coffee cat that that whole thing is that
that that that act of saying the same

1732
00:41:02,039 --> 00:41:02,049
that that that act of saying the same
 

1733
00:41:02,049 --> 00:41:04,200
that that that act of saying the same
thing happened to me is making an

1734
00:41:04,200 --> 00:41:04,210
thing happened to me is making an
 

1735
00:41:04,210 --> 00:41:06,960
thing happened to me is making an
analogy and in some sense that's what's

1736
00:41:06,960 --> 00:41:06,970
analogy and in some sense that's what's
 

1737
00:41:06,970 --> 00:41:11,160
analogy and in some sense that's what's
underlies all of our concepts why do you

1738
00:41:11,160 --> 00:41:11,170
underlies all of our concepts why do you
 

1739
00:41:11,170 --> 00:41:12,809
underlies all of our concepts why do you
think analogy making that you're

1740
00:41:12,809 --> 00:41:12,819
think analogy making that you're
 

1741
00:41:12,819 --> 00:41:15,720
think analogy making that you're
describing is so fundamental to

1742
00:41:15,720 --> 00:41:15,730
describing is so fundamental to
 

1743
00:41:15,730 --> 00:41:18,180
describing is so fundamental to
cognition like it seems like it's the

1744
00:41:18,180 --> 00:41:18,190
cognition like it seems like it's the
 

1745
00:41:18,190 --> 00:41:21,299
cognition like it seems like it's the
main element action of what we think of

1746
00:41:21,299 --> 00:41:21,309
main element action of what we think of
 

1747
00:41:21,309 --> 00:41:24,660
main element action of what we think of
us cognition yeah so it can be argued

1748
00:41:24,660 --> 00:41:24,670
us cognition yeah so it can be argued
 

1749
00:41:24,670 --> 00:41:30,109
us cognition yeah so it can be argued
that all of this generalization we do

1750
00:41:30,109 --> 00:41:30,119
that all of this generalization we do
 

1751
00:41:30,119 --> 00:41:35,579
that all of this generalization we do
concepts and recognizing concepts in

1752
00:41:35,579 --> 00:41:35,589
concepts and recognizing concepts in
 

1753
00:41:35,589 --> 00:41:41,720
concepts and recognizing concepts in
different situations is done by analogy

1754
00:41:41,720 --> 00:41:41,730
different situations is done by analogy
 

1755
00:41:41,730 --> 00:41:47,700
different situations is done by analogy
that that's every time I'm recognizing

1756
00:41:47,700 --> 00:41:47,710
that that's every time I'm recognizing
 

1757
00:41:47,710 --> 00:41:53,039
that that's every time I'm recognizing
that say you're a person that's by

1758
00:41:53,039 --> 00:41:53,049
that say you're a person that's by
 

1759
00:41:53,049 --> 00:41:54,960
that say you're a person that's by
analogy because I have this concept of

1760
00:41:54,960 --> 00:41:54,970
analogy because I have this concept of
 

1761
00:41:54,970 --> 00:41:56,460
analogy because I have this concept of
what person is and I'm applying it to

1762
00:41:56,460 --> 00:41:56,470
what person is and I'm applying it to
 

1763
00:41:56,470 --> 00:41:59,099
what person is and I'm applying it to
you and every

1764
00:41:59,099 --> 00:41:59,109
you and every
 

1765
00:41:59,109 --> 00:42:02,749
you and every
time I recognize a new situation like

1766
00:42:02,749 --> 00:42:02,759
time I recognize a new situation like
 

1767
00:42:02,759 --> 00:42:06,180
time I recognize a new situation like
one of the things I talked about it in

1768
00:42:06,180 --> 00:42:06,190
one of the things I talked about it in
 

1769
00:42:06,190 --> 00:42:08,430
one of the things I talked about it in
the book was the the concept of walking

1770
00:42:08,430 --> 00:42:08,440
the book was the the concept of walking
 

1771
00:42:08,440 --> 00:42:11,160
the book was the the concept of walking
a dog that that's actually making an

1772
00:42:11,160 --> 00:42:11,170
a dog that that's actually making an
 

1773
00:42:11,170 --> 00:42:13,559
a dog that that's actually making an
analogy because all that you know the

1774
00:42:13,559 --> 00:42:13,569
analogy because all that you know the
 

1775
00:42:13,569 --> 00:42:17,220
analogy because all that you know the
details are very different so it's so

1776
00:42:17,220 --> 00:42:17,230
details are very different so it's so
 

1777
00:42:17,230 --> 00:42:19,529
details are very different so it's so
now--so reasoning could be reduced on to

1778
00:42:19,529 --> 00:42:19,539
now--so reasoning could be reduced on to
 

1779
00:42:19,539 --> 00:42:22,229
now--so reasoning could be reduced on to
sense your analogy making so all the

1780
00:42:22,229 --> 00:42:22,239
sense your analogy making so all the
 

1781
00:42:22,239 --> 00:42:25,799
sense your analogy making so all the
things we think of as like yeah like you

1782
00:42:25,799 --> 00:42:25,809
things we think of as like yeah like you
 

1783
00:42:25,809 --> 00:42:27,930
things we think of as like yeah like you
said perception so what's perception is

1784
00:42:27,930 --> 00:42:27,940
said perception so what's perception is
 

1785
00:42:27,940 --> 00:42:29,940
said perception so what's perception is
taking raw sensory input and it's

1786
00:42:29,940 --> 00:42:29,950
taking raw sensory input and it's
 

1787
00:42:29,950 --> 00:42:31,999
taking raw sensory input and it's
somehow integrating into our our

1788
00:42:31,999 --> 00:42:32,009
somehow integrating into our our
 

1789
00:42:32,009 --> 00:42:34,109
somehow integrating into our our
understanding of the world updating the

1790
00:42:34,109 --> 00:42:34,119
understanding of the world updating the
 

1791
00:42:34,119 --> 00:42:36,809
understanding of the world updating the
understanding and all of that has just

1792
00:42:36,809 --> 00:42:36,819
understanding and all of that has just
 

1793
00:42:36,819 --> 00:42:39,390
understanding and all of that has just
this giant mess of analogies that are

1794
00:42:39,390 --> 00:42:39,400
this giant mess of analogies that are
 

1795
00:42:39,400 --> 00:42:43,019
this giant mess of analogies that are
being made I think so yeah if you just

1796
00:42:43,019 --> 00:42:43,029
being made I think so yeah if you just
 

1797
00:42:43,029 --> 00:42:45,299
being made I think so yeah if you just
linger on it a little bit like what what

1798
00:42:45,299 --> 00:42:45,309
linger on it a little bit like what what
 

1799
00:42:45,309 --> 00:42:47,160
linger on it a little bit like what what
do you think it takes to engineer a

1800
00:42:47,160 --> 00:42:47,170
do you think it takes to engineer a
 

1801
00:42:47,170 --> 00:42:50,130
do you think it takes to engineer a
process like that for us in our

1802
00:42:50,130 --> 00:42:50,140
process like that for us in our
 

1803
00:42:50,140 --> 00:42:55,049
process like that for us in our
artificial systems we need to understand

1804
00:42:55,049 --> 00:42:55,059
artificial systems we need to understand
 

1805
00:42:55,059 --> 00:42:59,789
artificial systems we need to understand
better I think how how we do it how

1806
00:42:59,789 --> 00:42:59,799
better I think how how we do it how
 

1807
00:42:59,799 --> 00:43:05,180
better I think how how we do it how
humans do it and it comes down to

1808
00:43:05,180 --> 00:43:05,190
humans do it and it comes down to
 

1809
00:43:05,190 --> 00:43:08,099
humans do it and it comes down to
internal models I think you know people

1810
00:43:08,099 --> 00:43:08,109
internal models I think you know people
 

1811
00:43:08,109 --> 00:43:11,249
internal models I think you know people
talk a lot about mental models that

1812
00:43:11,249 --> 00:43:11,259
talk a lot about mental models that
 

1813
00:43:11,259 --> 00:43:15,809
talk a lot about mental models that
concepts are mental models that I can in

1814
00:43:15,809 --> 00:43:15,819
concepts are mental models that I can in
 

1815
00:43:15,819 --> 00:43:19,799
concepts are mental models that I can in
my head I can do a simulation of a

1816
00:43:19,799 --> 00:43:19,809
my head I can do a simulation of a
 

1817
00:43:19,809 --> 00:43:22,769
my head I can do a simulation of a
situation like walking a dog and that

1818
00:43:22,769 --> 00:43:22,779
situation like walking a dog and that
 

1819
00:43:22,779 --> 00:43:25,410
situation like walking a dog and that
there there's some work in psychology

1820
00:43:25,410 --> 00:43:25,420
there there's some work in psychology
 

1821
00:43:25,420 --> 00:43:28,499
there there's some work in psychology
that promotes this idea that all of

1822
00:43:28,499 --> 00:43:28,509
that promotes this idea that all of
 

1823
00:43:28,509 --> 00:43:30,989
that promotes this idea that all of
concepts are really mental simulations

1824
00:43:30,989 --> 00:43:30,999
concepts are really mental simulations
 

1825
00:43:30,999 --> 00:43:34,700
concepts are really mental simulations
that whenever you encounter a concept or

1826
00:43:34,700 --> 00:43:34,710
that whenever you encounter a concept or
 

1827
00:43:34,710 --> 00:43:36,809
that whenever you encounter a concept or
situation in the world or you read about

1828
00:43:36,809 --> 00:43:36,819
situation in the world or you read about
 

1829
00:43:36,819 --> 00:43:39,210
situation in the world or you read about
it or whatever you do some kind of

1830
00:43:39,210 --> 00:43:39,220
it or whatever you do some kind of
 

1831
00:43:39,220 --> 00:43:42,120
it or whatever you do some kind of
mental simulation that allows you to

1832
00:43:42,120 --> 00:43:42,130
mental simulation that allows you to
 

1833
00:43:42,130 --> 00:43:43,859
mental simulation that allows you to
predict what's going to happen to

1834
00:43:43,859 --> 00:43:43,869
predict what's going to happen to
 

1835
00:43:43,869 --> 00:43:46,890
predict what's going to happen to
develop expectations of what's going to

1836
00:43:46,890 --> 00:43:46,900
develop expectations of what's going to
 

1837
00:43:46,900 --> 00:43:49,410
develop expectations of what's going to
happen mm-hm so that's the kind of

1838
00:43:49,410 --> 00:43:49,420
happen mm-hm so that's the kind of
 

1839
00:43:49,420 --> 00:43:52,259
happen mm-hm so that's the kind of
structure I think we need is that kind

1840
00:43:52,259 --> 00:43:52,269
structure I think we need is that kind
 

1841
00:43:52,269 --> 00:43:56,460
structure I think we need is that kind
of mental model that and the in our

1842
00:43:56,460 --> 00:43:56,470
of mental model that and the in our
 

1843
00:43:56,470 --> 00:43:58,170
of mental model that and the in our
brain somehow these mental models are

1844
00:43:58,170 --> 00:43:58,180
brain somehow these mental models are
 

1845
00:43:58,180 --> 00:44:02,130
brain somehow these mental models are
very much inter connected again so a lot

1846
00:44:02,130 --> 00:44:02,140
very much inter connected again so a lot
 

1847
00:44:02,140 --> 00:44:03,809
very much inter connected again so a lot
of stuff we're talking about it they're

1848
00:44:03,809 --> 00:44:03,819
of stuff we're talking about it they're
 

1849
00:44:03,819 --> 00:44:06,720
of stuff we're talking about it they're
essentially open problems right so if I

1850
00:44:06,720 --> 00:44:06,730
essentially open problems right so if I
 

1851
00:44:06,730 --> 00:44:08,999
essentially open problems right so if I
ask a question I don't mean that you

1852
00:44:08,999 --> 00:44:09,009
ask a question I don't mean that you
 

1853
00:44:09,009 --> 00:44:10,410
ask a question I don't mean that you
would know the answer already just

1854
00:44:10,410 --> 00:44:10,420
would know the answer already just
 

1855
00:44:10,420 --> 00:44:14,130
would know the answer already just
hypothesizing but how big do you think

1856
00:44:14,130 --> 00:44:14,140
hypothesizing but how big do you think
 

1857
00:44:14,140 --> 00:44:20,279
hypothesizing but how big do you think
is the the network graph data structure

1858
00:44:20,279 --> 00:44:20,289
is the the network graph data structure
 

1859
00:44:20,289 --> 00:44:23,519
is the the network graph data structure
of concepts that's in our head like if

1860
00:44:23,519 --> 00:44:23,529
of concepts that's in our head like if
 

1861
00:44:23,529 --> 00:44:25,609
of concepts that's in our head like if
we're trying to build that ourselves

1862
00:44:25,609 --> 00:44:25,619
we're trying to build that ourselves
 

1863
00:44:25,619 --> 00:44:28,529
we're trying to build that ourselves
like it's we take it and that's one of

1864
00:44:28,529 --> 00:44:28,539
like it's we take it and that's one of
 

1865
00:44:28,539 --> 00:44:29,910
like it's we take it and that's one of
the things we take for granted we think

1866
00:44:29,910 --> 00:44:29,920
the things we take for granted we think
 

1867
00:44:29,920 --> 00:44:31,979
the things we take for granted we think
I mean that's why we take common sense

1868
00:44:31,979 --> 00:44:31,989
I mean that's why we take common sense
 

1869
00:44:31,989 --> 00:44:33,509
I mean that's why we take common sense
for granted within common sense is

1870
00:44:33,509 --> 00:44:33,519
for granted within common sense is
 

1871
00:44:33,519 --> 00:44:38,160
for granted within common sense is
trivial but how big of a thing of

1872
00:44:38,160 --> 00:44:38,170
trivial but how big of a thing of
 

1873
00:44:38,170 --> 00:44:41,309
trivial but how big of a thing of
concepts is on that underlies what we

1874
00:44:41,309 --> 00:44:41,319
concepts is on that underlies what we
 

1875
00:44:41,319 --> 00:44:43,700
concepts is on that underlies what we
think of as common sense for example

1876
00:44:43,700 --> 00:44:43,710
think of as common sense for example
 

1877
00:44:43,710 --> 00:44:46,259
think of as common sense for example
yeah I don't know and I'm not I don't

1878
00:44:46,259 --> 00:44:46,269
yeah I don't know and I'm not I don't
 

1879
00:44:46,269 --> 00:44:49,789
yeah I don't know and I'm not I don't
even know what units to measure it in

1880
00:44:49,789 --> 00:44:49,799

 

1881
00:44:49,799 --> 00:44:53,640

beautifully put right but but you know

1882
00:44:53,640 --> 00:44:53,650
beautifully put right but but you know
 

1883
00:44:53,650 --> 00:44:55,470
beautifully put right but but you know
we have you know it's really hard to

1884
00:44:55,470 --> 00:44:55,480
we have you know it's really hard to
 

1885
00:44:55,480 --> 00:44:59,339
we have you know it's really hard to
know we have what a hundred billion

1886
00:44:59,339 --> 00:44:59,349
know we have what a hundred billion
 

1887
00:44:59,349 --> 00:45:02,370
know we have what a hundred billion
neurons or something I don't know and

1888
00:45:02,370 --> 00:45:02,380
neurons or something I don't know and
 

1889
00:45:02,380 --> 00:45:06,109
neurons or something I don't know and
they're connected via trillions of

1890
00:45:06,109 --> 00:45:06,119
they're connected via trillions of
 

1891
00:45:06,119 --> 00:45:09,359
they're connected via trillions of
synapses and there's all this chemical

1892
00:45:09,359 --> 00:45:09,369
synapses and there's all this chemical
 

1893
00:45:09,369 --> 00:45:11,249
synapses and there's all this chemical
processing going on there's just a lot

1894
00:45:11,249 --> 00:45:11,259
processing going on there's just a lot
 

1895
00:45:11,259 --> 00:45:14,370
processing going on there's just a lot
of capacity for the stuff and their

1896
00:45:14,370 --> 00:45:14,380
of capacity for the stuff and their
 

1897
00:45:14,380 --> 00:45:16,440
of capacity for the stuff and their
informations encoded in different ways

1898
00:45:16,440 --> 00:45:16,450
informations encoded in different ways
 

1899
00:45:16,450 --> 00:45:19,200
informations encoded in different ways
in the brain it's encoded in chemical

1900
00:45:19,200 --> 00:45:19,210
in the brain it's encoded in chemical
 

1901
00:45:19,210 --> 00:45:21,539
in the brain it's encoded in chemical
interactions it's encoded and electric

1902
00:45:21,539 --> 00:45:21,549
interactions it's encoded and electric
 

1903
00:45:21,549 --> 00:45:24,180
interactions it's encoded and electric
like firing and firing rates and and

1904
00:45:24,180 --> 00:45:24,190
like firing and firing rates and and
 

1905
00:45:24,190 --> 00:45:25,920
like firing and firing rates and and
nobody really knows how it's encoded but

1906
00:45:25,920 --> 00:45:25,930
nobody really knows how it's encoded but
 

1907
00:45:25,930 --> 00:45:28,319
nobody really knows how it's encoded but
it just seems like there's a huge amount

1908
00:45:28,319 --> 00:45:28,329
it just seems like there's a huge amount
 

1909
00:45:28,329 --> 00:45:30,630
it just seems like there's a huge amount
of capacity so I think it's it's huge

1910
00:45:30,630 --> 00:45:30,640
of capacity so I think it's it's huge
 

1911
00:45:30,640 --> 00:45:34,109
of capacity so I think it's it's huge
it's just enormous and it's amazing how

1912
00:45:34,109 --> 00:45:34,119
it's just enormous and it's amazing how
 

1913
00:45:34,119 --> 00:45:40,229
it's just enormous and it's amazing how
much stuff we know yeah and but we know

1914
00:45:40,229 --> 00:45:40,239
much stuff we know yeah and but we know
 

1915
00:45:40,239 --> 00:45:43,019
much stuff we know yeah and but we know
and not just know like facts but it's

1916
00:45:43,019 --> 00:45:43,029
and not just know like facts but it's
 

1917
00:45:43,029 --> 00:45:45,120
and not just know like facts but it's
all integrated into this thing that we

1918
00:45:45,120 --> 00:45:45,130
all integrated into this thing that we
 

1919
00:45:45,130 --> 00:45:47,579
all integrated into this thing that we
can make analogies with yes there's a

1920
00:45:47,579 --> 00:45:47,589
can make analogies with yes there's a
 

1921
00:45:47,589 --> 00:45:49,529
can make analogies with yes there's a
dream of semantic web and there's

1922
00:45:49,529 --> 00:45:49,539
dream of semantic web and there's
 

1923
00:45:49,539 --> 00:45:52,470
dream of semantic web and there's
there's a lot of Dreams from expert

1924
00:45:52,470 --> 00:45:52,480
there's a lot of Dreams from expert
 

1925
00:45:52,480 --> 00:45:54,630
there's a lot of Dreams from expert
systems of building giant knowledge

1926
00:45:54,630 --> 00:45:54,640
systems of building giant knowledge
 

1927
00:45:54,640 --> 00:45:57,749
systems of building giant knowledge
bases or do you see a hope for these

1928
00:45:57,749 --> 00:45:57,759
bases or do you see a hope for these
 

1929
00:45:57,759 --> 00:45:59,700
bases or do you see a hope for these
kinds of approaches of building of

1930
00:45:59,700 --> 00:45:59,710
kinds of approaches of building of
 

1931
00:45:59,710 --> 00:46:01,920
kinds of approaches of building of
converting Wikipedia into something that

1932
00:46:01,920 --> 00:46:01,930
converting Wikipedia into something that
 

1933
00:46:01,930 --> 00:46:06,660
converting Wikipedia into something that
could be used in analogy making sure and

1934
00:46:06,660 --> 00:46:06,670
could be used in analogy making sure and
 

1935
00:46:06,670 --> 00:46:09,120
could be used in analogy making sure and
I think people have have made some

1936
00:46:09,120 --> 00:46:09,130
I think people have have made some
 

1937
00:46:09,130 --> 00:46:10,920
I think people have have made some
progress along those lines I mean people

1938
00:46:10,920 --> 00:46:10,930
progress along those lines I mean people
 

1939
00:46:10,930 --> 00:46:12,089
progress along those lines I mean people
have been working on this for a long

1940
00:46:12,089 --> 00:46:12,099
have been working on this for a long
 

1941
00:46:12,099 --> 00:46:15,180
have been working on this for a long
time but the problem is and this I think

1942
00:46:15,180 --> 00:46:15,190
time but the problem is and this I think
 

1943
00:46:15,190 --> 00:46:17,160
time but the problem is and this I think
was is is the problem of common sense

1944
00:46:17,160 --> 00:46:17,170
was is is the problem of common sense
 

1945
00:46:17,170 --> 00:46:19,049
was is is the problem of common sense
like people have been trying to get

1946
00:46:19,049 --> 00:46:19,059
like people have been trying to get
 

1947
00:46:19,059 --> 00:46:21,509
like people have been trying to get
these common sense networks here at MIT

1948
00:46:21,509 --> 00:46:21,519
these common sense networks here at MIT
 

1949
00:46:21,519 --> 00:46:25,039
these common sense networks here at MIT
there's this concept net project right

1950
00:46:25,039 --> 00:46:25,049
there's this concept net project right
 

1951
00:46:25,049 --> 00:46:27,559
there's this concept net project right
but the problem is that as I said most

1952
00:46:27,559 --> 00:46:27,569
but the problem is that as I said most
 

1953
00:46:27,569 --> 00:46:30,529
but the problem is that as I said most
of the knowledge that we have is

1954
00:46:30,529 --> 00:46:30,539
of the knowledge that we have is
 

1955
00:46:30,539 --> 00:46:34,059
of the knowledge that we have is
invisible to us it's not in Wikipedia

1956
00:46:34,059 --> 00:46:34,069
invisible to us it's not in Wikipedia
 

1957
00:46:34,069 --> 00:46:40,149
invisible to us it's not in Wikipedia
it's very basic things about you know

1958
00:46:40,149 --> 00:46:40,159
it's very basic things about you know
 

1959
00:46:40,159 --> 00:46:44,380
it's very basic things about you know
intuitive physics intuitive psychology

1960
00:46:44,380 --> 00:46:44,390
intuitive physics intuitive psychology
 

1961
00:46:44,390 --> 00:46:47,329
intuitive physics intuitive psychology
to ative metaphysics all that stuff if

1962
00:46:47,329 --> 00:46:47,339
to ative metaphysics all that stuff if
 

1963
00:46:47,339 --> 00:46:49,719
to ative metaphysics all that stuff if
you were to create a website that

1964
00:46:49,719 --> 00:46:49,729
you were to create a website that
 

1965
00:46:49,729 --> 00:46:52,759
you were to create a website that
described intuitive physics intuitive

1966
00:46:52,759 --> 00:46:52,769
described intuitive physics intuitive
 

1967
00:46:52,769 --> 00:46:54,559
described intuitive physics intuitive
psychology would it be bigger or smaller

1968
00:46:54,559 --> 00:46:54,569
psychology would it be bigger or smaller
 

1969
00:46:54,569 --> 00:46:57,229
psychology would it be bigger or smaller
than Wikipedia what do you think

1970
00:46:57,229 --> 00:46:57,239
than Wikipedia what do you think
 

1971
00:46:57,239 --> 00:47:04,699
than Wikipedia what do you think
I guess describe to whom no that's very

1972
00:47:04,699 --> 00:47:04,709
I guess describe to whom no that's very
 

1973
00:47:04,709 --> 00:47:07,429
I guess describe to whom no that's very
really good right yeah that's a hard

1974
00:47:07,429 --> 00:47:07,439
really good right yeah that's a hard
 

1975
00:47:07,439 --> 00:47:09,409
really good right yeah that's a hard
question because you know how do you

1976
00:47:09,409 --> 00:47:09,419
question because you know how do you
 

1977
00:47:09,419 --> 00:47:11,449
question because you know how do you
represent that knowledge is the question

1978
00:47:11,449 --> 00:47:11,459
represent that knowledge is the question
 

1979
00:47:11,459 --> 00:47:14,419
represent that knowledge is the question
right I can certainly write down F

1980
00:47:14,419 --> 00:47:14,429
right I can certainly write down F
 

1981
00:47:14,429 --> 00:47:19,219
right I can certainly write down F
equals MA and Newton's laws and a lot of

1982
00:47:19,219 --> 00:47:19,229
equals MA and Newton's laws and a lot of
 

1983
00:47:19,229 --> 00:47:23,469
equals MA and Newton's laws and a lot of
physics can be deduced from that but

1984
00:47:23,469 --> 00:47:23,479
physics can be deduced from that but
 

1985
00:47:23,479 --> 00:47:25,630
physics can be deduced from that but
that's probably not the best

1986
00:47:25,630 --> 00:47:25,640
that's probably not the best
 

1987
00:47:25,640 --> 00:47:29,059
that's probably not the best
representation of that knowledge for for

1988
00:47:29,059 --> 00:47:29,069
representation of that knowledge for for
 

1989
00:47:29,069 --> 00:47:32,629
representation of that knowledge for for
doing the kinds of reasoning we want a

1990
00:47:32,629 --> 00:47:32,639
doing the kinds of reasoning we want a
 

1991
00:47:32,639 --> 00:47:37,969
doing the kinds of reasoning we want a
machine to do so so I don't know it's

1992
00:47:37,969 --> 00:47:37,979
machine to do so so I don't know it's
 

1993
00:47:37,979 --> 00:47:41,929
machine to do so so I don't know it's
it's it's impossible to say and you know

1994
00:47:41,929 --> 00:47:41,939
it's it's impossible to say and you know
 

1995
00:47:41,939 --> 00:47:44,479
it's it's impossible to say and you know
the projects like there's a famous the

1996
00:47:44,479 --> 00:47:44,489
the projects like there's a famous the
 

1997
00:47:44,489 --> 00:47:47,239
the projects like there's a famous the
famous psych project right that Doug

1998
00:47:47,239 --> 00:47:47,249
famous psych project right that Doug
 

1999
00:47:47,249 --> 00:47:49,969
famous psych project right that Doug
Douglass Lynott did that was trying

2000
00:47:49,969 --> 00:47:49,979
Douglass Lynott did that was trying
 

2001
00:47:49,979 --> 00:47:52,159
Douglass Lynott did that was trying
still going I think it's still going and

2002
00:47:52,159 --> 00:47:52,169
still going I think it's still going and
 

2003
00:47:52,169 --> 00:47:54,649
still going I think it's still going and
if the the idea was to try and encode

2004
00:47:54,649 --> 00:47:54,659
if the the idea was to try and encode
 

2005
00:47:54,659 --> 00:47:56,689
if the the idea was to try and encode
all of common-sense knowledge including

2006
00:47:56,689 --> 00:47:56,699
all of common-sense knowledge including
 

2007
00:47:56,699 --> 00:47:59,839
all of common-sense knowledge including
all this invisible knowledge in some

2008
00:47:59,839 --> 00:47:59,849
all this invisible knowledge in some
 

2009
00:47:59,849 --> 00:48:03,679
all this invisible knowledge in some
kind of logical representation and it

2010
00:48:03,679 --> 00:48:03,689
kind of logical representation and it
 

2011
00:48:03,689 --> 00:48:08,779
kind of logical representation and it
just never I think could do any of the

2012
00:48:08,779 --> 00:48:08,789
just never I think could do any of the
 

2013
00:48:08,789 --> 00:48:10,339
just never I think could do any of the
things that he was hoping it could do

2014
00:48:10,339 --> 00:48:10,349
things that he was hoping it could do
 

2015
00:48:10,349 --> 00:48:12,909
things that he was hoping it could do
because that's just the wrong approach

2016
00:48:12,909 --> 00:48:12,919
because that's just the wrong approach
 

2017
00:48:12,919 --> 00:48:15,009
because that's just the wrong approach
of course that's what they always say

2018
00:48:15,009 --> 00:48:15,019
of course that's what they always say
 

2019
00:48:15,019 --> 00:48:18,499
of course that's what they always say
you know and then the history books will

2020
00:48:18,499 --> 00:48:18,509
you know and then the history books will
 

2021
00:48:18,509 --> 00:48:20,959
you know and then the history books will
say well the psych project finally found

2022
00:48:20,959 --> 00:48:20,969
say well the psych project finally found
 

2023
00:48:20,969 --> 00:48:24,409
say well the psych project finally found
a breakthrough in 2058 or something and

2024
00:48:24,409 --> 00:48:24,419
a breakthrough in 2058 or something and
 

2025
00:48:24,419 --> 00:48:26,629
a breakthrough in 2058 or something and
it did you know we're so much progress

2026
00:48:26,629 --> 00:48:26,639
it did you know we're so much progress
 

2027
00:48:26,639 --> 00:48:28,609
it did you know we're so much progress
has been made in just a few decades that

2028
00:48:28,609 --> 00:48:28,619
has been made in just a few decades that
 

2029
00:48:28,619 --> 00:48:30,859
has been made in just a few decades that
yeah okay knows what the next

2030
00:48:30,859 --> 00:48:30,869
yeah okay knows what the next
 

2031
00:48:30,869 --> 00:48:32,599
yeah okay knows what the next
breakthroughs will be it could be a

2032
00:48:32,599 --> 00:48:32,609
breakthroughs will be it could be a
 

2033
00:48:32,609 --> 00:48:34,939
breakthroughs will be it could be a
certainly a compelling notion what the

2034
00:48:34,939 --> 00:48:34,949
certainly a compelling notion what the
 

2035
00:48:34,949 --> 00:48:37,000
certainly a compelling notion what the
psych project stands for

2036
00:48:37,000 --> 00:48:37,010
psych project stands for
 

2037
00:48:37,010 --> 00:48:38,890
psych project stands for
I think Lenin was one of the early

2038
00:48:38,890 --> 00:48:38,900
I think Lenin was one of the early
 

2039
00:48:38,900 --> 00:48:42,790
I think Lenin was one of the early
people do say common sense is what we

2040
00:48:42,790 --> 00:48:42,800
people do say common sense is what we
 

2041
00:48:42,800 --> 00:48:45,040
people do say common sense is what we
need and that's what we need all this

2042
00:48:45,040 --> 00:48:45,050
need and that's what we need all this
 

2043
00:48:45,050 --> 00:48:47,920
need and that's what we need all this
like expert system stuff that is not

2044
00:48:47,920 --> 00:48:47,930
like expert system stuff that is not
 

2045
00:48:47,930 --> 00:48:49,960
like expert system stuff that is not
going to get you to AI you need common

2046
00:48:49,960 --> 00:48:49,970
going to get you to AI you need common
 

2047
00:48:49,970 --> 00:48:54,210
going to get you to AI you need common
sense and he basically gave up his whole

2048
00:48:54,210 --> 00:48:54,220

 

2049
00:48:54,220 --> 00:48:57,910

academic career to to go pursue that I

2050
00:48:57,910 --> 00:48:57,920
academic career to to go pursue that I
 

2051
00:48:57,920 --> 00:49:00,930
academic career to to go pursue that I
told my er that but I think that the

2052
00:49:00,930 --> 00:49:00,940
told my er that but I think that the
 

2053
00:49:00,940 --> 00:49:09,310
told my er that but I think that the
approach itself will not what do you

2054
00:49:09,310 --> 00:49:09,320
approach itself will not what do you
 

2055
00:49:09,320 --> 00:49:10,540
approach itself will not what do you
think is wrong with approach what kind

2056
00:49:10,540 --> 00:49:10,550
think is wrong with approach what kind
 

2057
00:49:10,550 --> 00:49:13,770
think is wrong with approach what kind
of approach would might be successful

2058
00:49:13,770 --> 00:49:13,780
of approach would might be successful
 

2059
00:49:13,780 --> 00:49:16,990
of approach would might be successful
well again he knows the answer right I

2060
00:49:16,990 --> 00:49:17,000
well again he knows the answer right I
 

2061
00:49:17,000 --> 00:49:20,050
well again he knows the answer right I
knew that you know one of my talks one

2062
00:49:20,050 --> 00:49:20,060
knew that you know one of my talks one
 

2063
00:49:20,060 --> 00:49:21,190
knew that you know one of my talks one
of the people in the audience's a

2064
00:49:21,190 --> 00:49:21,200
of the people in the audience's a
 

2065
00:49:21,200 --> 00:49:22,660
of the people in the audience's a
published lecture one of the people in

2066
00:49:22,660 --> 00:49:22,670
published lecture one of the people in
 

2067
00:49:22,670 --> 00:49:25,630
published lecture one of the people in
the audience said what AI companies are

2068
00:49:25,630 --> 00:49:25,640
the audience said what AI companies are
 

2069
00:49:25,640 --> 00:49:30,400
the audience said what AI companies are
you investing in advice I'm a college

2070
00:49:30,400 --> 00:49:30,410
you investing in advice I'm a college
 

2071
00:49:30,410 --> 00:49:35,319
you investing in advice I'm a college
professor extra funds to invest but also

2072
00:49:35,319 --> 00:49:35,329
professor extra funds to invest but also
 

2073
00:49:35,329 --> 00:49:37,839
professor extra funds to invest but also
like no one knows what's gonna work in

2074
00:49:37,839 --> 00:49:37,849
like no one knows what's gonna work in
 

2075
00:49:37,849 --> 00:49:41,920
like no one knows what's gonna work in
AI right that's the problem let me ask

2076
00:49:41,920 --> 00:49:41,930
AI right that's the problem let me ask
 

2077
00:49:41,930 --> 00:49:43,569
AI right that's the problem let me ask
another impossible question in case you

2078
00:49:43,569 --> 00:49:43,579
another impossible question in case you
 

2079
00:49:43,579 --> 00:49:46,329
another impossible question in case you
have a sense in terms of data structures

2080
00:49:46,329 --> 00:49:46,339
have a sense in terms of data structures
 

2081
00:49:46,339 --> 00:49:48,640
have a sense in terms of data structures
that will store this kind of information

2082
00:49:48,640 --> 00:49:48,650
that will store this kind of information
 

2083
00:49:48,650 --> 00:49:51,089
that will store this kind of information
do you think they've been invented yet

2084
00:49:51,089 --> 00:49:51,099
do you think they've been invented yet
 

2085
00:49:51,099 --> 00:49:54,880
do you think they've been invented yet
both in hardware and software or is

2086
00:49:54,880 --> 00:49:54,890
both in hardware and software or is
 

2087
00:49:54,890 --> 00:49:57,069
both in hardware and software or is
something else needs to be are we

2088
00:49:57,069 --> 00:49:57,079
something else needs to be are we
 

2089
00:49:57,079 --> 00:49:58,990
something else needs to be are we
totally you know I think something else

2090
00:49:58,990 --> 00:49:59,000
totally you know I think something else
 

2091
00:49:59,000 --> 00:50:03,339
totally you know I think something else
has to be invented I that's my guess is

2092
00:50:03,339 --> 00:50:03,349
has to be invented I that's my guess is
 

2093
00:50:03,349 --> 00:50:06,400
has to be invented I that's my guess is
the breakthroughs that's most promising

2094
00:50:06,400 --> 00:50:06,410
the breakthroughs that's most promising
 

2095
00:50:06,410 --> 00:50:08,760
the breakthroughs that's most promising
would that be in hardware and software

2096
00:50:08,760 --> 00:50:08,770
would that be in hardware and software
 

2097
00:50:08,770 --> 00:50:10,930
would that be in hardware and software
do you think we can get far with the

2098
00:50:10,930 --> 00:50:10,940
do you think we can get far with the
 

2099
00:50:10,940 --> 00:50:13,540
do you think we can get far with the
current computers or do we need to do

2100
00:50:13,540 --> 00:50:13,550
current computers or do we need to do
 

2101
00:50:13,550 --> 00:50:16,930
current computers or do we need to do
something you're saying I don't know if

2102
00:50:16,930 --> 00:50:16,940
something you're saying I don't know if
 

2103
00:50:16,940 --> 00:50:19,270
something you're saying I don't know if
Turing computation is gonna be

2104
00:50:19,270 --> 00:50:19,280
Turing computation is gonna be
 

2105
00:50:19,280 --> 00:50:21,160
Turing computation is gonna be
sufficient probably I would guess it

2106
00:50:21,160 --> 00:50:21,170
sufficient probably I would guess it
 

2107
00:50:21,170 --> 00:50:23,440
sufficient probably I would guess it
will I don't I don't see any reason why

2108
00:50:23,440 --> 00:50:23,450
will I don't I don't see any reason why
 

2109
00:50:23,450 --> 00:50:26,410
will I don't I don't see any reason why
we need anything else but so so in that

2110
00:50:26,410 --> 00:50:26,420
we need anything else but so so in that
 

2111
00:50:26,420 --> 00:50:28,690
we need anything else but so so in that
sense we have invented the hardware we

2112
00:50:28,690 --> 00:50:28,700
sense we have invented the hardware we
 

2113
00:50:28,700 --> 00:50:30,550
sense we have invented the hardware we
need but we just need to make it faster

2114
00:50:30,550 --> 00:50:30,560
need but we just need to make it faster
 

2115
00:50:30,560 --> 00:50:33,370
need but we just need to make it faster
and bigger and we need to figure out the

2116
00:50:33,370 --> 00:50:33,380
and bigger and we need to figure out the
 

2117
00:50:33,380 --> 00:50:37,390
and bigger and we need to figure out the
right algorithms and and the right sort

2118
00:50:37,390 --> 00:50:37,400
right algorithms and and the right sort
 

2119
00:50:37,400 --> 00:50:41,800
right algorithms and and the right sort
of architecture touring that's a very

2120
00:50:41,800 --> 00:50:41,810
of architecture touring that's a very
 

2121
00:50:41,810 --> 00:50:43,720
of architecture touring that's a very
mathematical notion when we try to have

2122
00:50:43,720 --> 00:50:43,730
mathematical notion when we try to have
 

2123
00:50:43,730 --> 00:50:45,730
mathematical notion when we try to have
to build intelligence it's not an

2124
00:50:45,730 --> 00:50:45,740
to build intelligence it's not an
 

2125
00:50:45,740 --> 00:50:47,349
to build intelligence it's not an
engineering notion where you throw all

2126
00:50:47,349 --> 00:50:47,359
engineering notion where you throw all
 

2127
00:50:47,359 --> 00:50:48,420
engineering notion where you throw all
that stuff

2128
00:50:48,420 --> 00:50:48,430
that stuff
 

2129
00:50:48,430 --> 00:50:50,490
that stuff
I guess I guess it is a it is a question

2130
00:50:50,490 --> 00:50:50,500
I guess I guess it is a it is a question
 

2131
00:50:50,500 --> 00:50:54,240
I guess I guess it is a it is a question
that their people have brought up this

2132
00:50:54,240 --> 00:50:54,250
that their people have brought up this
 

2133
00:50:54,250 --> 00:50:56,940
that their people have brought up this
question you know and when you asked

2134
00:50:56,940 --> 00:50:56,950
question you know and when you asked
 

2135
00:50:56,950 --> 00:51:00,930
question you know and when you asked
about like is our current Hardware will

2136
00:51:00,930 --> 00:51:00,940
about like is our current Hardware will
 

2137
00:51:00,940 --> 00:51:04,290
about like is our current Hardware will
our current Hardware work well turing

2138
00:51:04,290 --> 00:51:04,300
our current Hardware work well turing
 

2139
00:51:04,300 --> 00:51:06,150
our current Hardware work well turing
computation says that like our current

2140
00:51:06,150 --> 00:51:06,160
computation says that like our current
 

2141
00:51:06,160 --> 00:51:11,340
computation says that like our current
hardware is in principle a Turing

2142
00:51:11,340 --> 00:51:11,350
hardware is in principle a Turing
 

2143
00:51:11,350 --> 00:51:14,640
hardware is in principle a Turing
machine right so all we have to do is

2144
00:51:14,640 --> 00:51:14,650
machine right so all we have to do is
 

2145
00:51:14,650 --> 00:51:17,100
machine right so all we have to do is
make it faster and bigger but there have

2146
00:51:17,100 --> 00:51:17,110
make it faster and bigger but there have
 

2147
00:51:17,110 --> 00:51:20,430
make it faster and bigger but there have
been people like Roger Penrose if you

2148
00:51:20,430 --> 00:51:20,440
been people like Roger Penrose if you
 

2149
00:51:20,440 --> 00:51:22,920
been people like Roger Penrose if you
might remember that he said Turing

2150
00:51:22,920 --> 00:51:22,930
might remember that he said Turing
 

2151
00:51:22,930 --> 00:51:25,820
might remember that he said Turing
machines cannot produce intelligence

2152
00:51:25,820 --> 00:51:25,830
machines cannot produce intelligence
 

2153
00:51:25,830 --> 00:51:29,520
machines cannot produce intelligence
because intelligence requires continuous

2154
00:51:29,520 --> 00:51:29,530
because intelligence requires continuous
 

2155
00:51:29,530 --> 00:51:31,140
because intelligence requires continuous
valued numbers I mean that was sort of

2156
00:51:31,140 --> 00:51:31,150
valued numbers I mean that was sort of
 

2157
00:51:31,150 --> 00:51:35,400
valued numbers I mean that was sort of
my reading of his argument and quantum

2158
00:51:35,400 --> 00:51:35,410
my reading of his argument and quantum
 

2159
00:51:35,410 --> 00:51:38,010
my reading of his argument and quantum
mechanics and what else whatever you

2160
00:51:38,010 --> 00:51:38,020
mechanics and what else whatever you
 

2161
00:51:38,020 --> 00:51:40,890
mechanics and what else whatever you
know but I don't see any evidence for

2162
00:51:40,890 --> 00:51:40,900
know but I don't see any evidence for
 

2163
00:51:40,900 --> 00:51:45,630
know but I don't see any evidence for
that that we need new computation

2164
00:51:45,630 --> 00:51:45,640
that that we need new computation
 

2165
00:51:45,640 --> 00:51:50,280
that that we need new computation
paradigms but I don't know if we're you

2166
00:51:50,280 --> 00:51:50,290
paradigms but I don't know if we're you
 

2167
00:51:50,290 --> 00:51:51,300
paradigms but I don't know if we're you
know I don't think we're going to be

2168
00:51:51,300 --> 00:51:51,310
know I don't think we're going to be
 

2169
00:51:51,310 --> 00:51:55,410
know I don't think we're going to be
able to scale up our current approaches

2170
00:51:55,410 --> 00:51:55,420
able to scale up our current approaches
 

2171
00:51:55,420 --> 00:51:59,010
able to scale up our current approaches
to programming these computers what is

2172
00:51:59,010 --> 00:51:59,020
to programming these computers what is
 

2173
00:51:59,020 --> 00:52:00,630
to programming these computers what is
your hope for approaches like copycat or

2174
00:52:00,630 --> 00:52:00,640
your hope for approaches like copycat or
 

2175
00:52:00,640 --> 00:52:02,760
your hope for approaches like copycat or
other cognitive architectures I've

2176
00:52:02,760 --> 00:52:02,770
other cognitive architectures I've
 

2177
00:52:02,770 --> 00:52:04,170
other cognitive architectures I've
talked to the creator of sore for

2178
00:52:04,170 --> 00:52:04,180
talked to the creator of sore for
 

2179
00:52:04,180 --> 00:52:06,060
talked to the creator of sore for
example I've used that arm myself I

2180
00:52:06,060 --> 00:52:06,070
example I've used that arm myself I
 

2181
00:52:06,070 --> 00:52:07,700
example I've used that arm myself I
don't know if you're familiar with yeah

2182
00:52:07,700 --> 00:52:07,710
don't know if you're familiar with yeah
 

2183
00:52:07,710 --> 00:52:10,590
don't know if you're familiar with yeah
woody what do you think is what's your

2184
00:52:10,590 --> 00:52:10,600
woody what do you think is what's your
 

2185
00:52:10,600 --> 00:52:12,600
woody what do you think is what's your
hope of approaches like that in helping

2186
00:52:12,600 --> 00:52:12,610
hope of approaches like that in helping
 

2187
00:52:12,610 --> 00:52:16,080
hope of approaches like that in helping
develop systems of greater and greater

2188
00:52:16,080 --> 00:52:16,090
develop systems of greater and greater
 

2189
00:52:16,090 --> 00:52:20,100
develop systems of greater and greater
intelligence in the coming decades well

2190
00:52:20,100 --> 00:52:20,110
intelligence in the coming decades well
 

2191
00:52:20,110 --> 00:52:22,740
intelligence in the coming decades well
that's what I'm working on now is trying

2192
00:52:22,740 --> 00:52:22,750
that's what I'm working on now is trying
 

2193
00:52:22,750 --> 00:52:24,710
that's what I'm working on now is trying
to take some of those ideas and

2194
00:52:24,710 --> 00:52:24,720
to take some of those ideas and
 

2195
00:52:24,720 --> 00:52:28,590
to take some of those ideas and
extending it so I think there are some

2196
00:52:28,590 --> 00:52:28,600
extending it so I think there are some
 

2197
00:52:28,600 --> 00:52:30,270
extending it so I think there are some
really promising approaches that are

2198
00:52:30,270 --> 00:52:30,280
really promising approaches that are
 

2199
00:52:30,280 --> 00:52:34,880
really promising approaches that are
going on now that have to do with more

2200
00:52:34,880 --> 00:52:34,890
going on now that have to do with more
 

2201
00:52:34,890 --> 00:52:40,260
going on now that have to do with more
active generative models so this is the

2202
00:52:40,260 --> 00:52:40,270
active generative models so this is the
 

2203
00:52:40,270 --> 00:52:42,630
active generative models so this is the
idea of this simulation in your head a

2204
00:52:42,630 --> 00:52:42,640
idea of this simulation in your head a
 

2205
00:52:42,640 --> 00:52:46,350
idea of this simulation in your head a
concept when you if you want to when

2206
00:52:46,350 --> 00:52:46,360
concept when you if you want to when
 

2207
00:52:46,360 --> 00:52:48,920
concept when you if you want to when
you're perceiving a new a new situation

2208
00:52:48,920 --> 00:52:48,930
you're perceiving a new a new situation
 

2209
00:52:48,930 --> 00:52:51,210
you're perceiving a new a new situation
you have some simulations in your head

2210
00:52:51,210 --> 00:52:51,220
you have some simulations in your head
 

2211
00:52:51,220 --> 00:52:52,590
you have some simulations in your head
those are generative models they're

2212
00:52:52,590 --> 00:52:52,600
those are generative models they're
 

2213
00:52:52,600 --> 00:52:54,660
those are generative models they're
generating your expectations they're

2214
00:52:54,660 --> 00:52:54,670
generating your expectations they're
 

2215
00:52:54,670 --> 00:52:56,490
generating your expectations they're
generating predictions that's part of a

2216
00:52:56,490 --> 00:52:56,500
generating predictions that's part of a
 

2217
00:52:56,500 --> 00:52:58,830
generating predictions that's part of a
perception you haven't met the model

2218
00:52:58,830 --> 00:52:58,840
perception you haven't met the model
 

2219
00:52:58,840 --> 00:53:00,840
perception you haven't met the model
that generates a prediction then you

2220
00:53:00,840 --> 00:53:00,850
that generates a prediction then you
 

2221
00:53:00,850 --> 00:53:01,170
that generates a prediction then you
come

2222
00:53:01,170 --> 00:53:01,180
come
 

2223
00:53:01,180 --> 00:53:03,510
come
parrot with ya and then the difference

2224
00:53:03,510 --> 00:53:03,520
parrot with ya and then the difference
 

2225
00:53:03,520 --> 00:53:06,480
parrot with ya and then the difference
and you also that that generative model

2226
00:53:06,480 --> 00:53:06,490
and you also that that generative model
 

2227
00:53:06,490 --> 00:53:08,819
and you also that that generative model
is telling you where to look and what to

2228
00:53:08,819 --> 00:53:08,829
is telling you where to look and what to
 

2229
00:53:08,829 --> 00:53:11,240
is telling you where to look and what to
look at and what to pay attention to and

2230
00:53:11,240 --> 00:53:11,250
look at and what to pay attention to and
 

2231
00:53:11,250 --> 00:53:13,829
look at and what to pay attention to and
it I think it affects your perception

2232
00:53:13,829 --> 00:53:13,839
it I think it affects your perception
 

2233
00:53:13,839 --> 00:53:15,540
it I think it affects your perception
it's not that just you compare it with

2234
00:53:15,540 --> 00:53:15,550
it's not that just you compare it with
 

2235
00:53:15,550 --> 00:53:20,430
it's not that just you compare it with
your perception it it becomes your

2236
00:53:20,430 --> 00:53:20,440
your perception it it becomes your
 

2237
00:53:20,440 --> 00:53:23,700
your perception it it becomes your
perception in a way it is kind of a

2238
00:53:23,700 --> 00:53:23,710
perception in a way it is kind of a
 

2239
00:53:23,710 --> 00:53:28,230
perception in a way it is kind of a
mixture of that bottom-up information

2240
00:53:28,230 --> 00:53:28,240
mixture of that bottom-up information
 

2241
00:53:28,240 --> 00:53:30,319
mixture of that bottom-up information
coming from the world and your top-down

2242
00:53:30,319 --> 00:53:30,329
coming from the world and your top-down
 

2243
00:53:30,329 --> 00:53:34,079
coming from the world and your top-down
model being opposed in the world is what

2244
00:53:34,079 --> 00:53:34,089
model being opposed in the world is what
 

2245
00:53:34,089 --> 00:53:36,750
model being opposed in the world is what
becomes your perception so your hope is

2246
00:53:36,750 --> 00:53:36,760
becomes your perception so your hope is
 

2247
00:53:36,760 --> 00:53:38,089
becomes your perception so your hope is
something like that can improve

2248
00:53:38,089 --> 00:53:38,099
something like that can improve
 

2249
00:53:38,099 --> 00:53:40,109
something like that can improve
perception systems and that they can

2250
00:53:40,109 --> 00:53:40,119
perception systems and that they can
 

2251
00:53:40,119 --> 00:53:42,420
perception systems and that they can
understand things better yes understand

2252
00:53:42,420 --> 00:53:42,430
understand things better yes understand
 

2253
00:53:42,430 --> 00:53:46,620
understand things better yes understand
things yes what's the what's the step

2254
00:53:46,620 --> 00:53:46,630
things yes what's the what's the step
 

2255
00:53:46,630 --> 00:53:49,650
things yes what's the what's the step
was the analogy making step there well

2256
00:53:49,650 --> 00:53:49,660
was the analogy making step there well
 

2257
00:53:49,660 --> 00:53:52,559
was the analogy making step there well
there the the the idea is that you have

2258
00:53:52,559 --> 00:53:52,569
there the the the idea is that you have
 

2259
00:53:52,569 --> 00:53:55,950
there the the the idea is that you have
this pretty complicated conceptual space

2260
00:53:55,950 --> 00:53:55,960
this pretty complicated conceptual space
 

2261
00:53:55,960 --> 00:53:58,440
this pretty complicated conceptual space
you know you can talk about a semantic

2262
00:53:58,440 --> 00:53:58,450
you know you can talk about a semantic
 

2263
00:53:58,450 --> 00:53:59,730
you know you can talk about a semantic
network or something like that

2264
00:53:59,730 --> 00:53:59,740
network or something like that
 

2265
00:53:59,740 --> 00:54:03,180
network or something like that
with these different kinds of concept

2266
00:54:03,180 --> 00:54:03,190
with these different kinds of concept
 

2267
00:54:03,190 --> 00:54:06,450
with these different kinds of concept
models in your brain that are connected

2268
00:54:06,450 --> 00:54:06,460
models in your brain that are connected
 

2269
00:54:06,460 --> 00:54:09,569
models in your brain that are connected
so so let's let's take the example of

2270
00:54:09,569 --> 00:54:09,579
so so let's let's take the example of
 

2271
00:54:09,579 --> 00:54:11,819
so so let's let's take the example of
walking a dog we were talking about that

2272
00:54:11,819 --> 00:54:11,829
walking a dog we were talking about that
 

2273
00:54:11,829 --> 00:54:14,789
walking a dog we were talking about that
okay let's see I say see someone out on

2274
00:54:14,789 --> 00:54:14,799
okay let's see I say see someone out on
 

2275
00:54:14,799 --> 00:54:17,010
okay let's see I say see someone out on
the street walking a cat some people

2276
00:54:17,010 --> 00:54:17,020
the street walking a cat some people
 

2277
00:54:17,020 --> 00:54:18,809
the street walking a cat some people
walk their cats I guess this seems like

2278
00:54:18,809 --> 00:54:18,819
walk their cats I guess this seems like
 

2279
00:54:18,819 --> 00:54:22,950
walk their cats I guess this seems like
a bad idea but yeah so my model of my

2280
00:54:22,950 --> 00:54:22,960
a bad idea but yeah so my model of my
 

2281
00:54:22,960 --> 00:54:25,220
a bad idea but yeah so my model of my
you know there's connections between my

2282
00:54:25,220 --> 00:54:25,230
you know there's connections between my
 

2283
00:54:25,230 --> 00:54:29,460
you know there's connections between my
model of a dog and model of a cat and I

2284
00:54:29,460 --> 00:54:29,470
model of a dog and model of a cat and I
 

2285
00:54:29,470 --> 00:54:35,640
model of a dog and model of a cat and I
can immediately see the analogy of that

2286
00:54:35,640 --> 00:54:35,650
can immediately see the analogy of that
 

2287
00:54:35,650 --> 00:54:39,569
can immediately see the analogy of that
those are analogous situations but I can

2288
00:54:39,569 --> 00:54:39,579
those are analogous situations but I can
 

2289
00:54:39,579 --> 00:54:41,579
those are analogous situations but I can
also see the differences and that tells

2290
00:54:41,579 --> 00:54:41,589
also see the differences and that tells
 

2291
00:54:41,589 --> 00:54:47,039
also see the differences and that tells
me what to expect so also you know I

2292
00:54:47,039 --> 00:54:47,049
me what to expect so also you know I
 

2293
00:54:47,049 --> 00:54:49,470
me what to expect so also you know I
have a new situation so another example

2294
00:54:49,470 --> 00:54:49,480
have a new situation so another example
 

2295
00:54:49,480 --> 00:54:51,440
have a new situation so another example
with the walking the dog thing is

2296
00:54:51,440 --> 00:54:51,450
with the walking the dog thing is
 

2297
00:54:51,450 --> 00:54:53,789
with the walking the dog thing is
sometimes people I see people riding

2298
00:54:53,789 --> 00:54:53,799
sometimes people I see people riding
 

2299
00:54:53,799 --> 00:54:55,559
sometimes people I see people riding
their bikes with Elise holding a leash

2300
00:54:55,559 --> 00:54:55,569
their bikes with Elise holding a leash
 

2301
00:54:55,569 --> 00:54:58,109
their bikes with Elise holding a leash
and the dogs running alongside okay so I

2302
00:54:58,109 --> 00:54:58,119
and the dogs running alongside okay so I
 

2303
00:54:58,119 --> 00:55:01,319
and the dogs running alongside okay so I
know that the I recognize that as kind

2304
00:55:01,319 --> 00:55:01,329
know that the I recognize that as kind
 

2305
00:55:01,329 --> 00:55:04,230
know that the I recognize that as kind
of a dog walking situation even though

2306
00:55:04,230 --> 00:55:04,240
of a dog walking situation even though
 

2307
00:55:04,240 --> 00:55:06,930
of a dog walking situation even though
the person's not walking right and the

2308
00:55:06,930 --> 00:55:06,940
the person's not walking right and the
 

2309
00:55:06,940 --> 00:55:10,620
the person's not walking right and the
dogs not walking because I I have the

2310
00:55:10,620 --> 00:55:10,630
dogs not walking because I I have the
 

2311
00:55:10,630 --> 00:55:13,430
dogs not walking because I I have the
these these models that say okay

2312
00:55:13,430 --> 00:55:13,440
these these models that say okay
 

2313
00:55:13,440 --> 00:55:15,059
these these models that say okay
riding a bike

2314
00:55:15,059 --> 00:55:15,069
riding a bike
 

2315
00:55:15,069 --> 00:55:16,739
riding a bike
is sort of similar to walking or it's

2316
00:55:16,739 --> 00:55:16,749
is sort of similar to walking or it's
 

2317
00:55:16,749 --> 00:55:19,249
is sort of similar to walking or it's
connected it's a means of transportation

2318
00:55:19,249 --> 00:55:19,259
connected it's a means of transportation
 

2319
00:55:19,259 --> 00:55:22,559
connected it's a means of transportation
but I because they have their dog there

2320
00:55:22,559 --> 00:55:22,569
but I because they have their dog there
 

2321
00:55:22,569 --> 00:55:24,479
but I because they have their dog there
I assume they're not going to work but

2322
00:55:24,479 --> 00:55:24,489
I assume they're not going to work but
 

2323
00:55:24,489 --> 00:55:26,519
I assume they're not going to work but
they're going out for exercise and you

2324
00:55:26,519 --> 00:55:26,529
they're going out for exercise and you
 

2325
00:55:26,529 --> 00:55:29,819
they're going out for exercise and you
know these analogies help me to figure

2326
00:55:29,819 --> 00:55:29,829
know these analogies help me to figure
 

2327
00:55:29,829 --> 00:55:31,529
know these analogies help me to figure
out kind of what's going on what's

2328
00:55:31,529 --> 00:55:31,539
out kind of what's going on what's
 

2329
00:55:31,539 --> 00:55:34,410
out kind of what's going on what's
likely but sort of these analogies are

2330
00:55:34,410 --> 00:55:34,420
likely but sort of these analogies are
 

2331
00:55:34,420 --> 00:55:37,380
likely but sort of these analogies are
very human interpreter Bowl mm-hmm so

2332
00:55:37,380 --> 00:55:37,390
very human interpreter Bowl mm-hmm so
 

2333
00:55:37,390 --> 00:55:39,509
very human interpreter Bowl mm-hmm so
that's that kind of space and then you

2334
00:55:39,509 --> 00:55:39,519
that's that kind of space and then you
 

2335
00:55:39,519 --> 00:55:41,999
that's that kind of space and then you
look at something like the current deep

2336
00:55:41,999 --> 00:55:42,009
look at something like the current deep
 

2337
00:55:42,009 --> 00:55:43,979
look at something like the current deep
learning approaches they kind of help

2338
00:55:43,979 --> 00:55:43,989
learning approaches they kind of help
 

2339
00:55:43,989 --> 00:55:46,499
learning approaches they kind of help
you to take raw sensory information and

2340
00:55:46,499 --> 00:55:46,509
you to take raw sensory information and
 

2341
00:55:46,509 --> 00:55:48,660
you to take raw sensory information and
just to automatically build up

2342
00:55:48,660 --> 00:55:48,670
just to automatically build up
 

2343
00:55:48,670 --> 00:55:52,140
just to automatically build up
hierarchies of role you can even call

2344
00:55:52,140 --> 00:55:52,150
hierarchies of role you can even call
 

2345
00:55:52,150 --> 00:55:53,789
hierarchies of role you can even call
them concepts they're just not human

2346
00:55:53,789 --> 00:55:53,799
them concepts they're just not human
 

2347
00:55:53,799 --> 00:55:55,519
them concepts they're just not human
interpretive or concepts

2348
00:55:55,519 --> 00:55:55,529
interpretive or concepts
 

2349
00:55:55,529 --> 00:55:59,160
interpretive or concepts
what's your what's the link here do you

2350
00:55:59,160 --> 00:55:59,170
what's your what's the link here do you
 

2351
00:55:59,170 --> 00:56:04,650
what's your what's the link here do you
hope it's sort of the hybrid system

2352
00:56:04,650 --> 00:56:04,660
hope it's sort of the hybrid system
 

2353
00:56:04,660 --> 00:56:06,930
hope it's sort of the hybrid system
question how do you think that two can

2354
00:56:06,930 --> 00:56:06,940
question how do you think that two can
 

2355
00:56:06,940 --> 00:56:08,670
question how do you think that two can
start to meet each other what's the

2356
00:56:08,670 --> 00:56:08,680
start to meet each other what's the
 

2357
00:56:08,680 --> 00:56:12,779
start to meet each other what's the
value of learning in this systems of

2358
00:56:12,779 --> 00:56:12,789
value of learning in this systems of
 

2359
00:56:12,789 --> 00:56:16,859
value of learning in this systems of
forming of analogy making the the goal

2360
00:56:16,859 --> 00:56:16,869
forming of analogy making the the goal
 

2361
00:56:16,869 --> 00:56:19,709
forming of analogy making the the goal
of I you know the original goal of deep

2362
00:56:19,709 --> 00:56:19,719
of I you know the original goal of deep
 

2363
00:56:19,719 --> 00:56:22,469
of I you know the original goal of deep
learning in at least visual perception

2364
00:56:22,469 --> 00:56:22,479
learning in at least visual perception
 

2365
00:56:22,479 --> 00:56:25,259
learning in at least visual perception
was that you would get the system to

2366
00:56:25,259 --> 00:56:25,269
was that you would get the system to
 

2367
00:56:25,269 --> 00:56:28,620
was that you would get the system to
learn to extract features that at these

2368
00:56:28,620 --> 00:56:28,630
learn to extract features that at these
 

2369
00:56:28,630 --> 00:56:30,569
learn to extract features that at these
different levels of complexities may be

2370
00:56:30,569 --> 00:56:30,579
different levels of complexities may be
 

2371
00:56:30,579 --> 00:56:32,640
different levels of complexities may be
edge detection and that would lead into

2372
00:56:32,640 --> 00:56:32,650
edge detection and that would lead into
 

2373
00:56:32,650 --> 00:56:36,059
edge detection and that would lead into
learning you know simple combinations of

2374
00:56:36,059 --> 00:56:36,069
learning you know simple combinations of
 

2375
00:56:36,069 --> 00:56:38,219
learning you know simple combinations of
edges and then more complex shapes and

2376
00:56:38,219 --> 00:56:38,229
edges and then more complex shapes and
 

2377
00:56:38,229 --> 00:56:45,150
edges and then more complex shapes and
then whole objects or faces and this was

2378
00:56:45,150 --> 00:56:45,160
then whole objects or faces and this was
 

2379
00:56:45,160 --> 00:56:48,739
then whole objects or faces and this was
based on that the ideas of the

2380
00:56:48,739 --> 00:56:48,749
based on that the ideas of the
 

2381
00:56:48,749 --> 00:56:51,779
based on that the ideas of the
neuroscientists Hubel and Wiesel who had

2382
00:56:51,779 --> 00:56:51,789
neuroscientists Hubel and Wiesel who had
 

2383
00:56:51,789 --> 00:56:54,390
neuroscientists Hubel and Wiesel who had
seen laid out this kind of structure and

2384
00:56:54,390 --> 00:56:54,400
seen laid out this kind of structure and
 

2385
00:56:54,400 --> 00:57:00,599
seen laid out this kind of structure and
brain and I think that is that's right

2386
00:57:00,599 --> 00:57:00,609
brain and I think that is that's right
 

2387
00:57:00,609 --> 00:57:03,079
brain and I think that is that's right
to some extent of course people have

2388
00:57:03,079 --> 00:57:03,089
to some extent of course people have
 

2389
00:57:03,089 --> 00:57:05,939
to some extent of course people have
come found that the whole story is a

2390
00:57:05,939 --> 00:57:05,949
come found that the whole story is a
 

2391
00:57:05,949 --> 00:57:07,439
come found that the whole story is a
little more complex than that and the

2392
00:57:07,439 --> 00:57:07,449
little more complex than that and the
 

2393
00:57:07,449 --> 00:57:09,359
little more complex than that and the
brain of course always is and there's a

2394
00:57:09,359 --> 00:57:09,369
brain of course always is and there's a
 

2395
00:57:09,369 --> 00:57:15,880
brain of course always is and there's a
lot of feedback and so I see that

2396
00:57:15,880 --> 00:57:15,890

 

2397
00:57:15,890 --> 00:57:21,460

as absolutely a good brain inspired

2398
00:57:21,460 --> 00:57:21,470
as absolutely a good brain inspired
 

2399
00:57:21,470 --> 00:57:24,910
as absolutely a good brain inspired
approach to some aspects of perception

2400
00:57:24,910 --> 00:57:24,920
approach to some aspects of perception
 

2401
00:57:24,920 --> 00:57:28,930
approach to some aspects of perception
but one thing that it's lacking for

2402
00:57:28,930 --> 00:57:28,940
but one thing that it's lacking for
 

2403
00:57:28,940 --> 00:57:32,200
but one thing that it's lacking for
example is all of that feedback which is

2404
00:57:32,200 --> 00:57:32,210
example is all of that feedback which is
 

2405
00:57:32,210 --> 00:57:33,880
example is all of that feedback which is
extremely important the interactive

2406
00:57:33,880 --> 00:57:33,890
extremely important the interactive
 

2407
00:57:33,890 --> 00:57:37,299
extremely important the interactive
element do you mentioned the expectation

2408
00:57:37,299 --> 00:57:37,309
element do you mentioned the expectation
 

2409
00:57:37,309 --> 00:57:40,059
element do you mentioned the expectation
the sexual level go back and forth with

2410
00:57:40,059 --> 00:57:40,069
the sexual level go back and forth with
 

2411
00:57:40,069 --> 00:57:43,029
the sexual level go back and forth with
the the expectation the perception and

2412
00:57:43,029 --> 00:57:43,039
the the expectation the perception and
 

2413
00:57:43,039 --> 00:57:45,160
the the expectation the perception and
yes going back and forth so right so

2414
00:57:45,160 --> 00:57:45,170
yes going back and forth so right so
 

2415
00:57:45,170 --> 00:57:49,480
yes going back and forth so right so
that is extremely important and you know

2416
00:57:49,480 --> 00:57:49,490
that is extremely important and you know
 

2417
00:57:49,490 --> 00:57:52,180
that is extremely important and you know
one thing about deep neural networks is

2418
00:57:52,180 --> 00:57:52,190
one thing about deep neural networks is
 

2419
00:57:52,190 --> 00:57:55,299
one thing about deep neural networks is
that in a given situation like you know

2420
00:57:55,299 --> 00:57:55,309
that in a given situation like you know
 

2421
00:57:55,309 --> 00:57:56,859
that in a given situation like you know
they they're trained right they get

2422
00:57:56,859 --> 00:57:56,869
they they're trained right they get
 

2423
00:57:56,869 --> 00:57:58,870
they they're trained right they get
these weights everything but then now I

2424
00:57:58,870 --> 00:57:58,880
these weights everything but then now I
 

2425
00:57:58,880 --> 00:58:01,539
these weights everything but then now I
give them a new a new image let's say

2426
00:58:01,539 --> 00:58:01,549
give them a new a new image let's say
 

2427
00:58:01,549 --> 00:58:06,609
give them a new a new image let's say
yes they treat every part of the image

2428
00:58:06,609 --> 00:58:06,619
yes they treat every part of the image
 

2429
00:58:06,619 --> 00:58:10,630
yes they treat every part of the image
in the same way you know they apply the

2430
00:58:10,630 --> 00:58:10,640
in the same way you know they apply the
 

2431
00:58:10,640 --> 00:58:14,230
in the same way you know they apply the
same filters at each layer to all parts

2432
00:58:14,230 --> 00:58:14,240
same filters at each layer to all parts
 

2433
00:58:14,240 --> 00:58:16,750
same filters at each layer to all parts
of the image mm-hmm there's no feedback

2434
00:58:16,750 --> 00:58:16,760
of the image mm-hmm there's no feedback
 

2435
00:58:16,760 --> 00:58:18,970
of the image mm-hmm there's no feedback
to say like oh this part of the image is

2436
00:58:18,970 --> 00:58:18,980
to say like oh this part of the image is
 

2437
00:58:18,980 --> 00:58:21,519
to say like oh this part of the image is
irrelevant right I shouldn't care about

2438
00:58:21,519 --> 00:58:21,529
irrelevant right I shouldn't care about
 

2439
00:58:21,529 --> 00:58:24,190
irrelevant right I shouldn't care about
this part of the image or this part of

2440
00:58:24,190 --> 00:58:24,200
this part of the image or this part of
 

2441
00:58:24,200 --> 00:58:26,279
this part of the image or this part of
the image is the most important part and

2442
00:58:26,279 --> 00:58:26,289
the image is the most important part and
 

2443
00:58:26,289 --> 00:58:28,960
the image is the most important part and
that's kind of what we humans are able

2444
00:58:28,960 --> 00:58:28,970
that's kind of what we humans are able
 

2445
00:58:28,970 --> 00:58:32,049
that's kind of what we humans are able
to do because we have these conceptual

2446
00:58:32,049 --> 00:58:32,059
to do because we have these conceptual
 

2447
00:58:32,059 --> 00:58:35,049
to do because we have these conceptual
expectations there's a little bit work

2448
00:58:35,049 --> 00:58:35,059
expectations there's a little bit work
 

2449
00:58:35,059 --> 00:58:36,819
expectations there's a little bit work
in that there's certainly a lot more in

2450
00:58:36,819 --> 00:58:36,829
in that there's certainly a lot more in
 

2451
00:58:36,829 --> 00:58:39,519
in that there's certainly a lot more in
a tent what's under the called attention

2452
00:58:39,519 --> 00:58:39,529
a tent what's under the called attention
 

2453
00:58:39,529 --> 00:58:41,950
a tent what's under the called attention
in natural language processing knowledge

2454
00:58:41,950 --> 00:58:41,960
in natural language processing knowledge
 

2455
00:58:41,960 --> 00:58:45,970
in natural language processing knowledge
ease it's a that's exceptionally

2456
00:58:45,970 --> 00:58:45,980
ease it's a that's exceptionally
 

2457
00:58:45,980 --> 00:58:49,180
ease it's a that's exceptionally
powerful and it's a very just as you say

2458
00:58:49,180 --> 00:58:49,190
powerful and it's a very just as you say
 

2459
00:58:49,190 --> 00:58:51,490
powerful and it's a very just as you say
it's really powerful idea but again in

2460
00:58:51,490 --> 00:58:51,500
it's really powerful idea but again in
 

2461
00:58:51,500 --> 00:58:53,920
it's really powerful idea but again in
sort of machine learning it all kind of

2462
00:58:53,920 --> 00:58:53,930
sort of machine learning it all kind of
 

2463
00:58:53,930 --> 00:58:56,170
sort of machine learning it all kind of
operates in an automated way that's not

2464
00:58:56,170 --> 00:58:56,180
operates in an automated way that's not
 

2465
00:58:56,180 --> 00:58:58,059
operates in an automated way that's not
human it's not it's not also okay so

2466
00:58:58,059 --> 00:58:58,069
human it's not it's not also okay so
 

2467
00:58:58,069 --> 00:59:00,490
human it's not it's not also okay so
that yeah right it's not dynamic I mean

2468
00:59:00,490 --> 00:59:00,500
that yeah right it's not dynamic I mean
 

2469
00:59:00,500 --> 00:59:03,579
that yeah right it's not dynamic I mean
in the sense that as a perception of a

2470
00:59:03,579 --> 00:59:03,589
in the sense that as a perception of a
 

2471
00:59:03,589 --> 00:59:08,859
in the sense that as a perception of a
new example is being processed those

2472
00:59:08,859 --> 00:59:08,869
new example is being processed those
 

2473
00:59:08,869 --> 00:59:13,329
new example is being processed those
attentions weights don't change right so

2474
00:59:13,329 --> 00:59:13,339
attentions weights don't change right so
 

2475
00:59:13,339 --> 00:59:16,480
attentions weights don't change right so
I mean there's a this

2476
00:59:16,480 --> 00:59:16,490
I mean there's a this
 

2477
00:59:16,490 --> 00:59:19,470
I mean there's a this
kind of notion that there's not a memory

2478
00:59:19,470 --> 00:59:19,480
kind of notion that there's not a memory
 

2479
00:59:19,480 --> 00:59:23,380
kind of notion that there's not a memory
so you're not aggregating the idea of

2480
00:59:23,380 --> 00:59:23,390
so you're not aggregating the idea of
 

2481
00:59:23,390 --> 00:59:26,920
so you're not aggregating the idea of
the this mental model yes yeah he that

2482
00:59:26,920 --> 00:59:26,930
the this mental model yes yeah he that
 

2483
00:59:26,930 --> 00:59:28,750
the this mental model yes yeah he that
seems to be a fundamental idea there's

2484
00:59:28,750 --> 00:59:28,760
seems to be a fundamental idea there's
 

2485
00:59:28,760 --> 00:59:31,329
seems to be a fundamental idea there's
not a really powerful I mean there's

2486
00:59:31,329 --> 00:59:31,339
not a really powerful I mean there's
 

2487
00:59:31,339 --> 00:59:33,190
not a really powerful I mean there's
some stuff with memory but there's not a

2488
00:59:33,190 --> 00:59:33,200
some stuff with memory but there's not a
 

2489
00:59:33,200 --> 00:59:37,380
some stuff with memory but there's not a
powerful way to represent the world in

2490
00:59:37,380 --> 00:59:37,390
powerful way to represent the world in
 

2491
00:59:37,390 --> 00:59:42,310
powerful way to represent the world in
some sort of way that's deeper than and

2492
00:59:42,310 --> 00:59:42,320
some sort of way that's deeper than and
 

2493
00:59:42,320 --> 00:59:45,040
some sort of way that's deeper than and
it's it's so difficult because uh you

2494
00:59:45,040 --> 00:59:45,050
it's it's so difficult because uh you
 

2495
00:59:45,050 --> 00:59:46,870
it's it's so difficult because uh you
know neural networks do represent the

2496
00:59:46,870 --> 00:59:46,880
know neural networks do represent the
 

2497
00:59:46,880 --> 00:59:50,140
know neural networks do represent the
world they do have a mental model right

2498
00:59:50,140 --> 00:59:50,150
world they do have a mental model right
 

2499
00:59:50,150 --> 00:59:54,400
world they do have a mental model right
but it just seems to be shallow I like

2500
00:59:54,400 --> 00:59:54,410
but it just seems to be shallow I like
 

2501
00:59:54,410 --> 00:59:57,310
but it just seems to be shallow I like
it it's it's hard to it's it's hard to

2502
00:59:57,310 --> 00:59:57,320
it it's it's hard to it's it's hard to
 

2503
00:59:57,320 --> 00:59:59,640
it it's it's hard to it's it's hard to
criticize them at the fundamental level

2504
00:59:59,640 --> 00:59:59,650
criticize them at the fundamental level
 

2505
00:59:59,650 --> 01:00:04,030
criticize them at the fundamental level
to me at least it's easy to it's it's

2506
01:00:04,030 --> 01:00:04,040
to me at least it's easy to it's it's
 

2507
01:00:04,040 --> 01:00:06,070
to me at least it's easy to it's it's
easy to criticize and we'll look like

2508
01:00:06,070 --> 01:00:06,080
easy to criticize and we'll look like
 

2509
01:00:06,080 --> 01:00:08,620
easy to criticize and we'll look like
exactly you're saying mental models sort

2510
01:00:08,620 --> 01:00:08,630
exactly you're saying mental models sort
 

2511
01:00:08,630 --> 01:00:10,210
exactly you're saying mental models sort
of almost from a sec I'll put a

2512
01:00:10,210 --> 01:00:10,220
of almost from a sec I'll put a
 

2513
01:00:10,220 --> 01:00:13,480
of almost from a sec I'll put a
psychology head on say look these

2514
01:00:13,480 --> 01:00:13,490
psychology head on say look these
 

2515
01:00:13,490 --> 01:00:15,460
psychology head on say look these
networks are clearly not able to achieve

2516
01:00:15,460 --> 01:00:15,470
networks are clearly not able to achieve
 

2517
01:00:15,470 --> 01:00:17,530
networks are clearly not able to achieve
what we humans do with forming mental

2518
01:00:17,530 --> 01:00:17,540
what we humans do with forming mental
 

2519
01:00:17,540 --> 01:00:20,320
what we humans do with forming mental
models but analogy making so on but that

2520
01:00:20,320 --> 01:00:20,330
models but analogy making so on but that
 

2521
01:00:20,330 --> 01:00:21,609
models but analogy making so on but that
doesn't mean that they fundamentally

2522
01:00:21,609 --> 01:00:21,619
doesn't mean that they fundamentally
 

2523
01:00:21,619 --> 01:00:24,460
doesn't mean that they fundamentally
cannot do that like you can it's very

2524
01:00:24,460 --> 01:00:24,470
cannot do that like you can it's very
 

2525
01:00:24,470 --> 01:00:26,320
cannot do that like you can it's very
difficult to say that I mean I used to

2526
01:00:26,320 --> 01:00:26,330
difficult to say that I mean I used to
 

2527
01:00:26,330 --> 01:00:27,609
difficult to say that I mean I used to
me do you have a notion that the

2528
01:00:27,609 --> 01:00:27,619
me do you have a notion that the
 

2529
01:00:27,619 --> 01:00:30,040
me do you have a notion that the
learning approaches really I mean

2530
01:00:30,040 --> 01:00:30,050
learning approaches really I mean
 

2531
01:00:30,050 --> 01:00:32,770
learning approaches really I mean
they're going to not not only are they

2532
01:00:32,770 --> 01:00:32,780
they're going to not not only are they
 

2533
01:00:32,780 --> 01:00:36,520
they're going to not not only are they
limited today but they will forever be

2534
01:00:36,520 --> 01:00:36,530
limited today but they will forever be
 

2535
01:00:36,530 --> 01:00:40,180
limited today but they will forever be
limited in being able to construct such

2536
01:00:40,180 --> 01:00:40,190
limited in being able to construct such
 

2537
01:00:40,190 --> 01:00:45,339
limited in being able to construct such
mental models I think the idea of the

2538
01:00:45,339 --> 01:00:45,349
mental models I think the idea of the
 

2539
01:00:45,349 --> 01:00:49,780
mental models I think the idea of the
dynamic perception is key here the idea

2540
01:00:49,780 --> 01:00:49,790
dynamic perception is key here the idea
 

2541
01:00:49,790 --> 01:00:54,130
dynamic perception is key here the idea
that moving your eyes around and getting

2542
01:00:54,130 --> 01:00:54,140
that moving your eyes around and getting
 

2543
01:00:54,140 --> 01:00:58,630
that moving your eyes around and getting
feedback and that's something that you

2544
01:00:58,630 --> 01:00:58,640
feedback and that's something that you
 

2545
01:00:58,640 --> 01:01:00,190
feedback and that's something that you
know there's been some models like that

2546
01:01:00,190 --> 01:01:00,200
know there's been some models like that
 

2547
01:01:00,200 --> 01:01:01,390
know there's been some models like that
there's certainly recurrent neural

2548
01:01:01,390 --> 01:01:01,400
there's certainly recurrent neural
 

2549
01:01:01,400 --> 01:01:03,970
there's certainly recurrent neural
networks that operate over several time

2550
01:01:03,970 --> 01:01:03,980
networks that operate over several time
 

2551
01:01:03,980 --> 01:01:07,120
networks that operate over several time
steps and but the problem is that it

2552
01:01:07,120 --> 01:01:07,130
steps and but the problem is that it
 

2553
01:01:07,130 --> 01:01:12,640
steps and but the problem is that it
that the actual the recurrence is you

2554
01:01:12,640 --> 01:01:12,650
that the actual the recurrence is you
 

2555
01:01:12,650 --> 01:01:17,260
that the actual the recurrence is you
know basically the the feedback is to

2556
01:01:17,260 --> 01:01:17,270
know basically the the feedback is to
 

2557
01:01:17,270 --> 01:01:21,160
know basically the the feedback is to
the next time step is the entire hidden

2558
01:01:21,160 --> 01:01:21,170
the next time step is the entire hidden
 

2559
01:01:21,170 --> 01:01:26,600
the next time step is the entire hidden
state yes the network which which is it

2560
01:01:26,600 --> 01:01:26,610
state yes the network which which is it
 

2561
01:01:26,610 --> 01:01:29,360
state yes the network which which is it
that it that's that doesn't work very

2562
01:01:29,360 --> 01:01:29,370
that it that's that doesn't work very
 

2563
01:01:29,370 --> 01:01:31,160
that it that's that doesn't work very
well does he hit the the thing I'm

2564
01:01:31,160 --> 01:01:31,170
well does he hit the the thing I'm
 

2565
01:01:31,170 --> 01:01:34,700
well does he hit the the thing I'm
saying is mathematically speaking it has

2566
01:01:34,700 --> 01:01:34,710
saying is mathematically speaking it has
 

2567
01:01:34,710 --> 01:01:38,840
saying is mathematically speaking it has
the information in that recurrence to

2568
01:01:38,840 --> 01:01:38,850
the information in that recurrence to
 

2569
01:01:38,850 --> 01:01:40,730
the information in that recurrence to
capture everything it just doesn't seem

2570
01:01:40,730 --> 01:01:40,740
capture everything it just doesn't seem
 

2571
01:01:40,740 --> 01:01:44,510
capture everything it just doesn't seem
to work yeah so like my you know it's

2572
01:01:44,510 --> 01:01:44,520
to work yeah so like my you know it's
 

2573
01:01:44,520 --> 01:01:46,700
to work yeah so like my you know it's
like it's the same touring machine

2574
01:01:46,700 --> 01:01:46,710
like it's the same touring machine
 

2575
01:01:46,710 --> 01:01:48,550
like it's the same touring machine
question right

2576
01:01:48,550 --> 01:01:48,560
question right
 

2577
01:01:48,560 --> 01:01:53,780
question right
yeah maybe theoretically it computers

2578
01:01:53,780 --> 01:01:53,790
yeah maybe theoretically it computers
 

2579
01:01:53,790 --> 01:01:57,500
yeah maybe theoretically it computers
and anything that's throwing a universal

2580
01:01:57,500 --> 01:01:57,510
and anything that's throwing a universal
 

2581
01:01:57,510 --> 01:01:59,690
and anything that's throwing a universal
Turing machine can can be intelligent

2582
01:01:59,690 --> 01:01:59,700
Turing machine can can be intelligent
 

2583
01:01:59,700 --> 01:02:02,270
Turing machine can can be intelligent
but practically the architecture might

2584
01:02:02,270 --> 01:02:02,280
but practically the architecture might
 

2585
01:02:02,280 --> 01:02:04,790
but practically the architecture might
be very specific kind of architecture to

2586
01:02:04,790 --> 01:02:04,800
be very specific kind of architecture to
 

2587
01:02:04,800 --> 01:02:07,730
be very specific kind of architecture to
be able to create it so just I guess

2588
01:02:07,730 --> 01:02:07,740
be able to create it so just I guess
 

2589
01:02:07,740 --> 01:02:09,350
be able to create it so just I guess
it's sort of ask almost the same

2590
01:02:09,350 --> 01:02:09,360
it's sort of ask almost the same
 

2591
01:02:09,360 --> 01:02:12,920
it's sort of ask almost the same
question again is how big of a role do

2592
01:02:12,920 --> 01:02:12,930
question again is how big of a role do
 

2593
01:02:12,930 --> 01:02:15,770
question again is how big of a role do
you think deep learning needs will play

2594
01:02:15,770 --> 01:02:15,780
you think deep learning needs will play
 

2595
01:02:15,780 --> 01:02:20,230
you think deep learning needs will play
or needs to play in this in perception I

2596
01:02:20,230 --> 01:02:20,240
or needs to play in this in perception I
 

2597
01:02:20,240 --> 01:02:25,640
or needs to play in this in perception I
think deep learning as it's currently as

2598
01:02:25,640 --> 01:02:25,650
think deep learning as it's currently as
 

2599
01:02:25,650 --> 01:02:27,770
think deep learning as it's currently as
it currently exists you know will place

2600
01:02:27,770 --> 01:02:27,780
it currently exists you know will place
 

2601
01:02:27,780 --> 01:02:29,900
it currently exists you know will place
that kind of thing will play some role

2602
01:02:29,900 --> 01:02:29,910
that kind of thing will play some role
 

2603
01:02:29,910 --> 01:02:33,830
that kind of thing will play some role
and but I think that there's a lot more

2604
01:02:33,830 --> 01:02:33,840
and but I think that there's a lot more
 

2605
01:02:33,840 --> 01:02:37,370
and but I think that there's a lot more
going on in perception but who knows you

2606
01:02:37,370 --> 01:02:37,380
going on in perception but who knows you
 

2607
01:02:37,380 --> 01:02:38,930
going on in perception but who knows you
know that the definition of deep

2608
01:02:38,930 --> 01:02:38,940
know that the definition of deep
 

2609
01:02:38,940 --> 01:02:41,540
know that the definition of deep
learning I mean it this it's pretty

2610
01:02:41,540 --> 01:02:41,550
learning I mean it this it's pretty
 

2611
01:02:41,550 --> 01:02:43,730
learning I mean it this it's pretty
broad it's kind of an umbrella so what I

2612
01:02:43,730 --> 01:02:43,740
broad it's kind of an umbrella so what I
 

2613
01:02:43,740 --> 01:02:45,920
broad it's kind of an umbrella so what I
mean is purely sort of neural networks

2614
01:02:45,920 --> 01:02:45,930
mean is purely sort of neural networks
 

2615
01:02:45,930 --> 01:02:48,140
mean is purely sort of neural networks
yeah and a feed-forward neural networks

2616
01:02:48,140 --> 01:02:48,150
yeah and a feed-forward neural networks
 

2617
01:02:48,150 --> 01:02:50,600
yeah and a feed-forward neural networks
essentially or there could be recurrence

2618
01:02:50,600 --> 01:02:50,610
essentially or there could be recurrence
 

2619
01:02:50,610 --> 01:02:54,440
essentially or there could be recurrence
but yeah sometimes it feels like for us

2620
01:02:54,440 --> 01:02:54,450
but yeah sometimes it feels like for us
 

2621
01:02:54,450 --> 01:02:56,990
but yeah sometimes it feels like for us
I'll talk to Gary Marcus it feels like

2622
01:02:56,990 --> 01:02:57,000
I'll talk to Gary Marcus it feels like
 

2623
01:02:57,000 --> 01:02:59,270
I'll talk to Gary Marcus it feels like
the criticism of deep learning is kind

2624
01:02:59,270 --> 01:02:59,280
the criticism of deep learning is kind
 

2625
01:02:59,280 --> 01:03:02,780
the criticism of deep learning is kind
of like us birds criticizing airplanes

2626
01:03:02,780 --> 01:03:02,790
of like us birds criticizing airplanes
 

2627
01:03:02,790 --> 01:03:05,870
of like us birds criticizing airplanes
for not flying well or that they're not

2628
01:03:05,870 --> 01:03:05,880
for not flying well or that they're not
 

2629
01:03:05,880 --> 01:03:10,190
for not flying well or that they're not
really flying do you think deep learning

2630
01:03:10,190 --> 01:03:10,200
really flying do you think deep learning
 

2631
01:03:10,200 --> 01:03:12,380
really flying do you think deep learning
do you think it could go all the way

2632
01:03:12,380 --> 01:03:12,390
do you think it could go all the way
 

2633
01:03:12,390 --> 01:03:15,830
do you think it could go all the way
like you're looking things do you think

2634
01:03:15,830 --> 01:03:15,840
like you're looking things do you think
 

2635
01:03:15,840 --> 01:03:20,000
like you're looking things do you think
that yeah the brute force learning

2636
01:03:20,000 --> 01:03:20,010
that yeah the brute force learning
 

2637
01:03:20,010 --> 01:03:22,130
that yeah the brute force learning
approach can go all the way I don't

2638
01:03:22,130 --> 01:03:22,140
approach can go all the way I don't
 

2639
01:03:22,140 --> 01:03:24,950
approach can go all the way I don't
think so no I mean I think it's an open

2640
01:03:24,950 --> 01:03:24,960
think so no I mean I think it's an open
 

2641
01:03:24,960 --> 01:03:28,090
think so no I mean I think it's an open
question but I I tend to be on the

2642
01:03:28,090 --> 01:03:28,100
question but I I tend to be on the
 

2643
01:03:28,100 --> 01:03:31,070
question but I I tend to be on the
innate Ness side that there has that

2644
01:03:31,070 --> 01:03:31,080
innate Ness side that there has that
 

2645
01:03:31,080 --> 01:03:35,090
innate Ness side that there has that
there's some things that we've been

2646
01:03:35,090 --> 01:03:35,100
there's some things that we've been
 

2647
01:03:35,100 --> 01:03:40,310
there's some things that we've been
evolved to be able to learn and

2648
01:03:40,310 --> 01:03:40,320
evolved to be able to learn and
 

2649
01:03:40,320 --> 01:03:44,000
evolved to be able to learn and
that learning just can't happen without

2650
01:03:44,000 --> 01:03:44,010
that learning just can't happen without
 

2651
01:03:44,010 --> 01:03:47,420
that learning just can't happen without
them so so one example here's an example

2652
01:03:47,420 --> 01:03:47,430
them so so one example here's an example
 

2653
01:03:47,430 --> 01:03:48,860
them so so one example here's an example
I had in the book that that I think is

2654
01:03:48,860 --> 01:03:48,870
I had in the book that that I think is
 

2655
01:03:48,870 --> 01:03:51,020
I had in the book that that I think is
useful to me at least in thinking about

2656
01:03:51,020 --> 01:03:51,030
useful to me at least in thinking about
 

2657
01:03:51,030 --> 01:03:54,910
useful to me at least in thinking about
this so this has to do with the

2658
01:03:54,910 --> 01:03:54,920
this so this has to do with the
 

2659
01:03:54,920 --> 01:03:57,680
this so this has to do with the
deepmind's atari game playing program

2660
01:03:57,680 --> 01:03:57,690
deepmind's atari game playing program
 

2661
01:03:57,690 --> 01:04:01,910
deepmind's atari game playing program
okay and learned to play these Atari

2662
01:04:01,910 --> 01:04:01,920
okay and learned to play these Atari
 

2663
01:04:01,920 --> 01:04:05,360
okay and learned to play these Atari
video games just by getting input from

2664
01:04:05,360 --> 01:04:05,370
video games just by getting input from
 

2665
01:04:05,370 --> 01:04:10,190
video games just by getting input from
the pixels of the screen and it learned

2666
01:04:10,190 --> 01:04:10,200
the pixels of the screen and it learned
 

2667
01:04:10,200 --> 01:04:16,250
the pixels of the screen and it learned
to play the game break out thousand

2668
01:04:16,250 --> 01:04:16,260
to play the game break out thousand
 

2669
01:04:16,260 --> 01:04:18,440
to play the game break out thousand
percent better than humans okay that was

2670
01:04:18,440 --> 01:04:18,450
percent better than humans okay that was
 

2671
01:04:18,450 --> 01:04:20,420
percent better than humans okay that was
one of the results and it was great and

2672
01:04:20,420 --> 01:04:20,430
one of the results and it was great and
 

2673
01:04:20,430 --> 01:04:22,280
one of the results and it was great and
and it learned this thing where it

2674
01:04:22,280 --> 01:04:22,290
and it learned this thing where it
 

2675
01:04:22,290 --> 01:04:24,950
and it learned this thing where it
tunneled through the side of the the

2676
01:04:24,950 --> 01:04:24,960
tunneled through the side of the the
 

2677
01:04:24,960 --> 01:04:27,320
tunneled through the side of the the
bricks in the breakout game and the ball

2678
01:04:27,320 --> 01:04:27,330
bricks in the breakout game and the ball
 

2679
01:04:27,330 --> 01:04:28,850
bricks in the breakout game and the ball
could bounce off the ceiling and then

2680
01:04:28,850 --> 01:04:28,860
could bounce off the ceiling and then
 

2681
01:04:28,860 --> 01:04:34,100
could bounce off the ceiling and then
just wipe out bricks okay so there was a

2682
01:04:34,100 --> 01:04:34,110
just wipe out bricks okay so there was a
 

2683
01:04:34,110 --> 01:04:37,750
just wipe out bricks okay so there was a
group who did an experiment where they

2684
01:04:37,750 --> 01:04:37,760
group who did an experiment where they
 

2685
01:04:37,760 --> 01:04:40,490
group who did an experiment where they
took the paddle you know that you move

2686
01:04:40,490 --> 01:04:40,500
took the paddle you know that you move
 

2687
01:04:40,500 --> 01:04:42,950
took the paddle you know that you move
with the joystick and moved it up to

2688
01:04:42,950 --> 01:04:42,960
with the joystick and moved it up to
 

2689
01:04:42,960 --> 01:04:45,860
with the joystick and moved it up to
pixels or something like that and then

2690
01:04:45,860 --> 01:04:45,870
pixels or something like that and then
 

2691
01:04:45,870 --> 01:04:49,760
pixels or something like that and then
they they looked at a deep Q learning

2692
01:04:49,760 --> 01:04:49,770
they they looked at a deep Q learning
 

2693
01:04:49,770 --> 01:04:51,740
they they looked at a deep Q learning
system that had been trained on breakout

2694
01:04:51,740 --> 01:04:51,750
system that had been trained on breakout
 

2695
01:04:51,750 --> 01:04:53,630
system that had been trained on breakout
and said could it now transfer its

2696
01:04:53,630 --> 01:04:53,640
and said could it now transfer its
 

2697
01:04:53,640 --> 01:04:55,430
and said could it now transfer its
learning to this new version of the game

2698
01:04:55,430 --> 01:04:55,440
learning to this new version of the game
 

2699
01:04:55,440 --> 01:04:58,310
learning to this new version of the game
of course a human could but and it

2700
01:04:58,310 --> 01:04:58,320
of course a human could but and it
 

2701
01:04:58,320 --> 01:05:00,650
of course a human could but and it
couldn't maybe that's not surprising but

2702
01:05:00,650 --> 01:05:00,660
couldn't maybe that's not surprising but
 

2703
01:05:00,660 --> 01:05:02,240
couldn't maybe that's not surprising but
I guess the point is it hadn't learned

2704
01:05:02,240 --> 01:05:02,250
I guess the point is it hadn't learned
 

2705
01:05:02,250 --> 01:05:05,510
I guess the point is it hadn't learned
the concept of a paddle it hadn't

2706
01:05:05,510 --> 01:05:05,520
the concept of a paddle it hadn't
 

2707
01:05:05,520 --> 01:05:07,010
the concept of a paddle it hadn't
learned that it hadn't learned the

2708
01:05:07,010 --> 01:05:07,020
learned that it hadn't learned the
 

2709
01:05:07,020 --> 01:05:08,870
learned that it hadn't learned the
concept of a ball or the concept of

2710
01:05:08,870 --> 01:05:08,880
concept of a ball or the concept of
 

2711
01:05:08,880 --> 01:05:11,060
concept of a ball or the concept of
tunneling it was learning something you

2712
01:05:11,060 --> 01:05:11,070
tunneling it was learning something you
 

2713
01:05:11,070 --> 01:05:14,800
tunneling it was learning something you
know we caught we looking at it kind of

2714
01:05:14,800 --> 01:05:14,810
know we caught we looking at it kind of
 

2715
01:05:14,810 --> 01:05:17,090
know we caught we looking at it kind of
anthropomorphised it and said oh it

2716
01:05:17,090 --> 01:05:17,100
anthropomorphised it and said oh it
 

2717
01:05:17,100 --> 01:05:18,620
anthropomorphised it and said oh it
here's what it's doing and the way we

2718
01:05:18,620 --> 01:05:18,630
here's what it's doing and the way we
 

2719
01:05:18,630 --> 01:05:20,420
here's what it's doing and the way we
describe it but it actually didn't learn

2720
01:05:20,420 --> 01:05:20,430
describe it but it actually didn't learn
 

2721
01:05:20,430 --> 01:05:22,700
describe it but it actually didn't learn
those concepts and so because it didn't

2722
01:05:22,700 --> 01:05:22,710
those concepts and so because it didn't
 

2723
01:05:22,710 --> 01:05:25,070
those concepts and so because it didn't
learn those concepts it couldn't make

2724
01:05:25,070 --> 01:05:25,080
learn those concepts it couldn't make
 

2725
01:05:25,080 --> 01:05:28,430
learn those concepts it couldn't make
this transfer yes so that's a beautiful

2726
01:05:28,430 --> 01:05:28,440
this transfer yes so that's a beautiful
 

2727
01:05:28,440 --> 01:05:30,470
this transfer yes so that's a beautiful
statement but at the same time by moving

2728
01:05:30,470 --> 01:05:30,480
statement but at the same time by moving
 

2729
01:05:30,480 --> 01:05:33,110
statement but at the same time by moving
the paddle we also anthropomorphize

2730
01:05:33,110 --> 01:05:33,120
the paddle we also anthropomorphize
 

2731
01:05:33,120 --> 01:05:36,590
the paddle we also anthropomorphize
flaws to inject into the system that

2732
01:05:36,590 --> 01:05:36,600
flaws to inject into the system that
 

2733
01:05:36,600 --> 01:05:38,900
flaws to inject into the system that
will then flip out how impressed we are

2734
01:05:38,900 --> 01:05:38,910
will then flip out how impressed we are
 

2735
01:05:38,910 --> 01:05:42,590
will then flip out how impressed we are
by it what I mean by that is to me the

2736
01:05:42,590 --> 01:05:42,600
by it what I mean by that is to me the
 

2737
01:05:42,600 --> 01:05:46,430
by it what I mean by that is to me the
Atari games were to me deeply impressive

2738
01:05:46,430 --> 01:05:46,440
Atari games were to me deeply impressive
 

2739
01:05:46,440 --> 01:05:49,430
Atari games were to me deeply impressive
that that was possible at all so that

2740
01:05:49,430 --> 01:05:49,440
that that was possible at all so that
 

2741
01:05:49,440 --> 01:05:51,110
that that was possible at all so that
guy first pause on that and people

2742
01:05:51,110 --> 01:05:51,120
guy first pause on that and people
 

2743
01:05:51,120 --> 01:05:52,490
guy first pause on that and people
should look at that just like the game

2744
01:05:52,490 --> 01:05:52,500
should look at that just like the game
 

2745
01:05:52,500 --> 01:05:53,750
should look at that just like the game
of Go

2746
01:05:53,750 --> 01:05:53,760
of Go
 

2747
01:05:53,760 --> 01:05:55,670
of Go
which is fundamentally different to me

2748
01:05:55,670 --> 01:05:55,680
which is fundamentally different to me
 

2749
01:05:55,680 --> 01:05:59,960
which is fundamentally different to me
then then what deep blue did even though

2750
01:05:59,960 --> 01:05:59,970
then then what deep blue did even though
 

2751
01:05:59,970 --> 01:06:02,330
then then what deep blue did even though
there's still mighty calls distillate

2752
01:06:02,330 --> 01:06:02,340
there's still mighty calls distillate
 

2753
01:06:02,340 --> 01:06:06,500
there's still mighty calls distillate
research it's just everything in deep

2754
01:06:06,500 --> 01:06:06,510
research it's just everything in deep
 

2755
01:06:06,510 --> 01:06:08,290
research it's just everything in deep
mind is done in terms of learning

2756
01:06:08,290 --> 01:06:08,300
mind is done in terms of learning
 

2757
01:06:08,300 --> 01:06:11,150
mind is done in terms of learning
however limited it is still deeply

2758
01:06:11,150 --> 01:06:11,160
however limited it is still deeply
 

2759
01:06:11,160 --> 01:06:13,190
however limited it is still deeply
surprising to me yeah i i'm not i'm not

2760
01:06:13,190 --> 01:06:13,200
surprising to me yeah i i'm not i'm not
 

2761
01:06:13,200 --> 01:06:15,980
surprising to me yeah i i'm not i'm not
trying to say that what they did wasn't

2762
01:06:15,980 --> 01:06:15,990
trying to say that what they did wasn't
 

2763
01:06:15,990 --> 01:06:17,360
trying to say that what they did wasn't
impressive i think it was incredibly

2764
01:06:17,360 --> 01:06:17,370
impressive i think it was incredibly
 

2765
01:06:17,370 --> 01:06:19,720
impressive i think it was incredibly
impressive to me is interesting is

2766
01:06:19,720 --> 01:06:19,730
impressive to me is interesting is
 

2767
01:06:19,730 --> 01:06:23,090
impressive to me is interesting is
moving the path aboard just another love

2768
01:06:23,090 --> 01:06:23,100
moving the path aboard just another love
 

2769
01:06:23,100 --> 01:06:24,920
moving the path aboard just another love
another thing that needs to be learned

2770
01:06:24,920 --> 01:06:24,930
another thing that needs to be learned
 

2771
01:06:24,930 --> 01:06:27,830
another thing that needs to be learned
so like we've been able to maybe maybe

2772
01:06:27,830 --> 01:06:27,840
so like we've been able to maybe maybe
 

2773
01:06:27,840 --> 01:06:29,720
so like we've been able to maybe maybe
been able to through the current neural

2774
01:06:29,720 --> 01:06:29,730
been able to through the current neural
 

2775
01:06:29,730 --> 01:06:31,970
been able to through the current neural
networks learn very basic concepts that

2776
01:06:31,970 --> 01:06:31,980
networks learn very basic concepts that
 

2777
01:06:31,980 --> 01:06:33,740
networks learn very basic concepts that
are not enough to do this general

2778
01:06:33,740 --> 01:06:33,750
are not enough to do this general
 

2779
01:06:33,750 --> 01:06:37,700
are not enough to do this general
reasoning and it may be with more data i

2780
01:06:37,700 --> 01:06:37,710
reasoning and it may be with more data i
 

2781
01:06:37,710 --> 01:06:40,280
reasoning and it may be with more data i
mean the data that you know the

2782
01:06:40,280 --> 01:06:40,290
mean the data that you know the
 

2783
01:06:40,290 --> 01:06:42,290
mean the data that you know the
interesting thing about the examples

2784
01:06:42,290 --> 01:06:42,300
interesting thing about the examples
 

2785
01:06:42,300 --> 01:06:45,110
interesting thing about the examples
that you talk about and beautifully is

2786
01:06:45,110 --> 01:06:45,120
that you talk about and beautifully is
 

2787
01:06:45,120 --> 01:06:49,130
that you talk about and beautifully is
they it's often flaws of the data well

2788
01:06:49,130 --> 01:06:49,140
they it's often flaws of the data well
 

2789
01:06:49,140 --> 01:06:50,750
they it's often flaws of the data well
that's the question i mean i i think

2790
01:06:50,750 --> 01:06:50,760
that's the question i mean i i think
 

2791
01:06:50,760 --> 01:06:52,550
that's the question i mean i i think
that is the key question it whether it's

2792
01:06:52,550 --> 01:06:52,560
that is the key question it whether it's
 

2793
01:06:52,560 --> 01:06:54,820
that is the key question it whether it's
a flaw of the data or not or the mexico

2794
01:06:54,820 --> 01:06:54,830
a flaw of the data or not or the mexico
 

2795
01:06:54,830 --> 01:06:57,200
a flaw of the data or not or the mexico
the reason I brought up this example was

2796
01:06:57,200 --> 01:06:57,210
the reason I brought up this example was
 

2797
01:06:57,210 --> 01:06:58,760
the reason I brought up this example was
because you were asking do I think that

2798
01:06:58,760 --> 01:06:58,770
because you were asking do I think that
 

2799
01:06:58,770 --> 01:07:01,610
because you were asking do I think that
you know learning from data could go all

2800
01:07:01,610 --> 01:07:01,620
you know learning from data could go all
 

2801
01:07:01,620 --> 01:07:03,620
you know learning from data could go all
the way yes and that this was why I

2802
01:07:03,620 --> 01:07:03,630
the way yes and that this was why I
 

2803
01:07:03,630 --> 01:07:05,560
the way yes and that this was why I
brought up the example because I think

2804
01:07:05,560 --> 01:07:05,570
brought up the example because I think
 

2805
01:07:05,570 --> 01:07:09,920
brought up the example because I think
and this was is not at all to to take

2806
01:07:09,920 --> 01:07:09,930
and this was is not at all to to take
 

2807
01:07:09,930 --> 01:07:11,630
and this was is not at all to to take
away from the impressive work that they

2808
01:07:11,630 --> 01:07:11,640
away from the impressive work that they
 

2809
01:07:11,640 --> 01:07:14,360
away from the impressive work that they
did but it's to say that when we look at

2810
01:07:14,360 --> 01:07:14,370
did but it's to say that when we look at
 

2811
01:07:14,370 --> 01:07:19,730
did but it's to say that when we look at
what these systems learn do they learn

2812
01:07:19,730 --> 01:07:19,740
what these systems learn do they learn
 

2813
01:07:19,740 --> 01:07:22,820
what these systems learn do they learn
the human the things that we humans

2814
01:07:22,820 --> 01:07:22,830
the human the things that we humans
 

2815
01:07:22,830 --> 01:07:26,110
the human the things that we humans
consider to be the relevant concepts and

2816
01:07:26,110 --> 01:07:26,120
consider to be the relevant concepts and
 

2817
01:07:26,120 --> 01:07:28,340
consider to be the relevant concepts and
in that example

2818
01:07:28,340 --> 01:07:28,350
in that example
 

2819
01:07:28,350 --> 01:07:32,140
in that example
it didn't sure if you train it on a

2820
01:07:32,140 --> 01:07:32,150
it didn't sure if you train it on a
 

2821
01:07:32,150 --> 01:07:34,700
it didn't sure if you train it on a
movie you know the pat paddle being in

2822
01:07:34,700 --> 01:07:34,710
movie you know the pat paddle being in
 

2823
01:07:34,710 --> 01:07:38,270
movie you know the pat paddle being in
different places maybe it could deal

2824
01:07:38,270 --> 01:07:38,280
different places maybe it could deal
 

2825
01:07:38,280 --> 01:07:41,000
different places maybe it could deal
with maybe it would learn that concept

2826
01:07:41,000 --> 01:07:41,010
with maybe it would learn that concept
 

2827
01:07:41,010 --> 01:07:43,580
with maybe it would learn that concept
I'm not totally sure but the question is

2828
01:07:43,580 --> 01:07:43,590
I'm not totally sure but the question is
 

2829
01:07:43,590 --> 01:07:45,560
I'm not totally sure but the question is
you know scaling that up to more

2830
01:07:45,560 --> 01:07:45,570
you know scaling that up to more
 

2831
01:07:45,570 --> 01:07:50,330
you know scaling that up to more
complicated worlds to what extent could

2832
01:07:50,330 --> 01:07:50,340
complicated worlds to what extent could
 

2833
01:07:50,340 --> 01:07:53,390
complicated worlds to what extent could
a machine that only gets this very raw

2834
01:07:53,390 --> 01:07:53,400
a machine that only gets this very raw
 

2835
01:07:53,400 --> 01:07:57,500
a machine that only gets this very raw
data learn to divide up the world into

2836
01:07:57,500 --> 01:07:57,510
data learn to divide up the world into
 

2837
01:07:57,510 --> 01:08:01,160
data learn to divide up the world into
relevant concepts and I don't know the

2838
01:08:01,160 --> 01:08:01,170
relevant concepts and I don't know the
 

2839
01:08:01,170 --> 01:08:06,000
relevant concepts and I don't know the
answer but I would bet that that

2840
01:08:06,000 --> 01:08:06,010
answer but I would bet that that
 

2841
01:08:06,010 --> 01:08:09,780
answer but I would bet that that
without some innate notion that it can't

2842
01:08:09,780 --> 01:08:09,790
without some innate notion that it can't
 

2843
01:08:09,790 --> 01:08:10,290
without some innate notion that it can't
do it

2844
01:08:10,290 --> 01:08:10,300
do it
 

2845
01:08:10,300 --> 01:08:12,630
do it
yeah ten years ago a hundred percent

2846
01:08:12,630 --> 01:08:12,640
yeah ten years ago a hundred percent
 

2847
01:08:12,640 --> 01:08:14,790
yeah ten years ago a hundred percent
agree with you as the deal most experts

2848
01:08:14,790 --> 01:08:14,800
agree with you as the deal most experts
 

2849
01:08:14,800 --> 01:08:17,999
agree with you as the deal most experts
in a system but now I have a one but

2850
01:08:17,999 --> 01:08:18,009
in a system but now I have a one but
 

2851
01:08:18,009 --> 01:08:20,550
in a system but now I have a one but
like I have a glimmer of hope okay

2852
01:08:20,550 --> 01:08:20,560
like I have a glimmer of hope okay
 

2853
01:08:20,560 --> 01:08:22,320
like I have a glimmer of hope okay
have you no that's very nice and I think

2854
01:08:22,320 --> 01:08:22,330
have you no that's very nice and I think
 

2855
01:08:22,330 --> 01:08:23,730
have you no that's very nice and I think
I think that's what deep learning did in

2856
01:08:23,730 --> 01:08:23,740
I think that's what deep learning did in
 

2857
01:08:23,740 --> 01:08:25,860
I think that's what deep learning did in
the community is no no I still if I had

2858
01:08:25,860 --> 01:08:25,870
the community is no no I still if I had
 

2859
01:08:25,870 --> 01:08:27,420
the community is no no I still if I had
to bet all my money it's a hundred

2860
01:08:27,420 --> 01:08:27,430
to bet all my money it's a hundred
 

2861
01:08:27,430 --> 01:08:29,579
to bet all my money it's a hundred
percent deep learning will not takes all

2862
01:08:29,579 --> 01:08:29,589
percent deep learning will not takes all
 

2863
01:08:29,589 --> 01:08:31,829
percent deep learning will not takes all
the way but there's still other it still

2864
01:08:31,829 --> 01:08:31,839
the way but there's still other it still
 

2865
01:08:31,839 --> 01:08:34,730
the way but there's still other it still
I was so personally sort of surprised

2866
01:08:34,730 --> 01:08:34,740
I was so personally sort of surprised
 

2867
01:08:34,740 --> 01:08:38,640
I was so personally sort of surprised
mm-hmm why the Thar games by go by by

2868
01:08:38,640 --> 01:08:38,650
mm-hmm why the Thar games by go by by
 

2869
01:08:38,650 --> 01:08:40,920
mm-hmm why the Thar games by go by by
the power of self play of just yeah I'm

2870
01:08:40,920 --> 01:08:40,930
the power of self play of just yeah I'm
 

2871
01:08:40,930 --> 01:08:44,430
the power of self play of just yeah I'm
playing against you that I was like many

2872
01:08:44,430 --> 01:08:44,440
playing against you that I was like many
 

2873
01:08:44,440 --> 01:08:46,530
playing against you that I was like many
other times just humbled of how little I

2874
01:08:46,530 --> 01:08:46,540
other times just humbled of how little I
 

2875
01:08:46,540 --> 01:08:49,920
other times just humbled of how little I
know about what's possible you know yeah

2876
01:08:49,920 --> 01:08:49,930
know about what's possible you know yeah
 

2877
01:08:49,930 --> 01:08:52,499
know about what's possible you know yeah
I think fair enough self play is

2878
01:08:52,499 --> 01:08:52,509
I think fair enough self play is
 

2879
01:08:52,509 --> 01:08:54,930
I think fair enough self play is
amazingly powerful and you know that's

2880
01:08:54,930 --> 01:08:54,940
amazingly powerful and you know that's
 

2881
01:08:54,940 --> 01:08:58,050
amazingly powerful and you know that's
that goes way back to Arthur Samuel

2882
01:08:58,050 --> 01:08:58,060
that goes way back to Arthur Samuel
 

2883
01:08:58,060 --> 01:09:00,269
that goes way back to Arthur Samuel
Wright with his checker playing program

2884
01:09:00,269 --> 01:09:00,279
Wright with his checker playing program
 

2885
01:09:00,279 --> 01:09:03,590
Wright with his checker playing program
and that which was brilliant and

2886
01:09:03,590 --> 01:09:03,600
and that which was brilliant and
 

2887
01:09:03,600 --> 01:09:07,590
and that which was brilliant and
surprising that it did so well so just

2888
01:09:07,590 --> 01:09:07,600
surprising that it did so well so just
 

2889
01:09:07,600 --> 01:09:10,200
surprising that it did so well so just
for fun let me ask you a topic of

2890
01:09:10,200 --> 01:09:10,210
for fun let me ask you a topic of
 

2891
01:09:10,210 --> 01:09:12,590
for fun let me ask you a topic of
autonomous vehicles it's the area that

2892
01:09:12,590 --> 01:09:12,600
autonomous vehicles it's the area that
 

2893
01:09:12,600 --> 01:09:15,510
autonomous vehicles it's the area that
that I work at least these days most

2894
01:09:15,510 --> 01:09:15,520
that I work at least these days most
 

2895
01:09:15,520 --> 01:09:18,269
that I work at least these days most
closely on and it's also area that I

2896
01:09:18,269 --> 01:09:18,279
closely on and it's also area that I
 

2897
01:09:18,279 --> 01:09:20,340
closely on and it's also area that I
think is a good example that you use a

2898
01:09:20,340 --> 01:09:20,350
think is a good example that you use a
 

2899
01:09:20,350 --> 01:09:24,720
think is a good example that you use a
sort of an example of things we as

2900
01:09:24,720 --> 01:09:24,730
sort of an example of things we as
 

2901
01:09:24,730 --> 01:09:28,110
sort of an example of things we as
humans don't always realize how hard it

2902
01:09:28,110 --> 01:09:28,120
humans don't always realize how hard it
 

2903
01:09:28,120 --> 01:09:30,090
humans don't always realize how hard it
is to do it's like the the constant

2904
01:09:30,090 --> 01:09:30,100
is to do it's like the the constant
 

2905
01:09:30,100 --> 01:09:32,220
is to do it's like the the constant
trend AI but the different problems that

2906
01:09:32,220 --> 01:09:32,230
trend AI but the different problems that
 

2907
01:09:32,230 --> 01:09:33,690
trend AI but the different problems that
we think are easy when we first try them

2908
01:09:33,690 --> 01:09:33,700
we think are easy when we first try them
 

2909
01:09:33,700 --> 01:09:38,510
we think are easy when we first try them
and then realize how hard it is okay so

2910
01:09:38,510 --> 01:09:38,520
and then realize how hard it is okay so
 

2911
01:09:38,520 --> 01:09:41,970
and then realize how hard it is okay so
why you've talked about this autonomous

2912
01:09:41,970 --> 01:09:41,980
why you've talked about this autonomous
 

2913
01:09:41,980 --> 01:09:43,710
why you've talked about this autonomous
driving being a difficult problem more

2914
01:09:43,710 --> 01:09:43,720
driving being a difficult problem more
 

2915
01:09:43,720 --> 01:09:45,570
driving being a difficult problem more
difficult than we realize you must give

2916
01:09:45,570 --> 01:09:45,580
difficult than we realize you must give
 

2917
01:09:45,580 --> 01:09:48,269
difficult than we realize you must give
it credit for why is it so difficult one

2918
01:09:48,269 --> 01:09:48,279
it credit for why is it so difficult one
 

2919
01:09:48,279 --> 01:09:49,920
it credit for why is it so difficult one
of the most difficult parts in your view

2920
01:09:49,920 --> 01:09:49,930
of the most difficult parts in your view
 

2921
01:09:49,930 --> 01:09:55,410
of the most difficult parts in your view
I think it's difficult because of the

2922
01:09:55,410 --> 01:09:55,420
I think it's difficult because of the
 

2923
01:09:55,420 --> 01:09:58,170
I think it's difficult because of the
world is so open-ended as to what what

2924
01:09:58,170 --> 01:09:58,180
world is so open-ended as to what what
 

2925
01:09:58,180 --> 01:10:02,930
world is so open-ended as to what what
kinds of things can happen so you have

2926
01:10:02,930 --> 01:10:02,940
kinds of things can happen so you have
 

2927
01:10:02,940 --> 01:10:06,240
kinds of things can happen so you have
sort of what normally happens which is

2928
01:10:06,240 --> 01:10:06,250
sort of what normally happens which is
 

2929
01:10:06,250 --> 01:10:08,820
sort of what normally happens which is
just you drive along and nothing nothing

2930
01:10:08,820 --> 01:10:08,830
just you drive along and nothing nothing
 

2931
01:10:08,830 --> 01:10:11,670
just you drive along and nothing nothing
surprising happens and autonomous

2932
01:10:11,670 --> 01:10:11,680
surprising happens and autonomous
 

2933
01:10:11,680 --> 01:10:14,300
surprising happens and autonomous
vehicles can do the ones we have now

2934
01:10:14,300 --> 01:10:14,310
vehicles can do the ones we have now
 

2935
01:10:14,310 --> 01:10:18,180
vehicles can do the ones we have now
evidently can do really well on most

2936
01:10:18,180 --> 01:10:18,190
evidently can do really well on most
 

2937
01:10:18,190 --> 01:10:20,010
evidently can do really well on most
normal situations as long

2938
01:10:20,010 --> 01:10:20,020
normal situations as long
 

2939
01:10:20,020 --> 01:10:21,810
normal situations as long
as long as you know the weather is

2940
01:10:21,810 --> 01:10:21,820
as long as you know the weather is
 

2941
01:10:21,820 --> 01:10:25,140
as long as you know the weather is
reasonably good and everything but if

2942
01:10:25,140 --> 01:10:25,150
reasonably good and everything but if
 

2943
01:10:25,150 --> 01:10:28,200
reasonably good and everything but if
some we have this notion of edge cases

2944
01:10:28,200 --> 01:10:28,210
some we have this notion of edge cases
 

2945
01:10:28,210 --> 01:10:31,800
some we have this notion of edge cases
or or you know things in the tail of the

2946
01:10:31,800 --> 01:10:31,810
or or you know things in the tail of the
 

2947
01:10:31,810 --> 01:10:33,690
or or you know things in the tail of the
distribution you call it the long tail

2948
01:10:33,690 --> 01:10:33,700
distribution you call it the long tail
 

2949
01:10:33,700 --> 01:10:36,630
distribution you call it the long tail
problem which says that there's so many

2950
01:10:36,630 --> 01:10:36,640
problem which says that there's so many
 

2951
01:10:36,640 --> 01:10:39,540
problem which says that there's so many
possible things that can happen that was

2952
01:10:39,540 --> 01:10:39,550
possible things that can happen that was
 

2953
01:10:39,550 --> 01:10:43,700
possible things that can happen that was
not in the training data of the machine

2954
01:10:43,700 --> 01:10:43,710
not in the training data of the machine
 

2955
01:10:43,710 --> 01:10:47,760
not in the training data of the machine
that it won't be able to handle it

2956
01:10:47,760 --> 01:10:47,770
that it won't be able to handle it
 

2957
01:10:47,770 --> 01:10:50,160
that it won't be able to handle it
because it doesn't have common sense

2958
01:10:50,160 --> 01:10:50,170
because it doesn't have common sense
 

2959
01:10:50,170 --> 01:10:54,900
because it doesn't have common sense
right it's the old the paddle moved yeah

2960
01:10:54,900 --> 01:10:54,910
right it's the old the paddle moved yeah
 

2961
01:10:54,910 --> 01:10:57,810
right it's the old the paddle moved yeah
it's the paddle moved problem right and

2962
01:10:57,810 --> 01:10:57,820
it's the paddle moved problem right and
 

2963
01:10:57,820 --> 01:10:59,970
it's the paddle moved problem right and
so my understanding and you probably are

2964
01:10:59,970 --> 01:10:59,980
so my understanding and you probably are
 

2965
01:10:59,980 --> 01:11:01,620
so my understanding and you probably are
more of an expert than I am on this is

2966
01:11:01,620 --> 01:11:01,630
more of an expert than I am on this is
 

2967
01:11:01,630 --> 01:11:07,530
more of an expert than I am on this is
that current self driving car vision

2968
01:11:07,530 --> 01:11:07,540
that current self driving car vision
 

2969
01:11:07,540 --> 01:11:09,770
that current self driving car vision
systems have problems with obstacles

2970
01:11:09,770 --> 01:11:09,780
systems have problems with obstacles
 

2971
01:11:09,780 --> 01:11:12,840
systems have problems with obstacles
meaning that they don't know which

2972
01:11:12,840 --> 01:11:12,850
meaning that they don't know which
 

2973
01:11:12,850 --> 01:11:15,480
meaning that they don't know which
obstacles which quote unquote obstacles

2974
01:11:15,480 --> 01:11:15,490
obstacles which quote unquote obstacles
 

2975
01:11:15,490 --> 01:11:17,190
obstacles which quote unquote obstacles
they should stop for and which ones they

2976
01:11:17,190 --> 01:11:17,200
they should stop for and which ones they
 

2977
01:11:17,200 --> 01:11:20,040
they should stop for and which ones they
shouldn't stop for and so a lot of times

2978
01:11:20,040 --> 01:11:20,050
shouldn't stop for and so a lot of times
 

2979
01:11:20,050 --> 01:11:22,410
shouldn't stop for and so a lot of times
I read that they tend to slam on the

2980
01:11:22,410 --> 01:11:22,420
I read that they tend to slam on the
 

2981
01:11:22,420 --> 01:11:26,010
I read that they tend to slam on the
brakes quite a bit and the most common

2982
01:11:26,010 --> 01:11:26,020
brakes quite a bit and the most common
 

2983
01:11:26,020 --> 01:11:28,230
brakes quite a bit and the most common
accidents with self-driving cars are

2984
01:11:28,230 --> 01:11:28,240
accidents with self-driving cars are
 

2985
01:11:28,240 --> 01:11:30,780
accidents with self-driving cars are
people rear-ending them because they

2986
01:11:30,780 --> 01:11:30,790
people rear-ending them because they
 

2987
01:11:30,790 --> 01:11:33,120
people rear-ending them because they
were surprised they've warned expecting

2988
01:11:33,120 --> 01:11:33,130
were surprised they've warned expecting
 

2989
01:11:33,130 --> 01:11:36,150
were surprised they've warned expecting
the machine the car to stop yeah so

2990
01:11:36,150 --> 01:11:36,160
the machine the car to stop yeah so
 

2991
01:11:36,160 --> 01:11:37,590
the machine the car to stop yeah so
there's there's a lot of interesting

2992
01:11:37,590 --> 01:11:37,600
there's there's a lot of interesting
 

2993
01:11:37,600 --> 01:11:41,760
there's there's a lot of interesting
questions there whether because because

2994
01:11:41,760 --> 01:11:41,770
questions there whether because because
 

2995
01:11:41,770 --> 01:11:43,530
questions there whether because because
you mentioned kind of two things so one

2996
01:11:43,530 --> 01:11:43,540
you mentioned kind of two things so one
 

2997
01:11:43,540 --> 01:11:45,210
you mentioned kind of two things so one
is the the problem of perception of

2998
01:11:45,210 --> 01:11:45,220
is the the problem of perception of
 

2999
01:11:45,220 --> 01:11:48,900
is the the problem of perception of
understanding of interpreting the

3000
01:11:48,900 --> 01:11:48,910
understanding of interpreting the
 

3001
01:11:48,910 --> 01:11:50,850
understanding of interpreting the
objects that are detected right

3002
01:11:50,850 --> 01:11:50,860
objects that are detected right
 

3003
01:11:50,860 --> 01:11:53,100
objects that are detected right
correctly and the other one is more like

3004
01:11:53,100 --> 01:11:53,110
correctly and the other one is more like
 

3005
01:11:53,110 --> 01:11:56,550
correctly and the other one is more like
the policy the action that you take how

3006
01:11:56,550 --> 01:11:56,560
the policy the action that you take how
 

3007
01:11:56,560 --> 01:11:59,310
the policy the action that you take how
you respond to it so a lot of the cars

3008
01:11:59,310 --> 01:11:59,320
you respond to it so a lot of the cars
 

3009
01:11:59,320 --> 01:12:03,540
you respond to it so a lot of the cars
braking is a kind of notion of to

3010
01:12:03,540 --> 01:12:03,550
braking is a kind of notion of to
 

3011
01:12:03,550 --> 01:12:05,580
braking is a kind of notion of to
clarify there's a lot of different kind

3012
01:12:05,580 --> 01:12:05,590
clarify there's a lot of different kind
 

3013
01:12:05,590 --> 01:12:06,960
clarify there's a lot of different kind
of things that are people calling

3014
01:12:06,960 --> 01:12:06,970
of things that are people calling
 

3015
01:12:06,970 --> 01:12:09,960
of things that are people calling
autonomous vehicles but a lot the L for

3016
01:12:09,960 --> 01:12:09,970
autonomous vehicles but a lot the L for
 

3017
01:12:09,970 --> 01:12:12,030
autonomous vehicles but a lot the L for
vehicles with a safety driver are the

3018
01:12:12,030 --> 01:12:12,040
vehicles with a safety driver are the
 

3019
01:12:12,040 --> 01:12:14,610
vehicles with a safety driver are the
ones like way moe and cruise and those

3020
01:12:14,610 --> 01:12:14,620
ones like way moe and cruise and those
 

3021
01:12:14,620 --> 01:12:16,490
ones like way moe and cruise and those
companies they tend to be very

3022
01:12:16,490 --> 01:12:16,500
companies they tend to be very
 

3023
01:12:16,500 --> 01:12:19,350
companies they tend to be very
conservative and cautious so they tend

3024
01:12:19,350 --> 01:12:19,360
conservative and cautious so they tend
 

3025
01:12:19,360 --> 01:12:21,570
conservative and cautious so they tend
to be very very afraid of hurting

3026
01:12:21,570 --> 01:12:21,580
to be very very afraid of hurting
 

3027
01:12:21,580 --> 01:12:23,670
to be very very afraid of hurting
anything or anyone and getting in any

3028
01:12:23,670 --> 01:12:23,680
anything or anyone and getting in any
 

3029
01:12:23,680 --> 01:12:26,070
anything or anyone and getting in any
kind of accidents so their policy is

3030
01:12:26,070 --> 01:12:26,080
kind of accidents so their policy is
 

3031
01:12:26,080 --> 01:12:28,770
kind of accidents so their policy is
very kind of that it that results in

3032
01:12:28,770 --> 01:12:28,780
very kind of that it that results in
 

3033
01:12:28,780 --> 01:12:31,170
very kind of that it that results in
being exceptionally responsive to

3034
01:12:31,170 --> 01:12:31,180
being exceptionally responsive to
 

3035
01:12:31,180 --> 01:12:32,760
being exceptionally responsive to
anything that could possibly be an

3036
01:12:32,760 --> 01:12:32,770
anything that could possibly be an
 

3037
01:12:32,770 --> 01:12:33,660
anything that could possibly be an
obstacle right

3038
01:12:33,660 --> 01:12:33,670
obstacle right
 

3039
01:12:33,670 --> 01:12:35,939
obstacle right
right which which which the human

3040
01:12:35,939 --> 01:12:35,949
right which which which the human
 

3041
01:12:35,949 --> 01:12:41,340
right which which which the human
drivers around it it's unpredictably

3042
01:12:41,340 --> 01:12:41,350
drivers around it it's unpredictably
 

3043
01:12:41,350 --> 01:12:43,320
drivers around it it's unpredictably
yeah that's not a very human thing to do

3044
01:12:43,320 --> 01:12:43,330
yeah that's not a very human thing to do
 

3045
01:12:43,330 --> 01:12:45,390
yeah that's not a very human thing to do
caution that's not the thing we're good

3046
01:12:45,390 --> 01:12:45,400
caution that's not the thing we're good
 

3047
01:12:45,400 --> 01:12:47,490
caution that's not the thing we're good
at specially in driving we're in a hurry

3048
01:12:47,490 --> 01:12:47,500
at specially in driving we're in a hurry
 

3049
01:12:47,500 --> 01:12:50,640
at specially in driving we're in a hurry
often angry and etc especially in Boston

3050
01:12:50,640 --> 01:12:50,650
often angry and etc especially in Boston
 

3051
01:12:50,650 --> 01:12:54,660
often angry and etc especially in Boston
so and then there's of another and a lot

3052
01:12:54,660 --> 01:12:54,670
so and then there's of another and a lot
 

3053
01:12:54,670 --> 01:12:56,910
so and then there's of another and a lot
of times that's machine learning is not

3054
01:12:56,910 --> 01:12:56,920
of times that's machine learning is not
 

3055
01:12:56,920 --> 01:12:59,040
of times that's machine learning is not
a huge part of that it's becoming more

3056
01:12:59,040 --> 01:12:59,050
a huge part of that it's becoming more
 

3057
01:12:59,050 --> 01:13:01,680
a huge part of that it's becoming more
and more unclear to me how much you you

3058
01:13:01,680 --> 01:13:01,690
and more unclear to me how much you you
 

3059
01:13:01,690 --> 01:13:04,140
and more unclear to me how much you you
know sort of speaking to public

3060
01:13:04,140 --> 01:13:04,150
know sort of speaking to public
 

3061
01:13:04,150 --> 01:13:07,979
know sort of speaking to public
information because a lot of companies

3062
01:13:07,979 --> 01:13:07,989
information because a lot of companies
 

3063
01:13:07,989 --> 01:13:09,300
information because a lot of companies
say they're doing deep learning and

3064
01:13:09,300 --> 01:13:09,310
say they're doing deep learning and
 

3065
01:13:09,310 --> 01:13:10,890
say they're doing deep learning and
machine learning just attract good

3066
01:13:10,890 --> 01:13:10,900
machine learning just attract good
 

3067
01:13:10,900 --> 01:13:14,400
machine learning just attract good
candidates the reality is in many cases

3068
01:13:14,400 --> 01:13:14,410
candidates the reality is in many cases
 

3069
01:13:14,410 --> 01:13:17,790
candidates the reality is in many cases
it's still not a huge part of the the

3070
01:13:17,790 --> 01:13:17,800
it's still not a huge part of the the
 

3071
01:13:17,800 --> 01:13:19,770
it's still not a huge part of the the
perception this is this lidar there's

3072
01:13:19,770 --> 01:13:19,780
perception this is this lidar there's
 

3073
01:13:19,780 --> 01:13:20,939
perception this is this lidar there's
other sensors that are much more

3074
01:13:20,939 --> 01:13:20,949
other sensors that are much more
 

3075
01:13:20,949 --> 01:13:24,090
other sensors that are much more
reliable for obstacle detection and then

3076
01:13:24,090 --> 01:13:24,100
reliable for obstacle detection and then
 

3077
01:13:24,100 --> 01:13:26,550
reliable for obstacle detection and then
there's Tesla approach which is vision

3078
01:13:26,550 --> 01:13:26,560
there's Tesla approach which is vision
 

3079
01:13:26,560 --> 01:13:30,060
there's Tesla approach which is vision
only and there's I think a few companies

3080
01:13:30,060 --> 01:13:30,070
only and there's I think a few companies
 

3081
01:13:30,070 --> 01:13:31,709
only and there's I think a few companies
doing that protest the most sort of

3082
01:13:31,709 --> 01:13:31,719
doing that protest the most sort of
 

3083
01:13:31,719 --> 01:13:33,570
doing that protest the most sort of
famously pushing that forward and that's

3084
01:13:33,570 --> 01:13:33,580
famously pushing that forward and that's
 

3085
01:13:33,580 --> 01:13:35,669
famously pushing that forward and that's
because the lidar is too expensive right

3086
01:13:35,669 --> 01:13:35,679
because the lidar is too expensive right
 

3087
01:13:35,679 --> 01:13:41,910
because the lidar is too expensive right
well I mean yes but I would say if you

3088
01:13:41,910 --> 01:13:41,920
well I mean yes but I would say if you
 

3089
01:13:41,920 --> 01:13:44,189
well I mean yes but I would say if you
were to for free give to every test

3090
01:13:44,189 --> 01:13:44,199
were to for free give to every test
 

3091
01:13:44,199 --> 01:13:47,310
were to for free give to every test
vehicle I mean Elon Musk fundamentally

3092
01:13:47,310 --> 01:13:47,320
vehicle I mean Elon Musk fundamentally
 

3093
01:13:47,320 --> 01:13:48,870
vehicle I mean Elon Musk fundamentally
believes that lidar is a crutch right

3094
01:13:48,870 --> 01:13:48,880
believes that lidar is a crutch right
 

3095
01:13:48,880 --> 01:13:53,310
believes that lidar is a crutch right
fantasy said that that if you want to

3096
01:13:53,310 --> 01:13:53,320
fantasy said that that if you want to
 

3097
01:13:53,320 --> 01:13:54,950
fantasy said that that if you want to
solve the problem of machine learning

3098
01:13:54,950 --> 01:13:54,960
solve the problem of machine learning
 

3099
01:13:54,960 --> 01:13:58,770
solve the problem of machine learning
lidar is not should not be the primary

3100
01:13:58,770 --> 01:13:58,780
lidar is not should not be the primary
 

3101
01:13:58,780 --> 01:14:02,280
lidar is not should not be the primary
sensor is the belief okay the camera

3102
01:14:02,280 --> 01:14:02,290
sensor is the belief okay the camera
 

3103
01:14:02,290 --> 01:14:04,709
sensor is the belief okay the camera
contains a lot more information mm-hmm

3104
01:14:04,709 --> 01:14:04,719
contains a lot more information mm-hmm
 

3105
01:14:04,719 --> 01:14:07,590
contains a lot more information mm-hmm
so if you want to learn you want that

3106
01:14:07,590 --> 01:14:07,600
so if you want to learn you want that
 

3107
01:14:07,600 --> 01:14:10,560
so if you want to learn you want that
information but if you want to not to

3108
01:14:10,560 --> 01:14:10,570
information but if you want to not to
 

3109
01:14:10,570 --> 01:14:13,860
information but if you want to not to
hit obstacles you want like are it's

3110
01:14:13,860 --> 01:14:13,870
hit obstacles you want like are it's
 

3111
01:14:13,870 --> 01:14:16,229
hit obstacles you want like are it's
sort of it's this weird trade-off

3112
01:14:16,229 --> 01:14:16,239
sort of it's this weird trade-off
 

3113
01:14:16,239 --> 01:14:19,740
sort of it's this weird trade-off
because yeah it's sort of what Tesla

3114
01:14:19,740 --> 01:14:19,750
because yeah it's sort of what Tesla
 

3115
01:14:19,750 --> 01:14:22,500
because yeah it's sort of what Tesla
vehicles have a lot of which is really

3116
01:14:22,500 --> 01:14:22,510
vehicles have a lot of which is really
 

3117
01:14:22,510 --> 01:14:26,970
vehicles have a lot of which is really
the thing the price of the fallback the

3118
01:14:26,970 --> 01:14:26,980
the thing the price of the fallback the
 

3119
01:14:26,980 --> 01:14:29,910
the thing the price of the fallback the
primary fallback sensor is radar which

3120
01:14:29,910 --> 01:14:29,920
primary fallback sensor is radar which
 

3121
01:14:29,920 --> 01:14:32,550
primary fallback sensor is radar which
is a very crude version of lighter it's

3122
01:14:32,550 --> 01:14:32,560
is a very crude version of lighter it's
 

3123
01:14:32,560 --> 01:14:35,760
is a very crude version of lighter it's
a good detector of obstacles except when

3124
01:14:35,760 --> 01:14:35,770
a good detector of obstacles except when
 

3125
01:14:35,770 --> 01:14:38,330
a good detector of obstacles except when
those things are standing right the

3126
01:14:38,330 --> 01:14:38,340
those things are standing right the
 

3127
01:14:38,340 --> 01:14:40,890
those things are standing right the
stopped vehicle right that's why it had

3128
01:14:40,890 --> 01:14:40,900
stopped vehicle right that's why it had
 

3129
01:14:40,900 --> 01:14:43,080
stopped vehicle right that's why it had
problems with crashing into stop fire

3130
01:14:43,080 --> 01:14:43,090
problems with crashing into stop fire
 

3131
01:14:43,090 --> 01:14:45,450
problems with crashing into stop fire
trucks stop fire trucks right so the

3132
01:14:45,450 --> 01:14:45,460
trucks stop fire trucks right so the
 

3133
01:14:45,460 --> 01:14:47,880
trucks stop fire trucks right so the
hope there is that the vision sensor

3134
01:14:47,880 --> 01:14:47,890
hope there is that the vision sensor
 

3135
01:14:47,890 --> 01:14:50,010
hope there is that the vision sensor
would somehow catch that and infer

3136
01:14:50,010 --> 01:14:50,020
would somehow catch that and infer
 

3137
01:14:50,020 --> 01:14:51,479
would somehow catch that and infer
there's a lot of problems of perception

3138
01:14:51,479 --> 01:14:51,489
there's a lot of problems of perception
 

3139
01:14:51,489 --> 01:14:55,860
there's a lot of problems of perception
I they are doing actually some

3140
01:14:55,860 --> 01:14:55,870
I they are doing actually some
 

3141
01:14:55,870 --> 01:15:01,320
I they are doing actually some
incredible stuff in the almost like an

3142
01:15:01,320 --> 01:15:01,330
incredible stuff in the almost like an
 

3143
01:15:01,330 --> 01:15:03,290
incredible stuff in the almost like an
active learning space where it's

3144
01:15:03,290 --> 01:15:03,300
active learning space where it's
 

3145
01:15:03,300 --> 01:15:06,240
active learning space where it's
constantly taking edge cases and pulling

3146
01:15:06,240 --> 01:15:06,250
constantly taking edge cases and pulling
 

3147
01:15:06,250 --> 01:15:08,310
constantly taking edge cases and pulling
back in there's a state data pipeline

3148
01:15:08,310 --> 01:15:08,320
back in there's a state data pipeline
 

3149
01:15:08,320 --> 01:15:13,020
back in there's a state data pipeline
another aspect that is really important

3150
01:15:13,020 --> 01:15:13,030
another aspect that is really important
 

3151
01:15:13,030 --> 01:15:14,220
another aspect that is really important
that people are studying now is called

3152
01:15:14,220 --> 01:15:14,230
that people are studying now is called
 

3153
01:15:14,230 --> 01:15:16,380
that people are studying now is called
multitask learning which is sort of

3154
01:15:16,380 --> 01:15:16,390
multitask learning which is sort of
 

3155
01:15:16,390 --> 01:15:18,810
multitask learning which is sort of
breaking apart this problem whatever the

3156
01:15:18,810 --> 01:15:18,820
breaking apart this problem whatever the
 

3157
01:15:18,820 --> 01:15:21,050
breaking apart this problem whatever the
problem is in this case driving into

3158
01:15:21,050 --> 01:15:21,060
problem is in this case driving into
 

3159
01:15:21,060 --> 01:15:24,180
problem is in this case driving into
dozens or hundreds of little problems

3160
01:15:24,180 --> 01:15:24,190
dozens or hundreds of little problems
 

3161
01:15:24,190 --> 01:15:25,860
dozens or hundreds of little problems
that you can turn into learning problems

3162
01:15:25,860 --> 01:15:25,870
that you can turn into learning problems
 

3163
01:15:25,870 --> 01:15:29,400
that you can turn into learning problems
so this giant pipeline the you know it's

3164
01:15:29,400 --> 01:15:29,410
so this giant pipeline the you know it's
 

3165
01:15:29,410 --> 01:15:31,950
so this giant pipeline the you know it's
kind of interesting I've been skeptical

3166
01:15:31,950 --> 01:15:31,960
kind of interesting I've been skeptical
 

3167
01:15:31,960 --> 01:15:33,600
kind of interesting I've been skeptical
from the very beginning we've become

3168
01:15:33,600 --> 01:15:33,610
from the very beginning we've become
 

3169
01:15:33,610 --> 01:15:35,729
from the very beginning we've become
less and less skeptical over time how

3170
01:15:35,729 --> 01:15:35,739
less and less skeptical over time how
 

3171
01:15:35,739 --> 01:15:37,950
less and less skeptical over time how
much of driving can be learned I'm still

3172
01:15:37,950 --> 01:15:37,960
much of driving can be learned I'm still
 

3173
01:15:37,960 --> 01:15:41,250
much of driving can be learned I'm still
think it's much farther than then the

3174
01:15:41,250 --> 01:15:41,260
think it's much farther than then the
 

3175
01:15:41,260 --> 01:15:43,919
think it's much farther than then the
CEO of that particular company thinks it

3176
01:15:43,919 --> 01:15:43,929
CEO of that particular company thinks it
 

3177
01:15:43,929 --> 01:15:47,669
CEO of that particular company thinks it
will be but it it is costly surprising

3178
01:15:47,669 --> 01:15:47,679
will be but it it is costly surprising
 

3179
01:15:47,679 --> 01:15:50,790
will be but it it is costly surprising
that through good engineering and data

3180
01:15:50,790 --> 01:15:50,800
that through good engineering and data
 

3181
01:15:50,800 --> 01:15:53,550
that through good engineering and data
collection and active selection of data

3182
01:15:53,550 --> 01:15:53,560
collection and active selection of data
 

3183
01:15:53,560 --> 01:15:56,700
collection and active selection of data
how you can attack that long tail and

3184
01:15:56,700 --> 01:15:56,710
how you can attack that long tail and
 

3185
01:15:56,710 --> 01:15:59,100
how you can attack that long tail and
it's an interesting open question that

3186
01:15:59,100 --> 01:15:59,110
it's an interesting open question that
 

3187
01:15:59,110 --> 01:16:00,810
it's an interesting open question that
you're absolutely right there's a much

3188
01:16:00,810 --> 01:16:00,820
you're absolutely right there's a much
 

3189
01:16:00,820 --> 01:16:02,610
you're absolutely right there's a much
longer tail and all these edge cases

3190
01:16:02,610 --> 01:16:02,620
longer tail and all these edge cases
 

3191
01:16:02,620 --> 01:16:05,070
longer tail and all these edge cases
that we don't think about but it's this

3192
01:16:05,070 --> 01:16:05,080
that we don't think about but it's this
 

3193
01:16:05,080 --> 01:16:07,140
that we don't think about but it's this
it's a fascinating question that applies

3194
01:16:07,140 --> 01:16:07,150
it's a fascinating question that applies
 

3195
01:16:07,150 --> 01:16:09,450
it's a fascinating question that applies
to natural language in all spaces how

3196
01:16:09,450 --> 01:16:09,460
to natural language in all spaces how
 

3197
01:16:09,460 --> 01:16:12,450
to natural language in all spaces how
big how how big is that long tail right

3198
01:16:12,450 --> 01:16:12,460
big how how big is that long tail right
 

3199
01:16:12,460 --> 01:16:16,890
big how how big is that long tail right
and I mean not to linger on the point

3200
01:16:16,890 --> 01:16:16,900
and I mean not to linger on the point
 

3201
01:16:16,900 --> 01:16:20,370
and I mean not to linger on the point
but what's your sense in driving in

3202
01:16:20,370 --> 01:16:20,380
but what's your sense in driving in
 

3203
01:16:20,380 --> 01:16:22,650
but what's your sense in driving in
these practical problems of the human

3204
01:16:22,650 --> 01:16:22,660
these practical problems of the human
 

3205
01:16:22,660 --> 01:16:27,030
these practical problems of the human
experience can it be learned so the

3206
01:16:27,030 --> 01:16:27,040
experience can it be learned so the
 

3207
01:16:27,040 --> 01:16:28,439
experience can it be learned so the
current what are your thoughts are sort

3208
01:16:28,439 --> 01:16:28,449
current what are your thoughts are sort
 

3209
01:16:28,449 --> 01:16:31,260
current what are your thoughts are sort
of Elon Musk thought let's forget the

3210
01:16:31,260 --> 01:16:31,270
of Elon Musk thought let's forget the
 

3211
01:16:31,270 --> 01:16:32,790
of Elon Musk thought let's forget the
thing that he says it'd be solved in a

3212
01:16:32,790 --> 01:16:32,800
thing that he says it'd be solved in a
 

3213
01:16:32,800 --> 01:16:37,680
thing that he says it'd be solved in a
year but can it be solved in in a

3214
01:16:37,680 --> 01:16:37,690
year but can it be solved in in a
 

3215
01:16:37,690 --> 01:16:40,380
year but can it be solved in in a
reasonable timeline or do fundamentally

3216
01:16:40,380 --> 01:16:40,390
reasonable timeline or do fundamentally
 

3217
01:16:40,390 --> 01:16:42,600
reasonable timeline or do fundamentally
other methods need to be invented so I I

3218
01:16:42,600 --> 01:16:42,610
other methods need to be invented so I I
 

3219
01:16:42,610 --> 01:16:48,360
other methods need to be invented so I I
don't I think that ultimately driving so

3220
01:16:48,360 --> 01:16:48,370
don't I think that ultimately driving so
 

3221
01:16:48,370 --> 01:16:50,640
don't I think that ultimately driving so
so it's a trade-off in a way I you know

3222
01:16:50,640 --> 01:16:50,650
so it's a trade-off in a way I you know
 

3223
01:16:50,650 --> 01:16:54,140
so it's a trade-off in a way I you know
being able to drive and deal with any

3224
01:16:54,140 --> 01:16:54,150
being able to drive and deal with any
 

3225
01:16:54,150 --> 01:16:57,419
being able to drive and deal with any
situation that comes up does require

3226
01:16:57,419 --> 01:16:57,429
situation that comes up does require
 

3227
01:16:57,429 --> 01:16:59,669
situation that comes up does require
kind of full human

3228
01:16:59,669 --> 01:16:59,679
kind of full human
 

3229
01:16:59,679 --> 01:17:01,199
kind of full human
telogen sand even in humans aren't

3230
01:17:01,199 --> 01:17:01,209
telogen sand even in humans aren't
 

3231
01:17:01,209 --> 01:17:03,359
telogen sand even in humans aren't
intelligent enough to do it because

3232
01:17:03,359 --> 01:17:03,369
intelligent enough to do it because
 

3233
01:17:03,369 --> 01:17:07,219
intelligent enough to do it because
humans I mean most human accidents are

3234
01:17:07,219 --> 01:17:07,229
humans I mean most human accidents are
 

3235
01:17:07,229 --> 01:17:09,419
humans I mean most human accidents are
because the human wasn't paying

3236
01:17:09,419 --> 01:17:09,429
because the human wasn't paying
 

3237
01:17:09,429 --> 01:17:11,580
because the human wasn't paying
attention or the humans drunk or

3238
01:17:11,580 --> 01:17:11,590
attention or the humans drunk or
 

3239
01:17:11,590 --> 01:17:13,379
attention or the humans drunk or
whatever and not because they weren't

3240
01:17:13,379 --> 01:17:13,389
whatever and not because they weren't
 

3241
01:17:13,389 --> 01:17:14,910
whatever and not because they weren't
intelligent but not because they weren't

3242
01:17:14,910 --> 01:17:14,920
intelligent but not because they weren't
 

3243
01:17:14,920 --> 01:17:20,419
intelligent but not because they weren't
intelligent enough right whereas the

3244
01:17:20,419 --> 01:17:20,429
intelligent enough right whereas the
 

3245
01:17:20,429 --> 01:17:24,060
intelligent enough right whereas the
accidents with autonomous vehicles is

3246
01:17:24,060 --> 01:17:24,070
accidents with autonomous vehicles is
 

3247
01:17:24,070 --> 01:17:25,620
accidents with autonomous vehicles is
because they weren't intelligent enough

3248
01:17:25,620 --> 01:17:25,630
because they weren't intelligent enough
 

3249
01:17:25,630 --> 01:17:28,350
because they weren't intelligent enough
they're always paying attention so it's

3250
01:17:28,350 --> 01:17:28,360
they're always paying attention so it's
 

3251
01:17:28,360 --> 01:17:29,819
they're always paying attention so it's
a it's a trade off you know and I think

3252
01:17:29,819 --> 01:17:29,829
a it's a trade off you know and I think
 

3253
01:17:29,829 --> 01:17:32,850
a it's a trade off you know and I think
that it's a very fair thing to say that

3254
01:17:32,850 --> 01:17:32,860
that it's a very fair thing to say that
 

3255
01:17:32,860 --> 01:17:35,520
that it's a very fair thing to say that
autonomous vehicles will be ultimately

3256
01:17:35,520 --> 01:17:35,530
autonomous vehicles will be ultimately
 

3257
01:17:35,530 --> 01:17:38,370
autonomous vehicles will be ultimately
safer than humans because humans are

3258
01:17:38,370 --> 01:17:38,380
safer than humans because humans are
 

3259
01:17:38,380 --> 01:17:43,699
safer than humans because humans are
very unsafe it's kind of a low bar but

3260
01:17:43,699 --> 01:17:43,709
very unsafe it's kind of a low bar but
 

3261
01:17:43,709 --> 01:17:45,479
very unsafe it's kind of a low bar but
just like you said

3262
01:17:45,479 --> 01:17:45,489
just like you said
 

3263
01:17:45,489 --> 01:17:48,270
just like you said
the III I think he was get a bad rap

3264
01:17:48,270 --> 01:17:48,280
the III I think he was get a bad rap
 

3265
01:17:48,280 --> 01:17:50,009
the III I think he was get a bad rap
right cuz we're really good at the

3266
01:17:50,009 --> 01:17:50,019
right cuz we're really good at the
 

3267
01:17:50,019 --> 01:17:51,660
right cuz we're really good at the
common-sense thing yeah we're great at

3268
01:17:51,660 --> 01:17:51,670
common-sense thing yeah we're great at
 

3269
01:17:51,670 --> 01:17:53,160
common-sense thing yeah we're great at
the common-sense thing we're bad at the

3270
01:17:53,160 --> 01:17:53,170
the common-sense thing we're bad at the
 

3271
01:17:53,170 --> 01:17:54,629
the common-sense thing we're bad at the
paying atten thing being attached a

3272
01:17:54,629 --> 01:17:54,639
paying atten thing being attached a
 

3273
01:17:54,639 --> 01:17:56,489
paying atten thing being attached a
thing especially moral you know driving

3274
01:17:56,489 --> 01:17:56,499
thing especially moral you know driving
 

3275
01:17:56,499 --> 01:17:57,689
thing especially moral you know driving
is kind of boring and we have these

3276
01:17:57,689 --> 01:17:57,699
is kind of boring and we have these
 

3277
01:17:57,699 --> 01:18:00,859
is kind of boring and we have these
phones to play with and everything but I

3278
01:18:00,859 --> 01:18:00,869
phones to play with and everything but I
 

3279
01:18:00,869 --> 01:18:06,449
phones to play with and everything but I
think what what's gonna happen is that

3280
01:18:06,449 --> 01:18:06,459
think what what's gonna happen is that
 

3281
01:18:06,459 --> 01:18:10,469
think what what's gonna happen is that
for many reasons not just AI reasons but

3282
01:18:10,469 --> 01:18:10,479
for many reasons not just AI reasons but
 

3283
01:18:10,479 --> 01:18:14,239
for many reasons not just AI reasons but
also like legal and other reasons that

3284
01:18:14,239 --> 01:18:14,249
also like legal and other reasons that
 

3285
01:18:14,249 --> 01:18:17,279
also like legal and other reasons that
the the definition of self-driving is

3286
01:18:17,279 --> 01:18:17,289
the the definition of self-driving is
 

3287
01:18:17,289 --> 01:18:19,529
the the definition of self-driving is
going to change or autonomous is going

3288
01:18:19,529 --> 01:18:19,539
going to change or autonomous is going
 

3289
01:18:19,539 --> 01:18:24,270
going to change or autonomous is going
to change it's not going to be just I'm

3290
01:18:24,270 --> 01:18:24,280
to change it's not going to be just I'm
 

3291
01:18:24,280 --> 01:18:25,620
to change it's not going to be just I'm
gonna go to sleep in the back and you

3292
01:18:25,620 --> 01:18:25,630
gonna go to sleep in the back and you
 

3293
01:18:25,630 --> 01:18:27,330
gonna go to sleep in the back and you
just drive me anywhere

3294
01:18:27,330 --> 01:18:27,340
just drive me anywhere
 

3295
01:18:27,340 --> 01:18:32,459
just drive me anywhere
it's gonna be more certain areas are

3296
01:18:32,459 --> 01:18:32,469
it's gonna be more certain areas are
 

3297
01:18:32,469 --> 01:18:36,270
it's gonna be more certain areas are
going to be instrumented to have the

3298
01:18:36,270 --> 01:18:36,280
going to be instrumented to have the
 

3299
01:18:36,280 --> 01:18:38,250
going to be instrumented to have the
sensors and the mapping and all the

3300
01:18:38,250 --> 01:18:38,260
sensors and the mapping and all the
 

3301
01:18:38,260 --> 01:18:40,259
sensors and the mapping and all the
stuff you need for that that the

3302
01:18:40,259 --> 01:18:40,269
stuff you need for that that the
 

3303
01:18:40,269 --> 01:18:42,149
stuff you need for that that the
autonomous cars won't have to have full

3304
01:18:42,149 --> 01:18:42,159
autonomous cars won't have to have full
 

3305
01:18:42,159 --> 01:18:45,569
autonomous cars won't have to have full
common sense and they'll do just fine in

3306
01:18:45,569 --> 01:18:45,579
common sense and they'll do just fine in
 

3307
01:18:45,579 --> 01:18:48,449
common sense and they'll do just fine in
those areas as long as pedestrians don't

3308
01:18:48,449 --> 01:18:48,459
those areas as long as pedestrians don't
 

3309
01:18:48,459 --> 01:18:50,669
those areas as long as pedestrians don't
mess with them too much that's another

3310
01:18:50,669 --> 01:18:50,679
mess with them too much that's another
 

3311
01:18:50,679 --> 01:18:57,679
mess with them too much that's another
question I don't think we will have

3312
01:18:57,679 --> 01:18:57,689
question I don't think we will have
 

3313
01:18:57,689 --> 01:19:00,330
question I don't think we will have
fully autonomous self-driving in the way

3314
01:19:00,330 --> 01:19:00,340
fully autonomous self-driving in the way
 

3315
01:19:00,340 --> 01:19:02,699
fully autonomous self-driving in the way
that like most the average person thinks

3316
01:19:02,699 --> 01:19:02,709
that like most the average person thinks
 

3317
01:19:02,709 --> 01:19:06,359
that like most the average person thinks
of it for a very long time and just to

3318
01:19:06,359 --> 01:19:06,369
of it for a very long time and just to
 

3319
01:19:06,369 --> 01:19:08,729
of it for a very long time and just to
reiterate this is the interesting open

3320
01:19:08,729 --> 01:19:08,739
reiterate this is the interesting open
 

3321
01:19:08,739 --> 01:19:11,250
reiterate this is the interesting open
question that I think I agree with you

3322
01:19:11,250 --> 01:19:11,260
question that I think I agree with you
 

3323
01:19:11,260 --> 01:19:13,800
question that I think I agree with you
on is to solve fully

3324
01:19:13,800 --> 01:19:13,810
on is to solve fully
 

3325
01:19:13,810 --> 01:19:16,200
on is to solve fully
Thomas driving you have to be able to

3326
01:19:16,200 --> 01:19:16,210
Thomas driving you have to be able to
 

3327
01:19:16,210 --> 01:19:20,190
Thomas driving you have to be able to
engineer in common sense yes I think

3328
01:19:20,190 --> 01:19:20,200
engineer in common sense yes I think
 

3329
01:19:20,200 --> 01:19:22,590
engineer in common sense yes I think
it's an important thing to hear and

3330
01:19:22,590 --> 01:19:22,600
it's an important thing to hear and
 

3331
01:19:22,600 --> 01:19:25,230
it's an important thing to hear and
think about I hope that's wrong but I

3332
01:19:25,230 --> 01:19:25,240
think about I hope that's wrong but I
 

3333
01:19:25,240 --> 01:19:28,010
think about I hope that's wrong but I
currently I could agree with you that

3334
01:19:28,010 --> 01:19:28,020
currently I could agree with you that
 

3335
01:19:28,020 --> 01:19:32,040
currently I could agree with you that
unfortunately you do have to have to be

3336
01:19:32,040 --> 01:19:32,050
unfortunately you do have to have to be
 

3337
01:19:32,050 --> 01:19:33,930
unfortunately you do have to have to be
more specific sort of these deep

3338
01:19:33,930 --> 01:19:33,940
more specific sort of these deep
 

3339
01:19:33,940 --> 01:19:36,450
more specific sort of these deep
understandings of physics and yeah of

3340
01:19:36,450 --> 01:19:36,460
understandings of physics and yeah of
 

3341
01:19:36,460 --> 01:19:39,030
understandings of physics and yeah of
the way this world works and also the

3342
01:19:39,030 --> 01:19:39,040
the way this world works and also the
 

3343
01:19:39,040 --> 01:19:40,380
the way this world works and also the
human dynamics like you mentioned

3344
01:19:40,380 --> 01:19:40,390
human dynamics like you mentioned
 

3345
01:19:40,390 --> 01:19:42,810
human dynamics like you mentioned
pedestrians and cyclists actually that's

3346
01:19:42,810 --> 01:19:42,820
pedestrians and cyclists actually that's
 

3347
01:19:42,820 --> 01:19:45,540
pedestrians and cyclists actually that's
whatever that nonverbal communication is

3348
01:19:45,540 --> 01:19:45,550
whatever that nonverbal communication is
 

3349
01:19:45,550 --> 01:19:47,970
whatever that nonverbal communication is
some people call it there's that dynamic

3350
01:19:47,970 --> 01:19:47,980
some people call it there's that dynamic
 

3351
01:19:47,980 --> 01:19:51,030
some people call it there's that dynamic
that is also part of this common sense

3352
01:19:51,030 --> 01:19:51,040
that is also part of this common sense
 

3353
01:19:51,040 --> 01:19:54,180
that is also part of this common sense
right and we're pretty we humans are

3354
01:19:54,180 --> 01:19:54,190
right and we're pretty we humans are
 

3355
01:19:54,190 --> 01:19:56,340
right and we're pretty we humans are
pretty good at predicting what other

3356
01:19:56,340 --> 01:19:56,350
pretty good at predicting what other
 

3357
01:19:56,350 --> 01:19:58,710
pretty good at predicting what other
humans are gonna do and how are our

3358
01:19:58,710 --> 01:19:58,720
humans are gonna do and how are our
 

3359
01:19:58,720 --> 01:20:01,350
humans are gonna do and how are our
actions impacts the behaviors of yes

3360
01:20:01,350 --> 01:20:01,360
actions impacts the behaviors of yes
 

3361
01:20:01,360 --> 01:20:03,840
actions impacts the behaviors of yes
this is weird game theoretic dance that

3362
01:20:03,840 --> 01:20:03,850
this is weird game theoretic dance that
 

3363
01:20:03,850 --> 01:20:06,570
this is weird game theoretic dance that
we're good at somehow and work well the

3364
01:20:06,570 --> 01:20:06,580
we're good at somehow and work well the
 

3365
01:20:06,580 --> 01:20:08,750
we're good at somehow and work well the
funny thing is is because I've watched

3366
01:20:08,750 --> 01:20:08,760
funny thing is is because I've watched
 

3367
01:20:08,760 --> 01:20:11,490
funny thing is is because I've watched
countless hours of pedestrian video and

3368
01:20:11,490 --> 01:20:11,500
countless hours of pedestrian video and
 

3369
01:20:11,500 --> 01:20:12,840
countless hours of pedestrian video and
talked to people

3370
01:20:12,840 --> 01:20:12,850
talked to people
 

3371
01:20:12,850 --> 01:20:14,910
talked to people
we humans are also really bad at

3372
01:20:14,910 --> 01:20:14,920
we humans are also really bad at
 

3373
01:20:14,920 --> 01:20:17,610
we humans are also really bad at
articulating the knowledge we have right

3374
01:20:17,610 --> 01:20:17,620
articulating the knowledge we have right
 

3375
01:20:17,620 --> 01:20:21,180
articulating the knowledge we have right
which is a been a huge challenge yes so

3376
01:20:21,180 --> 01:20:21,190
which is a been a huge challenge yes so
 

3377
01:20:21,190 --> 01:20:23,880
which is a been a huge challenge yes so
you've mentioned embodied intelligence

3378
01:20:23,880 --> 01:20:23,890
you've mentioned embodied intelligence
 

3379
01:20:23,890 --> 01:20:25,740
you've mentioned embodied intelligence
what do you think it takes to build a

3380
01:20:25,740 --> 01:20:25,750
what do you think it takes to build a
 

3381
01:20:25,750 --> 01:20:27,750
what do you think it takes to build a
system of human level intelligence does

3382
01:20:27,750 --> 01:20:27,760
system of human level intelligence does
 

3383
01:20:27,760 --> 01:20:31,380
system of human level intelligence does
he need to have a body I'm not sure but

3384
01:20:31,380 --> 01:20:31,390
he need to have a body I'm not sure but
 

3385
01:20:31,390 --> 01:20:34,470
he need to have a body I'm not sure but
I I'm coming around to that more and

3386
01:20:34,470 --> 01:20:34,480
I I'm coming around to that more and
 

3387
01:20:34,480 --> 01:20:37,890
I I'm coming around to that more and
more and what does it mean to be I don't

3388
01:20:37,890 --> 01:20:37,900
more and what does it mean to be I don't
 

3389
01:20:37,900 --> 01:20:40,610
more and what does it mean to be I don't
mean to keep breaking on up yeah Laocoon

3390
01:20:40,610 --> 01:20:40,620
mean to keep breaking on up yeah Laocoon
 

3391
01:20:40,620 --> 01:20:44,580
mean to keep breaking on up yeah Laocoon
he looms very large yeah well he

3392
01:20:44,580 --> 01:20:44,590
he looms very large yeah well he
 

3393
01:20:44,590 --> 01:20:47,130
he looms very large yeah well he
certainly has a large personality yes he

3394
01:20:47,130 --> 01:20:47,140
certainly has a large personality yes he
 

3395
01:20:47,140 --> 01:20:48,900
certainly has a large personality yes he
thinks that the system needs to be

3396
01:20:48,900 --> 01:20:48,910
thinks that the system needs to be
 

3397
01:20:48,910 --> 01:20:51,990
thinks that the system needs to be
grounded meaning he needs to sort of be

3398
01:20:51,990 --> 01:20:52,000
grounded meaning he needs to sort of be
 

3399
01:20:52,000 --> 01:20:54,540
grounded meaning he needs to sort of be
able to interact with reality but it

3400
01:20:54,540 --> 01:20:54,550
able to interact with reality but it
 

3401
01:20:54,550 --> 01:20:55,800
able to interact with reality but it
doesn't think it necessarily need to

3402
01:20:55,800 --> 01:20:55,810
doesn't think it necessarily need to
 

3403
01:20:55,810 --> 01:20:56,700
doesn't think it necessarily need to
have a body

3404
01:20:56,700 --> 01:20:56,710
have a body
 

3405
01:20:56,710 --> 01:20:57,780
have a body
so when you think of what's the

3406
01:20:57,780 --> 01:20:57,790
so when you think of what's the
 

3407
01:20:57,790 --> 01:21:01,410
so when you think of what's the
difference I guess I want to ask when

3408
01:21:01,410 --> 01:21:01,420
difference I guess I want to ask when
 

3409
01:21:01,420 --> 01:21:03,480
difference I guess I want to ask when
you mean body do you mean you have to be

3410
01:21:03,480 --> 01:21:03,490
you mean body do you mean you have to be
 

3411
01:21:03,490 --> 01:21:05,610
you mean body do you mean you have to be
able to play with the world or do you

3412
01:21:05,610 --> 01:21:05,620
able to play with the world or do you
 

3413
01:21:05,620 --> 01:21:07,680
able to play with the world or do you
also mean like there's a body that you

3414
01:21:07,680 --> 01:21:07,690
also mean like there's a body that you
 

3415
01:21:07,690 --> 01:21:11,310
also mean like there's a body that you
that you have to preserve oh that's a

3416
01:21:11,310 --> 01:21:11,320
that you have to preserve oh that's a
 

3417
01:21:11,320 --> 01:21:13,050
that you have to preserve oh that's a
good question I haven't really thought

3418
01:21:13,050 --> 01:21:13,060
good question I haven't really thought
 

3419
01:21:13,060 --> 01:21:15,450
good question I haven't really thought
about that but I think both I would

3420
01:21:15,450 --> 01:21:15,460
about that but I think both I would
 

3421
01:21:15,460 --> 01:21:20,720
about that but I think both I would
guess because it's because I think you I

3422
01:21:20,720 --> 01:21:20,730
guess because it's because I think you I
 

3423
01:21:20,730 --> 01:21:24,960
guess because it's because I think you I
think intelligence it's so hard to

3424
01:21:24,960 --> 01:21:24,970
think intelligence it's so hard to
 

3425
01:21:24,970 --> 01:21:27,620
think intelligence it's so hard to
separate it from

3426
01:21:27,620 --> 01:21:27,630
separate it from
 

3427
01:21:27,630 --> 01:21:30,740
separate it from
self our desire for self-preservation

3428
01:21:30,740 --> 01:21:30,750
self our desire for self-preservation
 

3429
01:21:30,750 --> 01:21:36,740
self our desire for self-preservation
our emotions are all that non rational

3430
01:21:36,740 --> 01:21:36,750
our emotions are all that non rational
 

3431
01:21:36,750 --> 01:21:41,200
our emotions are all that non rational
stuff that kind of gets in the way of

3432
01:21:41,200 --> 01:21:41,210

 

3433
01:21:41,210 --> 01:21:46,700

logical thinking because we the way you

3434
01:21:46,700 --> 01:21:46,710
logical thinking because we the way you
 

3435
01:21:46,710 --> 01:21:47,780
logical thinking because we the way you
know if we're talking about human

3436
01:21:47,780 --> 01:21:47,790
know if we're talking about human
 

3437
01:21:47,790 --> 01:21:49,640
know if we're talking about human
intelligence or human level intelligence

3438
01:21:49,640 --> 01:21:49,650
intelligence or human level intelligence
 

3439
01:21:49,650 --> 01:21:51,920
intelligence or human level intelligence
whatever that means

3440
01:21:51,920 --> 01:21:51,930
whatever that means
 

3441
01:21:51,930 --> 01:21:56,330
whatever that means
a huge part of it is social that you

3442
01:21:56,330 --> 01:21:56,340
a huge part of it is social that you
 

3443
01:21:56,340 --> 01:22:00,380
a huge part of it is social that you
know we were evolved to be social and to

3444
01:22:00,380 --> 01:22:00,390
know we were evolved to be social and to
 

3445
01:22:00,390 --> 01:22:02,990
know we were evolved to be social and to
deal with other people and that's just

3446
01:22:02,990 --> 01:22:03,000
deal with other people and that's just
 

3447
01:22:03,000 --> 01:22:06,860
deal with other people and that's just
so ingrained in us that it's hard to

3448
01:22:06,860 --> 01:22:06,870
so ingrained in us that it's hard to
 

3449
01:22:06,870 --> 01:22:10,130
so ingrained in us that it's hard to
separate intelligence from that I I

3450
01:22:10,130 --> 01:22:10,140
separate intelligence from that I I
 

3451
01:22:10,140 --> 01:22:15,080
separate intelligence from that I I
think you know AI for the last 70 years

3452
01:22:15,080 --> 01:22:15,090
think you know AI for the last 70 years
 

3453
01:22:15,090 --> 01:22:17,120
think you know AI for the last 70 years
or however long has been around it it

3454
01:22:17,120 --> 01:22:17,130
or however long has been around it it
 

3455
01:22:17,130 --> 01:22:18,920
or however long has been around it it
has largely been separated there's this

3456
01:22:18,920 --> 01:22:18,930
has largely been separated there's this
 

3457
01:22:18,930 --> 01:22:22,720
has largely been separated there's this
idea that there's like it's kind of very

3458
01:22:22,720 --> 01:22:22,730
idea that there's like it's kind of very
 

3459
01:22:22,730 --> 01:22:25,100
idea that there's like it's kind of very
Cartesian there's this you know thinking

3460
01:22:25,100 --> 01:22:25,110
Cartesian there's this you know thinking
 

3461
01:22:25,110 --> 01:22:27,980
Cartesian there's this you know thinking
thing that we're trying to create but we

3462
01:22:27,980 --> 01:22:27,990
thing that we're trying to create but we
 

3463
01:22:27,990 --> 01:22:29,360
thing that we're trying to create but we
don't care about all this other stuff

3464
01:22:29,360 --> 01:22:29,370
don't care about all this other stuff
 

3465
01:22:29,370 --> 01:22:34,010
don't care about all this other stuff
and I think the other stuff is very

3466
01:22:34,010 --> 01:22:34,020
and I think the other stuff is very
 

3467
01:22:34,020 --> 01:22:36,740
and I think the other stuff is very
fundamental so there's idea that things

3468
01:22:36,740 --> 01:22:36,750
fundamental so there's idea that things
 

3469
01:22:36,750 --> 01:22:38,510
fundamental so there's idea that things
like emotion get in the way of

3470
01:22:38,510 --> 01:22:38,520
like emotion get in the way of
 

3471
01:22:38,520 --> 01:22:41,570
like emotion get in the way of
intelligence as opposed to being an

3472
01:22:41,570 --> 01:22:41,580
intelligence as opposed to being an
 

3473
01:22:41,580 --> 01:22:44,300
intelligence as opposed to being an
integral part and part of it so I mean

3474
01:22:44,300 --> 01:22:44,310
integral part and part of it so I mean
 

3475
01:22:44,310 --> 01:22:47,120
integral part and part of it so I mean
I'm Russian so romanticize the notions

3476
01:22:47,120 --> 01:22:47,130
I'm Russian so romanticize the notions
 

3477
01:22:47,130 --> 01:22:48,830
I'm Russian so romanticize the notions
of emotion and suffering and all that

3478
01:22:48,830 --> 01:22:48,840
of emotion and suffering and all that
 

3479
01:22:48,840 --> 01:22:51,620
of emotion and suffering and all that
kind of fear of mortality those kinds of

3480
01:22:51,620 --> 01:22:51,630
kind of fear of mortality those kinds of
 

3481
01:22:51,630 --> 01:22:56,840
kind of fear of mortality those kinds of
things so I I especially sort of by the

3482
01:22:56,840 --> 01:22:56,850
things so I I especially sort of by the
 

3483
01:22:56,850 --> 01:22:58,220
things so I I especially sort of by the
way did you see that there was this

3484
01:22:58,220 --> 01:22:58,230
way did you see that there was this
 

3485
01:22:58,230 --> 01:22:59,450
way did you see that there was this
recent thing going around the internet

3486
01:22:59,450 --> 01:22:59,460
recent thing going around the internet
 

3487
01:22:59,460 --> 01:23:02,270
recent thing going around the internet
of this so some I think he's a Russian

3488
01:23:02,270 --> 01:23:02,280
of this so some I think he's a Russian
 

3489
01:23:02,280 --> 01:23:04,580
of this so some I think he's a Russian
or some Slavic head had written this

3490
01:23:04,580 --> 01:23:04,590
or some Slavic head had written this
 

3491
01:23:04,590 --> 01:23:07,040
or some Slavic head had written this
thing a sort of anti the idea of super

3492
01:23:07,040 --> 01:23:07,050
thing a sort of anti the idea of super
 

3493
01:23:07,050 --> 01:23:09,320
thing a sort of anti the idea of super
intelligence mmm-hmm I forgot maybes

3494
01:23:09,320 --> 01:23:09,330
intelligence mmm-hmm I forgot maybes
 

3495
01:23:09,330 --> 01:23:11,720
intelligence mmm-hmm I forgot maybes
polish anyway so at all these arguments

3496
01:23:11,720 --> 01:23:11,730
polish anyway so at all these arguments
 

3497
01:23:11,730 --> 01:23:14,750
polish anyway so at all these arguments
and one one was the argument from Slavic

3498
01:23:14,750 --> 01:23:14,760
and one one was the argument from Slavic
 

3499
01:23:14,760 --> 01:23:21,020
and one one was the argument from Slavic
pessimism do you remember what the

3500
01:23:21,020 --> 01:23:21,030
pessimism do you remember what the
 

3501
01:23:21,030 --> 01:23:27,010
pessimism do you remember what the
argument is it's like nothing ever works

3502
01:23:27,010 --> 01:23:27,020

 

3503
01:23:27,020 --> 01:23:29,480

so what what do you think is the role

3504
01:23:29,480 --> 01:23:29,490
so what what do you think is the role
 

3505
01:23:29,490 --> 01:23:32,180
so what what do you think is the role
like that's such a fascinating idea that

3506
01:23:32,180 --> 01:23:32,190
like that's such a fascinating idea that
 

3507
01:23:32,190 --> 01:23:35,300
like that's such a fascinating idea that
the what we perceive as serve the limits

3508
01:23:35,300 --> 01:23:35,310
the what we perceive as serve the limits
 

3509
01:23:35,310 --> 01:23:36,929
the what we perceive as serve the limits
of human

3510
01:23:36,929 --> 01:23:36,939
of human
 

3511
01:23:36,939 --> 01:23:40,319
of human
of the human mind which is emotion and

3512
01:23:40,319 --> 01:23:40,329
of the human mind which is emotion and
 

3513
01:23:40,329 --> 01:23:42,929
of the human mind which is emotion and
fear and all those kinds of things are

3514
01:23:42,929 --> 01:23:42,939
fear and all those kinds of things are
 

3515
01:23:42,939 --> 01:23:46,819
fear and all those kinds of things are
integral to intelligence could could you

3516
01:23:46,819 --> 01:23:46,829
integral to intelligence could could you
 

3517
01:23:46,829 --> 01:23:50,959
integral to intelligence could could you
elaborate on that like what why is that

3518
01:23:50,959 --> 01:23:50,969
elaborate on that like what why is that
 

3519
01:23:50,969 --> 01:23:52,169
elaborate on that like what why is that
important

3520
01:23:52,169 --> 01:23:52,179
important
 

3521
01:23:52,179 --> 01:23:56,370
important
do you think for human level

3522
01:23:56,370 --> 01:23:56,380
do you think for human level
 

3523
01:23:56,380 --> 01:24:00,239
do you think for human level
intelligence at least the way the humans

3524
01:24:00,239 --> 01:24:00,249
intelligence at least the way the humans
 

3525
01:24:00,249 --> 01:24:02,609
intelligence at least the way the humans
work it's a big part of how it affects

3526
01:24:02,609 --> 01:24:02,619
work it's a big part of how it affects
 

3527
01:24:02,619 --> 01:24:05,520
work it's a big part of how it affects
how we perceive the world it affects how

3528
01:24:05,520 --> 01:24:05,530
how we perceive the world it affects how
 

3529
01:24:05,530 --> 01:24:07,830
how we perceive the world it affects how
we make decisions about the world it

3530
01:24:07,830 --> 01:24:07,840
we make decisions about the world it
 

3531
01:24:07,840 --> 01:24:09,089
we make decisions about the world it
affects how we interact with other

3532
01:24:09,089 --> 01:24:09,099
affects how we interact with other
 

3533
01:24:09,099 --> 01:24:12,089
affects how we interact with other
people it affects our understanding of

3534
01:24:12,089 --> 01:24:12,099
people it affects our understanding of
 

3535
01:24:12,099 --> 01:24:15,089
people it affects our understanding of
other people you know for me to

3536
01:24:15,089 --> 01:24:15,099
other people you know for me to
 

3537
01:24:15,099 --> 01:24:20,489
other people you know for me to
understand your what you're going what

3538
01:24:20,489 --> 01:24:20,499
understand your what you're going what
 

3539
01:24:20,499 --> 01:24:22,259
understand your what you're going what
you're likely to do I need to have kind

3540
01:24:22,259 --> 01:24:22,269
you're likely to do I need to have kind
 

3541
01:24:22,269 --> 01:24:24,929
you're likely to do I need to have kind
of a theory of mine and that's very much

3542
01:24:24,929 --> 01:24:24,939
of a theory of mine and that's very much
 

3543
01:24:24,939 --> 01:24:29,129
of a theory of mine and that's very much
a theory of emotions and motivations and

3544
01:24:29,129 --> 01:24:29,139
a theory of emotions and motivations and
 

3545
01:24:29,139 --> 01:24:35,939
a theory of emotions and motivations and
goals and and to understand that I you

3546
01:24:35,939 --> 01:24:35,949
goals and and to understand that I you
 

3547
01:24:35,949 --> 01:24:39,179
goals and and to understand that I you
know we have the this whole system of

3548
01:24:39,179 --> 01:24:39,189
know we have the this whole system of
 

3549
01:24:39,189 --> 01:24:42,779
know we have the this whole system of
you know mirror neurons you know I sort

3550
01:24:42,779 --> 01:24:42,789
you know mirror neurons you know I sort
 

3551
01:24:42,789 --> 01:24:45,979
you know mirror neurons you know I sort
of understand your motivations through

3552
01:24:45,979 --> 01:24:45,989
of understand your motivations through
 

3553
01:24:45,989 --> 01:24:50,729
of understand your motivations through
sort of simulating it myself so you know

3554
01:24:50,729 --> 01:24:50,739
sort of simulating it myself so you know
 

3555
01:24:50,739 --> 01:24:53,600
sort of simulating it myself so you know
it's not something that I can prove

3556
01:24:53,600 --> 01:24:53,610
it's not something that I can prove
 

3557
01:24:53,610 --> 01:24:57,000
it's not something that I can prove
that's necessary but it seems very

3558
01:24:57,000 --> 01:24:57,010
that's necessary but it seems very
 

3559
01:24:57,010 --> 01:25:03,029
that's necessary but it seems very
likely so ok you've written the op-ed in

3560
01:25:03,029 --> 01:25:03,039
likely so ok you've written the op-ed in
 

3561
01:25:03,039 --> 01:25:05,100
likely so ok you've written the op-ed in
New York Times titled we shouldn't be

3562
01:25:05,100 --> 01:25:05,110
New York Times titled we shouldn't be
 

3563
01:25:05,110 --> 01:25:08,009
New York Times titled we shouldn't be
scared by super intelligent AI and it

3564
01:25:08,009 --> 01:25:08,019
scared by super intelligent AI and it
 

3565
01:25:08,019 --> 01:25:10,919
scared by super intelligent AI and it
criticized a little bit just to rustle

3566
01:25:10,919 --> 01:25:10,929
criticized a little bit just to rustle
 

3567
01:25:10,929 --> 01:25:14,790
criticized a little bit just to rustle
in the boss room can you try to

3568
01:25:14,790 --> 01:25:14,800
in the boss room can you try to
 

3569
01:25:14,800 --> 01:25:19,409
in the boss room can you try to
summarize that articles key ideas so it

3570
01:25:19,409 --> 01:25:19,419
summarize that articles key ideas so it
 

3571
01:25:19,419 --> 01:25:22,290
summarize that articles key ideas so it
was spurred by a earlier New York Times

3572
01:25:22,290 --> 01:25:22,300
was spurred by a earlier New York Times
 

3573
01:25:22,300 --> 01:25:24,810
was spurred by a earlier New York Times
op-ed by Stewart Russell which was

3574
01:25:24,810 --> 01:25:24,820
op-ed by Stewart Russell which was
 

3575
01:25:24,820 --> 01:25:27,839
op-ed by Stewart Russell which was
summarizing his book called human

3576
01:25:27,839 --> 01:25:27,849
summarizing his book called human
 

3577
01:25:27,849 --> 01:25:31,109
summarizing his book called human
compatible and the article was saying

3578
01:25:31,109 --> 01:25:31,119
compatible and the article was saying
 

3579
01:25:31,119 --> 01:25:34,890
compatible and the article was saying
you know if we if we have super

3580
01:25:34,890 --> 01:25:34,900
you know if we if we have super
 

3581
01:25:34,900 --> 01:25:38,449
you know if we if we have super
intelligent AI we need to have its

3582
01:25:38,449 --> 01:25:38,459
intelligent AI we need to have its
 

3583
01:25:38,459 --> 01:25:41,790
intelligent AI we need to have its
values align with our values and it has

3584
01:25:41,790 --> 01:25:41,800
values align with our values and it has
 

3585
01:25:41,800 --> 01:25:43,979
values align with our values and it has
to learn about what we really want and

3586
01:25:43,979 --> 01:25:43,989
to learn about what we really want and
 

3587
01:25:43,989 --> 01:25:47,520
to learn about what we really want and
he gave this example what if we have a

3588
01:25:47,520 --> 01:25:47,530
he gave this example what if we have a
 

3589
01:25:47,530 --> 01:25:50,100
he gave this example what if we have a
super intelligent AI and we give it the

3590
01:25:50,100 --> 01:25:50,110
super intelligent AI and we give it the
 

3591
01:25:50,110 --> 01:25:50,459
super intelligent AI and we give it the
prob

3592
01:25:50,459 --> 01:25:50,469
prob
 

3593
01:25:50,469 --> 01:25:54,720
prob
of solving climate change and it decides

3594
01:25:54,720 --> 01:25:54,730
of solving climate change and it decides
 

3595
01:25:54,730 --> 01:25:57,150
of solving climate change and it decides
that the best way to lower the carbon in

3596
01:25:57,150 --> 01:25:57,160
that the best way to lower the carbon in
 

3597
01:25:57,160 --> 01:25:59,180
that the best way to lower the carbon in
the atmosphere is to kill all the humans

3598
01:25:59,180 --> 01:25:59,190
the atmosphere is to kill all the humans
 

3599
01:25:59,190 --> 01:26:02,370
the atmosphere is to kill all the humans
okay so to me that just made no sense at

3600
01:26:02,370 --> 01:26:02,380
okay so to me that just made no sense at
 

3601
01:26:02,380 --> 01:26:08,910
okay so to me that just made no sense at
all because a super intelligent AI first

3602
01:26:08,910 --> 01:26:08,920
all because a super intelligent AI first
 

3603
01:26:08,920 --> 01:26:10,709
all because a super intelligent AI first
of all thinking what trying to figure

3604
01:26:10,709 --> 01:26:10,719
of all thinking what trying to figure
 

3605
01:26:10,719 --> 01:26:13,100
of all thinking what trying to figure
out what what super intelligence means

3606
01:26:13,100 --> 01:26:13,110
out what what super intelligence means
 

3607
01:26:13,110 --> 01:26:18,450
out what what super intelligence means
and it doesn't it seems that something

3608
01:26:18,450 --> 01:26:18,460
and it doesn't it seems that something
 

3609
01:26:18,460 --> 01:26:22,560
and it doesn't it seems that something
that super intelligent can't just be

3610
01:26:22,560 --> 01:26:22,570
that super intelligent can't just be
 

3611
01:26:22,570 --> 01:26:24,600
that super intelligent can't just be
intelligent along this one dimension of

3612
01:26:24,600 --> 01:26:24,610
intelligent along this one dimension of
 

3613
01:26:24,610 --> 01:26:26,880
intelligent along this one dimension of
okay I'm gonna figure out all the steps

3614
01:26:26,880 --> 01:26:26,890
okay I'm gonna figure out all the steps
 

3615
01:26:26,890 --> 01:26:29,610
okay I'm gonna figure out all the steps
the best optimal path to solving climate

3616
01:26:29,610 --> 01:26:29,620
the best optimal path to solving climate
 

3617
01:26:29,620 --> 01:26:32,430
the best optimal path to solving climate
change and not be intelligent enough to

3618
01:26:32,430 --> 01:26:32,440
change and not be intelligent enough to
 

3619
01:26:32,440 --> 01:26:35,250
change and not be intelligent enough to
figure out that humans don't want to be

3620
01:26:35,250 --> 01:26:35,260
figure out that humans don't want to be
 

3621
01:26:35,260 --> 01:26:37,979
figure out that humans don't want to be
killed that you could get to one without

3622
01:26:37,979 --> 01:26:37,989
killed that you could get to one without
 

3623
01:26:37,989 --> 01:26:41,310
killed that you could get to one without
having the other and you know

3624
01:26:41,310 --> 01:26:41,320
having the other and you know
 

3625
01:26:41,320 --> 01:26:44,340
having the other and you know
bostrm in his book talks about the

3626
01:26:44,340 --> 01:26:44,350
bostrm in his book talks about the
 

3627
01:26:44,350 --> 01:26:47,010
bostrm in his book talks about the
orthogonality hypothesis where he says

3628
01:26:47,010 --> 01:26:47,020
orthogonality hypothesis where he says
 

3629
01:26:47,020 --> 01:26:52,050
orthogonality hypothesis where he says
he thinks that systems I can't remember

3630
01:26:52,050 --> 01:26:52,060
he thinks that systems I can't remember
 

3631
01:26:52,060 --> 01:26:53,400
he thinks that systems I can't remember
exactly what it is but it like a systems

3632
01:26:53,400 --> 01:26:53,410
exactly what it is but it like a systems
 

3633
01:26:53,410 --> 01:26:57,450
exactly what it is but it like a systems
goals and it's uh values don't have to

3634
01:26:57,450 --> 01:26:57,460
goals and it's uh values don't have to
 

3635
01:26:57,460 --> 01:26:59,640
goals and it's uh values don't have to
be aligned there's some orthogonal 'ti

3636
01:26:59,640 --> 01:26:59,650
be aligned there's some orthogonal 'ti
 

3637
01:26:59,650 --> 01:27:02,010
be aligned there's some orthogonal 'ti
there which didn't make any sense to me

3638
01:27:02,010 --> 01:27:02,020
there which didn't make any sense to me
 

3639
01:27:02,020 --> 01:27:05,510
there which didn't make any sense to me
so you're saying it in any system that's

3640
01:27:05,510 --> 01:27:05,520
so you're saying it in any system that's
 

3641
01:27:05,520 --> 01:27:07,680
so you're saying it in any system that's
sufficiently not even super intelligent

3642
01:27:07,680 --> 01:27:07,690
sufficiently not even super intelligent
 

3643
01:27:07,690 --> 01:27:08,910
sufficiently not even super intelligent
but is it approach greater greater

3644
01:27:08,910 --> 01:27:08,920
but is it approach greater greater
 

3645
01:27:08,920 --> 01:27:11,250
but is it approach greater greater
intelligence there's a holistic nature

3646
01:27:11,250 --> 01:27:11,260
intelligence there's a holistic nature
 

3647
01:27:11,260 --> 01:27:13,350
intelligence there's a holistic nature
that will sort of attention that will

3648
01:27:13,350 --> 01:27:13,360
that will sort of attention that will
 

3649
01:27:13,360 --> 01:27:15,060
that will sort of attention that will
naturally emerge

3650
01:27:15,060 --> 01:27:15,070
naturally emerge
 

3651
01:27:15,070 --> 01:27:16,979
naturally emerge
yes events it from sort of any one

3652
01:27:16,979 --> 01:27:16,989
yes events it from sort of any one
 

3653
01:27:16,989 --> 01:27:19,620
yes events it from sort of any one
dimension running away yeah yeah exactly

3654
01:27:19,620 --> 01:27:19,630
dimension running away yeah yeah exactly
 

3655
01:27:19,630 --> 01:27:22,650
dimension running away yeah yeah exactly
so so you know

3656
01:27:22,650 --> 01:27:22,660
so so you know
 

3657
01:27:22,660 --> 01:27:25,439
so so you know
bostrm had this example of the the

3658
01:27:25,439 --> 01:27:25,449
bostrm had this example of the the
 

3659
01:27:25,449 --> 01:27:28,950
bostrm had this example of the the
super intelligent AI that that makes

3660
01:27:28,950 --> 01:27:28,960
super intelligent AI that that makes
 

3661
01:27:28,960 --> 01:27:30,689
super intelligent AI that that makes
that turns the world into paperclips

3662
01:27:30,689 --> 01:27:30,699
that turns the world into paperclips
 

3663
01:27:30,699 --> 01:27:33,180
that turns the world into paperclips
because its job is to make paper clips

3664
01:27:33,180 --> 01:27:33,190
because its job is to make paper clips
 

3665
01:27:33,190 --> 01:27:35,820
because its job is to make paper clips
or something and that just as a thought

3666
01:27:35,820 --> 01:27:35,830
or something and that just as a thought
 

3667
01:27:35,830 --> 01:27:37,700
or something and that just as a thought
experiment didn't make any sense to me

3668
01:27:37,700 --> 01:27:37,710
experiment didn't make any sense to me
 

3669
01:27:37,710 --> 01:27:40,950
experiment didn't make any sense to me
well as a thought experiment or the

3670
01:27:40,950 --> 01:27:40,960
well as a thought experiment or the
 

3671
01:27:40,960 --> 01:27:43,050
well as a thought experiment or the
thing that could possibly be realized

3672
01:27:43,050 --> 01:27:43,060
thing that could possibly be realized
 

3673
01:27:43,060 --> 01:27:46,920
thing that could possibly be realized
either so so I think that you know what

3674
01:27:46,920 --> 01:27:46,930
either so so I think that you know what
 

3675
01:27:46,930 --> 01:27:48,810
either so so I think that you know what
my op ed was trying to do was say that

3676
01:27:48,810 --> 01:27:48,820
my op ed was trying to do was say that
 

3677
01:27:48,820 --> 01:27:51,330
my op ed was trying to do was say that
that intelligence is more complex than

3678
01:27:51,330 --> 01:27:51,340
that intelligence is more complex than
 

3679
01:27:51,340 --> 01:27:56,400
that intelligence is more complex than
these people are presenting it that it's

3680
01:27:56,400 --> 01:27:56,410
these people are presenting it that it's
 

3681
01:27:56,410 --> 01:27:59,400
these people are presenting it that it's
not like it's not so separable the

3682
01:27:59,400 --> 01:27:59,410
not like it's not so separable the
 

3683
01:27:59,410 --> 01:28:04,229
not like it's not so separable the
rationality the the values the emotions

3684
01:28:04,229 --> 01:28:04,239
rationality the the values the emotions
 

3685
01:28:04,239 --> 01:28:08,010
rationality the the values the emotions
all of that that it's the the view that

3686
01:28:08,010 --> 01:28:08,020
all of that that it's the the view that
 

3687
01:28:08,020 --> 01:28:10,020
all of that that it's the the view that
you could separate all these dimensions

3688
01:28:10,020 --> 01:28:10,030
you could separate all these dimensions
 

3689
01:28:10,030 --> 01:28:12,180
you could separate all these dimensions
and build the machine that has one of

3690
01:28:12,180 --> 01:28:12,190
and build the machine that has one of
 

3691
01:28:12,190 --> 01:28:13,590
and build the machine that has one of
these dimensions and it's super

3692
01:28:13,590 --> 01:28:13,600
these dimensions and it's super
 

3693
01:28:13,600 --> 01:28:15,630
these dimensions and it's super
intelligent in one dimension but it

3694
01:28:15,630 --> 01:28:15,640
intelligent in one dimension but it
 

3695
01:28:15,640 --> 01:28:17,250
intelligent in one dimension but it
doesn't have any of the other dimensions

3696
01:28:17,250 --> 01:28:17,260
doesn't have any of the other dimensions
 

3697
01:28:17,260 --> 01:28:22,890
doesn't have any of the other dimensions
that's what I was trying to criticize

3698
01:28:22,890 --> 01:28:22,900
that's what I was trying to criticize
 

3699
01:28:22,900 --> 01:28:25,020
that's what I was trying to criticize
that that that I don't believe that

3700
01:28:25,020 --> 01:28:25,030
that that that I don't believe that
 

3701
01:28:25,030 --> 01:28:29,790
that that that I don't believe that
so can I read a few sentences from

3702
01:28:29,790 --> 01:28:29,800
so can I read a few sentences from
 

3703
01:28:29,800 --> 01:28:34,380
so can I read a few sentences from
yoshua bengio who is always super

3704
01:28:34,380 --> 01:28:34,390
yoshua bengio who is always super
 

3705
01:28:34,390 --> 01:28:39,959
yoshua bengio who is always super
eloquent so he writes I have the same

3706
01:28:39,959 --> 01:28:39,969
eloquent so he writes I have the same
 

3707
01:28:39,969 --> 01:28:42,000
eloquent so he writes I have the same
impression as Melanie that our cognitive

3708
01:28:42,000 --> 01:28:42,010
impression as Melanie that our cognitive
 

3709
01:28:42,010 --> 01:28:43,950
impression as Melanie that our cognitive
biases are linked with our ability to

3710
01:28:43,950 --> 01:28:43,960
biases are linked with our ability to
 

3711
01:28:43,960 --> 01:28:46,709
biases are linked with our ability to
learn to solve many problems they may

3712
01:28:46,709 --> 01:28:46,719
learn to solve many problems they may
 

3713
01:28:46,719 --> 01:28:50,430
learn to solve many problems they may
also be a limiting factor for AI however

3714
01:28:50,430 --> 01:28:50,440
also be a limiting factor for AI however
 

3715
01:28:50,440 --> 01:28:54,810
also be a limiting factor for AI however
this is a may in quotes things may also

3716
01:28:54,810 --> 01:28:54,820
this is a may in quotes things may also
 

3717
01:28:54,820 --> 01:28:56,340
this is a may in quotes things may also
turn out differently and there's a lot

3718
01:28:56,340 --> 01:28:56,350
turn out differently and there's a lot
 

3719
01:28:56,350 --> 01:28:57,930
turn out differently and there's a lot
of uncertainty about the capabilities of

3720
01:28:57,930 --> 01:28:57,940
of uncertainty about the capabilities of
 

3721
01:28:57,940 --> 01:29:01,680
of uncertainty about the capabilities of
future machines but more importantly for

3722
01:29:01,680 --> 01:29:01,690
future machines but more importantly for
 

3723
01:29:01,690 --> 01:29:04,020
future machines but more importantly for
me the value alignment problem is a

3724
01:29:04,020 --> 01:29:04,030
me the value alignment problem is a
 

3725
01:29:04,030 --> 01:29:06,690
me the value alignment problem is a
problem well before we reached some

3726
01:29:06,690 --> 01:29:06,700
problem well before we reached some
 

3727
01:29:06,700 --> 01:29:09,030
problem well before we reached some
hypothetical super intelligence it is

3728
01:29:09,030 --> 01:29:09,040
hypothetical super intelligence it is
 

3729
01:29:09,040 --> 01:29:11,040
hypothetical super intelligence it is
already posing a problem in the form of

3730
01:29:11,040 --> 01:29:11,050
already posing a problem in the form of
 

3731
01:29:11,050 --> 01:29:14,880
already posing a problem in the form of
super powerful companies whose objective

3732
01:29:14,880 --> 01:29:14,890
super powerful companies whose objective
 

3733
01:29:14,890 --> 01:29:17,400
super powerful companies whose objective
function may not be sufficiently aligned

3734
01:29:17,400 --> 01:29:17,410
function may not be sufficiently aligned
 

3735
01:29:17,410 --> 01:29:18,840
function may not be sufficiently aligned
with humanity's general well-being

3736
01:29:18,840 --> 01:29:18,850
with humanity's general well-being
 

3737
01:29:18,850 --> 01:29:20,790
with humanity's general well-being
creating all kinds of harmful side

3738
01:29:20,790 --> 01:29:20,800
creating all kinds of harmful side
 

3739
01:29:20,800 --> 01:29:25,380
creating all kinds of harmful side
effects so he goes on to argue that at

3740
01:29:25,380 --> 01:29:25,390
effects so he goes on to argue that at
 

3741
01:29:25,390 --> 01:29:28,830
effects so he goes on to argue that at
you know the orthogonality and those

3742
01:29:28,830 --> 01:29:28,840
you know the orthogonality and those
 

3743
01:29:28,840 --> 01:29:30,360
you know the orthogonality and those
kinds of things the concerns of just

3744
01:29:30,360 --> 01:29:30,370
kinds of things the concerns of just
 

3745
01:29:30,370 --> 01:29:34,440
kinds of things the concerns of just
aligning values with the capabilities of

3746
01:29:34,440 --> 01:29:34,450
aligning values with the capabilities of
 

3747
01:29:34,450 --> 01:29:36,500
aligning values with the capabilities of
the system is something that might come

3748
01:29:36,500 --> 01:29:36,510
the system is something that might come
 

3749
01:29:36,510 --> 01:29:39,330
the system is something that might come
long before we reach anything like in

3750
01:29:39,330 --> 01:29:39,340
long before we reach anything like in
 

3751
01:29:39,340 --> 01:29:41,640
long before we reach anything like in
super intelligence so your criticism

3752
01:29:41,640 --> 01:29:41,650
super intelligence so your criticism
 

3753
01:29:41,650 --> 01:29:44,520
super intelligence so your criticism
it's kind of really nice as saying this

3754
01:29:44,520 --> 01:29:44,530
it's kind of really nice as saying this
 

3755
01:29:44,530 --> 01:29:47,130
it's kind of really nice as saying this
idea of super intelligence systems seem

3756
01:29:47,130 --> 01:29:47,140
idea of super intelligence systems seem
 

3757
01:29:47,140 --> 01:29:49,140
idea of super intelligence systems seem
to be dismissing fundamental parts of

3758
01:29:49,140 --> 01:29:49,150
to be dismissing fundamental parts of
 

3759
01:29:49,150 --> 01:29:51,000
to be dismissing fundamental parts of
what intelligence would take and then

3760
01:29:51,000 --> 01:29:51,010
what intelligence would take and then
 

3761
01:29:51,010 --> 01:29:55,770
what intelligence would take and then
you know kind of says yes but if we look

3762
01:29:55,770 --> 01:29:55,780
you know kind of says yes but if we look
 

3763
01:29:55,780 --> 01:29:56,790
you know kind of says yes but if we look
at systems that are much less

3764
01:29:56,790 --> 01:29:56,800
at systems that are much less
 

3765
01:29:56,800 --> 01:29:59,790
at systems that are much less
intelligent there might be these same

3766
01:29:59,790 --> 01:29:59,800
intelligent there might be these same
 

3767
01:29:59,800 --> 01:30:04,140
intelligent there might be these same
kinds of problems that emerge sure but I

3768
01:30:04,140 --> 01:30:04,150
kinds of problems that emerge sure but I
 

3769
01:30:04,150 --> 01:30:06,750
kinds of problems that emerge sure but I
guess the example that he gives there of

3770
01:30:06,750 --> 01:30:06,760
guess the example that he gives there of
 

3771
01:30:06,760 --> 01:30:09,930
guess the example that he gives there of
these corporations that's people right

3772
01:30:09,930 --> 01:30:09,940
these corporations that's people right
 

3773
01:30:09,940 --> 01:30:12,450
these corporations that's people right
those are people's values I mean we're

3774
01:30:12,450 --> 01:30:12,460
those are people's values I mean we're
 

3775
01:30:12,460 --> 01:30:15,090
those are people's values I mean we're
talking about people the corporations

3776
01:30:15,090 --> 01:30:15,100
talking about people the corporations
 

3777
01:30:15,100 --> 01:30:18,100
talking about people the corporations
are their value

3778
01:30:18,100 --> 01:30:18,110
are their value
 

3779
01:30:18,110 --> 01:30:20,890
are their value
are the values of the people who run

3780
01:30:20,890 --> 01:30:20,900
are the values of the people who run
 

3781
01:30:20,900 --> 01:30:22,839
are the values of the people who run
those corporations but the idea is the

3782
01:30:22,839 --> 01:30:22,849
those corporations but the idea is the
 

3783
01:30:22,849 --> 01:30:25,240
those corporations but the idea is the
algorithm that's right so does the

3784
01:30:25,240 --> 01:30:25,250
algorithm that's right so does the
 

3785
01:30:25,250 --> 01:30:27,939
algorithm that's right so does the
fundamental person that the fundamental

3786
01:30:27,939 --> 01:30:27,949
fundamental person that the fundamental
 

3787
01:30:27,949 --> 01:30:30,729
fundamental person that the fundamental
element of what does the bad thing as a

3788
01:30:30,729 --> 01:30:30,739
element of what does the bad thing as a
 

3789
01:30:30,739 --> 01:30:31,689
element of what does the bad thing as a
human being

3790
01:30:31,689 --> 01:30:31,699
human being
 

3791
01:30:31,699 --> 01:30:35,379
human being
yeah but the the algorithm kind of

3792
01:30:35,379 --> 01:30:35,389
yeah but the the algorithm kind of
 

3793
01:30:35,389 --> 01:30:38,140
yeah but the the algorithm kind of
controls the behavior this mass of human

3794
01:30:38,140 --> 01:30:38,150
controls the behavior this mass of human
 

3795
01:30:38,150 --> 01:30:41,589
controls the behavior this mass of human
beings which help whatever for a company

3796
01:30:41,589 --> 01:30:41,599
beings which help whatever for a company
 

3797
01:30:41,599 --> 01:30:43,839
beings which help whatever for a company
that's the outs of for example if it's

3798
01:30:43,839 --> 01:30:43,849
that's the outs of for example if it's
 

3799
01:30:43,849 --> 01:30:45,459
that's the outs of for example if it's
advertisement driving company that

3800
01:30:45,459 --> 01:30:45,469
advertisement driving company that
 

3801
01:30:45,469 --> 01:30:49,810
advertisement driving company that
recommends certain things and encourages

3802
01:30:49,810 --> 01:30:49,820
recommends certain things and encourages
 

3803
01:30:49,820 --> 01:30:52,660
recommends certain things and encourages
engagement so it gets money by

3804
01:30:52,660 --> 01:30:52,670
engagement so it gets money by
 

3805
01:30:52,670 --> 01:30:55,689
engagement so it gets money by
encouraging engagement and therefore the

3806
01:30:55,689 --> 01:30:55,699
encouraging engagement and therefore the
 

3807
01:30:55,699 --> 01:30:59,200
encouraging engagement and therefore the
company more and more it's like the

3808
01:30:59,200 --> 01:30:59,210
company more and more it's like the
 

3809
01:30:59,210 --> 01:31:02,100
company more and more it's like the
cycle that builds an algorithm that

3810
01:31:02,100 --> 01:31:02,110
cycle that builds an algorithm that
 

3811
01:31:02,110 --> 01:31:04,419
cycle that builds an algorithm that
enforces more engagement and made

3812
01:31:04,419 --> 01:31:04,429
enforces more engagement and made
 

3813
01:31:04,429 --> 01:31:06,250
enforces more engagement and made
perhaps more division in the culture and

3814
01:31:06,250 --> 01:31:06,260
perhaps more division in the culture and
 

3815
01:31:06,260 --> 01:31:08,589
perhaps more division in the culture and
so on so on again I guess the question

3816
01:31:08,589 --> 01:31:08,599
so on so on again I guess the question
 

3817
01:31:08,599 --> 01:31:13,569
so on so on again I guess the question
here is sort of who has the agency so

3818
01:31:13,569 --> 01:31:13,579
here is sort of who has the agency so
 

3819
01:31:13,579 --> 01:31:15,490
here is sort of who has the agency so
you might say for instance we don't want

3820
01:31:15,490 --> 01:31:15,500
you might say for instance we don't want
 

3821
01:31:15,500 --> 01:31:19,470
you might say for instance we don't want
our algorithms to be racist right and

3822
01:31:19,470 --> 01:31:19,480
our algorithms to be racist right and
 

3823
01:31:19,480 --> 01:31:22,209
our algorithms to be racist right and
facial recognition you know some people

3824
01:31:22,209 --> 01:31:22,219
facial recognition you know some people
 

3825
01:31:22,219 --> 01:31:23,770
facial recognition you know some people
have criticized some facial recognition

3826
01:31:23,770 --> 01:31:23,780
have criticized some facial recognition
 

3827
01:31:23,780 --> 01:31:25,569
have criticized some facial recognition
systems as being racist because they're

3828
01:31:25,569 --> 01:31:25,579
systems as being racist because they're
 

3829
01:31:25,579 --> 01:31:30,010
systems as being racist because they're
not as good on darker skin and lighter

3830
01:31:30,010 --> 01:31:30,020
not as good on darker skin and lighter
 

3831
01:31:30,020 --> 01:31:33,459
not as good on darker skin and lighter
skin okay but the agency there the the

3832
01:31:33,459 --> 01:31:33,469
skin okay but the agency there the the
 

3833
01:31:33,469 --> 01:31:36,220
skin okay but the agency there the the
the the actual algal recognition

3834
01:31:36,220 --> 01:31:36,230
the the actual algal recognition
 

3835
01:31:36,230 --> 01:31:38,919
the the actual algal recognition
algorithm isn't what has the agency it's

3836
01:31:38,919 --> 01:31:38,929
algorithm isn't what has the agency it's
 

3837
01:31:38,929 --> 01:31:41,649
algorithm isn't what has the agency it's
it's not the racist thing right it's

3838
01:31:41,649 --> 01:31:41,659
it's not the racist thing right it's
 

3839
01:31:41,659 --> 01:31:46,479
it's not the racist thing right it's
it's the that the I don't know the the

3840
01:31:46,479 --> 01:31:46,489
it's the that the I don't know the the
 

3841
01:31:46,489 --> 01:31:49,419
it's the that the I don't know the the
combination of the training data the

3842
01:31:49,419 --> 01:31:49,429
combination of the training data the
 

3843
01:31:49,429 --> 01:31:52,479
combination of the training data the
cameras being used I whatever but my

3844
01:31:52,479 --> 01:31:52,489
cameras being used I whatever but my
 

3845
01:31:52,489 --> 01:31:55,240
cameras being used I whatever but my
understanding of and I'll say I told

3846
01:31:55,240 --> 01:31:55,250
understanding of and I'll say I told
 

3847
01:31:55,250 --> 01:31:57,189
understanding of and I'll say I told
agree with Benjy oh there that he you

3848
01:31:57,189 --> 01:31:57,199
agree with Benjy oh there that he you
 

3849
01:31:57,199 --> 01:31:59,649
agree with Benjy oh there that he you
know I think there are these value

3850
01:31:59,649 --> 01:31:59,659
know I think there are these value
 

3851
01:31:59,659 --> 01:32:05,290
know I think there are these value
issues with our use of algorithms but my

3852
01:32:05,290 --> 01:32:05,300
issues with our use of algorithms but my
 

3853
01:32:05,300 --> 01:32:09,040
issues with our use of algorithms but my
understanding of what Russell's argument

3854
01:32:09,040 --> 01:32:09,050
understanding of what Russell's argument
 

3855
01:32:09,050 --> 01:32:13,149
understanding of what Russell's argument
was is more that the algorithm itself

3856
01:32:13,149 --> 01:32:13,159
was is more that the algorithm itself
 

3857
01:32:13,159 --> 01:32:16,209
was is more that the algorithm itself
has the agency now it's the thing that's

3858
01:32:16,209 --> 01:32:16,219
has the agency now it's the thing that's
 

3859
01:32:16,219 --> 01:32:18,520
has the agency now it's the thing that's
making the decisions and it's the thing

3860
01:32:18,520 --> 01:32:18,530
making the decisions and it's the thing
 

3861
01:32:18,530 --> 01:32:22,479
making the decisions and it's the thing
that has what we would call values yes

3862
01:32:22,479 --> 01:32:22,489
that has what we would call values yes
 

3863
01:32:22,489 --> 01:32:25,000
that has what we would call values yes
so whether that's just a matter of

3864
01:32:25,000 --> 01:32:25,010
so whether that's just a matter of
 

3865
01:32:25,010 --> 01:32:26,740
so whether that's just a matter of
degree you know it's hard it's hard to

3866
01:32:26,740 --> 01:32:26,750
degree you know it's hard it's hard to
 

3867
01:32:26,750 --> 01:32:28,569
degree you know it's hard it's hard to
say right because but I would say that's

3868
01:32:28,569 --> 01:32:28,579
say right because but I would say that's
 

3869
01:32:28,579 --> 01:32:31,179
say right because but I would say that's
sort of qualitatively different than a

3870
01:32:31,179 --> 01:32:31,189
sort of qualitatively different than a
 

3871
01:32:31,189 --> 01:32:36,310
sort of qualitatively different than a
face recognition neural network and to

3872
01:32:36,310 --> 01:32:36,320
face recognition neural network and to
 

3873
01:32:36,320 --> 01:32:39,100
face recognition neural network and to
broadly linger on that point if you look

3874
01:32:39,100 --> 01:32:39,110
broadly linger on that point if you look
 

3875
01:32:39,110 --> 01:32:42,429
broadly linger on that point if you look
at Elon Musk goes to a rustle or bostrm

3876
01:32:42,429 --> 01:32:42,439
at Elon Musk goes to a rustle or bostrm
 

3877
01:32:42,439 --> 01:32:44,770
at Elon Musk goes to a rustle or bostrm
people who are worried about existential

3878
01:32:44,770 --> 01:32:44,780
people who are worried about existential
 

3879
01:32:44,780 --> 01:32:47,469
people who are worried about existential
risks of AI however far into the future

3880
01:32:47,469 --> 01:32:47,479
risks of AI however far into the future
 

3881
01:32:47,479 --> 01:32:50,290
risks of AI however far into the future
the argument goes is it eventually

3882
01:32:50,290 --> 01:32:50,300
the argument goes is it eventually
 

3883
01:32:50,300 --> 01:32:52,089
the argument goes is it eventually
happens we don't know how far but it

3884
01:32:52,089 --> 01:32:52,099
happens we don't know how far but it
 

3885
01:32:52,099 --> 01:32:53,020
happens we don't know how far but it
eventually happens

3886
01:32:53,020 --> 01:32:53,030
eventually happens
 

3887
01:32:53,030 --> 01:32:56,350
eventually happens
do you share any of those concerns and

3888
01:32:56,350 --> 01:32:56,360
do you share any of those concerns and
 

3889
01:32:56,360 --> 01:32:59,020
do you share any of those concerns and
what kind of concerns in general do you

3890
01:32:59,020 --> 01:32:59,030
what kind of concerns in general do you
 

3891
01:32:59,030 --> 01:33:01,540
what kind of concerns in general do you
have a body I that approach anything

3892
01:33:01,540 --> 01:33:01,550
have a body I that approach anything
 

3893
01:33:01,550 --> 01:33:07,149
have a body I that approach anything
like existential threat to humanity so I

3894
01:33:07,149 --> 01:33:07,159
like existential threat to humanity so I
 

3895
01:33:07,159 --> 01:33:11,799
like existential threat to humanity so I
would say yes it's possible but I think

3896
01:33:11,799 --> 01:33:11,809
would say yes it's possible but I think
 

3897
01:33:11,809 --> 01:33:15,100
would say yes it's possible but I think
there's a lot more closer in existential

3898
01:33:15,100 --> 01:33:15,110
there's a lot more closer in existential
 

3899
01:33:15,110 --> 01:33:16,540
there's a lot more closer in existential
threats you had as you said like a

3900
01:33:16,540 --> 01:33:16,550
threats you had as you said like a
 

3901
01:33:16,550 --> 01:33:19,330
threats you had as you said like a
hundred years for so your times more

3902
01:33:19,330 --> 01:33:19,340
hundred years for so your times more
 

3903
01:33:19,340 --> 01:33:20,830
hundred years for so your times more
more than a hundred more than a hundred

3904
01:33:20,830 --> 01:33:20,840
more than a hundred more than a hundred
 

3905
01:33:20,840 --> 01:33:22,839
more than a hundred more than a hundred
years and so that maybe even more than

3906
01:33:22,839 --> 01:33:22,849
years and so that maybe even more than
 

3907
01:33:22,849 --> 01:33:25,000
years and so that maybe even more than
500 years I don't I don't know I mean

3908
01:33:25,000 --> 01:33:25,010
500 years I don't I don't know I mean
 

3909
01:33:25,010 --> 01:33:27,520
500 years I don't I don't know I mean
it's so the existential threats are so

3910
01:33:27,520 --> 01:33:27,530
it's so the existential threats are so
 

3911
01:33:27,530 --> 01:33:30,939
it's so the existential threats are so
far out that the future is the immune

3912
01:33:30,939 --> 01:33:30,949
far out that the future is the immune
 

3913
01:33:30,949 --> 01:33:32,350
far out that the future is the immune
there'll be a million different

3914
01:33:32,350 --> 01:33:32,360
there'll be a million different
 

3915
01:33:32,360 --> 01:33:34,149
there'll be a million different
technologies that we can't even predict

3916
01:33:34,149 --> 01:33:34,159
technologies that we can't even predict
 

3917
01:33:34,159 --> 01:33:35,739
technologies that we can't even predict
now that will fundamentally change the

3918
01:33:35,739 --> 01:33:35,749
now that will fundamentally change the
 

3919
01:33:35,749 --> 01:33:38,679
now that will fundamentally change the
nature of our behavior reality society

3920
01:33:38,679 --> 01:33:38,689
nature of our behavior reality society
 

3921
01:33:38,689 --> 01:33:41,080
nature of our behavior reality society
and so on before then I think so I think

3922
01:33:41,080 --> 01:33:41,090
and so on before then I think so I think
 

3923
01:33:41,090 --> 01:33:43,709
and so on before then I think so I think
so and you know we have so many other

3924
01:33:43,709 --> 01:33:43,719
so and you know we have so many other
 

3925
01:33:43,719 --> 01:33:46,239
so and you know we have so many other
pressing existential threats going on

3926
01:33:46,239 --> 01:33:46,249
pressing existential threats going on
 

3927
01:33:46,249 --> 01:33:48,779
pressing existential threats going on
new hangouts even their nuclear weapons

3928
01:33:48,779 --> 01:33:48,789
new hangouts even their nuclear weapons
 

3929
01:33:48,789 --> 01:33:52,650
new hangouts even their nuclear weapons
climate problems you know

3930
01:33:52,650 --> 01:33:52,660
climate problems you know
 

3931
01:33:52,660 --> 01:33:58,450
climate problems you know
poverty possible pandemics that you can

3932
01:33:58,450 --> 01:33:58,460
poverty possible pandemics that you can
 

3933
01:33:58,460 --> 01:34:00,940
poverty possible pandemics that you can
go on and on and I think though you know

3934
01:34:00,940 --> 01:34:00,950
go on and on and I think though you know
 

3935
01:34:00,950 --> 01:34:04,420
go on and on and I think though you know
worrying about existential threat from

3936
01:34:04,420 --> 01:34:04,430
worrying about existential threat from
 

3937
01:34:04,430 --> 01:34:12,730
worrying about existential threat from
AI is it's not the best priority for

3938
01:34:12,730 --> 01:34:12,740
AI is it's not the best priority for
 

3939
01:34:12,740 --> 01:34:14,080
AI is it's not the best priority for
what we should be worried about that

3940
01:34:14,080 --> 01:34:14,090
what we should be worried about that
 

3941
01:34:14,090 --> 01:34:15,250
what we should be worried about that
that's kind of my view because we're so

3942
01:34:15,250 --> 01:34:15,260
that's kind of my view because we're so
 

3943
01:34:15,260 --> 01:34:19,930
that's kind of my view because we're so
far away but I you know I I'm not I'm

3944
01:34:19,930 --> 01:34:19,940
far away but I you know I I'm not I'm
 

3945
01:34:19,940 --> 01:34:23,730
far away but I you know I I'm not I'm
not necessarily criticizing Russell or

3946
01:34:23,730 --> 01:34:23,740
not necessarily criticizing Russell or
 

3947
01:34:23,740 --> 01:34:26,410
not necessarily criticizing Russell or
bostrm or whoever for worrying about

3948
01:34:26,410 --> 01:34:26,420
bostrm or whoever for worrying about
 

3949
01:34:26,420 --> 01:34:28,570
bostrm or whoever for worrying about
that and I'm I think it's some some

3950
01:34:28,570 --> 01:34:28,580
that and I'm I think it's some some
 

3951
01:34:28,580 --> 01:34:30,070
that and I'm I think it's some some
people should be worried about it it's

3952
01:34:30,070 --> 01:34:30,080
people should be worried about it it's
 

3953
01:34:30,080 --> 01:34:32,650
people should be worried about it it's
it's certainly fine but I I was more

3954
01:34:32,650 --> 01:34:32,660
it's certainly fine but I I was more
 

3955
01:34:32,660 --> 01:34:36,040
it's certainly fine but I I was more
sort of getting at their their view of

3956
01:34:36,040 --> 01:34:36,050
sort of getting at their their view of
 

3957
01:34:36,050 --> 01:34:39,190
sort of getting at their their view of
intelligible intelligence is mmm-hmm so

3958
01:34:39,190 --> 01:34:39,200
intelligible intelligence is mmm-hmm so
 

3959
01:34:39,200 --> 01:34:40,780
intelligible intelligence is mmm-hmm so
I was more focusing on like their view

3960
01:34:40,780 --> 01:34:40,790
I was more focusing on like their view
 

3961
01:34:40,790 --> 01:34:48,460
I was more focusing on like their view
of the super intelligence then uh just

3962
01:34:48,460 --> 01:34:48,470
of the super intelligence then uh just
 

3963
01:34:48,470 --> 01:34:51,400
of the super intelligence then uh just
the fact of them worrying and the title

3964
01:34:51,400 --> 01:34:51,410
the fact of them worrying and the title
 

3965
01:34:51,410 --> 01:34:53,860
the fact of them worrying and the title
of the article was written by the the

3966
01:34:53,860 --> 01:34:53,870
of the article was written by the the
 

3967
01:34:53,870 --> 01:34:55,360
of the article was written by the the
New York Times editors I wouldn't have

3968
01:34:55,360 --> 01:34:55,370
New York Times editors I wouldn't have
 

3969
01:34:55,370 --> 01:34:58,480
New York Times editors I wouldn't have
called it that we shouldn't be scared by

3970
01:34:58,480 --> 01:34:58,490
called it that we shouldn't be scared by
 

3971
01:34:58,490 --> 01:35:00,700
called it that we shouldn't be scared by
super intelligent and no if you wrote it

3972
01:35:00,700 --> 01:35:00,710
super intelligent and no if you wrote it
 

3973
01:35:00,710 --> 01:35:02,650
super intelligent and no if you wrote it
be like we should redefine what you mean

3974
01:35:02,650 --> 01:35:02,660
be like we should redefine what you mean
 

3975
01:35:02,660 --> 01:35:05,650
be like we should redefine what you mean
by super in I actually said it said you

3976
01:35:05,650 --> 01:35:05,660
by super in I actually said it said you
 

3977
01:35:05,660 --> 01:35:07,270
by super in I actually said it said you
know something like super intelligence

3978
01:35:07,270 --> 01:35:07,280
know something like super intelligence
 

3979
01:35:07,280 --> 01:35:16,080
know something like super intelligence
is not is is not a sort of coherent idea

3980
01:35:16,080 --> 01:35:16,090

 

3981
01:35:16,090 --> 01:35:18,730

that's not like it's only New York Times

3982
01:35:18,730 --> 01:35:18,740
that's not like it's only New York Times
 

3983
01:35:18,740 --> 01:35:21,790
that's not like it's only New York Times
would put in and the follow-up argument

3984
01:35:21,790 --> 01:35:21,800
would put in and the follow-up argument
 

3985
01:35:21,800 --> 01:35:24,160
would put in and the follow-up argument
that Yoshio makes also not argument but

3986
01:35:24,160 --> 01:35:24,170
that Yoshio makes also not argument but
 

3987
01:35:24,170 --> 01:35:26,080
that Yoshio makes also not argument but
a statement and I've heard him say it

3988
01:35:26,080 --> 01:35:26,090
a statement and I've heard him say it
 

3989
01:35:26,090 --> 01:35:28,960
a statement and I've heard him say it
before and I think I agree he's kind of

3990
01:35:28,960 --> 01:35:28,970
before and I think I agree he's kind of
 

3991
01:35:28,970 --> 01:35:30,760
before and I think I agree he's kind of
has a very friendly way of phrasing it

3992
01:35:30,760 --> 01:35:30,770
has a very friendly way of phrasing it
 

3993
01:35:30,770 --> 01:35:33,100
has a very friendly way of phrasing it
is it's good for a lot of people to

3994
01:35:33,100 --> 01:35:33,110
is it's good for a lot of people to
 

3995
01:35:33,110 --> 01:35:37,540
is it's good for a lot of people to
believe different things yeah well no

3996
01:35:37,540 --> 01:35:37,550
believe different things yeah well no
 

3997
01:35:37,550 --> 01:35:39,430
believe different things yeah well no
but he's it's also practically speaking

3998
01:35:39,430 --> 01:35:39,440
but he's it's also practically speaking
 

3999
01:35:39,440 --> 01:35:43,300
but he's it's also practically speaking
like we shouldn't be like while your

4000
01:35:43,300 --> 01:35:43,310
like we shouldn't be like while your
 

4001
01:35:43,310 --> 01:35:46,450
like we shouldn't be like while your
article stands like Stuart Russell does

4002
01:35:46,450 --> 01:35:46,460
article stands like Stuart Russell does
 

4003
01:35:46,460 --> 01:35:48,580
article stands like Stuart Russell does
amazing work bostrm does amazing work

4004
01:35:48,580 --> 01:35:48,590
amazing work bostrm does amazing work
 

4005
01:35:48,590 --> 01:35:51,340
amazing work bostrm does amazing work
you do amazing work and even when you

4006
01:35:51,340 --> 01:35:51,350
you do amazing work and even when you
 

4007
01:35:51,350 --> 01:35:53,530
you do amazing work and even when you
disagree about the definition of super

4008
01:35:53,530 --> 01:35:53,540
disagree about the definition of super
 

4009
01:35:53,540 --> 01:35:55,420
disagree about the definition of super
intelligence or the usefulness of even

4010
01:35:55,420 --> 01:35:55,430
intelligence or the usefulness of even
 

4011
01:35:55,430 --> 01:35:57,910
intelligence or the usefulness of even
the term it's still useful to have

4012
01:35:57,910 --> 01:35:57,920
the term it's still useful to have
 

4013
01:35:57,920 --> 01:36:01,870
the term it's still useful to have
people that like use that term all right

4014
01:36:01,870 --> 01:36:01,880
people that like use that term all right
 

4015
01:36:01,880 --> 01:36:04,030
people that like use that term all right
and then argue it sir I

4016
01:36:04,030 --> 01:36:04,040
and then argue it sir I
 

4017
01:36:04,040 --> 01:36:06,640
and then argue it sir I
I absolutely agree with video there and

4018
01:36:06,640 --> 01:36:06,650
I absolutely agree with video there and
 

4019
01:36:06,650 --> 01:36:08,710
I absolutely agree with video there and
I think it's great that you know and

4020
01:36:08,710 --> 01:36:08,720
I think it's great that you know and
 

4021
01:36:08,720 --> 01:36:09,880
I think it's great that you know and
it's great that New York Times will

4022
01:36:09,880 --> 01:36:09,890
it's great that New York Times will
 

4023
01:36:09,890 --> 01:36:12,610
it's great that New York Times will
publish all this stuff that's right it's

4024
01:36:12,610 --> 01:36:12,620
publish all this stuff that's right it's
 

4025
01:36:12,620 --> 01:36:15,160
publish all this stuff that's right it's
an exciting time to be here what what do

4026
01:36:15,160 --> 01:36:15,170
an exciting time to be here what what do
 

4027
01:36:15,170 --> 01:36:16,660
an exciting time to be here what what do
you think is a good test of intelligence

4028
01:36:16,660 --> 01:36:16,670
you think is a good test of intelligence
 

4029
01:36:16,670 --> 01:36:20,110
you think is a good test of intelligence
IQ is is natural language ultimately a

4030
01:36:20,110 --> 01:36:20,120
IQ is is natural language ultimately a
 

4031
01:36:20,120 --> 01:36:21,940
IQ is is natural language ultimately a
test that you find the most compelling

4032
01:36:21,940 --> 01:36:21,950
test that you find the most compelling
 

4033
01:36:21,950 --> 01:36:25,630
test that you find the most compelling
like the the original or the what you

4034
01:36:25,630 --> 01:36:25,640
like the the original or the what you
 

4035
01:36:25,640 --> 01:36:27,430
like the the original or the what you
know the higher levels of the Turing

4036
01:36:27,430 --> 01:36:27,440
know the higher levels of the Turing
 

4037
01:36:27,440 --> 01:36:32,500
know the higher levels of the Turing
test kind of yeah yeah I still think the

4038
01:36:32,500 --> 01:36:32,510
test kind of yeah yeah I still think the
 

4039
01:36:32,510 --> 01:36:34,630
test kind of yeah yeah I still think the
original idea of the Turing test is a

4040
01:36:34,630 --> 01:36:34,640
original idea of the Turing test is a
 

4041
01:36:34,640 --> 01:36:37,960
original idea of the Turing test is a
good test for intelligence I mean I

4042
01:36:37,960 --> 01:36:37,970
good test for intelligence I mean I
 

4043
01:36:37,970 --> 01:36:39,370
good test for intelligence I mean I
can't think of anything better

4044
01:36:39,370 --> 01:36:39,380
can't think of anything better
 

4045
01:36:39,380 --> 01:36:42,010
can't think of anything better
you know the Turing tests the way that

4046
01:36:42,010 --> 01:36:42,020
you know the Turing tests the way that
 

4047
01:36:42,020 --> 01:36:43,890
you know the Turing tests the way that
it's been carried out so far has been

4048
01:36:43,890 --> 01:36:43,900
it's been carried out so far has been
 

4049
01:36:43,900 --> 01:36:49,060
it's been carried out so far has been
very impoverished if you will but I

4050
01:36:49,060 --> 01:36:49,070
very impoverished if you will but I
 

4051
01:36:49,070 --> 01:36:51,700
very impoverished if you will but I
think a real Turing test that really

4052
01:36:51,700 --> 01:36:51,710
think a real Turing test that really
 

4053
01:36:51,710 --> 01:36:53,440
think a real Turing test that really
goes into depth like the one that I

4054
01:36:53,440 --> 01:36:53,450
goes into depth like the one that I
 

4055
01:36:53,450 --> 01:36:54,760
goes into depth like the one that I
mentioned I talk about in the book I

4056
01:36:54,760 --> 01:36:54,770
mentioned I talk about in the book I
 

4057
01:36:54,770 --> 01:36:57,490
mentioned I talk about in the book I
talk about Ray Kurzweil and Mitchell

4058
01:36:57,490 --> 01:36:57,500
talk about Ray Kurzweil and Mitchell
 

4059
01:36:57,500 --> 01:37:01,230
talk about Ray Kurzweil and Mitchell
Kapoor have this bet right that that in

4060
01:37:01,230 --> 01:37:01,240
Kapoor have this bet right that that in
 

4061
01:37:01,240 --> 01:37:06,190
Kapoor have this bet right that that in
2029 I think is the date there a machine

4062
01:37:06,190 --> 01:37:06,200
2029 I think is the date there a machine
 

4063
01:37:06,200 --> 01:37:07,990
2029 I think is the date there a machine
will pass the Turing test and turn says

4064
01:37:07,990 --> 01:37:08,000
will pass the Turing test and turn says
 

4065
01:37:08,000 --> 01:37:10,300
will pass the Turing test and turn says
and they have a very specific like how

4066
01:37:10,300 --> 01:37:10,310
and they have a very specific like how
 

4067
01:37:10,310 --> 01:37:14,050
and they have a very specific like how
many hours many expert judges and all of

4068
01:37:14,050 --> 01:37:14,060
many hours many expert judges and all of
 

4069
01:37:14,060 --> 01:37:16,720
many hours many expert judges and all of
that and you know Kurzweil says yes

4070
01:37:16,720 --> 01:37:16,730
that and you know Kurzweil says yes
 

4071
01:37:16,730 --> 01:37:19,090
that and you know Kurzweil says yes
Kapoor says no we can't we only have

4072
01:37:19,090 --> 01:37:19,100
Kapoor says no we can't we only have
 

4073
01:37:19,100 --> 01:37:24,070
Kapoor says no we can't we only have
like nine more years to go to see I you

4074
01:37:24,070 --> 01:37:24,080
like nine more years to go to see I you
 

4075
01:37:24,080 --> 01:37:26,500
like nine more years to go to see I you
know if something a machine could pass

4076
01:37:26,500 --> 01:37:26,510
know if something a machine could pass
 

4077
01:37:26,510 --> 01:37:29,470
know if something a machine could pass
that I would be willing to call it

4078
01:37:29,470 --> 01:37:29,480
that I would be willing to call it
 

4079
01:37:29,480 --> 01:37:33,880
that I would be willing to call it
intelligent of course nobody will they

4080
01:37:33,880 --> 01:37:33,890
intelligent of course nobody will they
 

4081
01:37:33,890 --> 01:37:37,090
intelligent of course nobody will they
will say that's just a language model if

4082
01:37:37,090 --> 01:37:37,100
will say that's just a language model if
 

4083
01:37:37,100 --> 01:37:39,820
will say that's just a language model if
it does so you would be comfortable it's

4084
01:37:39,820 --> 01:37:39,830
it does so you would be comfortable it's
 

4085
01:37:39,830 --> 01:37:44,470
it does so you would be comfortable it's
a language a long conversation that well

4086
01:37:44,470 --> 01:37:44,480
a language a long conversation that well
 

4087
01:37:44,480 --> 01:37:46,030
a language a long conversation that well
yeah here I mean you're right because I

4088
01:37:46,030 --> 01:37:46,040
yeah here I mean you're right because I
 

4089
01:37:46,040 --> 01:37:47,710
yeah here I mean you're right because I
think probably to carry out that long

4090
01:37:47,710 --> 01:37:47,720
think probably to carry out that long
 

4091
01:37:47,720 --> 01:37:50,020
think probably to carry out that long
conversation you would literally need to

4092
01:37:50,020 --> 01:37:50,030
conversation you would literally need to
 

4093
01:37:50,030 --> 01:37:52,150
conversation you would literally need to
have deep common-sense understanding of

4094
01:37:52,150 --> 01:37:52,160
have deep common-sense understanding of
 

4095
01:37:52,160 --> 01:37:54,820
have deep common-sense understanding of
the world I think so and the

4096
01:37:54,820 --> 01:37:54,830
the world I think so and the
 

4097
01:37:54,830 --> 01:38:00,010
the world I think so and the
conversation is enough to reveal that so

4098
01:38:00,010 --> 01:38:00,020
conversation is enough to reveal that so
 

4099
01:38:00,020 --> 01:38:03,370
conversation is enough to reveal that so
another super fun topic of complexity

4100
01:38:03,370 --> 01:38:03,380
another super fun topic of complexity
 

4101
01:38:03,380 --> 01:38:08,820
another super fun topic of complexity
that you have worked on written about

4102
01:38:08,820 --> 01:38:08,830
that you have worked on written about
 

4103
01:38:08,830 --> 01:38:11,460
that you have worked on written about
let me ask the basic question what is

4104
01:38:11,460 --> 01:38:11,470
let me ask the basic question what is
 

4105
01:38:11,470 --> 01:38:14,890
let me ask the basic question what is
complexity so complexity is another one

4106
01:38:14,890 --> 01:38:14,900
complexity so complexity is another one
 

4107
01:38:14,900 --> 01:38:17,889
complexity so complexity is another one
of those terms like intelligence

4108
01:38:17,889 --> 01:38:17,899
of those terms like intelligence
 

4109
01:38:17,899 --> 01:38:21,009
of those terms like intelligence
it's perhaps overused but my book about

4110
01:38:21,009 --> 01:38:21,019
it's perhaps overused but my book about
 

4111
01:38:21,019 --> 01:38:28,089
it's perhaps overused but my book about
complexity was about this wide area of

4112
01:38:28,089 --> 01:38:28,099
complexity was about this wide area of
 

4113
01:38:28,099 --> 01:38:30,790
complexity was about this wide area of
complex systems studying different

4114
01:38:30,790 --> 01:38:30,800
complex systems studying different
 

4115
01:38:30,800 --> 01:38:35,799
complex systems studying different
systems in nature in technology in

4116
01:38:35,799 --> 01:38:35,809
systems in nature in technology in
 

4117
01:38:35,809 --> 01:38:39,699
systems in nature in technology in
society in which you have emergence kind

4118
01:38:39,699 --> 01:38:39,709
society in which you have emergence kind
 

4119
01:38:39,709 --> 01:38:41,080
society in which you have emergence kind
of like I was talking about with

4120
01:38:41,080 --> 01:38:41,090
of like I was talking about with
 

4121
01:38:41,090 --> 01:38:42,699
of like I was talking about with
intelligence you know we have the brain

4122
01:38:42,699 --> 01:38:42,709
intelligence you know we have the brain
 

4123
01:38:42,709 --> 01:38:47,169
intelligence you know we have the brain
which has billions of neurons and each

4124
01:38:47,169 --> 01:38:47,179
which has billions of neurons and each
 

4125
01:38:47,179 --> 01:38:50,080
which has billions of neurons and each
neuron individually could be said to be

4126
01:38:50,080 --> 01:38:50,090
neuron individually could be said to be
 

4127
01:38:50,090 --> 01:38:52,270
neuron individually could be said to be
not very complex compared to the system

4128
01:38:52,270 --> 01:38:52,280
not very complex compared to the system
 

4129
01:38:52,280 --> 01:38:56,040
not very complex compared to the system
as a whole but the system the the

4130
01:38:56,040 --> 01:38:56,050
as a whole but the system the the
 

4131
01:38:56,050 --> 01:38:58,239
as a whole but the system the the
interactions of those neurons and the

4132
01:38:58,239 --> 01:38:58,249
interactions of those neurons and the
 

4133
01:38:58,249 --> 01:39:01,270
interactions of those neurons and the
dynamics creates these phenomena that we

4134
01:39:01,270 --> 01:39:01,280
dynamics creates these phenomena that we
 

4135
01:39:01,280 --> 01:39:03,279
dynamics creates these phenomena that we
call we call intelligence or

4136
01:39:03,279 --> 01:39:03,289
call we call intelligence or
 

4137
01:39:03,289 --> 01:39:06,759
call we call intelligence or
consciousness you know that are we

4138
01:39:06,759 --> 01:39:06,769
consciousness you know that are we
 

4139
01:39:06,769 --> 01:39:10,779
consciousness you know that are we
consider to be very complex so the field

4140
01:39:10,779 --> 01:39:10,789
consider to be very complex so the field
 

4141
01:39:10,789 --> 01:39:14,169
consider to be very complex so the field
of complexity is trying to find general

4142
01:39:14,169 --> 01:39:14,179
of complexity is trying to find general
 

4143
01:39:14,179 --> 01:39:16,089
of complexity is trying to find general
principles that underlie all these

4144
01:39:16,089 --> 01:39:16,099
principles that underlie all these
 

4145
01:39:16,099 --> 01:39:18,219
principles that underlie all these
systems that have these kinds of

4146
01:39:18,219 --> 01:39:18,229
systems that have these kinds of
 

4147
01:39:18,229 --> 01:39:21,159
systems that have these kinds of
emergent properties and the the

4148
01:39:21,159 --> 01:39:21,169
emergent properties and the the
 

4149
01:39:21,169 --> 01:39:23,859
emergent properties and the the
emergence occurs from like underlying

4150
01:39:23,859 --> 01:39:23,869
emergence occurs from like underlying
 

4151
01:39:23,869 --> 01:39:26,369
emergence occurs from like underlying
the complex system is usually simple

4152
01:39:26,369 --> 01:39:26,379
the complex system is usually simple
 

4153
01:39:26,379 --> 01:39:29,580
the complex system is usually simple
fundamental interactions yes and the

4154
01:39:29,580 --> 01:39:29,590
fundamental interactions yes and the
 

4155
01:39:29,590 --> 01:39:32,799
fundamental interactions yes and the
emergence happens when there's just a

4156
01:39:32,799 --> 01:39:32,809
emergence happens when there's just a
 

4157
01:39:32,809 --> 01:39:36,189
emergence happens when there's just a
lot of these things interacting yes sort

4158
01:39:36,189 --> 01:39:36,199
lot of these things interacting yes sort
 

4159
01:39:36,199 --> 01:39:40,449
lot of these things interacting yes sort
of what and then most of science to date

4160
01:39:40,449 --> 01:39:40,459
of what and then most of science to date
 

4161
01:39:40,459 --> 01:39:42,279
of what and then most of science to date
can you talk about what what is

4162
01:39:42,279 --> 01:39:42,289
can you talk about what what is
 

4163
01:39:42,289 --> 01:39:45,509
can you talk about what what is
reductionism

4164
01:39:45,509 --> 01:39:45,519

 

4165
01:39:45,519 --> 01:39:48,609

well reductionism is when you try and

4166
01:39:48,609 --> 01:39:48,619
well reductionism is when you try and
 

4167
01:39:48,619 --> 01:39:52,919
well reductionism is when you try and
take a system and divide it up into its

4168
01:39:52,919 --> 01:39:52,929
take a system and divide it up into its
 

4169
01:39:52,929 --> 01:39:57,399
take a system and divide it up into its
elements whether those be cells or atoms

4170
01:39:57,399 --> 01:39:57,409
elements whether those be cells or atoms
 

4171
01:39:57,409 --> 01:40:01,689
elements whether those be cells or atoms
or subatomic particles whatever your

4172
01:40:01,689 --> 01:40:01,699
or subatomic particles whatever your
 

4173
01:40:01,699 --> 01:40:04,139
or subatomic particles whatever your
field is and then try and understand

4174
01:40:04,139 --> 01:40:04,149
field is and then try and understand
 

4175
01:40:04,149 --> 01:40:08,589
field is and then try and understand
those elements and then try and build up

4176
01:40:08,589 --> 01:40:08,599
those elements and then try and build up
 

4177
01:40:08,599 --> 01:40:10,629
those elements and then try and build up
an understanding of the whole system by

4178
01:40:10,629 --> 01:40:10,639
an understanding of the whole system by
 

4179
01:40:10,639 --> 01:40:12,790
an understanding of the whole system by
looking at sort of the sum of all the

4180
01:40:12,790 --> 01:40:12,800
looking at sort of the sum of all the
 

4181
01:40:12,800 --> 01:40:16,270
looking at sort of the sum of all the
elements so what's your sense whether

4182
01:40:16,270 --> 01:40:16,280
elements so what's your sense whether
 

4183
01:40:16,280 --> 01:40:17,979
elements so what's your sense whether
we're talking about intelligence or

4184
01:40:17,979 --> 01:40:17,989
we're talking about intelligence or
 

4185
01:40:17,989 --> 01:40:20,020
we're talking about intelligence or
these kinds of interesting complex

4186
01:40:20,020 --> 01:40:20,030
these kinds of interesting complex
 

4187
01:40:20,030 --> 01:40:22,479
these kinds of interesting complex
systems is it possible to understand

4188
01:40:22,479 --> 01:40:22,489
systems is it possible to understand
 

4189
01:40:22,489 --> 01:40:25,419
systems is it possible to understand
them in in a reductionist way it's just

4190
01:40:25,419 --> 01:40:25,429
them in in a reductionist way it's just
 

4191
01:40:25,429 --> 01:40:28,149
them in in a reductionist way it's just
probably the approach of most of science

4192
01:40:28,149 --> 01:40:28,159
probably the approach of most of science
 

4193
01:40:28,159 --> 01:40:29,740
probably the approach of most of science
today right

4194
01:40:29,740 --> 01:40:29,750
today right
 

4195
01:40:29,750 --> 01:40:32,920
today right
I don't think it's always possible to

4196
01:40:32,920 --> 01:40:32,930
I don't think it's always possible to
 

4197
01:40:32,930 --> 01:40:34,120
I don't think it's always possible to
understand the things we want to

4198
01:40:34,120 --> 01:40:34,130
understand the things we want to
 

4199
01:40:34,130 --> 01:40:36,730
understand the things we want to
understand the most so I don't think

4200
01:40:36,730 --> 01:40:36,740
understand the most so I don't think
 

4201
01:40:36,740 --> 01:40:39,430
understand the most so I don't think
it's possible to look at single neurons

4202
01:40:39,430 --> 01:40:39,440
it's possible to look at single neurons
 

4203
01:40:39,440 --> 01:40:45,430
it's possible to look at single neurons
and understand what we call intelligence

4204
01:40:45,430 --> 01:40:45,440
and understand what we call intelligence
 

4205
01:40:45,440 --> 01:40:48,220
and understand what we call intelligence
you know just look at sort of summing up

4206
01:40:48,220 --> 01:40:48,230
you know just look at sort of summing up
 

4207
01:40:48,230 --> 01:40:51,790
you know just look at sort of summing up
and the sort of the summing up is the

4208
01:40:51,790 --> 01:40:51,800
and the sort of the summing up is the
 

4209
01:40:51,800 --> 01:40:55,540
and the sort of the summing up is the
issue here that were you know that one

4210
01:40:55,540 --> 01:40:55,550
issue here that were you know that one
 

4211
01:40:55,550 --> 01:40:58,000
issue here that were you know that one
example is that the human genome alright

4212
01:40:58,000 --> 01:40:58,010
example is that the human genome alright
 

4213
01:40:58,010 --> 01:41:01,840
example is that the human genome alright
so there was a lot of work on excitement

4214
01:41:01,840 --> 01:41:01,850
so there was a lot of work on excitement
 

4215
01:41:01,850 --> 01:41:03,460
so there was a lot of work on excitement
about sequencing the human genome

4216
01:41:03,460 --> 01:41:03,470
about sequencing the human genome
 

4217
01:41:03,470 --> 01:41:07,180
about sequencing the human genome
because the idea would be that we'd be

4218
01:41:07,180 --> 01:41:07,190
because the idea would be that we'd be
 

4219
01:41:07,190 --> 01:41:09,570
because the idea would be that we'd be
able to find genes that underlies

4220
01:41:09,570 --> 01:41:09,580
able to find genes that underlies
 

4221
01:41:09,580 --> 01:41:14,230
able to find genes that underlies
diseases but it turns out that and I was

4222
01:41:14,230 --> 01:41:14,240
diseases but it turns out that and I was
 

4223
01:41:14,240 --> 01:41:16,180
diseases but it turns out that and I was
a very reductionist idea you know we

4224
01:41:16,180 --> 01:41:16,190
a very reductionist idea you know we
 

4225
01:41:16,190 --> 01:41:18,730
a very reductionist idea you know we
figure out what all the the parts are

4226
01:41:18,730 --> 01:41:18,740
figure out what all the the parts are
 

4227
01:41:18,740 --> 01:41:20,860
figure out what all the the parts are
and then we would be able to figure out

4228
01:41:20,860 --> 01:41:20,870
and then we would be able to figure out
 

4229
01:41:20,870 --> 01:41:23,290
and then we would be able to figure out
which parts cause which things but it

4230
01:41:23,290 --> 01:41:23,300
which parts cause which things but it
 

4231
01:41:23,300 --> 01:41:25,150
which parts cause which things but it
turns out that the parts don't cause the

4232
01:41:25,150 --> 01:41:25,160
turns out that the parts don't cause the
 

4233
01:41:25,160 --> 01:41:26,380
turns out that the parts don't cause the
things that we're interested in it's

4234
01:41:26,380 --> 01:41:26,390
things that we're interested in it's
 

4235
01:41:26,390 --> 01:41:28,630
things that we're interested in it's
like the interactions it's the networks

4236
01:41:28,630 --> 01:41:28,640
like the interactions it's the networks
 

4237
01:41:28,640 --> 01:41:32,470
like the interactions it's the networks
of these parts and so that kind of

4238
01:41:32,470 --> 01:41:32,480
of these parts and so that kind of
 

4239
01:41:32,480 --> 01:41:35,500
of these parts and so that kind of
reductionist approach didn't yield the

4240
01:41:35,500 --> 01:41:35,510
reductionist approach didn't yield the
 

4241
01:41:35,510 --> 01:41:38,560
reductionist approach didn't yield the
the explanation that we wanted would he

4242
01:41:38,560 --> 01:41:38,570
the explanation that we wanted would he
 

4243
01:41:38,570 --> 01:41:42,250
the explanation that we wanted would he
would use the most beautiful complex

4244
01:41:42,250 --> 01:41:42,260
would use the most beautiful complex
 

4245
01:41:42,260 --> 01:41:44,530
would use the most beautiful complex
system that you've encountered most

4246
01:41:44,530 --> 01:41:44,540
system that you've encountered most
 

4247
01:41:44,540 --> 01:41:47,380
system that you've encountered most
beautiful that you've been captivated by

4248
01:41:47,380 --> 01:41:47,390
beautiful that you've been captivated by
 

4249
01:41:47,390 --> 01:41:52,600
beautiful that you've been captivated by
is it sort of I mean for me that is the

4250
01:41:52,600 --> 01:41:52,610
is it sort of I mean for me that is the
 

4251
01:41:52,610 --> 01:41:55,750
is it sort of I mean for me that is the
simplest to be cellular automata oh yeah

4252
01:41:55,750 --> 01:41:55,760
simplest to be cellular automata oh yeah
 

4253
01:41:55,760 --> 01:41:57,520
simplest to be cellular automata oh yeah
so I was very captivated by cellular

4254
01:41:57,520 --> 01:41:57,530
so I was very captivated by cellular
 

4255
01:41:57,530 --> 01:41:59,980
so I was very captivated by cellular
automata and worked on cellular automata

4256
01:41:59,980 --> 01:41:59,990
automata and worked on cellular automata
 

4257
01:41:59,990 --> 01:42:03,580
automata and worked on cellular automata
for several years do you find it amazing

4258
01:42:03,580 --> 01:42:03,590
for several years do you find it amazing
 

4259
01:42:03,590 --> 01:42:06,910
for several years do you find it amazing
or is it surprising that such simple

4260
01:42:06,910 --> 01:42:06,920
or is it surprising that such simple
 

4261
01:42:06,920 --> 01:42:08,920
or is it surprising that such simple
systems such simple rules and cellular

4262
01:42:08,920 --> 01:42:08,930
systems such simple rules and cellular
 

4263
01:42:08,930 --> 01:42:12,420
systems such simple rules and cellular
Domino can create sort of seemingly

4264
01:42:12,420 --> 01:42:12,430
Domino can create sort of seemingly
 

4265
01:42:12,430 --> 01:42:15,310
Domino can create sort of seemingly
unlimited complexity yeah that was very

4266
01:42:15,310 --> 01:42:15,320
unlimited complexity yeah that was very
 

4267
01:42:15,320 --> 01:42:17,560
unlimited complexity yeah that was very
surprising to me I didn't make sense of

4268
01:42:17,560 --> 01:42:17,570
surprising to me I didn't make sense of
 

4269
01:42:17,570 --> 01:42:19,420
surprising to me I didn't make sense of
it how does that make you feel this is

4270
01:42:19,420 --> 01:42:19,430
it how does that make you feel this is
 

4271
01:42:19,430 --> 01:42:22,090
it how does that make you feel this is
just ultimately humbling or is there

4272
01:42:22,090 --> 01:42:22,100
just ultimately humbling or is there
 

4273
01:42:22,100 --> 01:42:24,520
just ultimately humbling or is there
hope to somehow leverage this into a

4274
01:42:24,520 --> 01:42:24,530
hope to somehow leverage this into a
 

4275
01:42:24,530 --> 01:42:27,820
hope to somehow leverage this into a
deeper understanding and even able to

4276
01:42:27,820 --> 01:42:27,830
deeper understanding and even able to
 

4277
01:42:27,830 --> 01:42:29,770
deeper understanding and even able to
engineer things like intelligence

4278
01:42:29,770 --> 01:42:29,780
engineer things like intelligence
 

4279
01:42:29,780 --> 01:42:34,300
engineer things like intelligence
it's definitely humbling how humbling in

4280
01:42:34,300 --> 01:42:34,310
it's definitely humbling how humbling in
 

4281
01:42:34,310 --> 01:42:39,360
it's definitely humbling how humbling in
that also kind of awe-inspiring that

4282
01:42:39,360 --> 01:42:39,370
that also kind of awe-inspiring that
 

4283
01:42:39,370 --> 01:42:42,160
that also kind of awe-inspiring that
it's that inspiring like part of

4284
01:42:42,160 --> 01:42:42,170
it's that inspiring like part of
 

4285
01:42:42,170 --> 01:42:43,840
it's that inspiring like part of
mathematics that these credible

4286
01:42:43,840 --> 01:42:43,850
mathematics that these credible
 

4287
01:42:43,850 --> 01:42:46,690
mathematics that these credible
simple rules can produce this very

4288
01:42:46,690 --> 01:42:46,700
simple rules can produce this very
 

4289
01:42:46,700 --> 01:42:49,770
simple rules can produce this very
beautiful complex hard to understand

4290
01:42:49,770 --> 01:42:49,780
beautiful complex hard to understand
 

4291
01:42:49,780 --> 01:42:56,020
beautiful complex hard to understand
behavior and that that's it's mysterious

4292
01:42:56,020 --> 01:42:56,030
behavior and that that's it's mysterious
 

4293
01:42:56,030 --> 01:43:00,780
behavior and that that's it's mysterious
you know and and surprising still but

4294
01:43:00,780 --> 01:43:00,790
you know and and surprising still but
 

4295
01:43:00,790 --> 01:43:03,130
you know and and surprising still but
exciting because it does give you kind

4296
01:43:03,130 --> 01:43:03,140
exciting because it does give you kind
 

4297
01:43:03,140 --> 01:43:04,660
exciting because it does give you kind
of the hope that you might be able to

4298
01:43:04,660 --> 01:43:04,670
of the hope that you might be able to
 

4299
01:43:04,670 --> 01:43:09,250
of the hope that you might be able to
engineer complexity just from from these

4300
01:43:09,250 --> 01:43:09,260
engineer complexity just from from these
 

4301
01:43:09,260 --> 01:43:11,650
engineer complexity just from from these
can you briefly say what is the Santa Fe

4302
01:43:11,650 --> 01:43:11,660
can you briefly say what is the Santa Fe
 

4303
01:43:11,660 --> 01:43:13,480
can you briefly say what is the Santa Fe
Institute its history its culture its

4304
01:43:13,480 --> 01:43:13,490
Institute its history its culture its
 

4305
01:43:13,490 --> 01:43:15,930
Institute its history its culture its
ideas its future stuff I've never

4306
01:43:15,930 --> 01:43:15,940
ideas its future stuff I've never
 

4307
01:43:15,940 --> 01:43:18,880
ideas its future stuff I've never
semester G I've never been but so has

4308
01:43:18,880 --> 01:43:18,890
semester G I've never been but so has
 

4309
01:43:18,890 --> 01:43:21,940
semester G I've never been but so has
been this in my - mystical place where

4310
01:43:21,940 --> 01:43:21,950
been this in my - mystical place where
 

4311
01:43:21,950 --> 01:43:25,320
been this in my - mystical place where
brilliant people study the edge of chaos

4312
01:43:25,320 --> 01:43:25,330
brilliant people study the edge of chaos
 

4313
01:43:25,330 --> 01:43:30,160
brilliant people study the edge of chaos
exactly so the Santa Fe Institute was

4314
01:43:30,160 --> 01:43:30,170
exactly so the Santa Fe Institute was
 

4315
01:43:30,170 --> 01:43:35,680
exactly so the Santa Fe Institute was
started in 1984 and it was created by a

4316
01:43:35,680 --> 01:43:35,690
started in 1984 and it was created by a
 

4317
01:43:35,690 --> 01:43:38,020
started in 1984 and it was created by a
group of scientists a lot of them from

4318
01:43:38,020 --> 01:43:38,030
group of scientists a lot of them from
 

4319
01:43:38,030 --> 01:43:42,310
group of scientists a lot of them from
Los Alamos National Lab which is about a

4320
01:43:42,310 --> 01:43:42,320
Los Alamos National Lab which is about a
 

4321
01:43:42,320 --> 01:43:44,590
Los Alamos National Lab which is about a
40-minute drive from the Santa Fe

4322
01:43:44,590 --> 01:43:44,600
40-minute drive from the Santa Fe
 

4323
01:43:44,600 --> 01:43:46,020
40-minute drive from the Santa Fe
Institute

4324
01:43:46,020 --> 01:43:46,030
Institute
 

4325
01:43:46,030 --> 01:43:49,170
Institute
they were mostly physicists and chemists

4326
01:43:49,170 --> 01:43:49,180
they were mostly physicists and chemists
 

4327
01:43:49,180 --> 01:43:53,010
they were mostly physicists and chemists
but they were frustrated in their field

4328
01:43:53,010 --> 01:43:53,020
but they were frustrated in their field
 

4329
01:43:53,020 --> 01:43:56,980
but they were frustrated in their field
because they felt so that their field

4330
01:43:56,980 --> 01:43:56,990
because they felt so that their field
 

4331
01:43:56,990 --> 01:43:59,050
because they felt so that their field
wasn't approaching kind of big

4332
01:43:59,050 --> 01:43:59,060
wasn't approaching kind of big
 

4333
01:43:59,060 --> 01:44:01,930
wasn't approaching kind of big
interdisciplinary questions like the

4334
01:44:01,930 --> 01:44:01,940
interdisciplinary questions like the
 

4335
01:44:01,940 --> 01:44:04,930
interdisciplinary questions like the
kinds we've been talking about and they

4336
01:44:04,930 --> 01:44:04,940
kinds we've been talking about and they
 

4337
01:44:04,940 --> 01:44:07,690
kinds we've been talking about and they
wanted to have a place where people from

4338
01:44:07,690 --> 01:44:07,700
wanted to have a place where people from
 

4339
01:44:07,700 --> 01:44:10,270
wanted to have a place where people from
different disciplines could work on

4340
01:44:10,270 --> 01:44:10,280
different disciplines could work on
 

4341
01:44:10,280 --> 01:44:12,310
different disciplines could work on
these big questions without sort of

4342
01:44:12,310 --> 01:44:12,320
these big questions without sort of
 

4343
01:44:12,320 --> 01:44:14,770
these big questions without sort of
being siloed into physics chemistry

4344
01:44:14,770 --> 01:44:14,780
being siloed into physics chemistry
 

4345
01:44:14,780 --> 01:44:19,120
being siloed into physics chemistry
biology whatever so they started this

4346
01:44:19,120 --> 01:44:19,130
biology whatever so they started this
 

4347
01:44:19,130 --> 01:44:22,290
biology whatever so they started this
Institute and this was people like

4348
01:44:22,290 --> 01:44:22,300
Institute and this was people like
 

4349
01:44:22,300 --> 01:44:25,660
Institute and this was people like
George Cowan who is a chemist in the

4350
01:44:25,660 --> 01:44:25,670
George Cowan who is a chemist in the
 

4351
01:44:25,670 --> 01:44:28,900
George Cowan who is a chemist in the
Manhattan Project and Nicholas

4352
01:44:28,900 --> 01:44:28,910
Manhattan Project and Nicholas
 

4353
01:44:28,910 --> 01:44:34,320
Manhattan Project and Nicholas
Metropolis who mathematician physicist

4354
01:44:34,320 --> 01:44:34,330
Metropolis who mathematician physicist
 

4355
01:44:34,330 --> 01:44:37,930
Metropolis who mathematician physicist
Murray gell-mann physicist nism so some

4356
01:44:37,930 --> 01:44:37,940
Murray gell-mann physicist nism so some
 

4357
01:44:37,940 --> 01:44:40,570
Murray gell-mann physicist nism so some
really big names here ken arrow an

4358
01:44:40,570 --> 01:44:40,580
really big names here ken arrow an
 

4359
01:44:40,580 --> 01:44:42,550
really big names here ken arrow an
economist Nobel prize-winning economist

4360
01:44:42,550 --> 01:44:42,560
economist Nobel prize-winning economist
 

4361
01:44:42,560 --> 01:44:46,170
economist Nobel prize-winning economist
and they started having these workshops

4362
01:44:46,170 --> 01:44:46,180
and they started having these workshops
 

4363
01:44:46,180 --> 01:44:50,680
and they started having these workshops
and this whole enterprise kind of grew

4364
01:44:50,680 --> 01:44:50,690
and this whole enterprise kind of grew
 

4365
01:44:50,690 --> 01:44:55,710
and this whole enterprise kind of grew
into this Research Institute that's

4366
01:44:55,710 --> 01:44:55,720
into this Research Institute that's
 

4367
01:44:55,720 --> 01:44:57,069
into this Research Institute that's
itself has been

4368
01:44:57,069 --> 01:44:57,079
itself has been
 

4369
01:44:57,079 --> 01:44:58,750
itself has been
kind of on the edge of chaos its whole

4370
01:44:58,750 --> 01:44:58,760
kind of on the edge of chaos its whole
 

4371
01:44:58,760 --> 01:45:01,149
kind of on the edge of chaos its whole
life because it doesn't have any it

4372
01:45:01,149 --> 01:45:01,159
life because it doesn't have any it
 

4373
01:45:01,159 --> 01:45:03,459
life because it doesn't have any it
doesn't have a significant endowment and

4374
01:45:03,459 --> 01:45:03,469
doesn't have a significant endowment and
 

4375
01:45:03,469 --> 01:45:06,810
doesn't have a significant endowment and
it's just been kind of living on

4376
01:45:06,810 --> 01:45:06,820
it's just been kind of living on
 

4377
01:45:06,820 --> 01:45:11,219
it's just been kind of living on
whatever funding it can raise through

4378
01:45:11,219 --> 01:45:11,229
whatever funding it can raise through
 

4379
01:45:11,229 --> 01:45:17,349
whatever funding it can raise through
donations and grants and however it can

4380
01:45:17,349 --> 01:45:17,359
donations and grants and however it can
 

4381
01:45:17,359 --> 01:45:19,929
donations and grants and however it can
you know business business associates

4382
01:45:19,929 --> 01:45:19,939
you know business business associates
 

4383
01:45:19,939 --> 01:45:23,139
you know business business associates
and so on but it's a great place it's a

4384
01:45:23,139 --> 01:45:23,149
and so on but it's a great place it's a
 

4385
01:45:23,149 --> 01:45:25,359
and so on but it's a great place it's a
really fun place to go think about ideas

4386
01:45:25,359 --> 01:45:25,369
really fun place to go think about ideas
 

4387
01:45:25,369 --> 01:45:27,389
really fun place to go think about ideas
from that you wouldn't normally

4388
01:45:27,389 --> 01:45:27,399
from that you wouldn't normally
 

4389
01:45:27,399 --> 01:45:32,169
from that you wouldn't normally
encounter I saw Sean Carroll so

4390
01:45:32,169 --> 01:45:32,179
encounter I saw Sean Carroll so
 

4391
01:45:32,179 --> 01:45:34,779
encounter I saw Sean Carroll so
physicists yeah yeah external faculty

4392
01:45:34,779 --> 01:45:34,789
physicists yeah yeah external faculty
 

4393
01:45:34,789 --> 01:45:36,310
physicists yeah yeah external faculty
and you mentioned that there's so

4394
01:45:36,310 --> 01:45:36,320
and you mentioned that there's so
 

4395
01:45:36,320 --> 01:45:37,659
and you mentioned that there's so
there's some external faculty and

4396
01:45:37,659 --> 01:45:37,669
there's some external faculty and
 

4397
01:45:37,669 --> 01:45:38,949
there's some external faculty and
there's people there's a very small

4398
01:45:38,949 --> 01:45:38,959
there's people there's a very small
 

4399
01:45:38,959 --> 01:45:42,129
there's people there's a very small
group of resident faculty maybe maybe

4400
01:45:42,129 --> 01:45:42,139
group of resident faculty maybe maybe
 

4401
01:45:42,139 --> 01:45:45,909
group of resident faculty maybe maybe
about ten who are there for five year

4402
01:45:45,909 --> 01:45:45,919
about ten who are there for five year
 

4403
01:45:45,919 --> 01:45:48,729
about ten who are there for five year
terms that can sometimes get renewed and

4404
01:45:48,729 --> 01:45:48,739
terms that can sometimes get renewed and
 

4405
01:45:48,739 --> 01:45:51,579
terms that can sometimes get renewed and
then they have some postdocs and then

4406
01:45:51,579 --> 01:45:51,589
then they have some postdocs and then
 

4407
01:45:51,589 --> 01:45:54,040
then they have some postdocs and then
they have this much larger on the order

4408
01:45:54,040 --> 01:45:54,050
they have this much larger on the order
 

4409
01:45:54,050 --> 01:45:56,349
they have this much larger on the order
of a hundred external faculty or people

4410
01:45:56,349 --> 01:45:56,359
of a hundred external faculty or people
 

4411
01:45:56,359 --> 01:45:58,389
of a hundred external faculty or people
come like me who come and visit for

4412
01:45:58,389 --> 01:45:58,399
come like me who come and visit for
 

4413
01:45:58,399 --> 01:46:00,279
come like me who come and visit for
various periods of time so what do you

4414
01:46:00,279 --> 01:46:00,289
various periods of time so what do you
 

4415
01:46:00,289 --> 01:46:01,569
various periods of time so what do you
think this is the future of the Santa Fe

4416
01:46:01,569 --> 01:46:01,579
think this is the future of the Santa Fe
 

4417
01:46:01,579 --> 01:46:03,909
think this is the future of the Santa Fe
Institute like what and if people are

4418
01:46:03,909 --> 01:46:03,919
Institute like what and if people are
 

4419
01:46:03,919 --> 01:46:07,239
Institute like what and if people are
interested like what what's there in

4420
01:46:07,239 --> 01:46:07,249
interested like what what's there in
 

4421
01:46:07,249 --> 01:46:09,429
interested like what what's there in
terms of the public interaction or

4422
01:46:09,429 --> 01:46:09,439
terms of the public interaction or
 

4423
01:46:09,439 --> 01:46:12,429
terms of the public interaction or
students or so on that's that could be a

4424
01:46:12,429 --> 01:46:12,439
students or so on that's that could be a
 

4425
01:46:12,439 --> 01:46:13,869
students or so on that's that could be a
possible interaction on the Santa Fe

4426
01:46:13,869 --> 01:46:13,879
possible interaction on the Santa Fe
 

4427
01:46:13,879 --> 01:46:16,299
possible interaction on the Santa Fe
Institute or its ideas yeah so there's a

4428
01:46:16,299 --> 01:46:16,309
Institute or its ideas yeah so there's a
 

4429
01:46:16,309 --> 01:46:18,040
Institute or its ideas yeah so there's a
there's a few different things they do

4430
01:46:18,040 --> 01:46:18,050
there's a few different things they do
 

4431
01:46:18,050 --> 01:46:21,939
there's a few different things they do
they have a complex system summer school

4432
01:46:21,939 --> 01:46:21,949
they have a complex system summer school
 

4433
01:46:21,949 --> 01:46:23,829
they have a complex system summer school
for graduate students and postdocs and

4434
01:46:23,829 --> 01:46:23,839
for graduate students and postdocs and
 

4435
01:46:23,839 --> 01:46:26,349
for graduate students and postdocs and
sometimes faculty attend to and that's a

4436
01:46:26,349 --> 01:46:26,359
sometimes faculty attend to and that's a
 

4437
01:46:26,359 --> 01:46:29,379
sometimes faculty attend to and that's a
four week very intensive residential

4438
01:46:29,379 --> 01:46:29,389
four week very intensive residential
 

4439
01:46:29,389 --> 01:46:32,169
four week very intensive residential
program where you go and you listen to

4440
01:46:32,169 --> 01:46:32,179
program where you go and you listen to
 

4441
01:46:32,179 --> 01:46:34,750
program where you go and you listen to
lectures and you do projects and people

4442
01:46:34,750 --> 01:46:34,760
lectures and you do projects and people
 

4443
01:46:34,760 --> 01:46:36,790
lectures and you do projects and people
people really like that I mean it's a

4444
01:46:36,790 --> 01:46:36,800
people really like that I mean it's a
 

4445
01:46:36,800 --> 01:46:40,860
people really like that I mean it's a
lot of fun they also have some specialty

4446
01:46:40,860 --> 01:46:40,870
lot of fun they also have some specialty
 

4447
01:46:40,870 --> 01:46:42,840
lot of fun they also have some specialty
summer schools there's one on

4448
01:46:42,840 --> 01:46:42,850
summer schools there's one on
 

4449
01:46:42,850 --> 01:46:45,840
summer schools there's one on
computational social science there's one

4450
01:46:45,840 --> 01:46:45,850
computational social science there's one
 

4451
01:46:45,850 --> 01:46:48,640
computational social science there's one
on

4452
01:46:48,640 --> 01:46:48,650

 

4453
01:46:48,650 --> 01:46:51,130

climate and sustainability I think it's

4454
01:46:51,130 --> 01:46:51,140
climate and sustainability I think it's
 

4455
01:46:51,140 --> 01:46:55,090
climate and sustainability I think it's
called there's a few and then they have

4456
01:46:55,090 --> 01:46:55,100
called there's a few and then they have
 

4457
01:46:55,100 --> 01:46:57,610
called there's a few and then they have
short courses where just a few days on

4458
01:46:57,610 --> 01:46:57,620
short courses where just a few days on
 

4459
01:46:57,620 --> 01:47:00,340
short courses where just a few days on
different topics they also have an

4460
01:47:00,340 --> 01:47:00,350
different topics they also have an
 

4461
01:47:00,350 --> 01:47:04,420
different topics they also have an
online education platform that offers a

4462
01:47:04,420 --> 01:47:04,430
online education platform that offers a
 

4463
01:47:04,430 --> 01:47:06,340
online education platform that offers a
lot of different courses and tutorials

4464
01:47:06,340 --> 01:47:06,350
lot of different courses and tutorials
 

4465
01:47:06,350 --> 01:47:09,570
lot of different courses and tutorials
from SFI faculty

4466
01:47:09,570 --> 01:47:09,580
from SFI faculty
 

4467
01:47:09,580 --> 01:47:11,760
from SFI faculty
including an introduction to complexity

4468
01:47:11,760 --> 01:47:11,770
including an introduction to complexity
 

4469
01:47:11,770 --> 01:47:15,240
including an introduction to complexity
course that I talk and there's a bunch

4470
01:47:15,240 --> 01:47:15,250
course that I talk and there's a bunch
 

4471
01:47:15,250 --> 01:47:18,750
course that I talk and there's a bunch
of talks to online from there's guest

4472
01:47:18,750 --> 01:47:18,760
of talks to online from there's guest
 

4473
01:47:18,760 --> 01:47:20,340
of talks to online from there's guest
speakers and so on they they host a lot

4474
01:47:20,340 --> 01:47:20,350
speakers and so on they they host a lot
 

4475
01:47:20,350 --> 01:47:23,430
speakers and so on they they host a lot
of yeah they have sort of technical

4476
01:47:23,430 --> 01:47:23,440
of yeah they have sort of technical
 

4477
01:47:23,440 --> 01:47:26,280
of yeah they have sort of technical
seminars and colloquia they all and they

4478
01:47:26,280 --> 01:47:26,290
seminars and colloquia they all and they
 

4479
01:47:26,290 --> 01:47:29,430
seminars and colloquia they all and they
have a community lecture series like

4480
01:47:29,430 --> 01:47:29,440
have a community lecture series like
 

4481
01:47:29,440 --> 01:47:30,960
have a community lecture series like
public lectures and they put everything

4482
01:47:30,960 --> 01:47:30,970
public lectures and they put everything
 

4483
01:47:30,970 --> 01:47:33,330
public lectures and they put everything
on their YouTube channel so you can see

4484
01:47:33,330 --> 01:47:33,340
on their YouTube channel so you can see
 

4485
01:47:33,340 --> 01:47:35,520
on their YouTube channel so you can see
it all watching douglas hofstadter

4486
01:47:35,520 --> 01:47:35,530
it all watching douglas hofstadter
 

4487
01:47:35,530 --> 01:47:39,900
it all watching douglas hofstadter
author of get olestra bach was your PhD

4488
01:47:39,900 --> 01:47:39,910
author of get olestra bach was your PhD
 

4489
01:47:39,910 --> 01:47:41,970
author of get olestra bach was your PhD
adviser he mentioned a couple times and

4490
01:47:41,970 --> 01:47:41,980
adviser he mentioned a couple times and
 

4491
01:47:41,980 --> 01:47:44,640
adviser he mentioned a couple times and
collaborator do you have any favorite

4492
01:47:44,640 --> 01:47:44,650
collaborator do you have any favorite
 

4493
01:47:44,650 --> 01:47:46,350
collaborator do you have any favorite
lessons or memories from your time

4494
01:47:46,350 --> 01:47:46,360
lessons or memories from your time
 

4495
01:47:46,360 --> 01:47:49,170
lessons or memories from your time
working with him that continues to this

4496
01:47:49,170 --> 01:47:49,180
working with him that continues to this
 

4497
01:47:49,180 --> 01:47:51,900
working with him that continues to this
day yes but just even looking back

4498
01:47:51,900 --> 01:47:51,910
day yes but just even looking back
 

4499
01:47:51,910 --> 01:47:53,670
day yes but just even looking back
through throughout your time working

4500
01:47:53,670 --> 01:47:53,680
through throughout your time working
 

4501
01:47:53,680 --> 01:47:56,880
through throughout your time working
with him so one of the things he taught

4502
01:47:56,880 --> 01:47:56,890
with him so one of the things he taught
 

4503
01:47:56,890 --> 01:48:00,950
with him so one of the things he taught
me was that when you're looking at a

4504
01:48:00,950 --> 01:48:00,960
me was that when you're looking at a
 

4505
01:48:00,960 --> 01:48:06,720
me was that when you're looking at a
complex problem to to idealize it as

4506
01:48:06,720 --> 01:48:06,730
complex problem to to idealize it as
 

4507
01:48:06,730 --> 01:48:08,460
complex problem to to idealize it as
much as possible to try and figure out

4508
01:48:08,460 --> 01:48:08,470
much as possible to try and figure out
 

4509
01:48:08,470 --> 01:48:10,500
much as possible to try and figure out
what are really what is the essence of

4510
01:48:10,500 --> 01:48:10,510
what are really what is the essence of
 

4511
01:48:10,510 --> 01:48:13,020
what are really what is the essence of
this problem and this is how like the

4512
01:48:13,020 --> 01:48:13,030
this problem and this is how like the
 

4513
01:48:13,030 --> 01:48:16,860
this problem and this is how like the
copycat program came into being was by

4514
01:48:16,860 --> 01:48:16,870
copycat program came into being was by
 

4515
01:48:16,870 --> 01:48:19,170
copycat program came into being was by
taking an analogy making and saying how

4516
01:48:19,170 --> 01:48:19,180
taking an analogy making and saying how
 

4517
01:48:19,180 --> 01:48:20,790
taking an analogy making and saying how
can we make this as idealized as

4518
01:48:20,790 --> 01:48:20,800
can we make this as idealized as
 

4519
01:48:20,800 --> 01:48:23,280
can we make this as idealized as
possible but still retain really the

4520
01:48:23,280 --> 01:48:23,290
possible but still retain really the
 

4521
01:48:23,290 --> 01:48:25,460
possible but still retain really the
important things we want to study and

4522
01:48:25,460 --> 01:48:25,470
important things we want to study and
 

4523
01:48:25,470 --> 01:48:30,440
important things we want to study and
that's really kept you know been a core

4524
01:48:30,440 --> 01:48:30,450
that's really kept you know been a core
 

4525
01:48:30,450 --> 01:48:34,560
that's really kept you know been a core
theme of my research I think and I

4526
01:48:34,560 --> 01:48:34,570
theme of my research I think and I
 

4527
01:48:34,570 --> 01:48:36,720
theme of my research I think and I
continue to try and do that and it's

4528
01:48:36,720 --> 01:48:36,730
continue to try and do that and it's
 

4529
01:48:36,730 --> 01:48:38,960
continue to try and do that and it's
really very much kind of physics

4530
01:48:38,960 --> 01:48:38,970
really very much kind of physics
 

4531
01:48:38,970 --> 01:48:42,330
really very much kind of physics
inspired Hofstadter was a PhD in physics

4532
01:48:42,330 --> 01:48:42,340
inspired Hofstadter was a PhD in physics
 

4533
01:48:42,340 --> 01:48:44,700
inspired Hofstadter was a PhD in physics
that was his background it's like first

4534
01:48:44,700 --> 01:48:44,710
that was his background it's like first
 

4535
01:48:44,710 --> 01:48:46,080
that was his background it's like first
principles kind of thinking like you

4536
01:48:46,080 --> 01:48:46,090
principles kind of thinking like you
 

4537
01:48:46,090 --> 01:48:48,480
principles kind of thinking like you
reduced to the the most fundamental

4538
01:48:48,480 --> 01:48:48,490
reduced to the the most fundamental
 

4539
01:48:48,490 --> 01:48:50,370
reduced to the the most fundamental
aspect of the problem yeah so there you

4540
01:48:50,370 --> 01:48:50,380
aspect of the problem yeah so there you
 

4541
01:48:50,380 --> 01:48:51,960
aspect of the problem yeah so there you
can focus on solving that fun than I

4542
01:48:51,960 --> 01:48:51,970
can focus on solving that fun than I
 

4543
01:48:51,970 --> 01:48:54,030
can focus on solving that fun than I
thought yeah and in AI you know that was

4544
01:48:54,030 --> 01:48:54,040
thought yeah and in AI you know that was
 

4545
01:48:54,040 --> 01:48:56,550
thought yeah and in AI you know that was
people used to work in these micro

4546
01:48:56,550 --> 01:48:56,560
people used to work in these micro
 

4547
01:48:56,560 --> 01:48:58,980
people used to work in these micro
worlds right like the blocks world was

4548
01:48:58,980 --> 01:48:58,990
worlds right like the blocks world was
 

4549
01:48:58,990 --> 01:49:03,300
worlds right like the blocks world was
very early important area in AI and then

4550
01:49:03,300 --> 01:49:03,310
very early important area in AI and then
 

4551
01:49:03,310 --> 01:49:06,180
very early important area in AI and then
that got criticized because they said oh

4552
01:49:06,180 --> 01:49:06,190
that got criticized because they said oh
 

4553
01:49:06,190 --> 01:49:07,740
that got criticized because they said oh
you know you can't scale that to the

4554
01:49:07,740 --> 01:49:07,750
you know you can't scale that to the
 

4555
01:49:07,750 --> 01:49:10,950
you know you can't scale that to the
real world and so people started working

4556
01:49:10,950 --> 01:49:10,960
real world and so people started working
 

4557
01:49:10,960 --> 01:49:12,810
real world and so people started working
on much like more real world like

4558
01:49:12,810 --> 01:49:12,820
on much like more real world like
 

4559
01:49:12,820 --> 01:49:16,440
on much like more real world like
problems but now there's been kind of a

4560
01:49:16,440 --> 01:49:16,450
problems but now there's been kind of a
 

4561
01:49:16,450 --> 01:49:19,410
problems but now there's been kind of a
return even to the blocks world itself

4562
01:49:19,410 --> 01:49:19,420
return even to the blocks world itself
 

4563
01:49:19,420 --> 01:49:21,270
return even to the blocks world itself
you know we've seen a lot of people who

4564
01:49:21,270 --> 01:49:21,280
you know we've seen a lot of people who
 

4565
01:49:21,280 --> 01:49:22,540
you know we've seen a lot of people who
are trying to work on

4566
01:49:22,540 --> 01:49:22,550
are trying to work on
 

4567
01:49:22,550 --> 01:49:24,700
are trying to work on
more of these very idealized problems or

4568
01:49:24,700 --> 01:49:24,710
more of these very idealized problems or
 

4569
01:49:24,710 --> 01:49:27,910
more of these very idealized problems or
things like natural language and common

4570
01:49:27,910 --> 01:49:27,920
things like natural language and common
 

4571
01:49:27,920 --> 01:49:30,310
things like natural language and common
sense so that's an interesting evolution

4572
01:49:30,310 --> 01:49:30,320
sense so that's an interesting evolution
 

4573
01:49:30,320 --> 01:49:33,220
sense so that's an interesting evolution
of those ideas so the perhaps the

4574
01:49:33,220 --> 01:49:33,230
of those ideas so the perhaps the
 

4575
01:49:33,230 --> 01:49:34,750
of those ideas so the perhaps the
block's world's represents the

4576
01:49:34,750 --> 01:49:34,760
block's world's represents the
 

4577
01:49:34,760 --> 01:49:36,940
block's world's represents the
fundamental challenges of the problem of

4578
01:49:36,940 --> 01:49:36,950
fundamental challenges of the problem of
 

4579
01:49:36,950 --> 01:49:38,800
fundamental challenges of the problem of
intelligence more than people realized

4580
01:49:38,800 --> 01:49:38,810
intelligence more than people realized
 

4581
01:49:38,810 --> 01:49:42,970
intelligence more than people realized
it might yeah is there sort of when you

4582
01:49:42,970 --> 01:49:42,980
it might yeah is there sort of when you
 

4583
01:49:42,980 --> 01:49:44,680
it might yeah is there sort of when you
look back at your body of work and your

4584
01:49:44,680 --> 01:49:44,690
look back at your body of work and your
 

4585
01:49:44,690 --> 01:49:46,060
look back at your body of work and your
life you've worked in so many different

4586
01:49:46,060 --> 01:49:46,070
life you've worked in so many different
 

4587
01:49:46,070 --> 01:49:48,220
life you've worked in so many different
fields is there something that you're

4588
01:49:48,220 --> 01:49:48,230
fields is there something that you're
 

4589
01:49:48,230 --> 01:49:51,310
fields is there something that you're
just really proud of in terms of ideas

4590
01:49:51,310 --> 01:49:51,320
just really proud of in terms of ideas
 

4591
01:49:51,320 --> 01:49:52,900
just really proud of in terms of ideas
that you've gotten chance to explore

4592
01:49:52,900 --> 01:49:52,910
that you've gotten chance to explore
 

4593
01:49:52,910 --> 01:49:56,830
that you've gotten chance to explore
create yourself so I am really proud of

4594
01:49:56,830 --> 01:49:56,840
create yourself so I am really proud of
 

4595
01:49:56,840 --> 01:49:59,770
create yourself so I am really proud of
my work on the copycat project I think

4596
01:49:59,770 --> 01:49:59,780
my work on the copycat project I think
 

4597
01:49:59,780 --> 01:50:03,220
my work on the copycat project I think
it's really different from what almost

4598
01:50:03,220 --> 01:50:03,230
it's really different from what almost
 

4599
01:50:03,230 --> 01:50:05,470
it's really different from what almost
everyone is done in AI I think there's a

4600
01:50:05,470 --> 01:50:05,480
everyone is done in AI I think there's a
 

4601
01:50:05,480 --> 01:50:09,460
everyone is done in AI I think there's a
lot of ideas there to be explored and I

4602
01:50:09,460 --> 01:50:09,470
lot of ideas there to be explored and I
 

4603
01:50:09,470 --> 01:50:12,250
lot of ideas there to be explored and I
guess one of the happiest days of my

4604
01:50:12,250 --> 01:50:12,260
guess one of the happiest days of my
 

4605
01:50:12,260 --> 01:50:16,150
guess one of the happiest days of my
life you know aside from like the births

4606
01:50:16,150 --> 01:50:16,160
life you know aside from like the births
 

4607
01:50:16,160 --> 01:50:19,990
life you know aside from like the births
of my children was the birth of copycat

4608
01:50:19,990 --> 01:50:20,000
of my children was the birth of copycat
 

4609
01:50:20,000 --> 01:50:21,520
of my children was the birth of copycat
when it actually started to be able to

4610
01:50:21,520 --> 01:50:21,530
when it actually started to be able to
 

4611
01:50:21,530 --> 01:50:25,630
when it actually started to be able to
make really interesting analogies and I

4612
01:50:25,630 --> 01:50:25,640
make really interesting analogies and I
 

4613
01:50:25,640 --> 01:50:27,940
make really interesting analogies and I
remember that very clearly you know it

4614
01:50:27,940 --> 01:50:27,950
remember that very clearly you know it
 

4615
01:50:27,950 --> 01:50:31,630
remember that very clearly you know it
was very exciting time well you kind of

4616
01:50:31,630 --> 01:50:31,640
was very exciting time well you kind of
 

4617
01:50:31,640 --> 01:50:34,740
was very exciting time well you kind of
gave life yes artificial so that's right

4618
01:50:34,740 --> 01:50:34,750
gave life yes artificial so that's right
 

4619
01:50:34,750 --> 01:50:36,850
gave life yes artificial so that's right
what in terms of what people can

4620
01:50:36,850 --> 01:50:36,860
what in terms of what people can
 

4621
01:50:36,860 --> 01:50:39,460
what in terms of what people can
interact I saw there's like a I think

4622
01:50:39,460 --> 01:50:39,470
interact I saw there's like a I think
 

4623
01:50:39,470 --> 01:50:41,800
interact I saw there's like a I think
it's called meta copy kinetic hat mad

4624
01:50:41,800 --> 01:50:41,810
it's called meta copy kinetic hat mad
 

4625
01:50:41,810 --> 01:50:44,110
it's called meta copy kinetic hat mad
cat and there's a Python three

4626
01:50:44,110 --> 01:50:44,120
cat and there's a Python three
 

4627
01:50:44,120 --> 01:50:46,120
cat and there's a Python three
implementation at if people actually

4628
01:50:46,120 --> 01:50:46,130
implementation at if people actually
 

4629
01:50:46,130 --> 01:50:47,740
implementation at if people actually
want to play around with it and actually

4630
01:50:47,740 --> 01:50:47,750
want to play around with it and actually
 

4631
01:50:47,750 --> 01:50:49,920
want to play around with it and actually
get into it and study it maybe integrate

4632
01:50:49,920 --> 01:50:49,930
get into it and study it maybe integrate
 

4633
01:50:49,930 --> 01:50:52,540
get into it and study it maybe integrate
into whether it's with deep learning or

4634
01:50:52,540 --> 01:50:52,550
into whether it's with deep learning or
 

4635
01:50:52,550 --> 01:50:53,980
into whether it's with deep learning or
any other kind of work they're doing

4636
01:50:53,980 --> 01:50:53,990
any other kind of work they're doing
 

4637
01:50:53,990 --> 01:50:57,280
any other kind of work they're doing
what what would you suggest they do to

4638
01:50:57,280 --> 01:50:57,290
what what would you suggest they do to
 

4639
01:50:57,290 --> 01:50:59,350
what what would you suggest they do to
learn more about it and to take it

4640
01:50:59,350 --> 01:50:59,360
learn more about it and to take it
 

4641
01:50:59,360 --> 01:51:00,970
learn more about it and to take it
forward in different kinds of directions

4642
01:51:00,970 --> 01:51:00,980
forward in different kinds of directions
 

4643
01:51:00,980 --> 01:51:03,490
forward in different kinds of directions
yeah so that there's a Douglas

4644
01:51:03,490 --> 01:51:03,500
yeah so that there's a Douglas
 

4645
01:51:03,500 --> 01:51:06,100
yeah so that there's a Douglas
Hofstadter's book called fluid concepts

4646
01:51:06,100 --> 01:51:06,110
Hofstadter's book called fluid concepts
 

4647
01:51:06,110 --> 01:51:08,590
Hofstadter's book called fluid concepts
and creative analogies talks in great

4648
01:51:08,590 --> 01:51:08,600
and creative analogies talks in great
 

4649
01:51:08,600 --> 01:51:10,810
and creative analogies talks in great
detail about copycat I have a book

4650
01:51:10,810 --> 01:51:10,820
detail about copycat I have a book
 

4651
01:51:10,820 --> 01:51:13,300
detail about copycat I have a book
called analogy making as perception

4652
01:51:13,300 --> 01:51:13,310
called analogy making as perception
 

4653
01:51:13,310 --> 01:51:16,030
called analogy making as perception
which is a version of my PhD thesis on

4654
01:51:16,030 --> 01:51:16,040
which is a version of my PhD thesis on
 

4655
01:51:16,040 --> 01:51:16,270
which is a version of my PhD thesis on
it

4656
01:51:16,270 --> 01:51:16,280
it
 

4657
01:51:16,280 --> 01:51:19,330
it
there's also code that's available that

4658
01:51:19,330 --> 01:51:19,340
there's also code that's available that
 

4659
01:51:19,340 --> 01:51:21,820
there's also code that's available that
you can get it to run I have some links

4660
01:51:21,820 --> 01:51:21,830
you can get it to run I have some links
 

4661
01:51:21,830 --> 01:51:24,280
you can get it to run I have some links
on my web page to where people can get

4662
01:51:24,280 --> 01:51:24,290
on my web page to where people can get
 

4663
01:51:24,290 --> 01:51:27,640
on my web page to where people can get
the code for it and I think that that

4664
01:51:27,640 --> 01:51:27,650
the code for it and I think that that
 

4665
01:51:27,650 --> 01:51:29,080
the code for it and I think that that
would really be the best way I get into

4666
01:51:29,080 --> 01:51:29,090
would really be the best way I get into
 

4667
01:51:29,090 --> 01:51:32,590
would really be the best way I get into
it yeah play with it well Melanie is a

4668
01:51:32,590 --> 01:51:32,600
it yeah play with it well Melanie is a
 

4669
01:51:32,600 --> 01:51:34,570
it yeah play with it well Melanie is a
honor talking to you I really enjoyed it

4670
01:51:34,570 --> 01:51:34,580
honor talking to you I really enjoyed it
 

4671
01:51:34,580 --> 01:51:36,279
honor talking to you I really enjoyed it
thank you so much for your time today

4672
01:51:36,279 --> 01:51:36,289
thank you so much for your time today
 

4673
01:51:36,289 --> 01:51:38,529
thank you so much for your time today
has been really great

4674
01:51:38,529 --> 01:51:38,539
has been really great
 

4675
01:51:38,539 --> 01:51:39,700
has been really great
thanks for listening to this

4676
01:51:39,700 --> 01:51:39,710
thanks for listening to this
 

4677
01:51:39,710 --> 01:51:41,649
thanks for listening to this
conversation with Melanie Mitchell and

4678
01:51:41,649 --> 01:51:41,659
conversation with Melanie Mitchell and
 

4679
01:51:41,659 --> 01:51:44,140
conversation with Melanie Mitchell and
thank you to our presenting sponsor cash

4680
01:51:44,140 --> 01:51:44,150
thank you to our presenting sponsor cash
 

4681
01:51:44,150 --> 01:51:47,290
thank you to our presenting sponsor cash
app downloaded use code Lex podcast

4682
01:51:47,290 --> 01:51:47,300
app downloaded use code Lex podcast
 

4683
01:51:47,300 --> 01:51:49,600
app downloaded use code Lex podcast
you'll get ten dollars and ten dollars

4684
01:51:49,600 --> 01:51:49,610
you'll get ten dollars and ten dollars
 

4685
01:51:49,610 --> 01:51:51,700
you'll get ten dollars and ten dollars
will go to first a stem education

4686
01:51:51,700 --> 01:51:51,710
will go to first a stem education
 

4687
01:51:51,710 --> 01:51:53,709
will go to first a stem education
nonprofit that inspires hundreds of

4688
01:51:53,709 --> 01:51:53,719
nonprofit that inspires hundreds of
 

4689
01:51:53,719 --> 01:51:56,259
nonprofit that inspires hundreds of
thousands of young minds to learn and to

4690
01:51:56,259 --> 01:51:56,269
thousands of young minds to learn and to
 

4691
01:51:56,269 --> 01:51:59,049
thousands of young minds to learn and to
dream of engineering our future if you

4692
01:51:59,049 --> 01:51:59,059
dream of engineering our future if you
 

4693
01:51:59,059 --> 01:52:00,609
dream of engineering our future if you
enjoyed this podcast subscribe on

4694
01:52:00,609 --> 01:52:00,619
enjoyed this podcast subscribe on
 

4695
01:52:00,619 --> 01:52:02,379
enjoyed this podcast subscribe on
youtube give it five stars an apple

4696
01:52:02,379 --> 01:52:02,389
youtube give it five stars an apple
 

4697
01:52:02,389 --> 01:52:04,899
youtube give it five stars an apple
podcast supported on patreon or connect

4698
01:52:04,899 --> 01:52:04,909
podcast supported on patreon or connect
 

4699
01:52:04,909 --> 01:52:07,750
podcast supported on patreon or connect
with me on Twitter and now let me leave

4700
01:52:07,750 --> 01:52:07,760
with me on Twitter and now let me leave
 

4701
01:52:07,760 --> 01:52:09,939
with me on Twitter and now let me leave
you some words of wisdom from Douglas

4702
01:52:09,939 --> 01:52:09,949
you some words of wisdom from Douglas
 

4703
01:52:09,949 --> 01:52:12,850
you some words of wisdom from Douglas
Hofstadter and Melanie Mitchell without

4704
01:52:12,850 --> 01:52:12,860
Hofstadter and Melanie Mitchell without
 

4705
01:52:12,860 --> 01:52:15,399
Hofstadter and Melanie Mitchell without
concepts there can be no thought and

4706
01:52:15,399 --> 01:52:15,409
concepts there can be no thought and
 

4707
01:52:15,409 --> 01:52:16,990
concepts there can be no thought and
without analogies there can be no

4708
01:52:16,990 --> 01:52:17,000
without analogies there can be no
 

4709
01:52:17,000 --> 01:52:21,129
without analogies there can be no
concepts and Melanie adds how to form

4710
01:52:21,129 --> 01:52:21,139
concepts and Melanie adds how to form
 

4711
01:52:21,139 --> 01:52:24,069
concepts and Melanie adds how to form
and fluidly use concepts is the most

4712
01:52:24,069 --> 01:52:24,079
and fluidly use concepts is the most
 

4713
01:52:24,079 --> 01:52:27,149
and fluidly use concepts is the most
important open problem in AI

4714
01:52:27,149 --> 01:52:27,159
important open problem in AI
 

4715
01:52:27,159 --> 01:52:29,589
important open problem in AI
thank you for listening and hope to see

4716
01:52:29,589 --> 01:52:29,599
thank you for listening and hope to see
 

4717
01:52:29,599 --> 01:52:37,590
thank you for listening and hope to see
you next time

4718
01:52:37,590 --> 01:52:37,600

 

4719
01:52:37,600 --> 01:52:39,660

you


1
00:00:00,120 --> 00:00:03,820
- The following is a
conversation with Noam Chomsky.

2
00:00:03,820 --> 00:00:06,780
He's truly one of the
great minds of our time

3
00:00:06,780 --> 00:00:08,430
and is one of the most cited scholars

4
00:00:08,430 --> 00:00:10,770
in the history of our civilization.

5
00:00:10,770 --> 00:00:13,440
He has spent over 60 years at MIT

6
00:00:13,440 --> 00:00:16,350
and recently also joined
the University of Arizona

7
00:00:16,350 --> 00:00:18,660
where we met for this conversation,

8
00:00:18,660 --> 00:00:21,840
but it was at MIT about
four and 1/2 years ago

9
00:00:21,840 --> 00:00:23,480
when I first met Noam.

10
00:00:23,480 --> 00:00:25,180
My first few days there I remember

11
00:00:25,180 --> 00:00:27,420
getting into an elevator at Stata Center,

12
00:00:27,420 --> 00:00:30,600
pressing the button for
whatever floor, looking up

13
00:00:30,600 --> 00:00:33,610
and realizing it was
just me and Noam Chomsky

14
00:00:33,610 --> 00:00:37,490
riding the elevator, just me
and one of the seminal figures

15
00:00:37,490 --> 00:00:40,040
of linguistics, cognitive
science, philosophy,

16
00:00:40,040 --> 00:00:43,950
and political thought in the
past century if not ever.

17
00:00:43,950 --> 00:00:46,930
I tell that silly story
because I think life

18
00:00:46,930 --> 00:00:49,230
is made up of funny
little defining moments

19
00:00:49,230 --> 00:00:52,813
that you never forget for
reasons that may be too poetic

20
00:00:52,813 --> 00:00:56,193
to try and explain, that was one of mine.

21
00:00:57,350 --> 00:01:00,940
Noam has been an inspiration
to me and millions of others.

22
00:01:00,940 --> 00:01:02,610
It was truly an honor for me

23
00:01:02,610 --> 00:01:04,630
to sit down with him in Arizona.

24
00:01:04,630 --> 00:01:07,520
I traveled there just
for this conversation,

25
00:01:07,520 --> 00:01:10,150
and in a rare, heartbreaking moment

26
00:01:10,150 --> 00:01:12,720
after everything was set up and tested

27
00:01:12,720 --> 00:01:14,520
the camera was moved and accidentally

28
00:01:14,520 --> 00:01:17,320
the recording button was
pressed stopping the recording.

29
00:01:18,550 --> 00:01:22,180
So I have good audio of both
of us but no video of Noam,

30
00:01:22,180 --> 00:01:26,640
just a video of me and my
sleep deprived but excited face

31
00:01:26,640 --> 00:01:30,153
that I get to keep as a
reminder of my failures.

32
00:01:30,153 --> 00:01:32,500
Most people just listen
to this audio version

33
00:01:32,500 --> 00:01:35,800
for the podcast as opposed
to watching it on YouTube,

34
00:01:35,800 --> 00:01:39,040
but still it's heartbreaking for me.

35
00:01:39,040 --> 00:01:40,320
I hope you understand

36
00:01:40,320 --> 00:01:43,140
and still enjoy this
conversation as much as I did.

37
00:01:43,140 --> 00:01:45,042
The depth of intellect that Noam showed

38
00:01:45,042 --> 00:01:48,360
and his willingness to truly listen to me,

39
00:01:48,360 --> 00:01:52,550
a silly looking Russian
in a suit was humbling

40
00:01:52,550 --> 00:01:54,663
and something I'm deeply grateful for.

41
00:01:55,580 --> 00:01:59,334
As some of you know, this
podcast is a side project for me

42
00:01:59,334 --> 00:02:02,260
where my main journey and dream

43
00:02:02,260 --> 00:02:05,480
is to build AI systems that
do some good for the world.

44
00:02:05,480 --> 00:02:07,820
This latter effort
takes up most of my time

45
00:02:07,820 --> 00:02:10,560
but for the moment has
been mostly private,

46
00:02:10,560 --> 00:02:14,110
but the former, the podcast
is something I put my heart

47
00:02:14,110 --> 00:02:16,850
and soul into and I hope you feel that

48
00:02:16,850 --> 00:02:18,603
even when I screw things up.

49
00:02:19,550 --> 00:02:21,150
I recently started doing ads

50
00:02:21,150 --> 00:02:22,870
at the end of the introduction.

51
00:02:22,870 --> 00:02:25,660
I'll do one or two minutes
after introducing the episode

52
00:02:25,660 --> 00:02:27,440
and never any ads in the middle

53
00:02:27,440 --> 00:02:29,750
that break the flow of the conversation.

54
00:02:29,750 --> 00:02:31,210
I hope that works for you

55
00:02:31,210 --> 00:02:33,980
and doesn't hurt the listening experience.

56
00:02:33,980 --> 00:02:37,230
This is the Artificial
Intelligence podcast.

57
00:02:37,230 --> 00:02:39,850
If you enjoy it, subscribe on YouTube,

58
00:02:39,850 --> 00:02:41,880
give it five stars on Apple Podcast,

59
00:02:41,880 --> 00:02:45,377
support it on Patreon, or simply
contact with me on Twitter

60
00:02:45,377 --> 00:02:49,470
@lexfridman spelled F-R-I-D-M-A-N.

61
00:02:49,470 --> 00:02:51,760
This show is presented by Cash App,

62
00:02:51,760 --> 00:02:54,270
the number one finance
app on the App Store.

63
00:02:54,270 --> 00:02:56,850
I personally use cash app
to send money to friends,

64
00:02:56,850 --> 00:02:58,790
but you can also use it to buy, sell,

65
00:02:58,790 --> 00:03:01,370
and deposit Bitcoin in just seconds.

66
00:03:01,370 --> 00:03:04,220
Cash App also has a new investing feature.

67
00:03:04,220 --> 00:03:05,820
You can buy fractions of a stock,

68
00:03:05,820 --> 00:03:09,260
say $1 worth, no matter
what the stock price is.

69
00:03:09,260 --> 00:03:11,990
Broker services are provided
by Cash App Investing,

70
00:03:11,990 --> 00:03:15,570
a subsidiary of Square and member SIPC.

71
00:03:15,570 --> 00:03:17,700
I'm excited to be working with Cash App

72
00:03:17,700 --> 00:03:20,910
to support one of my favorite
organizations called the FIRST

73
00:03:20,910 --> 00:03:24,360
best known for their FIRST
robotics and LEGO competitions.

74
00:03:24,360 --> 00:03:27,710
They educate and inspire
hundreds of thousands of students

75
00:03:27,710 --> 00:03:30,740
in over 110 countries
and have a perfect rating

76
00:03:30,740 --> 00:03:33,840
on Charity Navigator which
means the donated money

77
00:03:33,840 --> 00:03:36,580
is used to maximum effectiveness.

78
00:03:36,580 --> 00:03:39,566
When you get Cash App in
the App Store or Google Play

79
00:03:39,566 --> 00:03:43,980
and use code LexPodcast you'll get $10

80
00:03:43,980 --> 00:03:47,140
and Cash App will also
donate $10 to FIRST,

81
00:03:47,140 --> 00:03:48,790
which again is an organization

82
00:03:48,790 --> 00:03:51,390
that I've personally seen
inspire girls and boys

83
00:03:51,390 --> 00:03:54,180
to dream of engineering a better world.

84
00:03:54,180 --> 00:03:58,923
And now here's my conversation
with Noam Chomsky.

85
00:03:59,860 --> 00:04:04,150
I apologize for the absurd
philosophical question,

86
00:04:04,150 --> 00:04:07,173
but if an alien species
were to visit Earth,

87
00:04:08,200 --> 00:04:10,960
do you think we would be able
to find a common language

88
00:04:10,960 --> 00:04:13,720
or protocol of communication with them?

89
00:04:13,720 --> 00:04:18,360
- [Noam] There are arguments
to the effect that we could.

90
00:04:18,360 --> 00:04:22,500
In fact, one of them was Marv Minsky's.

91
00:04:22,500 --> 00:04:26,860
Back about 20 or 30 years ago he performed

92
00:04:26,860 --> 00:04:31,020
a brief experiment with a
student of his, Daniel Bobrow

93
00:04:31,020 --> 00:04:36,020
they essentially ran the
simplest possible Turing machines

94
00:04:36,760 --> 00:04:39,610
just free to see what would happen.

95
00:04:39,610 --> 00:04:44,320
And most of them crashed,
either got into an infinite loop

96
00:04:44,320 --> 00:04:49,320
or were stopped, the few that persisted

97
00:04:51,050 --> 00:04:55,500
essentially gave
something like arithmetic.

98
00:04:55,500 --> 00:04:58,550
And his conclusion from that was

99
00:04:58,550 --> 00:05:03,550
that if some alien species
developed higher intelligence

100
00:05:05,850 --> 00:05:07,490
they would at least have arithmetic.

101
00:05:07,490 --> 00:05:12,490
They would at least have what
the simplest computer would do

102
00:05:12,970 --> 00:05:16,080
and in fact he didn't
know that at the time,

103
00:05:16,080 --> 00:05:20,800
but the core principles
of natural language

104
00:05:20,800 --> 00:05:25,260
are based on operations
which yield something

105
00:05:25,260 --> 00:05:29,400
like arithmetic in the limiting
case, in the minimal case.

106
00:05:29,400 --> 00:05:34,090
So it's conceivable that
a mode of communication

107
00:05:34,090 --> 00:05:38,600
could be established based
on the core properties

108
00:05:38,600 --> 00:05:41,510
of human language and the
core properties of arithmetic

109
00:05:41,510 --> 00:05:46,510
which maybe are universally
shared so it's conceivable.

110
00:05:46,720 --> 00:05:50,830
- [Lex] What is the
structure of that language,

111
00:05:50,830 --> 00:05:55,180
of language as an internal
system inside our mind

112
00:05:55,180 --> 00:05:58,163
versus an external
system as it's expressed?

113
00:05:59,060 --> 00:06:00,910
- [Noam] It's not an alternative.

114
00:06:00,910 --> 00:06:02,950
It's two different concepts of language.

115
00:06:02,950 --> 00:06:03,783
- [Lex] Different.

116
00:06:03,783 --> 00:06:05,000
- [Noam] It's a simple fact

117
00:06:05,000 --> 00:06:09,030
that there's something
about you, a trait of yours,

118
00:06:09,030 --> 00:06:13,220
part of the organism you that determines

119
00:06:13,220 --> 00:06:17,020
that you're talking English
and not Tagalog, let's say.

120
00:06:17,020 --> 00:06:18,683
So there is an inner system.

121
00:06:19,550 --> 00:06:23,010
It determines the sound and meaning

122
00:06:23,010 --> 00:06:27,150
of the infinite number of
expressions of your language.

123
00:06:27,150 --> 00:06:29,750
It's localized, it's not in your foot

124
00:06:29,750 --> 00:06:31,790
obviously it's in your brain.

125
00:06:31,790 --> 00:06:35,280
If you look more closely it's
in specific configurations

126
00:06:35,280 --> 00:06:37,820
of your brain and that's essentially

127
00:06:37,820 --> 00:06:42,000
like the internal
structure of your laptop.

128
00:06:42,000 --> 00:06:45,010
Whatever programs it has are in there.

129
00:06:45,010 --> 00:06:47,723
Now, one of the things
you can do with language,

130
00:06:47,723 --> 00:06:52,723
it's a marginal thing in
fact is use it to externalize

131
00:06:53,410 --> 00:06:54,990
what's in your head.

132
00:06:54,990 --> 00:06:57,400
I think most of your use
of language is thought,

133
00:06:57,400 --> 00:07:00,960
internal thought, but can do
what you and I are now doing.

134
00:07:00,960 --> 00:07:02,690
We can externalize it.

135
00:07:02,690 --> 00:07:05,680
Well, the set of things
that we're externalizing

136
00:07:05,680 --> 00:07:10,680
are an external system, they're
noises in the atmosphere,

137
00:07:11,200 --> 00:07:12,950
and you can call that language

138
00:07:12,950 --> 00:07:14,420
in some other sense of the word,

139
00:07:14,420 --> 00:07:16,870
but it's not a set of alternatives.

140
00:07:16,870 --> 00:07:19,010
These are just different concepts.

141
00:07:19,010 --> 00:07:20,610
- [Lex] So how deep do the roots

142
00:07:20,610 --> 00:07:22,253
of language go in our brain?

143
00:07:23,140 --> 00:07:24,111
- Well--
- Our mind,

144
00:07:24,111 --> 00:07:26,830
is it yet another feature like vision?

145
00:07:26,830 --> 00:07:28,510
Or is it something more fundamental

146
00:07:28,510 --> 00:07:31,560
from which everything else
springs in the human mind?

147
00:07:31,560 --> 00:07:33,903
- [Noam] Well in a way it's like vision.

148
00:07:35,960 --> 00:07:38,630
There's something about
our genetic endowment

149
00:07:38,630 --> 00:07:41,650
that determines that we have a mammalian

150
00:07:41,650 --> 00:07:44,750
rather than an insect visual system.

151
00:07:44,750 --> 00:07:47,470
And there's something
in our genetic endowment

152
00:07:47,470 --> 00:07:51,510
that determines that we have
a human language faculty.

153
00:07:51,510 --> 00:07:55,240
No other organism has
anything remotely similar.

154
00:07:55,240 --> 00:07:58,300
So in that sense it's internal.

155
00:07:58,300 --> 00:08:01,330
Now, there is a long tradition
which I think is valid

156
00:08:01,330 --> 00:08:05,550
going back centuries to the
early scientific revolution

157
00:08:05,550 --> 00:08:10,330
at least that holds that language is the

158
00:08:10,330 --> 00:08:13,660
sort of the core of
human cognitive nature.

159
00:08:13,660 --> 00:08:18,140
It's the source, it's the
mode for constructing thoughts

160
00:08:18,140 --> 00:08:22,780
and expressing them and
that is what forms thought

161
00:08:22,780 --> 00:08:27,220
and it's got fundamental
creative capacities.

162
00:08:27,220 --> 00:08:31,320
It's free, independent,
unbounded and so on.

163
00:08:31,320 --> 00:08:34,870
And undoubtedly I think the basis

164
00:08:34,870 --> 00:08:39,870
for our creative capacities
and the other remarkable

165
00:08:42,530 --> 00:08:47,490
human capacities that lead
to the unique achievements

166
00:08:47,490 --> 00:08:51,300
and not so great
achievements of the species.

167
00:08:51,300 --> 00:08:53,620
- [Lex] The capacity to think and reason.

168
00:08:53,620 --> 00:08:56,250
Do you think that's deeply
linked with language?

169
00:08:56,250 --> 00:09:01,010
Do you think the internal
language system is essentially

170
00:09:01,010 --> 00:09:04,160
the mechanism by which we
also reason internally?

171
00:09:04,160 --> 00:09:06,970
- [Noam] It is undoubtedly the
mechanism by which we reason.

172
00:09:06,970 --> 00:09:10,900
There may also be other,
there are undoubtedly

173
00:09:10,900 --> 00:09:13,263
other faculties involved in reasoning.

174
00:09:14,750 --> 00:09:17,560
We have a kind of scientific faculty.

175
00:09:17,560 --> 00:09:19,970
Nobody knows what it
is, but whatever it is

176
00:09:19,970 --> 00:09:24,740
that enables us to pursue
certain lines of endeavor

177
00:09:24,740 --> 00:09:28,480
and inquiry and to decide what makes sense

178
00:09:28,480 --> 00:09:32,240
and doesn't make sense and
to achieve a certain degree

179
00:09:32,240 --> 00:09:35,330
of understanding in the
world that uses language

180
00:09:35,330 --> 00:09:40,330
but goes beyond it just as using
our capacity for arithmetic

181
00:09:42,060 --> 00:09:44,010
is not the same as having the capacity.

182
00:09:45,154 --> 00:09:49,420
- [Lex] The idea of capacity,
our biology, evolution,

183
00:09:49,420 --> 00:09:52,550
you've talked about it defining
essentially our capacity,

184
00:09:52,550 --> 00:09:55,240
our limit and our scope.

185
00:09:55,240 --> 00:09:58,510
Can you try to define
what limit and scope are,

186
00:09:58,510 --> 00:10:02,450
and the bigger question,
do you think it's possible

187
00:10:02,450 --> 00:10:06,263
to find the limit of human cognition?

188
00:10:07,600 --> 00:10:09,930
- [Noam] Well that's an
interesting question.

189
00:10:09,930 --> 00:10:13,120
It's commonly believed,
most scientists believe

190
00:10:13,120 --> 00:10:15,750
that human intelligence

191
00:10:15,750 --> 00:10:19,380
can answer any question in principle.

192
00:10:19,380 --> 00:10:21,830
I think that's a very strange belief.

193
00:10:21,830 --> 00:10:26,190
If we're biological organisms
which are not angels

194
00:10:26,190 --> 00:10:31,190
then our capacities ought
to have scope and limits

195
00:10:33,220 --> 00:10:34,950
which are interrelated.

196
00:10:34,950 --> 00:10:36,650
- [Lex] Can you define those two terms?

197
00:10:36,650 --> 00:10:40,790
- [Noam] Well, let's
take a concrete example.

198
00:10:40,790 --> 00:10:44,080
Your genetic endowment, it determines

199
00:10:44,080 --> 00:10:46,870
that you can have a
mammalian visual system

200
00:10:46,870 --> 00:10:48,690
and arms and legs and so on

201
00:10:50,040 --> 00:10:53,480
and therefore become a
rich, complex organism,

202
00:10:53,480 --> 00:10:56,270
but if you look at that
same genetic endowment

203
00:10:56,270 --> 00:11:00,030
it prevents you from
developing in other directions.

204
00:11:00,030 --> 00:11:04,317
There's no kind of experience
which would yield the embryo

205
00:11:05,810 --> 00:11:08,800
to develop an insect visual system

206
00:11:08,800 --> 00:11:12,010
or to develop wings instead of arms.

207
00:11:12,010 --> 00:11:17,010
So the very endowment that
confers richness and complexity

208
00:11:18,490 --> 00:11:23,490
also sets bounds on what can be attained.

209
00:11:23,620 --> 00:11:27,480
Now I assume that our cognitive capacities

210
00:11:27,480 --> 00:11:29,680
are part of the organic world

211
00:11:29,680 --> 00:11:32,300
therefore they should
have the same properties.

212
00:11:32,300 --> 00:11:36,845
If they had no built-in
capacity to develop a rich

213
00:11:36,845 --> 00:11:41,414
and complex structure we
would understand nothing

214
00:11:41,414 --> 00:11:46,100
just as if your genetic endowment

215
00:11:46,100 --> 00:11:50,360
did not compel you to
develop arms and legs

216
00:11:50,360 --> 00:11:54,040
you would just be some kind
of a random ameboid creature

217
00:11:54,040 --> 00:11:57,640
with no structure at all
so I think it's plausible

218
00:11:57,640 --> 00:12:00,270
to assume that there are limits,

219
00:12:00,270 --> 00:12:03,730
and I think we even have some
evidence as to what they are.

220
00:12:03,730 --> 00:12:06,700
So for example there's a classic moment

221
00:12:06,700 --> 00:12:10,713
in the history of science
at the time of Newton.

222
00:12:11,660 --> 00:12:15,918
There was from Galileo to
Newton modern science developed

223
00:12:15,918 --> 00:12:20,160
on a fundamental assumption
which Newton also accepted,

224
00:12:20,160 --> 00:12:24,120
namely that the world, the entire universe

225
00:12:24,120 --> 00:12:28,630
is a mechanical object and
by mechanical they meant

226
00:12:28,630 --> 00:12:30,660
something like the kinds of artifacts

227
00:12:30,660 --> 00:12:33,030
that were being developed
by skilled artisans

228
00:12:33,030 --> 00:12:37,150
all over Europe, the
gears, levers, and so on.

229
00:12:37,150 --> 00:12:39,820
And their belief was, well the world

230
00:12:39,820 --> 00:12:42,740
is just a more complex variant of this.

231
00:12:42,740 --> 00:12:47,740
Newton to his astonishment
and distress proved that there

232
00:12:49,180 --> 00:12:53,503
are no machines, that there's
interaction without contact.

233
00:12:54,350 --> 00:12:57,710
His contemporaries like
Leibniz and Huygens

234
00:12:57,710 --> 00:13:02,580
just dismissed this as
returning to the mysticism

235
00:13:02,580 --> 00:13:05,880
of the Neo-Scholastics and Newton agreed.

236
00:13:05,880 --> 00:13:08,227
He said, "It is totally absurd.

237
00:13:08,227 --> 00:13:11,067
"No person of any scientific intelligence

238
00:13:11,067 --> 00:13:13,810
"could ever accept this for a moment."

239
00:13:13,810 --> 00:13:15,330
In fact, he spent the rest of his life

240
00:13:15,330 --> 00:13:17,760
trying to get around it somehow

241
00:13:17,760 --> 00:13:20,340
as did many other scientists.

242
00:13:20,340 --> 00:13:24,100
That was the very criterion
of intelligibility

243
00:13:24,100 --> 00:13:26,543
for say Galileo or Newton.

244
00:13:27,690 --> 00:13:31,390
Theory did not produce
an intelligible world

245
00:13:31,390 --> 00:13:34,090
unless you could duplicate it in a machine

246
00:13:34,090 --> 00:13:37,550
and he showed you can't,
there are no machines, any.

247
00:13:37,550 --> 00:13:41,250
Finally after a long
struggle, took a long time

248
00:13:41,250 --> 00:13:45,250
scientists just accepted
this as common sense,

249
00:13:45,250 --> 00:13:47,410
but that's a significant moment.

250
00:13:47,410 --> 00:13:49,370
That means they abandoned the search

251
00:13:49,370 --> 00:13:54,050
for an intelligible world
and the great philosophers

252
00:13:54,050 --> 00:13:57,010
of the time understood that very well.

253
00:13:57,010 --> 00:14:02,010
So for example, David Hume
in his encomium to Newton

254
00:14:02,330 --> 00:14:05,570
wrote that, who was the
greatest thinker ever and so on.

255
00:14:05,570 --> 00:14:10,530
He said that he unveiled
many of the secrets of nature

256
00:14:10,530 --> 00:14:13,007
but by showing the imperfections

257
00:14:13,007 --> 00:14:17,520
of the mechanical philosophy,
mechanical science

258
00:14:17,520 --> 00:14:21,250
he left us with, he showed
that there are mysteries

259
00:14:21,250 --> 00:14:26,250
which ever will remain, and
science just changed its goals.

260
00:14:26,750 --> 00:14:28,720
It abandoned the mysteries.

261
00:14:28,720 --> 00:14:31,470
It can't solve it, they'll put it aside.

262
00:14:31,470 --> 00:14:34,750
We only look for intelligible theories.

263
00:14:34,750 --> 00:14:36,690
Newton's theories were intelligible

264
00:14:36,690 --> 00:14:39,120
it's just what they described wasn't.

265
00:14:39,120 --> 00:14:42,830
Well, Locke said the same thing.

266
00:14:42,830 --> 00:14:45,500
I think they're basically right and if so

267
00:14:45,500 --> 00:14:49,740
that showed something about
the limits of human cognition.

268
00:14:49,740 --> 00:14:54,740
We cannot attain the goal
of understanding the world,

269
00:14:55,730 --> 00:14:58,440
of finding an intelligible world.

270
00:14:58,440 --> 00:15:02,573
This mechanical philosophy,
Galileo to Newton,

271
00:15:03,770 --> 00:15:05,500
there's a good case that can be made that

272
00:15:05,500 --> 00:15:10,500
that's our instinctive
conception of how things work.

273
00:15:11,040 --> 00:15:15,720
So if say infants are tested with things

274
00:15:15,720 --> 00:15:18,700
that if this moves and then this moves

275
00:15:18,700 --> 00:15:22,100
they kind of invent something
that must be invisible

276
00:15:22,100 --> 00:15:24,970
that's in between them that's
making them move and so on.

277
00:15:24,970 --> 00:15:26,580
- [Lex] Yeah, we like physical contact.

278
00:15:26,580 --> 00:15:28,505
Something about our brain seeks--

279
00:15:28,505 --> 00:15:31,222
- [Noam] Makes us want a world like then

280
00:15:31,222 --> 00:15:34,190
just like it wants a world that has

281
00:15:34,190 --> 00:15:38,030
regular geometric figures
so for example Descartes

282
00:15:38,030 --> 00:15:41,870
pointed this out that
if you have an infant

283
00:15:41,870 --> 00:15:46,870
who's never seen a triangle
before and you draw a triangle

284
00:15:47,358 --> 00:15:52,270
the infant will see a distorted triangle

285
00:15:52,270 --> 00:15:56,370
not whatever crazy figure
it actually is, you know,

286
00:15:56,370 --> 00:15:58,430
three lines not coming quite together

287
00:15:58,430 --> 00:16:00,350
or one of them a little
bit curved and so on.

288
00:16:00,350 --> 00:16:04,550
We just impose a conception of the world

289
00:16:04,550 --> 00:16:09,420
in terms of perfect geometric objects.

290
00:16:09,420 --> 00:16:11,680
It's now been shown that
it goes way beyond that,

291
00:16:11,680 --> 00:16:15,047
that if you show on a
tachistoscope, let's say,

292
00:16:16,040 --> 00:16:19,270
a couple of lights
shining, you do it three

293
00:16:19,270 --> 00:16:22,850
or four times in a row
what people actually see

294
00:16:22,850 --> 00:16:26,913
is a rigid object in motion
not whatever's there.

295
00:16:28,230 --> 00:16:31,890
We all know that from a
television set basically.

296
00:16:31,890 --> 00:16:34,680
- [Lex] So that gives us
hints of potential limits

297
00:16:34,680 --> 00:16:36,850
to our cognition?
- I think it does,

298
00:16:36,850 --> 00:16:39,440
but it's a very contested view.

299
00:16:39,440 --> 00:16:43,900
If you do a poll among scientists
they'll say impossible.

300
00:16:43,900 --> 00:16:45,483
We can understand anything.

301
00:16:46,360 --> 00:16:48,640
- [Lex] Let me ask and
give me a chance with this.

302
00:16:48,640 --> 00:16:52,560
So I just spent a day at a
company called Neuralink,

303
00:16:52,560 --> 00:16:56,813
and what they do is try
to design what's called

304
00:16:56,813 --> 00:16:59,610
a brain machine, a brain
computer interface.

305
00:16:59,610 --> 00:17:03,330
So they try to just do thousands
of readings in the brain,

306
00:17:03,330 --> 00:17:05,610
be able to read what
the neurons are firing

307
00:17:05,610 --> 00:17:08,550
and then stimulate back, so two-way.

308
00:17:08,550 --> 00:17:12,800
Do you think their dream
is to expand the capacity

309
00:17:12,800 --> 00:17:16,690
of the brain to attain information,

310
00:17:16,690 --> 00:17:18,180
sort of increase the bandwidth

311
00:17:18,180 --> 00:17:22,460
at which we can search
Google kind of thing?

312
00:17:22,460 --> 00:17:26,280
Do you think our cognitive
capacity might be expanded,

313
00:17:26,280 --> 00:17:29,400
our linguistic capacity,
our ability to reason

314
00:17:29,400 --> 00:17:33,220
might be expanded by adding
a machine into the picture?

315
00:17:33,220 --> 00:17:35,660
- [Noam] It can be expanded
in a certain sense,

316
00:17:35,660 --> 00:17:39,900
but a sense that was known
thousands of years ago.

317
00:17:39,900 --> 00:17:44,070
A book expands your
cognitive capacity, okay,

318
00:17:44,070 --> 00:17:46,070
so this could expand it, too.

319
00:17:46,070 --> 00:17:47,980
- [Lex] But it's not a
fundamental expansion.

320
00:17:47,980 --> 00:17:51,000
It's not totally new
things could be understood.

321
00:17:51,000 --> 00:17:53,070
- [Noam] Well, nothing that goes beyond

322
00:17:53,070 --> 00:17:56,002
our native cognitive capacities

323
00:17:56,002 --> 00:17:58,670
just like you can't turn the visual system

324
00:17:58,670 --> 00:18:00,710
into an insect system.

325
00:18:00,710 --> 00:18:05,710
- [Lex] Well, I mean
the thought is perhaps

326
00:18:05,730 --> 00:18:07,850
you can't directly but you can map.

327
00:18:07,850 --> 00:18:12,430
- [Noam] You could be we know
that without this experiment

328
00:18:12,430 --> 00:18:16,220
you could map what a
bee sees and present it

329
00:18:16,220 --> 00:18:18,310
in a form so that we could follow it.

330
00:18:18,310 --> 00:18:20,364
In fact every bee scientist does that.

331
00:18:20,364 --> 00:18:23,240
- [Lex] Uh-huh, but you
don't think there's something

332
00:18:23,240 --> 00:18:26,730
greater than bees that we can map

333
00:18:26,730 --> 00:18:29,730
and then all of a sudden
discover something,

334
00:18:29,730 --> 00:18:33,830
be able to understand a quantum
world, quantum mechanics,

335
00:18:33,830 --> 00:18:35,290
be able to start to be able to make sense.

336
00:18:35,290 --> 00:18:37,800
- [Noam] You can, students at MIT study

337
00:18:37,800 --> 00:18:40,615
and understand quantum mechanics.

338
00:18:40,615 --> 00:18:44,000
- [Lex] (laughs) But they
always reduce it to the infant,

339
00:18:44,000 --> 00:18:46,480
the physical, I mean they
don't really understand--

340
00:18:46,480 --> 00:18:50,320
- [Noam] Not physical,
that may be another area

341
00:18:50,320 --> 00:18:52,760
where there's just a
limit to understanding.

342
00:18:52,760 --> 00:18:54,530
We understand the theories,

343
00:18:54,530 --> 00:18:58,480
but the world that it describes
doesn't make any sense.

344
00:18:58,480 --> 00:19:01,510
So you know the experiment,
the Schrodinger's cat

345
00:19:01,510 --> 00:19:03,750
for example, can understand the theory

346
00:19:03,750 --> 00:19:05,810
but as Schrodinger pointed out

347
00:19:05,810 --> 00:19:07,543
it's not an intelligible world.

348
00:19:09,330 --> 00:19:13,500
One of the reasons why Einstein
was always very skeptical

349
00:19:13,500 --> 00:19:17,240
about quantum theory, he described himself

350
00:19:17,240 --> 00:19:21,137
as a classical realist
and wants intelligibility.

351
00:19:23,070 --> 00:19:26,070
- [Lex] He has something in
common with infants in that way.

352
00:19:27,470 --> 00:19:32,470
So back to linguistics,
if you could humor me,

353
00:19:32,670 --> 00:19:35,300
what are the most beautiful
or fascinating aspects

354
00:19:35,300 --> 00:19:37,740
of language or ideas in linguistics

355
00:19:37,740 --> 00:19:39,540
or cognitive science that you've seen

356
00:19:39,540 --> 00:19:42,070
in a lifetime of studying language

357
00:19:42,070 --> 00:19:44,200
and studying the human mind?

358
00:19:44,200 --> 00:19:49,200
- [Noam] Well, I think the
deepest property of language

359
00:19:50,170 --> 00:19:52,880
and puzzling property
that's been discovered

360
00:19:52,880 --> 00:19:57,230
is what is sometimes called
structure dependence.

361
00:19:57,230 --> 00:19:59,610
We now understand it pretty well,

362
00:19:59,610 --> 00:20:01,970
but it was puzzling for a long time.

363
00:20:01,970 --> 00:20:03,640
I'll give you a concrete example.

364
00:20:03,640 --> 00:20:08,640
So suppose you say, the
guy who fixed the car

365
00:20:09,316 --> 00:20:11,910
carefully packed his tools.

366
00:20:11,910 --> 00:20:15,450
That's ambiguous, he could
fix the car carefully

367
00:20:15,450 --> 00:20:17,960
or carefully pack his tools.

368
00:20:17,960 --> 00:20:21,080
Now suppose you put carefully in front.

369
00:20:21,080 --> 00:20:25,870
Carefully the guy who fixed
the car packed his tools.

370
00:20:25,870 --> 00:20:29,400
Then it's carefully packed,
not carefully fixed.

371
00:20:29,400 --> 00:20:32,330
And in fact you do that
even if it makes no sense.

372
00:20:32,330 --> 00:20:35,150
So suppose you say, carefully the guy

373
00:20:35,150 --> 00:20:38,173
who fixed the car is tall.

374
00:20:39,370 --> 00:20:41,900
You have to interpret it
as carefully he's tall

375
00:20:41,900 --> 00:20:44,270
even though that doesn't make any sense.

376
00:20:44,270 --> 00:20:46,837
And notice that that's
a very puzzling fact

377
00:20:46,837 --> 00:20:50,100
because you're relating carefully

378
00:20:50,100 --> 00:20:53,670
not to the linearly closest verb

379
00:20:53,670 --> 00:20:57,340
but to the linearly more remote verb.

380
00:20:57,340 --> 00:21:02,097
Linear closeness is a easy computation,

381
00:21:02,097 --> 00:21:03,750
but here you're doing a much more,

382
00:21:03,750 --> 00:21:06,810
what looks like a more
complex computation.

383
00:21:06,810 --> 00:21:09,520
You're doing something that's taking you

384
00:21:09,520 --> 00:21:11,913
essentially to the more remote thing,

385
00:21:13,640 --> 00:21:17,800
it's now if you look at the
actual structure of the sentence

386
00:21:17,800 --> 00:21:20,720
where the phrases are and so on turns out

387
00:21:20,720 --> 00:21:24,230
you're picking out the
structurally closest thing,

388
00:21:24,230 --> 00:21:28,000
but the linearly more remote thing.

389
00:21:28,000 --> 00:21:32,540
But notice that what's linear
is 100% of what you hear.

390
00:21:32,540 --> 00:21:33,943
You never hear of structure.

391
00:21:35,190 --> 00:21:39,280
So what you're doing is and
instantly this is universal.

392
00:21:39,280 --> 00:21:42,190
All constructions, all languages

393
00:21:42,190 --> 00:21:45,600
and what we're compelled
to do is carry out

394
00:21:45,600 --> 00:21:48,720
what looks like the
more complex computation

395
00:21:48,720 --> 00:21:53,720
on material that we never
hear and we ignore 100%

396
00:21:54,000 --> 00:21:57,030
of what we hear on the
simplest computation.

397
00:21:57,030 --> 00:22:00,720
And by now there's even
a neural basis for this

398
00:22:00,720 --> 00:22:04,060
that's somewhat understood,
and there's good theories

399
00:22:04,060 --> 00:22:06,660
but none that explain why it's true.

400
00:22:06,660 --> 00:22:10,661
That's a deep insight
into the surprising nature

401
00:22:10,661 --> 00:22:13,826
of language with many consequences.

402
00:22:13,826 --> 00:22:17,317
- [Lex] Let me ask you about
a field of machine learning

403
00:22:17,317 --> 00:22:20,220
and deep learning, there's
been a lot of progress

404
00:22:20,220 --> 00:22:23,920
in neural network-based machine learning

405
00:22:24,920 --> 00:22:26,410
in the recent decade.

406
00:22:26,410 --> 00:22:30,064
Of course, neural network
research goes back many decades.

407
00:22:30,064 --> 00:22:30,897
- [Noam] Yeah.

408
00:22:30,897 --> 00:22:35,610
- [Lex] What do you think are
the limits of deep learning,

409
00:22:35,610 --> 00:22:38,510
of neural network-based machine learning?

410
00:22:38,510 --> 00:22:41,160
- [Noam] Well, to give
a real answer to that

411
00:22:41,160 --> 00:22:44,940
you'd have to understand
the exact processes

412
00:22:44,940 --> 00:22:47,960
that are taking place, and
those are pretty opaque

413
00:22:47,960 --> 00:22:50,290
so it's pretty hard to prove a theorem

414
00:22:50,290 --> 00:22:54,060
about what can be done
and what can't be done.

415
00:22:54,060 --> 00:22:56,520
But I think it's reasonably clear,

416
00:22:56,520 --> 00:22:59,220
I mean, putting technicalities aside

417
00:22:59,220 --> 00:23:04,030
what deep learning is doing
is taking huge numbers

418
00:23:04,030 --> 00:23:07,770
of examples and finding some patterns.

419
00:23:07,770 --> 00:23:12,010
Okay, that could be interesting
and in some areas it is

420
00:23:12,010 --> 00:23:15,090
but we have to ask here
a certain question.

421
00:23:15,090 --> 00:23:17,883
Is it engineering or is it science?

422
00:23:17,883 --> 00:23:21,450
Engineering in the sense of
just trying to build something

423
00:23:21,450 --> 00:23:24,270
that's useful or science in the sense

424
00:23:24,270 --> 00:23:27,600
that it's trying to understand
something about elements

425
00:23:27,600 --> 00:23:31,513
of the world so it takes a Google parser.

426
00:23:31,513 --> 00:23:35,190
We can ask that question, is it useful?

427
00:23:35,190 --> 00:23:36,900
Yeah, it's pretty useful.

428
00:23:36,900 --> 00:23:41,900
I use Google Translator
so on engineering grounds

429
00:23:41,960 --> 00:23:44,923
it's kinda worth having like a bulldozer.

430
00:23:45,770 --> 00:23:49,050
Does it tell you anything
about human language?

431
00:23:49,050 --> 00:23:54,050
Zero, nothing, and in
fact it's very striking.

432
00:23:54,970 --> 00:23:56,820
From the very beginning

433
00:23:56,820 --> 00:24:00,056
it's just totally remote from science

434
00:24:00,056 --> 00:24:02,620
so what is a Google parser doing?

435
00:24:02,620 --> 00:24:05,190
It's taking an enormous text,

436
00:24:05,190 --> 00:24:08,930
let's say The Wall Street
Journal corpus and asking,

437
00:24:08,930 --> 00:24:13,930
how close can we come to
getting the right description

438
00:24:14,150 --> 00:24:16,440
of every sentence in the corpus?

439
00:24:16,440 --> 00:24:18,550
Well, ever sentence in the corpus

440
00:24:18,550 --> 00:24:21,131
is essentially an experiment.

441
00:24:21,131 --> 00:24:25,310
Each sentence that you produce
is an experiment which is,

442
00:24:25,310 --> 00:24:26,980
am I a grammatical sentence?

443
00:24:26,980 --> 00:24:30,730
Now the answer is usually
yes so most of the stuff

444
00:24:30,730 --> 00:24:33,270
in the corpus is grammatical sentences,

445
00:24:33,270 --> 00:24:36,860
but now ask yourself, is there any science

446
00:24:36,860 --> 00:24:41,540
which takes random experiments
which are carried out

447
00:24:41,540 --> 00:24:44,340
for no reason whatsoever and tries

448
00:24:44,340 --> 00:24:46,540
to find out something from them?

449
00:24:46,540 --> 00:24:49,680
Like if you're, say, a
chemistry PhD student

450
00:24:49,680 --> 00:24:51,230
you want to get a thesis can you say,

451
00:24:51,230 --> 00:24:54,710
well I'm just gonna do a
lot of, mix a lot of things

452
00:24:54,710 --> 00:24:59,690
together, no purpose, and
maybe I'll find something.

453
00:24:59,690 --> 00:25:01,640
You'd be laughed out of the department.

454
00:25:02,490 --> 00:25:06,240
Science tries to find
critical experiments,

455
00:25:06,240 --> 00:25:09,160
ones that answer some
theoretical question.

456
00:25:09,160 --> 00:25:13,020
Doesn't care about coverage
of millions of experiments.

457
00:25:13,020 --> 00:25:16,227
So it just begins by being
very remote from science

458
00:25:16,227 --> 00:25:20,700
and it continues like
that so the usual question

459
00:25:20,700 --> 00:25:23,540
that's asked about, say, a Google parser

460
00:25:23,540 --> 00:25:26,230
is how well does it do, or some parser,

461
00:25:26,230 --> 00:25:28,370
how well does it do on a corpus?

462
00:25:28,370 --> 00:25:30,764
But there's another
question that's never asked.

463
00:25:30,764 --> 00:25:32,950
How well does it do on something

464
00:25:32,950 --> 00:25:36,120
that violates all the rules of language?

465
00:25:36,120 --> 00:25:38,770
So for example, take the
structure dependence case

466
00:25:38,770 --> 00:25:41,670
that I mentioned, suppose
there was a language

467
00:25:41,670 --> 00:25:46,510
in which you used linear
proximity as the mode

468
00:25:47,350 --> 00:25:50,090
of interpretation, these deep learning

469
00:25:50,090 --> 00:25:51,280
would work very easily on that.

470
00:25:51,280 --> 00:25:54,820
In fact, much more easily
than on an actual language.

471
00:25:54,820 --> 00:25:56,000
Is that a success?

472
00:25:56,000 --> 00:25:57,640
No, that's a failure.

473
00:25:57,640 --> 00:26:00,728
From a scientific point
of view that's a failure.

474
00:26:00,728 --> 00:26:03,560
It shows that we're not discovering

475
00:26:03,560 --> 00:26:05,880
the nature of the system at all

476
00:26:05,880 --> 00:26:07,780
'cause it does just as well or even better

477
00:26:07,780 --> 00:26:10,777
on things that violate the
structure of the system,

478
00:26:10,777 --> 00:26:12,750
and it goes on from there.

479
00:26:12,750 --> 00:26:14,830
It's not an argument against doing it.

480
00:26:14,830 --> 00:26:17,230
It is useful to have devices like this.

481
00:26:17,230 --> 00:26:20,670
- [Lex] So yes, neural networks
are kind of approximators

482
00:26:20,670 --> 00:26:24,410
that look, there's echoes of
the behavioral debates right,

483
00:26:24,410 --> 00:26:27,620
behavioralism.
- More than echoes.

484
00:26:27,620 --> 00:26:30,080
Many of the people in deep learning

485
00:26:30,080 --> 00:26:32,840
say they vindicated.
- (laughs) Yeah.

486
00:26:32,840 --> 00:26:35,650
- [Noam] Terry Sejnowski for
example in his recent book

487
00:26:35,650 --> 00:26:38,870
says this vindicates Skinnerian behaviors

488
00:26:38,870 --> 00:26:41,700
and it doesn't have
anything to do with it.

489
00:26:41,700 --> 00:26:43,800
- [Lex] Yes, but I think there's something

490
00:26:44,670 --> 00:26:48,300
actually fundamentally different
when the data set is huge,

491
00:26:48,300 --> 00:26:51,180
but your point is extremely well taken.

492
00:26:51,180 --> 00:26:55,410
But do you think we can learn, approximate

493
00:26:55,410 --> 00:26:58,810
that interesting, complex
structure of language

494
00:26:58,810 --> 00:27:00,850
with neural networks that will somehow

495
00:27:00,850 --> 00:27:02,833
help us understand the science?

496
00:27:03,680 --> 00:27:06,330
- [Noam] It's possible,
I mean, you find patterns

497
00:27:06,330 --> 00:27:08,730
that you hadn't noticed, let's say.

498
00:27:08,730 --> 00:27:13,630
Could be, in fact it's very
much like a kind of linguistics

499
00:27:13,630 --> 00:27:18,630
that's done, what's called
corpus linguistics when you,

500
00:27:19,200 --> 00:27:22,610
suppose you have some language
where all the speakers

501
00:27:22,610 --> 00:27:25,140
have died out but you have records.

502
00:27:25,140 --> 00:27:28,110
So you just look at the records

503
00:27:28,110 --> 00:27:30,630
and see what you can figure out from that.

504
00:27:30,630 --> 00:27:33,690
It's much better to have actual speakers

505
00:27:33,690 --> 00:27:36,090
where you can do critical experiments,

506
00:27:36,090 --> 00:27:38,540
but if they're all dead you can't do them

507
00:27:38,540 --> 00:27:40,810
so you have to try to
see what you can find out

508
00:27:40,810 --> 00:27:43,890
from just looking at
the data that's around.

509
00:27:43,890 --> 00:27:45,088
You can learn things.

510
00:27:45,088 --> 00:27:48,400
Anthropology is very much like that.

511
00:27:48,400 --> 00:27:50,630
You can't do a critical experiment

512
00:27:50,630 --> 00:27:53,530
on what happened two million years ago

513
00:27:53,530 --> 00:27:56,550
so you're kinda forced to
take what data's around

514
00:27:56,550 --> 00:27:59,250
and see what you can figure out from it.

515
00:27:59,250 --> 00:28:01,440
Okay, it's a serious study.

516
00:28:01,440 --> 00:28:05,620
- [Lex] So let me venture into
another whole body of work

517
00:28:05,620 --> 00:28:07,423
and philosophical question.

518
00:28:08,400 --> 00:28:13,120
You've said that evil in society
arises from institutions,

519
00:28:13,120 --> 00:28:15,245
not inherently from our nature.

520
00:28:15,245 --> 00:28:17,840
Do you think most human beings are good,

521
00:28:17,840 --> 00:28:21,230
they have good intent or
do most have the capacity

522
00:28:21,230 --> 00:28:24,730
for intentional evil that
depends on their upbringing,

523
00:28:24,730 --> 00:28:27,320
depends on their environment, on context?

524
00:28:27,320 --> 00:28:28,153
- [Noam] I wouldn't say

525
00:28:28,153 --> 00:28:30,143
that they don't arise from our nature.

526
00:28:31,030 --> 00:28:34,060
Anything we do arises from our nature.

527
00:28:34,060 --> 00:28:36,750
And the fact that we
have certain institutions

528
00:28:36,750 --> 00:28:40,560
and not others is one mode

529
00:28:40,560 --> 00:28:43,740
in which human nature
has expressed itself.

530
00:28:43,740 --> 00:28:46,300
But as far as we know, human nature

531
00:28:46,300 --> 00:28:50,260
could yield many different
kinds of institutions.

532
00:28:50,260 --> 00:28:52,847
The particular ones that have developed

533
00:28:52,847 --> 00:28:56,980
have to do with historical contingency,

534
00:28:56,980 --> 00:28:59,183
who conquered whom and that sort of thing,

535
00:29:00,260 --> 00:29:03,870
then they're not rooted in our nature

536
00:29:03,870 --> 00:29:06,790
in the sense that they're
essential to our nature

537
00:29:06,790 --> 00:29:11,420
so it's commonly argued that
these days that something

538
00:29:11,420 --> 00:29:15,610
like market systems is
just part of our nature,

539
00:29:15,610 --> 00:29:18,020
but we know from a huge amount of evidence

540
00:29:18,020 --> 00:29:21,780
that that's not true, there's
all kinds of other structures.

541
00:29:21,780 --> 00:29:26,270
That's a particular fact of
a moment of modern history.

542
00:29:26,270 --> 00:29:30,489
Others have argued that the
roots of classical liberalism

543
00:29:30,489 --> 00:29:34,450
actually argue that
what's called sometimes

544
00:29:34,450 --> 00:29:37,510
an instinct for freedom, an instinct

545
00:29:37,510 --> 00:29:42,170
to be free of domination
by illegitimate authority

546
00:29:42,170 --> 00:29:43,690
is the core of our nature.

547
00:29:43,690 --> 00:29:45,660
That would be the opposite of this.

548
00:29:45,660 --> 00:29:48,960
And we don't know, we just
know that human nature

549
00:29:48,960 --> 00:29:50,733
can accommodate both kinds.

550
00:29:52,240 --> 00:29:54,930
- [Lex] If you look back at your life,

551
00:29:54,930 --> 00:29:58,150
is there a moment in
your intellectual life

552
00:29:58,150 --> 00:30:00,210
or life in general that jumps from memory

553
00:30:00,210 --> 00:30:02,120
that brought you happiness

554
00:30:02,120 --> 00:30:04,073
that you would love to relive again?

555
00:30:05,130 --> 00:30:10,130
- [Noam] Sure, falling
in love, having children.

556
00:30:10,140 --> 00:30:13,130
- [Lex] What about, so
you have put forward

557
00:30:13,130 --> 00:30:17,690
into the world a lot of
incredible ideas in linguistics,

558
00:30:17,690 --> 00:30:22,350
in cognitive science, in terms of ideas

559
00:30:22,350 --> 00:30:25,953
that just excites you
when it first came to you

560
00:30:25,953 --> 00:30:28,970
that you love to relive those moments.

561
00:30:28,970 --> 00:30:31,600
- [Noam] Well, I mean,
when you make a discovery

562
00:30:32,460 --> 00:30:34,713
about something it's exciting like say

563
00:30:37,050 --> 00:30:40,550
even the observation
of structure dependence

564
00:30:40,550 --> 00:30:44,460
and on from that the explanation for it,

565
00:30:44,460 --> 00:30:49,460
but the major things just
seem like common sense.

566
00:30:49,510 --> 00:30:53,210
So if you go back to, take your question

567
00:30:53,210 --> 00:30:55,840
about external and internal language.

568
00:30:55,840 --> 00:30:58,813
You go back to, say, the 1950s

569
00:30:58,813 --> 00:31:03,421
almost entirely language is
regarded as an external object,

570
00:31:03,421 --> 00:31:06,320
something outside the mind.

571
00:31:06,320 --> 00:31:09,423
It just seemed obvious
that that can't be true.

572
00:31:10,740 --> 00:31:14,440
Like I said, there's something
about you that determines

573
00:31:14,440 --> 00:31:18,249
you're talking English
not Swahili or something.

574
00:31:18,249 --> 00:31:20,330
But that's not really a discovery.

575
00:31:20,330 --> 00:31:24,150
That's just an observation
of what's transparent.

576
00:31:24,150 --> 00:31:26,660
You might say it's kind of like

577
00:31:28,409 --> 00:31:32,490
the 17th century, the
beginnings of modern science

578
00:31:32,490 --> 00:31:37,150
17th century, they came from being willing

579
00:31:37,150 --> 00:31:40,440
to be puzzled about things
that seemed obvious.

580
00:31:40,440 --> 00:31:45,440
So it seems obvious that a heavy
ball of lead'll fall faster

581
00:31:45,510 --> 00:31:50,380
than a light ball of lead,
but Galileo was not impressed

582
00:31:50,380 --> 00:31:52,720
by the fact that it seemed obvious.

583
00:31:52,720 --> 00:31:55,018
so he wanted to know if it's true

584
00:31:55,018 --> 00:31:59,190
He carried out experiments,
actually thought experiments

585
00:31:59,190 --> 00:32:01,520
never actually carried
them out which showed

586
00:32:01,520 --> 00:32:04,216
that it can't be true, you know.

587
00:32:04,216 --> 00:32:09,216
And out of things like that,
observations of that kind,

588
00:32:11,110 --> 00:32:14,476
you know, why does a
ball fall to the ground

589
00:32:14,476 --> 00:32:16,964
instead of rising, let's say?

590
00:32:16,964 --> 00:32:20,261
It seems obvious till you
start thinking about it

591
00:32:20,261 --> 00:32:23,950
'cause why does steam rise, let's say.

592
00:32:23,950 --> 00:32:27,300
And I think the beginnings
of modern linguistics

593
00:32:27,300 --> 00:32:30,080
roughly in the 50s are kind of like that,

594
00:32:30,080 --> 00:32:33,670
just being willing to be
puzzled about phenomena

595
00:32:33,670 --> 00:32:38,050
that looked from some
point of view obvious.

596
00:32:38,050 --> 00:32:41,370
And for example a kind of doctrine,

597
00:32:41,370 --> 00:32:44,990
almost official doctrine
of structural linguistics

598
00:32:44,990 --> 00:32:49,990
in the 50s was that languages
can differ from one another

599
00:32:50,570 --> 00:32:54,840
in arbitrary ways and
each one has to be studied

600
00:32:55,770 --> 00:32:58,940
on its own without any presuppositions

601
00:32:58,940 --> 00:33:02,430
and in fact there were
similar views among biologists

602
00:33:02,430 --> 00:33:05,910
about the nature of
organisms that each one's,

603
00:33:05,910 --> 00:33:07,820
they're so different when you look at them

604
00:33:07,820 --> 00:33:11,000
that you could be almost anything.

605
00:33:11,000 --> 00:33:13,170
Well in both domains it's been learned

606
00:33:13,170 --> 00:33:15,560
that it's very far from true.

607
00:33:15,560 --> 00:33:17,010
There are very narrow constraints

608
00:33:17,010 --> 00:33:20,653
on what could be an organism
or what could be a language.

609
00:33:21,630 --> 00:33:26,090
But these are, you know, that's
just the nature of inquiry.

610
00:33:27,030 --> 00:33:29,400
- [Lex] Science in general, yeah, inquiry.

611
00:33:29,400 --> 00:33:32,060
So one of the peculiar things

612
00:33:32,060 --> 00:33:35,290
about us human beings is our mortality.

613
00:33:35,290 --> 00:33:36,773
Ernest Becker explored it.

614
00:33:36,773 --> 00:33:40,490
In general do you ponder
the value of mortality?

615
00:33:40,490 --> 00:33:42,453
Do you think about your own mortality?

616
00:33:43,470 --> 00:33:46,853
- [Noam] I used to when
I was about 12 years old.

617
00:33:48,090 --> 00:33:51,940
I wondered, I didn't care
much about my own mortality,

618
00:33:51,940 --> 00:33:56,410
but I was worried about the
fact that if my consciousness

619
00:33:56,410 --> 00:34:00,330
disappeared would the
entire universe disappear.

620
00:34:00,330 --> 00:34:01,610
That was frightening.

621
00:34:01,610 --> 00:34:03,770
- [Lex] Did you ever find
an answer to that question?

622
00:34:03,770 --> 00:34:05,920
- [Noam] No, nobody's
ever found an answer,

623
00:34:05,920 --> 00:34:07,900
but I stopped being bothered by it.

624
00:34:07,900 --> 00:34:10,420
It's kind of like Woody
Allen in one of his films.

625
00:34:10,420 --> 00:34:15,120
You may recall he goes to
a shrink when he's a child

626
00:34:15,120 --> 00:34:17,560
and the shrink asks him,
"What's your problem?"

627
00:34:17,560 --> 00:34:21,798
He says, "I just learned that
the universe is expanding.

628
00:34:21,798 --> 00:34:23,236
"I can't handle that."

629
00:34:23,236 --> 00:34:27,280
- [Lex] (laughs) And
another absurd question is,

630
00:34:27,280 --> 00:34:32,280
what do you think is the
meaning of our existence here,

631
00:34:32,630 --> 00:34:36,047
our life on Earth, our
brief little moment in time?

632
00:34:36,047 --> 00:34:38,947
- [Noam] That's something we
answer by our own activities.

633
00:34:40,640 --> 00:34:42,380
There's no general answer.

634
00:34:42,380 --> 00:34:44,523
We determine what the meaning of it is.

635
00:34:46,640 --> 00:34:48,740
- [Lex] The action determine the meaning.

636
00:34:48,740 --> 00:34:50,600
- [Noam] Meaning in the
sense of significance

637
00:34:50,600 --> 00:34:55,420
not meaning in the sense that
chair means this, you know,

638
00:34:55,420 --> 00:34:58,833
but the significance of your
life is something you create.

639
00:35:01,090 --> 00:35:02,570
- Noam, thank you so
much for talking today.

640
00:35:02,570 --> 00:35:05,023
It was a huge honor, thank you so much.

641
00:35:05,970 --> 00:35:08,570
Thanks for listening to this
conversation with Noam Chomsky,

642
00:35:08,570 --> 00:35:11,980
and thank you to our
presenting sponsor Cash App.

643
00:35:11,980 --> 00:35:13,893
Download it, use code LexPodcast.

644
00:35:14,800 --> 00:35:18,010
You'll get $10 and $10 will go to FIRST,

645
00:35:18,010 --> 00:35:20,620
a STEM education nonprofit
that inspires hundreds

646
00:35:20,620 --> 00:35:23,240
of thousands of young minds to learn

647
00:35:23,240 --> 00:35:26,010
and to dream of engineering our future.

648
00:35:26,010 --> 00:35:28,660
If you enjoy this podcast
subscribe on YouTube.

649
00:35:28,660 --> 00:35:30,640
Give us five stars on Apple Podcast,

650
00:35:30,640 --> 00:35:34,270
support on Patreon, or
connect with me on Twitter.

651
00:35:34,270 --> 00:35:37,013
Thank you for listening and
hope to see you next time.


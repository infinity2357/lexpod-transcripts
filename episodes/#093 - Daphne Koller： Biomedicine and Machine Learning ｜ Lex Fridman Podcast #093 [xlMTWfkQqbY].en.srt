1
00:00:00,060 --> 00:00:01,699

the following is a conversation with

2
00:00:01,699 --> 00:00:01,709
the following is a conversation with
 

3
00:00:01,709 --> 00:00:04,280
the following is a conversation with
Daphne Koller a professor of computer

4
00:00:04,280 --> 00:00:04,290
Daphne Koller a professor of computer
 

5
00:00:04,290 --> 00:00:06,039
Daphne Koller a professor of computer
science at Stanford University a

6
00:00:06,039 --> 00:00:06,049
science at Stanford University a
 

7
00:00:06,049 --> 00:00:08,480
science at Stanford University a
co-founder of Coursera with Andrew Eng

8
00:00:08,480 --> 00:00:08,490
co-founder of Coursera with Andrew Eng
 

9
00:00:08,490 --> 00:00:11,660
co-founder of Coursera with Andrew Eng
and founder and CEO of in seat row a

10
00:00:11,660 --> 00:00:11,670
and founder and CEO of in seat row a
 

11
00:00:11,670 --> 00:00:13,789
and founder and CEO of in seat row a
company at the intersection of machine

12
00:00:13,789 --> 00:00:13,799
company at the intersection of machine
 

13
00:00:13,799 --> 00:00:16,640
company at the intersection of machine
learning and biomedicine we're now in

14
00:00:16,640 --> 00:00:16,650
learning and biomedicine we're now in
 

15
00:00:16,650 --> 00:00:18,410
learning and biomedicine we're now in
the exciting early days of using the

16
00:00:18,410 --> 00:00:18,420
the exciting early days of using the
 

17
00:00:18,420 --> 00:00:20,269
the exciting early days of using the
data-driven methods of machine learning

18
00:00:20,269 --> 00:00:20,279
data-driven methods of machine learning
 

19
00:00:20,279 --> 00:00:22,340
data-driven methods of machine learning
to help discover and develop new drugs

20
00:00:22,340 --> 00:00:22,350
to help discover and develop new drugs
 

21
00:00:22,350 --> 00:00:25,429
to help discover and develop new drugs
and treatments at scale Daphne and in

22
00:00:25,429 --> 00:00:25,439
and treatments at scale Daphne and in
 

23
00:00:25,439 --> 00:00:27,560
and treatments at scale Daphne and in
seat row are leading the way on this

24
00:00:27,560 --> 00:00:27,570
seat row are leading the way on this
 

25
00:00:27,570 --> 00:00:29,689
seat row are leading the way on this
with breakthroughs they may ripple

26
00:00:29,689 --> 00:00:29,699
with breakthroughs they may ripple
 

27
00:00:29,699 --> 00:00:32,089
with breakthroughs they may ripple
through all fields of medicine including

28
00:00:32,089 --> 00:00:32,099
through all fields of medicine including
 

29
00:00:32,099 --> 00:00:34,430
through all fields of medicine including
ones most critical for helping with a

30
00:00:34,430 --> 00:00:34,440
ones most critical for helping with a
 

31
00:00:34,440 --> 00:00:37,370
ones most critical for helping with a
current coronavirus pandemic this

32
00:00:37,370 --> 00:00:37,380
current coronavirus pandemic this
 

33
00:00:37,380 --> 00:00:39,500
current coronavirus pandemic this
conversation was recorded before the

34
00:00:39,500 --> 00:00:39,510
conversation was recorded before the
 

35
00:00:39,510 --> 00:00:42,080
conversation was recorded before the
cove 8:19 outbreak for everyone feeling

36
00:00:42,080 --> 00:00:42,090
cove 8:19 outbreak for everyone feeling
 

37
00:00:42,090 --> 00:00:43,790
cove 8:19 outbreak for everyone feeling
the medical psychological and financial

38
00:00:43,790 --> 00:00:43,800
the medical psychological and financial
 

39
00:00:43,800 --> 00:00:45,410
the medical psychological and financial
burden of this crisis

40
00:00:45,410 --> 00:00:45,420
burden of this crisis
 

41
00:00:45,420 --> 00:00:48,560
burden of this crisis
I'm sending love your way stay strong

42
00:00:48,560 --> 00:00:48,570
I'm sending love your way stay strong
 

43
00:00:48,570 --> 00:00:50,540
I'm sending love your way stay strong
we're in this together we'll beat this

44
00:00:50,540 --> 00:00:50,550
we're in this together we'll beat this
 

45
00:00:50,550 --> 00:00:52,880
we're in this together we'll beat this
thing this is the artificial

46
00:00:52,880 --> 00:00:52,890
thing this is the artificial
 

47
00:00:52,890 --> 00:00:54,799
thing this is the artificial
intelligence podcast if you enjoy it

48
00:00:54,799 --> 00:00:54,809
intelligence podcast if you enjoy it
 

49
00:00:54,809 --> 00:00:57,229
intelligence podcast if you enjoy it
subscribe I need to review it with five

50
00:00:57,229 --> 00:00:57,239
subscribe I need to review it with five
 

51
00:00:57,239 --> 00:00:59,270
subscribe I need to review it with five
stars an apple podcast supported on

52
00:00:59,270 --> 00:00:59,280
stars an apple podcast supported on
 

53
00:00:59,280 --> 00:01:01,220
stars an apple podcast supported on
patreon are simply connected me on

54
00:01:01,220 --> 00:01:01,230
patreon are simply connected me on
 

55
00:01:01,230 --> 00:01:05,240
patreon are simply connected me on
Twitter Alex Friedman spelled Fri D ma M

56
00:01:05,240 --> 00:01:05,250
Twitter Alex Friedman spelled Fri D ma M
 

57
00:01:05,250 --> 00:01:07,520
Twitter Alex Friedman spelled Fri D ma M
as usual I'll do a few minutes of ads

58
00:01:07,520 --> 00:01:07,530
as usual I'll do a few minutes of ads
 

59
00:01:07,530 --> 00:01:09,380
as usual I'll do a few minutes of ads
now and never any ads in the middle that

60
00:01:09,380 --> 00:01:09,390
now and never any ads in the middle that
 

61
00:01:09,390 --> 00:01:10,880
now and never any ads in the middle that
can break the flow of this conversation

62
00:01:10,880 --> 00:01:10,890
can break the flow of this conversation
 

63
00:01:10,890 --> 00:01:13,550
can break the flow of this conversation
I hope that works for you and doesn't

64
00:01:13,550 --> 00:01:13,560
I hope that works for you and doesn't
 

65
00:01:13,560 --> 00:01:16,340
I hope that works for you and doesn't
hurt the listening experience this show

66
00:01:16,340 --> 00:01:16,350
hurt the listening experience this show
 

67
00:01:16,350 --> 00:01:18,440
hurt the listening experience this show
is presented by cash app the number-one

68
00:01:18,440 --> 00:01:18,450
is presented by cash app the number-one
 

69
00:01:18,450 --> 00:01:20,510
is presented by cash app the number-one
finance app in the App Store when you

70
00:01:20,510 --> 00:01:20,520
finance app in the App Store when you
 

71
00:01:20,520 --> 00:01:23,870
finance app in the App Store when you
get it used collects podcast cash app

72
00:01:23,870 --> 00:01:23,880
get it used collects podcast cash app
 

73
00:01:23,880 --> 00:01:25,730
get it used collects podcast cash app
lets you send money to friends buy

74
00:01:25,730 --> 00:01:25,740
lets you send money to friends buy
 

75
00:01:25,740 --> 00:01:27,859
lets you send money to friends buy
Bitcoin and invest in the stock market

76
00:01:27,859 --> 00:01:27,869
Bitcoin and invest in the stock market
 

77
00:01:27,869 --> 00:01:30,380
Bitcoin and invest in the stock market
with as little as one dollar since

78
00:01:30,380 --> 00:01:30,390
with as little as one dollar since
 

79
00:01:30,390 --> 00:01:32,090
with as little as one dollar since
ketchup allows you to send and receive

80
00:01:32,090 --> 00:01:32,100
ketchup allows you to send and receive
 

81
00:01:32,100 --> 00:01:34,460
ketchup allows you to send and receive
money digitally peer-to-peer and

82
00:01:34,460 --> 00:01:34,470
money digitally peer-to-peer and
 

83
00:01:34,470 --> 00:01:36,950
money digitally peer-to-peer and
security in all digital transactions is

84
00:01:36,950 --> 00:01:36,960
security in all digital transactions is
 

85
00:01:36,960 --> 00:01:38,749
security in all digital transactions is
very important and you mentioned that

86
00:01:38,749 --> 00:01:38,759
very important and you mentioned that
 

87
00:01:38,759 --> 00:01:41,899
very important and you mentioned that
PCI data security standard the cash shop

88
00:01:41,899 --> 00:01:41,909
PCI data security standard the cash shop
 

89
00:01:41,909 --> 00:01:44,600
PCI data security standard the cash shop
is compliant with I'm a big fan of

90
00:01:44,600 --> 00:01:44,610
is compliant with I'm a big fan of
 

91
00:01:44,610 --> 00:01:47,090
is compliant with I'm a big fan of
standards for safety and security PCI

92
00:01:47,090 --> 00:01:47,100
standards for safety and security PCI
 

93
00:01:47,100 --> 00:01:49,639
standards for safety and security PCI
DSS is a good example of that where a

94
00:01:49,639 --> 00:01:49,649
DSS is a good example of that where a
 

95
00:01:49,649 --> 00:01:51,200
DSS is a good example of that where a
bunch of competitors got together and

96
00:01:51,200 --> 00:01:51,210
bunch of competitors got together and
 

97
00:01:51,210 --> 00:01:53,179
bunch of competitors got together and
agreed that there needs to be a global

98
00:01:53,179 --> 00:01:53,189
agreed that there needs to be a global
 

99
00:01:53,189 --> 00:01:54,649
agreed that there needs to be a global
standard around the security of

100
00:01:54,649 --> 00:01:54,659
standard around the security of
 

101
00:01:54,659 --> 00:01:56,929
standard around the security of
transactions now we just need to do the

102
00:01:56,929 --> 00:01:56,939
transactions now we just need to do the
 

103
00:01:56,939 --> 00:01:58,819
transactions now we just need to do the
same for Thomas vehicles and the ad

104
00:01:58,819 --> 00:01:58,829
same for Thomas vehicles and the ad
 

105
00:01:58,829 --> 00:02:01,940
same for Thomas vehicles and the ad
systems in general so again if you get

106
00:02:01,940 --> 00:02:01,950
systems in general so again if you get
 

107
00:02:01,950 --> 00:02:03,590
systems in general so again if you get
cash app from the App Store Google Play

108
00:02:03,590 --> 00:02:03,600
cash app from the App Store Google Play
 

109
00:02:03,600 --> 00:02:07,370
cash app from the App Store Google Play
and use the code luxe podcast you get

110
00:02:07,370 --> 00:02:07,380
and use the code luxe podcast you get
 

111
00:02:07,380 --> 00:02:09,139
and use the code luxe podcast you get
ten dollars in cash that will also

112
00:02:09,139 --> 00:02:09,149
ten dollars in cash that will also
 

113
00:02:09,149 --> 00:02:11,270
ten dollars in cash that will also
donate ten dollars to first an

114
00:02:11,270 --> 00:02:11,280
donate ten dollars to first an
 

115
00:02:11,280 --> 00:02:13,130
donate ten dollars to first an
organization that is helping to advance

116
00:02:13,130 --> 00:02:13,140
organization that is helping to advance
 

117
00:02:13,140 --> 00:02:13,860
organization that is helping to advance
robotics

118
00:02:13,860 --> 00:02:13,870
robotics
 

119
00:02:13,870 --> 00:02:16,140
robotics
and STEM education for young people

120
00:02:16,140 --> 00:02:16,150
and STEM education for young people
 

121
00:02:16,150 --> 00:02:18,660
and STEM education for young people
around the world and now here's my

122
00:02:18,660 --> 00:02:18,670
around the world and now here's my
 

123
00:02:18,670 --> 00:02:21,559
around the world and now here's my
conversation with Daphne Koller

124
00:02:21,559 --> 00:02:21,569
conversation with Daphne Koller
 

125
00:02:21,569 --> 00:02:24,570
conversation with Daphne Koller
so you co-founded Coursera I made a huge

126
00:02:24,570 --> 00:02:24,580
so you co-founded Coursera I made a huge
 

127
00:02:24,580 --> 00:02:26,729
so you co-founded Coursera I made a huge
impact in the global education of AI and

128
00:02:26,729 --> 00:02:26,739
impact in the global education of AI and
 

129
00:02:26,739 --> 00:02:29,910
impact in the global education of AI and
after five years in August 2016 wrote a

130
00:02:29,910 --> 00:02:29,920
after five years in August 2016 wrote a
 

131
00:02:29,920 --> 00:02:32,220
after five years in August 2016 wrote a
blog post saying that you're stepping

132
00:02:32,220 --> 00:02:32,230
blog post saying that you're stepping
 

133
00:02:32,230 --> 00:02:35,490
blog post saying that you're stepping
away and wrote quote it's time for me to

134
00:02:35,490 --> 00:02:35,500
away and wrote quote it's time for me to
 

135
00:02:35,500 --> 00:02:37,559
away and wrote quote it's time for me to
turn to another critical challenge the

136
00:02:37,559 --> 00:02:37,569
turn to another critical challenge the
 

137
00:02:37,569 --> 00:02:39,180
turn to another critical challenge the
development of machine learning and it's

138
00:02:39,180 --> 00:02:39,190
development of machine learning and it's
 

139
00:02:39,190 --> 00:02:40,789
development of machine learning and it's
applications to improving human health

140
00:02:40,789 --> 00:02:40,799
applications to improving human health
 

141
00:02:40,799 --> 00:02:43,949
applications to improving human health
so let me ask two far-out philosophical

142
00:02:43,949 --> 00:02:43,959
so let me ask two far-out philosophical
 

143
00:02:43,959 --> 00:02:46,890
so let me ask two far-out philosophical
questions one do you think will one day

144
00:02:46,890 --> 00:02:46,900
questions one do you think will one day
 

145
00:02:46,900 --> 00:02:49,289
questions one do you think will one day
find cures for all major diseases known

146
00:02:49,289 --> 00:02:49,299
find cures for all major diseases known
 

147
00:02:49,299 --> 00:02:52,680
find cures for all major diseases known
today and two do you think will one day

148
00:02:52,680 --> 00:02:52,690
today and two do you think will one day
 

149
00:02:52,690 --> 00:02:54,599
today and two do you think will one day
figure out a way to extend the human

150
00:02:54,599 --> 00:02:54,609
figure out a way to extend the human
 

151
00:02:54,609 --> 00:02:56,910
figure out a way to extend the human
lifespan perhaps to the point of

152
00:02:56,910 --> 00:02:56,920
lifespan perhaps to the point of
 

153
00:02:56,920 --> 00:03:01,110
lifespan perhaps to the point of
immortality so one day is a very long

154
00:03:01,110 --> 00:03:01,120
immortality so one day is a very long
 

155
00:03:01,120 --> 00:03:03,270
immortality so one day is a very long
time and I don't like to make

156
00:03:03,270 --> 00:03:03,280
time and I don't like to make
 

157
00:03:03,280 --> 00:03:05,910
time and I don't like to make
predictions of the type we will never be

158
00:03:05,910 --> 00:03:05,920
predictions of the type we will never be
 

159
00:03:05,920 --> 00:03:09,559
predictions of the type we will never be
able to do X because I think that's a

160
00:03:09,559 --> 00:03:09,569
able to do X because I think that's a
 

161
00:03:09,569 --> 00:03:12,690
able to do X because I think that's a
you know that's the smacks of hubris it

162
00:03:12,690 --> 00:03:12,700
you know that's the smacks of hubris it
 

163
00:03:12,700 --> 00:03:15,180
you know that's the smacks of hubris it
seems that never and in in in the entire

164
00:03:15,180 --> 00:03:15,190
seems that never and in in in the entire
 

165
00:03:15,190 --> 00:03:17,879
seems that never and in in in the entire
eternity of human existence will we be

166
00:03:17,879 --> 00:03:17,889
eternity of human existence will we be
 

167
00:03:17,889 --> 00:03:20,479
eternity of human existence will we be
able to solve a problem that being said

168
00:03:20,479 --> 00:03:20,489
able to solve a problem that being said
 

169
00:03:20,489 --> 00:03:24,470
able to solve a problem that being said
curing disease is very hard because

170
00:03:24,470 --> 00:03:24,480
curing disease is very hard because
 

171
00:03:24,480 --> 00:03:27,750
curing disease is very hard because
oftentimes by the time you discover the

172
00:03:27,750 --> 00:03:27,760
oftentimes by the time you discover the
 

173
00:03:27,760 --> 00:03:29,940
oftentimes by the time you discover the
disease a lot of damage has already been

174
00:03:29,940 --> 00:03:29,950
disease a lot of damage has already been
 

175
00:03:29,950 --> 00:03:32,430
disease a lot of damage has already been
done and so to assume that we would be

176
00:03:32,430 --> 00:03:32,440
done and so to assume that we would be
 

177
00:03:32,440 --> 00:03:35,699
done and so to assume that we would be
able to cure disease at that stage

178
00:03:35,699 --> 00:03:35,709
able to cure disease at that stage
 

179
00:03:35,709 --> 00:03:37,470
able to cure disease at that stage
assumes that we would come up with ways

180
00:03:37,470 --> 00:03:37,480
assumes that we would come up with ways
 

181
00:03:37,480 --> 00:03:40,289
assumes that we would come up with ways
is basically regenerating entire parts

182
00:03:40,289 --> 00:03:40,299
is basically regenerating entire parts
 

183
00:03:40,299 --> 00:03:42,629
is basically regenerating entire parts
of the human body in the way that

184
00:03:42,629 --> 00:03:42,639
of the human body in the way that
 

185
00:03:42,639 --> 00:03:44,610
of the human body in the way that
actually returns it to its original

186
00:03:44,610 --> 00:03:44,620
actually returns it to its original
 

187
00:03:44,620 --> 00:03:46,409
actually returns it to its original
state and that's a very challenging

188
00:03:46,409 --> 00:03:46,419
state and that's a very challenging
 

189
00:03:46,419 --> 00:03:49,110
state and that's a very challenging
problem we have cured very few diseases

190
00:03:49,110 --> 00:03:49,120
problem we have cured very few diseases
 

191
00:03:49,120 --> 00:03:51,300
problem we have cured very few diseases
we've been able to provide treatment for

192
00:03:51,300 --> 00:03:51,310
we've been able to provide treatment for
 

193
00:03:51,310 --> 00:03:53,159
we've been able to provide treatment for
an increasingly large number but the

194
00:03:53,159 --> 00:03:53,169
an increasingly large number but the
 

195
00:03:53,169 --> 00:03:54,210
an increasingly large number but the
number of things that you could actually

196
00:03:54,210 --> 00:03:54,220
number of things that you could actually
 

197
00:03:54,220 --> 00:03:56,580
number of things that you could actually
define to be cures is actually not that

198
00:03:56,580 --> 00:03:56,590
define to be cures is actually not that
 

199
00:03:56,590 --> 00:04:01,920
define to be cures is actually not that
large so I think that's it there's a lot

200
00:04:01,920 --> 00:04:01,930
large so I think that's it there's a lot
 

201
00:04:01,930 --> 00:04:04,349
large so I think that's it there's a lot
of work that would need to happen for

202
00:04:04,349 --> 00:04:04,359
of work that would need to happen for
 

203
00:04:04,359 --> 00:04:06,119
of work that would need to happen for
one could legitimately say that we have

204
00:04:06,119 --> 00:04:06,129
one could legitimately say that we have
 

205
00:04:06,129 --> 00:04:09,030
one could legitimately say that we have
cured even a reasonable number of far

206
00:04:09,030 --> 00:04:09,040
cured even a reasonable number of far
 

207
00:04:09,040 --> 00:04:11,699
cured even a reasonable number of far
less all diseases on the scale of 0 to

208
00:04:11,699 --> 00:04:11,709
less all diseases on the scale of 0 to
 

209
00:04:11,709 --> 00:04:14,220
less all diseases on the scale of 0 to
100 where are we in understanding the

210
00:04:14,220 --> 00:04:14,230
100 where are we in understanding the
 

211
00:04:14,230 --> 00:04:16,770
100 where are we in understanding the
fundamental mechanisms of all major

212
00:04:16,770 --> 00:04:16,780
fundamental mechanisms of all major
 

213
00:04:16,780 --> 00:04:19,860
fundamental mechanisms of all major
diseases what's your sense so from the

214
00:04:19,860 --> 00:04:19,870
diseases what's your sense so from the
 

215
00:04:19,870 --> 00:04:21,300
diseases what's your sense so from the
computer science perspective that you've

216
00:04:21,300 --> 00:04:21,310
computer science perspective that you've
 

217
00:04:21,310 --> 00:04:24,690
computer science perspective that you've
entered the world of health how far

218
00:04:24,690 --> 00:04:24,700
entered the world of health how far
 

219
00:04:24,700 --> 00:04:26,460
entered the world of health how far
along are we

220
00:04:26,460 --> 00:04:26,470
along are we
 

221
00:04:26,470 --> 00:04:29,190
along are we
I think it depends on which disease I

222
00:04:29,190 --> 00:04:29,200
I think it depends on which disease I
 

223
00:04:29,200 --> 00:04:31,590
I think it depends on which disease I
mean there are ones where I would say

224
00:04:31,590 --> 00:04:31,600
mean there are ones where I would say
 

225
00:04:31,600 --> 00:04:33,240
mean there are ones where I would say
we're maybe not quite at a hundred

226
00:04:33,240 --> 00:04:33,250
we're maybe not quite at a hundred
 

227
00:04:33,250 --> 00:04:35,190
we're maybe not quite at a hundred
because biology is really complicated

228
00:04:35,190 --> 00:04:35,200
because biology is really complicated
 

229
00:04:35,200 --> 00:04:38,040
because biology is really complicated
and there's always new things that we

230
00:04:38,040 --> 00:04:38,050
and there's always new things that we
 

231
00:04:38,050 --> 00:04:40,200
and there's always new things that we
uncover that people didn't even realize

232
00:04:40,200 --> 00:04:40,210
uncover that people didn't even realize
 

233
00:04:40,210 --> 00:04:43,830
uncover that people didn't even realize
existed so but I would say there's

234
00:04:43,830 --> 00:04:43,840
existed so but I would say there's
 

235
00:04:43,840 --> 00:04:45,500
existed so but I would say there's
diseases where we might be in the

236
00:04:45,500 --> 00:04:45,510
diseases where we might be in the
 

237
00:04:45,510 --> 00:04:49,260
diseases where we might be in the
seventies or eighties and then there's

238
00:04:49,260 --> 00:04:49,270
seventies or eighties and then there's
 

239
00:04:49,270 --> 00:04:52,170
seventies or eighties and then there's
diseases in which I would say probably

240
00:04:52,170 --> 00:04:52,180
diseases in which I would say probably
 

241
00:04:52,180 --> 00:04:54,150
diseases in which I would say probably
the majority where we're really close to

242
00:04:54,150 --> 00:04:54,160
the majority where we're really close to
 

243
00:04:54,160 --> 00:04:57,660
the majority where we're really close to
zero with Alzheimer's and schizophrenia

244
00:04:57,660 --> 00:04:57,670
zero with Alzheimer's and schizophrenia
 

245
00:04:57,670 --> 00:05:01,590
zero with Alzheimer's and schizophrenia
and type 2 diabetes fall closer to zero

246
00:05:01,590 --> 00:05:01,600
and type 2 diabetes fall closer to zero
 

247
00:05:01,600 --> 00:05:03,390
and type 2 diabetes fall closer to zero
or to the 80

248
00:05:03,390 --> 00:05:03,400
or to the 80
 

249
00:05:03,400 --> 00:05:08,670
or to the 80
I think Alzheimer's is probably closer

250
00:05:08,670 --> 00:05:08,680
I think Alzheimer's is probably closer
 

251
00:05:08,680 --> 00:05:12,360
I think Alzheimer's is probably closer
to zero than to 80 there are hypotheses

252
00:05:12,360 --> 00:05:12,370
to zero than to 80 there are hypotheses
 

253
00:05:12,370 --> 00:05:15,930
to zero than to 80 there are hypotheses
but I don't think those hypotheses have

254
00:05:15,930 --> 00:05:15,940
but I don't think those hypotheses have
 

255
00:05:15,940 --> 00:05:19,860
but I don't think those hypotheses have
as of yet been sufficiently validated

256
00:05:19,860 --> 00:05:19,870
as of yet been sufficiently validated
 

257
00:05:19,870 --> 00:05:22,110
as of yet been sufficiently validated
that we believe them to be true and

258
00:05:22,110 --> 00:05:22,120
that we believe them to be true and
 

259
00:05:22,120 --> 00:05:23,760
that we believe them to be true and
there is an increasing number of people

260
00:05:23,760 --> 00:05:23,770
there is an increasing number of people
 

261
00:05:23,770 --> 00:05:24,930
there is an increasing number of people
who believe there's a traditional

262
00:05:24,930 --> 00:05:24,940
who believe there's a traditional
 

263
00:05:24,940 --> 00:05:27,030
who believe there's a traditional
hypotheses might not really explain

264
00:05:27,030 --> 00:05:27,040
hypotheses might not really explain
 

265
00:05:27,040 --> 00:05:29,040
hypotheses might not really explain
what's going on I would also say that

266
00:05:29,040 --> 00:05:29,050
what's going on I would also say that
 

267
00:05:29,050 --> 00:05:32,190
what's going on I would also say that
Alzheimer's and schizophrenia and in

268
00:05:32,190 --> 00:05:32,200
Alzheimer's and schizophrenia and in
 

269
00:05:32,200 --> 00:05:34,590
Alzheimer's and schizophrenia and in
even type 2 diabetes are not really one

270
00:05:34,590 --> 00:05:34,600
even type 2 diabetes are not really one
 

271
00:05:34,600 --> 00:05:37,350
even type 2 diabetes are not really one
disease they're almost certainly a

272
00:05:37,350 --> 00:05:37,360
disease they're almost certainly a
 

273
00:05:37,360 --> 00:05:40,260
disease they're almost certainly a
heterogeneous collection of mechanisms

274
00:05:40,260 --> 00:05:40,270
heterogeneous collection of mechanisms
 

275
00:05:40,270 --> 00:05:42,840
heterogeneous collection of mechanisms
that manifests in clinically similar

276
00:05:42,840 --> 00:05:42,850
that manifests in clinically similar
 

277
00:05:42,850 --> 00:05:45,210
that manifests in clinically similar
ways so in the same way that we now

278
00:05:45,210 --> 00:05:45,220
ways so in the same way that we now
 

279
00:05:45,220 --> 00:05:47,730
ways so in the same way that we now
understand that breast cancer is really

280
00:05:47,730 --> 00:05:47,740
understand that breast cancer is really
 

281
00:05:47,740 --> 00:05:51,650
understand that breast cancer is really
not one disease it is multitude of

282
00:05:51,650 --> 00:05:51,660
not one disease it is multitude of
 

283
00:05:51,660 --> 00:05:53,880
not one disease it is multitude of
cellular mechanisms all of which

284
00:05:53,880 --> 00:05:53,890
cellular mechanisms all of which
 

285
00:05:53,890 --> 00:05:56,400
cellular mechanisms all of which
ultimately translate to uncontrolled

286
00:05:56,400 --> 00:05:56,410
ultimately translate to uncontrolled
 

287
00:05:56,410 --> 00:05:58,920
ultimately translate to uncontrolled
proliferation but it's not one disease

288
00:05:58,920 --> 00:05:58,930
proliferation but it's not one disease
 

289
00:05:58,930 --> 00:06:01,350
proliferation but it's not one disease
the same is almost undoubtedly true for

290
00:06:01,350 --> 00:06:01,360
the same is almost undoubtedly true for
 

291
00:06:01,360 --> 00:06:03,390
the same is almost undoubtedly true for
those other diseases as well that

292
00:06:03,390 --> 00:06:03,400
those other diseases as well that
 

293
00:06:03,400 --> 00:06:05,850
those other diseases as well that
understanding that needs to precede any

294
00:06:05,850 --> 00:06:05,860
understanding that needs to precede any
 

295
00:06:05,860 --> 00:06:08,010
understanding that needs to precede any
understanding of the specific mechanisms

296
00:06:08,010 --> 00:06:08,020
understanding of the specific mechanisms
 

297
00:06:08,020 --> 00:06:10,469
understanding of the specific mechanisms
of any of those other diseases now in

298
00:06:10,469 --> 00:06:10,479
of any of those other diseases now in
 

299
00:06:10,479 --> 00:06:11,880
of any of those other diseases now in
schizophrenia I would say we're almost

300
00:06:11,880 --> 00:06:11,890
schizophrenia I would say we're almost
 

301
00:06:11,890 --> 00:06:13,620
schizophrenia I would say we're almost
certainly closer to zero than to

302
00:06:13,620 --> 00:06:13,630
certainly closer to zero than to
 

303
00:06:13,630 --> 00:06:16,740
certainly closer to zero than to
anything else type 2 diabetes is a bit

304
00:06:16,740 --> 00:06:16,750
anything else type 2 diabetes is a bit
 

305
00:06:16,750 --> 00:06:20,580
anything else type 2 diabetes is a bit
of a mix there are clear mechanisms that

306
00:06:20,580 --> 00:06:20,590
of a mix there are clear mechanisms that
 

307
00:06:20,590 --> 00:06:22,020
of a mix there are clear mechanisms that
are implicated that I think have been

308
00:06:22,020 --> 00:06:22,030
are implicated that I think have been
 

309
00:06:22,030 --> 00:06:24,060
are implicated that I think have been
validated they have to do with insulin

310
00:06:24,060 --> 00:06:24,070
validated they have to do with insulin
 

311
00:06:24,070 --> 00:06:27,090
validated they have to do with insulin
resistance and such but there's almost

312
00:06:27,090 --> 00:06:27,100
resistance and such but there's almost
 

313
00:06:27,100 --> 00:06:29,010
resistance and such but there's almost
certainly there as well many mechanisms

314
00:06:29,010 --> 00:06:29,020
certainly there as well many mechanisms
 

315
00:06:29,020 --> 00:06:31,530
certainly there as well many mechanisms
that we have not yet understood you've

316
00:06:31,530 --> 00:06:31,540
that we have not yet understood you've
 

317
00:06:31,540 --> 00:06:34,469
that we have not yet understood you've
also thought and worked a little bit on

318
00:06:34,469 --> 00:06:34,479
also thought and worked a little bit on
 

319
00:06:34,479 --> 00:06:36,630
also thought and worked a little bit on
the longevity side do you see the

320
00:06:36,630 --> 00:06:36,640
the longevity side do you see the
 

321
00:06:36,640 --> 00:06:39,059
the longevity side do you see the
disease and longevity as

322
00:06:39,059 --> 00:06:39,069
disease and longevity as
 

323
00:06:39,069 --> 00:06:42,339
disease and longevity as
overlapping completely partially or not

324
00:06:42,339 --> 00:06:42,349
overlapping completely partially or not
 

325
00:06:42,349 --> 00:06:46,360
overlapping completely partially or not
at all as efforts those mechanisms are

326
00:06:46,360 --> 00:06:46,370
at all as efforts those mechanisms are
 

327
00:06:46,370 --> 00:06:49,420
at all as efforts those mechanisms are
certainly overlapping there's a

328
00:06:49,420 --> 00:06:49,430
certainly overlapping there's a
 

329
00:06:49,430 --> 00:06:53,110
certainly overlapping there's a
well-known phenomenon that says that for

330
00:06:53,110 --> 00:06:53,120
well-known phenomenon that says that for
 

331
00:06:53,120 --> 00:06:55,839
well-known phenomenon that says that for
most diseases other than childhood

332
00:06:55,839 --> 00:06:55,849
most diseases other than childhood
 

333
00:06:55,849 --> 00:07:00,070
most diseases other than childhood
diseases the risk for getting for

334
00:07:00,070 --> 00:07:00,080
diseases the risk for getting for
 

335
00:07:00,080 --> 00:07:01,629
diseases the risk for getting for
contracting that disease increases

336
00:07:01,629 --> 00:07:01,639
contracting that disease increases
 

337
00:07:01,639 --> 00:07:03,760
contracting that disease increases
exponentially year-on-year every year

338
00:07:03,760 --> 00:07:03,770
exponentially year-on-year every year
 

339
00:07:03,770 --> 00:07:05,860
exponentially year-on-year every year
from the time you're about 40 so

340
00:07:05,860 --> 00:07:05,870
from the time you're about 40 so
 

341
00:07:05,870 --> 00:07:07,540
from the time you're about 40 so
obviously there is a connection between

342
00:07:07,540 --> 00:07:07,550
obviously there is a connection between
 

343
00:07:07,550 --> 00:07:11,379
obviously there is a connection between
those two things I that's not to say

344
00:07:11,379 --> 00:07:11,389
those two things I that's not to say
 

345
00:07:11,389 --> 00:07:13,689
those two things I that's not to say
that they're identical there's clearly

346
00:07:13,689 --> 00:07:13,699
that they're identical there's clearly
 

347
00:07:13,699 --> 00:07:15,959
that they're identical there's clearly
aging that happens that is not really

348
00:07:15,959 --> 00:07:15,969
aging that happens that is not really
 

349
00:07:15,969 --> 00:07:19,059
aging that happens that is not really
associated with any specific disease and

350
00:07:19,059 --> 00:07:19,069
associated with any specific disease and
 

351
00:07:19,069 --> 00:07:21,730
associated with any specific disease and
there's also diseases and mechanisms of

352
00:07:21,730 --> 00:07:21,740
there's also diseases and mechanisms of
 

353
00:07:21,740 --> 00:07:24,129
there's also diseases and mechanisms of
disease that are not specifically

354
00:07:24,129 --> 00:07:24,139
disease that are not specifically
 

355
00:07:24,139 --> 00:07:27,459
disease that are not specifically
related to aging so I think overlap is

356
00:07:27,459 --> 00:07:27,469
related to aging so I think overlap is
 

357
00:07:27,469 --> 00:07:31,240
related to aging so I think overlap is
where we're at okay it is a little

358
00:07:31,240 --> 00:07:31,250
where we're at okay it is a little
 

359
00:07:31,250 --> 00:07:32,860
where we're at okay it is a little
unfortunate that would get older and it

360
00:07:32,860 --> 00:07:32,870
unfortunate that would get older and it
 

361
00:07:32,870 --> 00:07:34,800
unfortunate that would get older and it
seems that there's some correlation with

362
00:07:34,800 --> 00:07:34,810
seems that there's some correlation with
 

363
00:07:34,810 --> 00:07:38,439
seems that there's some correlation with
the fact the the occurrence of diseases

364
00:07:38,439 --> 00:07:38,449
the fact the the occurrence of diseases
 

365
00:07:38,449 --> 00:07:40,149
the fact the the occurrence of diseases
or the fact that we'll get all there

366
00:07:40,149 --> 00:07:40,159
or the fact that we'll get all there
 

367
00:07:40,159 --> 00:07:43,360
or the fact that we'll get all there
mm-hmm and both are quite sad I mean

368
00:07:43,360 --> 00:07:43,370
mm-hmm and both are quite sad I mean
 

369
00:07:43,370 --> 00:07:45,820
mm-hmm and both are quite sad I mean
there's processes that happen as cells

370
00:07:45,820 --> 00:07:45,830
there's processes that happen as cells
 

371
00:07:45,830 --> 00:07:48,999
there's processes that happen as cells
age that I think are contributing to

372
00:07:48,999 --> 00:07:49,009
age that I think are contributing to
 

373
00:07:49,009 --> 00:07:50,529
age that I think are contributing to
disease some of those have to do with

374
00:07:50,529 --> 00:07:50,539
disease some of those have to do with
 

375
00:07:50,539 --> 00:07:53,980
disease some of those have to do with
the DNA damage that accumulates the

376
00:07:53,980 --> 00:07:53,990
the DNA damage that accumulates the
 

377
00:07:53,990 --> 00:07:56,320
the DNA damage that accumulates the
cells divide where the repair mechanisms

378
00:07:56,320 --> 00:07:56,330
cells divide where the repair mechanisms
 

379
00:07:56,330 --> 00:07:59,769
cells divide where the repair mechanisms
don't fully it correct for those there

380
00:07:59,769 --> 00:07:59,779
don't fully it correct for those there
 

381
00:07:59,779 --> 00:08:04,089
don't fully it correct for those there
are accumulations of proteins that are

382
00:08:04,089 --> 00:08:04,099
are accumulations of proteins that are
 

383
00:08:04,099 --> 00:08:06,459
are accumulations of proteins that are
misfolded and potentially aggregate and

384
00:08:06,459 --> 00:08:06,469
misfolded and potentially aggregate and
 

385
00:08:06,469 --> 00:08:08,649
misfolded and potentially aggregate and
those two contributes a disease and

386
00:08:08,649 --> 00:08:08,659
those two contributes a disease and
 

387
00:08:08,659 --> 00:08:11,019
those two contributes a disease and
contribute to inflammation there is an

388
00:08:11,019 --> 00:08:11,029
contribute to inflammation there is an
 

389
00:08:11,029 --> 00:08:12,969
contribute to inflammation there is an
um there's a multitude of mechanisms

390
00:08:12,969 --> 00:08:12,979
um there's a multitude of mechanisms
 

391
00:08:12,979 --> 00:08:15,100
um there's a multitude of mechanisms
that have been uncovered that are sort

392
00:08:15,100 --> 00:08:15,110
that have been uncovered that are sort
 

393
00:08:15,110 --> 00:08:16,659
that have been uncovered that are sort
of wear and tear at the cellular level

394
00:08:16,659 --> 00:08:16,669
of wear and tear at the cellular level
 

395
00:08:16,669 --> 00:08:20,519
of wear and tear at the cellular level
that contribute to disease processes

396
00:08:20,519 --> 00:08:20,529
that contribute to disease processes
 

397
00:08:20,529 --> 00:08:22,809
that contribute to disease processes
that and I'm sure there's many that we

398
00:08:22,809 --> 00:08:22,819
that and I'm sure there's many that we
 

399
00:08:22,819 --> 00:08:26,050
that and I'm sure there's many that we
don't yet understand on a small tangent

400
00:08:26,050 --> 00:08:26,060
don't yet understand on a small tangent
 

401
00:08:26,060 --> 00:08:30,580
don't yet understand on a small tangent
perhaps philosophical this uh the the

402
00:08:30,580 --> 00:08:30,590
perhaps philosophical this uh the the
 

403
00:08:30,590 --> 00:08:33,010
perhaps philosophical this uh the the
fact that things get older and the fact

404
00:08:33,010 --> 00:08:33,020
fact that things get older and the fact
 

405
00:08:33,020 --> 00:08:35,769
fact that things get older and the fact
that things die is a very powerful

406
00:08:35,769 --> 00:08:35,779
that things die is a very powerful
 

407
00:08:35,779 --> 00:08:38,019
that things die is a very powerful
feature for the growth of new things

408
00:08:38,019 --> 00:08:38,029
feature for the growth of new things
 

409
00:08:38,029 --> 00:08:39,639
feature for the growth of new things
that you know it's a learning it's a

410
00:08:39,639 --> 00:08:39,649
that you know it's a learning it's a
 

411
00:08:39,649 --> 00:08:41,889
that you know it's a learning it's a
kind of learning mechanism so it's both

412
00:08:41,889 --> 00:08:41,899
kind of learning mechanism so it's both
 

413
00:08:41,899 --> 00:08:49,240
kind of learning mechanism so it's both
tragic and beautiful so do you do you do

414
00:08:49,240 --> 00:08:49,250
tragic and beautiful so do you do you do
 

415
00:08:49,250 --> 00:08:51,220
tragic and beautiful so do you do you do
you so in you know in trying to fight

416
00:08:51,220 --> 00:08:51,230
you so in you know in trying to fight
 

417
00:08:51,230 --> 00:08:52,220
you so in you know in trying to fight
disease

418
00:08:52,220 --> 00:08:52,230
disease
 

419
00:08:52,230 --> 00:08:55,640
disease
and trying to fight aging do you think

420
00:08:55,640 --> 00:08:55,650
and trying to fight aging do you think
 

421
00:08:55,650 --> 00:08:58,100
and trying to fight aging do you think
about sort of the useful fact of our

422
00:08:58,100 --> 00:08:58,110
about sort of the useful fact of our
 

423
00:08:58,110 --> 00:09:01,430
about sort of the useful fact of our
mortality or would you like what if you

424
00:09:01,430 --> 00:09:01,440
mortality or would you like what if you
 

425
00:09:01,440 --> 00:09:03,320
mortality or would you like what if you
were could be immortal would you choose

426
00:09:03,320 --> 00:09:03,330
were could be immortal would you choose
 

427
00:09:03,330 --> 00:09:06,460
were could be immortal would you choose
to be immortal

428
00:09:06,460 --> 00:09:06,470

 

429
00:09:06,470 --> 00:09:09,800

again I think immortal is a very long

430
00:09:09,800 --> 00:09:09,810
again I think immortal is a very long
 

431
00:09:09,810 --> 00:09:14,450
again I think immortal is a very long
time I don't know that that would

432
00:09:14,450 --> 00:09:14,460
time I don't know that that would
 

433
00:09:14,460 --> 00:09:16,520
time I don't know that that would
necessarily be something that I would

434
00:09:16,520 --> 00:09:16,530
necessarily be something that I would
 

435
00:09:16,530 --> 00:09:20,050
necessarily be something that I would
want to aspire to but I think all of us

436
00:09:20,050 --> 00:09:20,060
want to aspire to but I think all of us
 

437
00:09:20,060 --> 00:09:24,230
want to aspire to but I think all of us
aspire to an increased health span I

438
00:09:24,230 --> 00:09:24,240
aspire to an increased health span I
 

439
00:09:24,240 --> 00:09:26,300
aspire to an increased health span I
would say which is an increased amount

440
00:09:26,300 --> 00:09:26,310
would say which is an increased amount
 

441
00:09:26,310 --> 00:09:29,420
would say which is an increased amount
of time where you're healthy and active

442
00:09:29,420 --> 00:09:29,430
of time where you're healthy and active
 

443
00:09:29,430 --> 00:09:33,220
of time where you're healthy and active
and feel as you did when you were 20 and

444
00:09:33,220 --> 00:09:33,230
and feel as you did when you were 20 and
 

445
00:09:33,230 --> 00:09:37,180
and feel as you did when you were 20 and
we're nowhere close to that people

446
00:09:37,180 --> 00:09:37,190
we're nowhere close to that people
 

447
00:09:37,190 --> 00:09:41,420
we're nowhere close to that people
deteriorate physically and mentally over

448
00:09:41,420 --> 00:09:41,430
deteriorate physically and mentally over
 

449
00:09:41,430 --> 00:09:43,550
deteriorate physically and mentally over
time and that is a very sad phenomenon

450
00:09:43,550 --> 00:09:43,560
time and that is a very sad phenomenon
 

451
00:09:43,560 --> 00:09:46,310
time and that is a very sad phenomenon
so I think a wonderful aspiration would

452
00:09:46,310 --> 00:09:46,320
so I think a wonderful aspiration would
 

453
00:09:46,320 --> 00:09:50,030
so I think a wonderful aspiration would
be if we could all live to you know the

454
00:09:50,030 --> 00:09:50,040
be if we could all live to you know the
 

455
00:09:50,040 --> 00:09:53,840
be if we could all live to you know the
biblical 120 may be in perfect health in

456
00:09:53,840 --> 00:09:53,850
biblical 120 may be in perfect health in
 

457
00:09:53,850 --> 00:09:55,730
biblical 120 may be in perfect health in
my quality of life high quality of life

458
00:09:55,730 --> 00:09:55,740
my quality of life high quality of life
 

459
00:09:55,740 --> 00:09:57,320
my quality of life high quality of life
I think that would be an amazing goal

460
00:09:57,320 --> 00:09:57,330
I think that would be an amazing goal
 

461
00:09:57,330 --> 00:09:59,600
I think that would be an amazing goal
for us to achieve as a society now is

462
00:09:59,600 --> 00:09:59,610
for us to achieve as a society now is
 

463
00:09:59,610 --> 00:10:04,070
for us to achieve as a society now is
the right age 120 or 100 or 150 I think

464
00:10:04,070 --> 00:10:04,080
the right age 120 or 100 or 150 I think
 

465
00:10:04,080 --> 00:10:06,620
the right age 120 or 100 or 150 I think
that's up for debate but I think an

466
00:10:06,620 --> 00:10:06,630
that's up for debate but I think an
 

467
00:10:06,630 --> 00:10:08,390
that's up for debate but I think an
increased health span is a really worthy

468
00:10:08,390 --> 00:10:08,400
increased health span is a really worthy
 

469
00:10:08,400 --> 00:10:14,000
increased health span is a really worthy
goal and anyway in a grand time the age

470
00:10:14,000 --> 00:10:14,010
goal and anyway in a grand time the age
 

471
00:10:14,010 --> 00:10:16,210
goal and anyway in a grand time the age
of the universe it's all pretty short so

472
00:10:16,210 --> 00:10:16,220
of the universe it's all pretty short so
 

473
00:10:16,220 --> 00:10:18,970
of the universe it's all pretty short so
from the perspective you've done

474
00:10:18,970 --> 00:10:18,980
from the perspective you've done
 

475
00:10:18,980 --> 00:10:21,110
from the perspective you've done
obviously a lot of incredible work on

476
00:10:21,110 --> 00:10:21,120
obviously a lot of incredible work on
 

477
00:10:21,120 --> 00:10:23,660
obviously a lot of incredible work on
machine learning so what role do you

478
00:10:23,660 --> 00:10:23,670
machine learning so what role do you
 

479
00:10:23,670 --> 00:10:25,550
machine learning so what role do you
think data and machine learning play in

480
00:10:25,550 --> 00:10:25,560
think data and machine learning play in
 

481
00:10:25,560 --> 00:10:28,070
think data and machine learning play in
this and his goal of trying to

482
00:10:28,070 --> 00:10:28,080
this and his goal of trying to
 

483
00:10:28,080 --> 00:10:29,990
this and his goal of trying to
understand diseases in trying to

484
00:10:29,990 --> 00:10:30,000
understand diseases in trying to
 

485
00:10:30,000 --> 00:10:33,950
understand diseases in trying to
eradicate diseases up until now I don't

486
00:10:33,950 --> 00:10:33,960
eradicate diseases up until now I don't
 

487
00:10:33,960 --> 00:10:36,050
eradicate diseases up until now I don't
think it's played very much of a

488
00:10:36,050 --> 00:10:36,060
think it's played very much of a
 

489
00:10:36,060 --> 00:10:40,190
think it's played very much of a
significant role because largely the

490
00:10:40,190 --> 00:10:40,200
significant role because largely the
 

491
00:10:40,200 --> 00:10:42,700
significant role because largely the
data sets that one really needed to

492
00:10:42,700 --> 00:10:42,710
data sets that one really needed to
 

493
00:10:42,710 --> 00:10:46,250
data sets that one really needed to
enable a powerful machine learning

494
00:10:46,250 --> 00:10:46,260
enable a powerful machine learning
 

495
00:10:46,260 --> 00:10:48,440
enable a powerful machine learning
methods those data sets haven't really

496
00:10:48,440 --> 00:10:48,450
methods those data sets haven't really
 

497
00:10:48,450 --> 00:10:51,080
methods those data sets haven't really
existed there's been dribs and drabs and

498
00:10:51,080 --> 00:10:51,090
existed there's been dribs and drabs and
 

499
00:10:51,090 --> 00:10:53,270
existed there's been dribs and drabs and
some interesting machine learning that

500
00:10:53,270 --> 00:10:53,280
some interesting machine learning that
 

501
00:10:53,280 --> 00:10:55,400
some interesting machine learning that
has been applied I would say machine

502
00:10:55,400 --> 00:10:55,410
has been applied I would say machine
 

503
00:10:55,410 --> 00:10:58,610
has been applied I would say machine
learning / data science but the last few

504
00:10:58,610 --> 00:10:58,620
learning / data science but the last few
 

505
00:10:58,620 --> 00:11:00,380
learning / data science but the last few
years are starting to change thoughts so

506
00:11:00,380 --> 00:11:00,390
years are starting to change thoughts so
 

507
00:11:00,390 --> 00:11:05,330
years are starting to change thoughts so
we now see an increase in some large

508
00:11:05,330 --> 00:11:05,340
we now see an increase in some large
 

509
00:11:05,340 --> 00:11:06,079
we now see an increase in some large
data set

510
00:11:06,079 --> 00:11:06,089
data set
 

511
00:11:06,089 --> 00:11:09,970
data set
but equally importantly an increase in

512
00:11:09,970 --> 00:11:09,980
but equally importantly an increase in
 

513
00:11:09,980 --> 00:11:12,470
but equally importantly an increase in
technologies that are able to produce

514
00:11:12,470 --> 00:11:12,480
technologies that are able to produce
 

515
00:11:12,480 --> 00:11:15,829
technologies that are able to produce
data at scale it's not typically the

516
00:11:15,829 --> 00:11:15,839
data at scale it's not typically the
 

517
00:11:15,839 --> 00:11:19,100
data at scale it's not typically the
case that people have deliberately

518
00:11:19,100 --> 00:11:19,110
case that people have deliberately
 

519
00:11:19,110 --> 00:11:22,009
case that people have deliberately
proactively used those tools for the

520
00:11:22,009 --> 00:11:22,019
proactively used those tools for the
 

521
00:11:22,019 --> 00:11:23,780
proactively used those tools for the
purpose of generating data for machine

522
00:11:23,780 --> 00:11:23,790
purpose of generating data for machine
 

523
00:11:23,790 --> 00:11:25,850
purpose of generating data for machine
learning they to the extent that those

524
00:11:25,850 --> 00:11:25,860
learning they to the extent that those
 

525
00:11:25,860 --> 00:11:27,350
learning they to the extent that those
techniques have been used for data

526
00:11:27,350 --> 00:11:27,360
techniques have been used for data
 

527
00:11:27,360 --> 00:11:29,329
techniques have been used for data
production they've been used for data

528
00:11:29,329 --> 00:11:29,339
production they've been used for data
 

529
00:11:29,339 --> 00:11:31,189
production they've been used for data
production to drive scientific discovery

530
00:11:31,189 --> 00:11:31,199
production to drive scientific discovery
 

531
00:11:31,199 --> 00:11:33,590
production to drive scientific discovery
and the machine learning came as a sort

532
00:11:33,590 --> 00:11:33,600
and the machine learning came as a sort
 

533
00:11:33,600 --> 00:11:35,569
and the machine learning came as a sort
of by-product second stage of oh you

534
00:11:35,569 --> 00:11:35,579
of by-product second stage of oh you
 

535
00:11:35,579 --> 00:11:37,369
of by-product second stage of oh you
know now we have a data set let's do

536
00:11:37,369 --> 00:11:37,379
know now we have a data set let's do
 

537
00:11:37,379 --> 00:11:38,720
know now we have a data set let's do
machine learning on that rather than a

538
00:11:38,720 --> 00:11:38,730
machine learning on that rather than a
 

539
00:11:38,730 --> 00:11:42,019
machine learning on that rather than a
more simplistic data analysis method but

540
00:11:42,019 --> 00:11:42,029
more simplistic data analysis method but
 

541
00:11:42,029 --> 00:11:44,449
more simplistic data analysis method but
what we are doing it in seat rows

542
00:11:44,449 --> 00:11:44,459
what we are doing it in seat rows
 

543
00:11:44,459 --> 00:11:46,460
what we are doing it in seat rows
actually flipping that around and saying

544
00:11:46,460 --> 00:11:46,470
actually flipping that around and saying
 

545
00:11:46,470 --> 00:11:49,429
actually flipping that around and saying
here's this incredible repertoire of

546
00:11:49,429 --> 00:11:49,439
here's this incredible repertoire of
 

547
00:11:49,439 --> 00:11:52,189
here's this incredible repertoire of
methods that bile engineers cell

548
00:11:52,189 --> 00:11:52,199
methods that bile engineers cell
 

549
00:11:52,199 --> 00:11:55,069
methods that bile engineers cell
biologists have come up with let's see

550
00:11:55,069 --> 00:11:55,079
biologists have come up with let's see
 

551
00:11:55,079 --> 00:11:56,840
biologists have come up with let's see
if we can put them together in brand-new

552
00:11:56,840 --> 00:11:56,850
if we can put them together in brand-new
 

553
00:11:56,850 --> 00:12:00,139
if we can put them together in brand-new
ways with the goal of creating data sets

554
00:12:00,139 --> 00:12:00,149
ways with the goal of creating data sets
 

555
00:12:00,149 --> 00:12:01,639
ways with the goal of creating data sets
that machine learning can really be

556
00:12:01,639 --> 00:12:01,649
that machine learning can really be
 

557
00:12:01,649 --> 00:12:04,329
that machine learning can really be
applied on productively to create

558
00:12:04,329 --> 00:12:04,339
applied on productively to create
 

559
00:12:04,339 --> 00:12:07,040
applied on productively to create
powerful predictive models that can help

560
00:12:07,040 --> 00:12:07,050
powerful predictive models that can help
 

561
00:12:07,050 --> 00:12:08,720
powerful predictive models that can help
us address fundamental problems in human

562
00:12:08,720 --> 00:12:08,730
us address fundamental problems in human
 

563
00:12:08,730 --> 00:12:12,739
us address fundamental problems in human
health so really focus to get make data

564
00:12:12,739 --> 00:12:12,749
health so really focus to get make data
 

565
00:12:12,749 --> 00:12:15,079
health so really focus to get make data
the the primary focus and the primary

566
00:12:15,079 --> 00:12:15,089
the the primary focus and the primary
 

567
00:12:15,089 --> 00:12:17,449
the the primary focus and the primary
goal and find use the mechanisms of

568
00:12:17,449 --> 00:12:17,459
goal and find use the mechanisms of
 

569
00:12:17,459 --> 00:12:22,429
goal and find use the mechanisms of
biology and chemistry to to uh to create

570
00:12:22,429 --> 00:12:22,439
biology and chemistry to to uh to create
 

571
00:12:22,439 --> 00:12:24,290
biology and chemistry to to uh to create
the kinds of data set that could allow a

572
00:12:24,290 --> 00:12:24,300
the kinds of data set that could allow a
 

573
00:12:24,300 --> 00:12:25,699
the kinds of data set that could allow a
machine learning to benefit the most I

574
00:12:25,699 --> 00:12:25,709
machine learning to benefit the most I
 

575
00:12:25,709 --> 00:12:27,860
machine learning to benefit the most I
wouldn't put it in those terms because

576
00:12:27,860 --> 00:12:27,870
wouldn't put it in those terms because
 

577
00:12:27,870 --> 00:12:30,230
wouldn't put it in those terms because
that says the data is the end goal

578
00:12:30,230 --> 00:12:30,240
that says the data is the end goal
 

579
00:12:30,240 --> 00:12:33,650
that says the data is the end goal
data's the means so for us the end goal

580
00:12:33,650 --> 00:12:33,660
data's the means so for us the end goal
 

581
00:12:33,660 --> 00:12:36,139
data's the means so for us the end goal
is helping address challenges in human

582
00:12:36,139 --> 00:12:36,149
is helping address challenges in human
 

583
00:12:36,149 --> 00:12:39,169
is helping address challenges in human
health and the method that we've elected

584
00:12:39,169 --> 00:12:39,179
health and the method that we've elected
 

585
00:12:39,179 --> 00:12:42,169
health and the method that we've elected
to do that is to apply machine learning

586
00:12:42,169 --> 00:12:42,179
to do that is to apply machine learning
 

587
00:12:42,179 --> 00:12:44,569
to do that is to apply machine learning
to build predictive models and machine

588
00:12:44,569 --> 00:12:44,579
to build predictive models and machine
 

589
00:12:44,579 --> 00:12:46,610
to build predictive models and machine
learning in my opinion can only be

590
00:12:46,610 --> 00:12:46,620
learning in my opinion can only be
 

591
00:12:46,620 --> 00:12:49,340
learning in my opinion can only be
really successfully applied especially

592
00:12:49,340 --> 00:12:49,350
really successfully applied especially
 

593
00:12:49,350 --> 00:12:51,499
really successfully applied especially
the more powerful models if you give it

594
00:12:51,499 --> 00:12:51,509
the more powerful models if you give it
 

595
00:12:51,509 --> 00:12:53,600
the more powerful models if you give it
data that is of sufficient scale and

596
00:12:53,600 --> 00:12:53,610
data that is of sufficient scale and
 

597
00:12:53,610 --> 00:12:57,049
data that is of sufficient scale and
sufficient quality so how do you create

598
00:12:57,049 --> 00:12:57,059
sufficient quality so how do you create
 

599
00:12:57,059 --> 00:13:01,150
sufficient quality so how do you create
those data sets so as to drive the

600
00:13:01,150 --> 00:13:01,160
those data sets so as to drive the
 

601
00:13:01,160 --> 00:13:03,650
those data sets so as to drive the
ability to generate predictive models

602
00:13:03,650 --> 00:13:03,660
ability to generate predictive models
 

603
00:13:03,660 --> 00:13:05,179
ability to generate predictive models
which subsequently help improve human

604
00:13:05,179 --> 00:13:05,189
which subsequently help improve human
 

605
00:13:05,189 --> 00:13:06,739
which subsequently help improve human
health so before we dive into the

606
00:13:06,739 --> 00:13:06,749
health so before we dive into the
 

607
00:13:06,749 --> 00:13:09,410
health so before we dive into the
details of that even take a step back

608
00:13:09,410 --> 00:13:09,420
details of that even take a step back
 

609
00:13:09,420 --> 00:13:14,869
details of that even take a step back
and ask when and where was your interest

610
00:13:14,869 --> 00:13:14,879
and ask when and where was your interest
 

611
00:13:14,879 --> 00:13:17,509
and ask when and where was your interest
in human health born are there moments

612
00:13:17,509 --> 00:13:17,519
in human health born are there moments
 

613
00:13:17,519 --> 00:13:18,750
in human health born are there moments
events perhaps

614
00:13:18,750 --> 00:13:18,760
events perhaps
 

615
00:13:18,760 --> 00:13:21,360
events perhaps
if I may ask tragedies in your own life

616
00:13:21,360 --> 00:13:21,370
if I may ask tragedies in your own life
 

617
00:13:21,370 --> 00:13:23,550
if I may ask tragedies in your own life
that catalyzes passion or was at the

618
00:13:23,550 --> 00:13:23,560
that catalyzes passion or was at the
 

619
00:13:23,560 --> 00:13:27,000
that catalyzes passion or was at the
broader desire to help humankind so I

620
00:13:27,000 --> 00:13:27,010
broader desire to help humankind so I
 

621
00:13:27,010 --> 00:13:30,660
broader desire to help humankind so I
would say it's a bit of both so on I

622
00:13:30,660 --> 00:13:30,670
would say it's a bit of both so on I
 

623
00:13:30,670 --> 00:13:32,430
would say it's a bit of both so on I
mean my interest in human health

624
00:13:32,430 --> 00:13:32,440
mean my interest in human health
 

625
00:13:32,440 --> 00:13:37,170
mean my interest in human health
actually dates back to the early 2000s

626
00:13:37,170 --> 00:13:37,180
actually dates back to the early 2000s
 

627
00:13:37,180 --> 00:13:43,530
actually dates back to the early 2000s
when when a lot of my peers and machine

628
00:13:43,530 --> 00:13:43,540
when when a lot of my peers and machine
 

629
00:13:43,540 --> 00:13:45,600
when when a lot of my peers and machine
learning and I were using datasets that

630
00:13:45,600 --> 00:13:45,610
learning and I were using datasets that
 

631
00:13:45,610 --> 00:13:47,790
learning and I were using datasets that
frankly we're not very inspiring some of

632
00:13:47,790 --> 00:13:47,800
frankly we're not very inspiring some of
 

633
00:13:47,800 --> 00:13:49,950
frankly we're not very inspiring some of
us old-timers still remember the

634
00:13:49,950 --> 00:13:49,960
us old-timers still remember the
 

635
00:13:49,960 --> 00:13:52,140
us old-timers still remember the
quote-unquote twenty newsgroups dataset

636
00:13:52,140 --> 00:13:52,150
quote-unquote twenty newsgroups dataset
 

637
00:13:52,150 --> 00:13:55,710
quote-unquote twenty newsgroups dataset
where it was literally a bunch of text

638
00:13:55,710 --> 00:13:55,720
where it was literally a bunch of text
 

639
00:13:55,720 --> 00:13:57,540
where it was literally a bunch of text
from twenty newsgroups a concept that

640
00:13:57,540 --> 00:13:57,550
from twenty newsgroups a concept that
 

641
00:13:57,550 --> 00:13:59,220
from twenty newsgroups a concept that
doesn't really even exist anymore and

642
00:13:59,220 --> 00:13:59,230
doesn't really even exist anymore and
 

643
00:13:59,230 --> 00:14:02,420
doesn't really even exist anymore and
the question was can you classify which

644
00:14:02,420 --> 00:14:02,430
the question was can you classify which
 

645
00:14:02,430 --> 00:14:05,610
the question was can you classify which
which news group a particular bag of

646
00:14:05,610 --> 00:14:05,620
which news group a particular bag of
 

647
00:14:05,620 --> 00:14:07,590
which news group a particular bag of
words came from and it wasn't very

648
00:14:07,590 --> 00:14:07,600
words came from and it wasn't very
 

649
00:14:07,600 --> 00:14:10,980
words came from and it wasn't very
interesting the datasets at the time on

650
00:14:10,980 --> 00:14:10,990
interesting the datasets at the time on
 

651
00:14:10,990 --> 00:14:13,200
interesting the datasets at the time on
the biology side were much more

652
00:14:13,200 --> 00:14:13,210
the biology side were much more
 

653
00:14:13,210 --> 00:14:15,030
the biology side were much more
interesting both from a technical and

654
00:14:15,030 --> 00:14:15,040
interesting both from a technical and
 

655
00:14:15,040 --> 00:14:17,010
interesting both from a technical and
also from an aspirational perspective

656
00:14:17,010 --> 00:14:17,020
also from an aspirational perspective
 

657
00:14:17,020 --> 00:14:19,200
also from an aspirational perspective
they were still pretty small but they

658
00:14:19,200 --> 00:14:19,210
they were still pretty small but they
 

659
00:14:19,210 --> 00:14:22,350
they were still pretty small but they
were better than 20 news groups and so I

660
00:14:22,350 --> 00:14:22,360
were better than 20 news groups and so I
 

661
00:14:22,360 --> 00:14:25,260
were better than 20 news groups and so I
started out I think just by just by

662
00:14:25,260 --> 00:14:25,270
started out I think just by just by
 

663
00:14:25,270 --> 00:14:26,910
started out I think just by just by
wanting to do something that was more I

664
00:14:26,910 --> 00:14:26,920
wanting to do something that was more I
 

665
00:14:26,920 --> 00:14:29,280
wanting to do something that was more I
don't know societally useful and

666
00:14:29,280 --> 00:14:29,290
don't know societally useful and
 

667
00:14:29,290 --> 00:14:31,740
don't know societally useful and
technically interesting and then over

668
00:14:31,740 --> 00:14:31,750
technically interesting and then over
 

669
00:14:31,750 --> 00:14:34,610
technically interesting and then over
time became more and more interested in

670
00:14:34,610 --> 00:14:34,620
time became more and more interested in
 

671
00:14:34,620 --> 00:14:38,220
time became more and more interested in
the biology in the and the human health

672
00:14:38,220 --> 00:14:38,230
the biology in the and the human health
 

673
00:14:38,230 --> 00:14:41,940
the biology in the and the human health
aspects for themselves and began to work

674
00:14:41,940 --> 00:14:41,950
aspects for themselves and began to work
 

675
00:14:41,950 --> 00:14:44,130
aspects for themselves and began to work
even sometimes on papers that were just

676
00:14:44,130 --> 00:14:44,140
even sometimes on papers that were just
 

677
00:14:44,140 --> 00:14:46,410
even sometimes on papers that were just
in biology without having a significant

678
00:14:46,410 --> 00:14:46,420
in biology without having a significant
 

679
00:14:46,420 --> 00:14:49,140
in biology without having a significant
machine learning component I think my

680
00:14:49,140 --> 00:14:49,150
machine learning component I think my
 

681
00:14:49,150 --> 00:14:54,420
machine learning component I think my
interest in drug discovery is partly due

682
00:14:54,420 --> 00:14:54,430
interest in drug discovery is partly due
 

683
00:14:54,430 --> 00:14:59,130
interest in drug discovery is partly due
to an incident I had with when my father

684
00:14:59,130 --> 00:14:59,140
to an incident I had with when my father
 

685
00:14:59,140 --> 00:15:02,700
to an incident I had with when my father
sadly passed away about 12 years ago he

686
00:15:02,700 --> 00:15:02,710
sadly passed away about 12 years ago he
 

687
00:15:02,710 --> 00:15:05,850
sadly passed away about 12 years ago he
had an autoimmune disease that settled

688
00:15:05,850 --> 00:15:05,860
had an autoimmune disease that settled
 

689
00:15:05,860 --> 00:15:11,400
had an autoimmune disease that settled
in his lungs and the doctors basis it

690
00:15:11,400 --> 00:15:11,410
in his lungs and the doctors basis it
 

691
00:15:11,410 --> 00:15:13,170
in his lungs and the doctors basis it
well there was only one thing we could

692
00:15:13,170 --> 00:15:13,180
well there was only one thing we could
 

693
00:15:13,180 --> 00:15:15,270
well there was only one thing we could
do which is give him prednisone at some

694
00:15:15,270 --> 00:15:15,280
do which is give him prednisone at some
 

695
00:15:15,280 --> 00:15:17,130
do which is give him prednisone at some
point I remember doctor even came and

696
00:15:17,130 --> 00:15:17,140
point I remember doctor even came and
 

697
00:15:17,140 --> 00:15:19,170
point I remember doctor even came and
said hey let's do a lung biopsy to

698
00:15:19,170 --> 00:15:19,180
said hey let's do a lung biopsy to
 

699
00:15:19,180 --> 00:15:20,670
said hey let's do a lung biopsy to
figure out which autoimmune disease he

700
00:15:20,670 --> 00:15:20,680
figure out which autoimmune disease he
 

701
00:15:20,680 --> 00:15:22,920
figure out which autoimmune disease he
has and I said would that be helpful

702
00:15:22,920 --> 00:15:22,930
has and I said would that be helpful
 

703
00:15:22,930 --> 00:15:24,660
has and I said would that be helpful
would that change treatments no there's

704
00:15:24,660 --> 00:15:24,670
would that change treatments no there's
 

705
00:15:24,670 --> 00:15:26,040
would that change treatments no there's
only prednisone that's the only thing we

706
00:15:26,040 --> 00:15:26,050
only prednisone that's the only thing we
 

707
00:15:26,050 --> 00:15:28,470
only prednisone that's the only thing we
can give him and I have friends who were

708
00:15:28,470 --> 00:15:28,480
can give him and I have friends who were
 

709
00:15:28,480 --> 00:15:30,570
can give him and I have friends who were
rheumatologist who said the FDA would

710
00:15:30,570 --> 00:15:30,580
rheumatologist who said the FDA would
 

711
00:15:30,580 --> 00:15:31,890
rheumatologist who said the FDA would
never approve press his own today

712
00:15:31,890 --> 00:15:31,900
never approve press his own today
 

713
00:15:31,900 --> 00:15:32,650
never approve press his own today
because

714
00:15:32,650 --> 00:15:32,660
because
 

715
00:15:32,660 --> 00:15:37,329
because
the ratio of side effects to benefit is

716
00:15:37,329 --> 00:15:37,339
the ratio of side effects to benefit is
 

717
00:15:37,339 --> 00:15:40,960
the ratio of side effects to benefit is
probably not large enough today we're in

718
00:15:40,960 --> 00:15:40,970
probably not large enough today we're in
 

719
00:15:40,970 --> 00:15:44,379
probably not large enough today we're in
a state where there's probably four or

720
00:15:44,379 --> 00:15:44,389
a state where there's probably four or
 

721
00:15:44,389 --> 00:15:47,889
a state where there's probably four or
five maybe even more well depends for

722
00:15:47,889 --> 00:15:47,899
five maybe even more well depends for
 

723
00:15:47,899 --> 00:15:49,119
five maybe even more well depends for
which autoimmune disease but there are

724
00:15:49,119 --> 00:15:49,129
which autoimmune disease but there are
 

725
00:15:49,129 --> 00:15:53,019
which autoimmune disease but there are
multiple drugs that can help people with

726
00:15:53,019 --> 00:15:53,029
multiple drugs that can help people with
 

727
00:15:53,029 --> 00:15:54,579
multiple drugs that can help people with
autoimmune disease and many of which can

728
00:15:54,579 --> 00:15:54,589
autoimmune disease and many of which can
 

729
00:15:54,589 --> 00:15:57,819
autoimmune disease and many of which can
exist at 12 years ago and I think we're

730
00:15:57,819 --> 00:15:57,829
exist at 12 years ago and I think we're
 

731
00:15:57,829 --> 00:16:00,610
exist at 12 years ago and I think we're
at a golden time in some ways and drug

732
00:16:00,610 --> 00:16:00,620
at a golden time in some ways and drug
 

733
00:16:00,620 --> 00:16:03,670
at a golden time in some ways and drug
discovery where there's the ability to

734
00:16:03,670 --> 00:16:03,680
discovery where there's the ability to
 

735
00:16:03,680 --> 00:16:08,920
discovery where there's the ability to
create drugs that are much more safe for

736
00:16:08,920 --> 00:16:08,930
create drugs that are much more safe for
 

737
00:16:08,930 --> 00:16:11,619
create drugs that are much more safe for
much more effective than we've ever been

738
00:16:11,619 --> 00:16:11,629
much more effective than we've ever been
 

739
00:16:11,629 --> 00:16:14,230
much more effective than we've ever been
able to before and what's lacking is

740
00:16:14,230 --> 00:16:14,240
able to before and what's lacking is
 

741
00:16:14,240 --> 00:16:17,619
able to before and what's lacking is
enough understanding of biology and

742
00:16:17,619 --> 00:16:17,629
enough understanding of biology and
 

743
00:16:17,629 --> 00:16:20,340
enough understanding of biology and
mechanism to know where to aim that

744
00:16:20,340 --> 00:16:20,350
mechanism to know where to aim that
 

745
00:16:20,350 --> 00:16:22,809
mechanism to know where to aim that
weird ain't that engine and I think

746
00:16:22,809 --> 00:16:22,819
weird ain't that engine and I think
 

747
00:16:22,819 --> 00:16:24,569
weird ain't that engine and I think
that's where machine learning can help

748
00:16:24,569 --> 00:16:24,579
that's where machine learning can help
 

749
00:16:24,579 --> 00:16:28,030
that's where machine learning can help
so in 2018 he started and now lead a

750
00:16:28,030 --> 00:16:28,040
so in 2018 he started and now lead a
 

751
00:16:28,040 --> 00:16:30,879
so in 2018 he started and now lead a
company in seat row which is a like you

752
00:16:30,879 --> 00:16:30,889
company in seat row which is a like you
 

753
00:16:30,889 --> 00:16:33,850
company in seat row which is a like you
mentioned perhaps the focus is drug

754
00:16:33,850 --> 00:16:33,860
mentioned perhaps the focus is drug
 

755
00:16:33,860 --> 00:16:36,069
mentioned perhaps the focus is drug
discovery and the utilization of machine

756
00:16:36,069 --> 00:16:36,079
discovery and the utilization of machine
 

757
00:16:36,079 --> 00:16:38,410
discovery and the utilization of machine
learning for drug discovery so you

758
00:16:38,410 --> 00:16:38,420
learning for drug discovery so you
 

759
00:16:38,420 --> 00:16:40,990
learning for drug discovery so you
mentioned that quote we're really

760
00:16:40,990 --> 00:16:41,000
mentioned that quote we're really
 

761
00:16:41,000 --> 00:16:42,939
mentioned that quote we're really
interested in creating what you might

762
00:16:42,939 --> 00:16:42,949
interested in creating what you might
 

763
00:16:42,949 --> 00:16:45,939
interested in creating what you might
call a disease in a dish model disease

764
00:16:45,939 --> 00:16:45,949
call a disease in a dish model disease
 

765
00:16:45,949 --> 00:16:48,220
call a disease in a dish model disease
in a dish models places where disease is

766
00:16:48,220 --> 00:16:48,230
in a dish models places where disease is
 

767
00:16:48,230 --> 00:16:50,439
in a dish models places where disease is
a complex where we really haven't had a

768
00:16:50,439 --> 00:16:50,449
a complex where we really haven't had a
 

769
00:16:50,449 --> 00:16:53,110
a complex where we really haven't had a
good model system or typical animal

770
00:16:53,110 --> 00:16:53,120
good model system or typical animal
 

771
00:16:53,120 --> 00:16:54,420
good model system or typical animal
models that have been used for years

772
00:16:54,420 --> 00:16:54,430
models that have been used for years
 

773
00:16:54,430 --> 00:16:57,189
models that have been used for years
including testing on mice just aren't

774
00:16:57,189 --> 00:16:57,199
including testing on mice just aren't
 

775
00:16:57,199 --> 00:17:00,429
including testing on mice just aren't
very effective so can you can you try to

776
00:17:00,429 --> 00:17:00,439
very effective so can you can you try to
 

777
00:17:00,439 --> 00:17:02,679
very effective so can you can you try to
describe what is an animal model and

778
00:17:02,679 --> 00:17:02,689
describe what is an animal model and
 

779
00:17:02,689 --> 00:17:04,899
describe what is an animal model and
what what is a disease in a dish model

780
00:17:04,899 --> 00:17:04,909
what what is a disease in a dish model
 

781
00:17:04,909 --> 00:17:09,340
what what is a disease in a dish model
sure so an animal models for disease is

782
00:17:09,340 --> 00:17:09,350
sure so an animal models for disease is
 

783
00:17:09,350 --> 00:17:14,409
sure so an animal models for disease is
where you create effectively its what it

784
00:17:14,409 --> 00:17:14,419
where you create effectively its what it
 

785
00:17:14,419 --> 00:17:16,449
where you create effectively its what it
sounds like it's it's a oftentimes a

786
00:17:16,449 --> 00:17:16,459
sounds like it's it's a oftentimes a
 

787
00:17:16,459 --> 00:17:19,329
sounds like it's it's a oftentimes a
mouse where we have introduced some

788
00:17:19,329 --> 00:17:19,339
mouse where we have introduced some
 

789
00:17:19,339 --> 00:17:21,819
mouse where we have introduced some
external perturbation that creates the

790
00:17:21,819 --> 00:17:21,829
external perturbation that creates the
 

791
00:17:21,829 --> 00:17:25,649
external perturbation that creates the
disease and then we cure that disease

792
00:17:25,649 --> 00:17:25,659
disease and then we cure that disease
 

793
00:17:25,659 --> 00:17:28,840
disease and then we cure that disease
and the hope is that by doing that we

794
00:17:28,840 --> 00:17:28,850
and the hope is that by doing that we
 

795
00:17:28,850 --> 00:17:31,450
and the hope is that by doing that we
will cure a similar disease in human the

796
00:17:31,450 --> 00:17:31,460
will cure a similar disease in human the
 

797
00:17:31,460 --> 00:17:33,820
will cure a similar disease in human the
problem is is that oftentimes the way in

798
00:17:33,820 --> 00:17:33,830
problem is is that oftentimes the way in
 

799
00:17:33,830 --> 00:17:36,430
problem is is that oftentimes the way in
which we generate the disease and the

800
00:17:36,430 --> 00:17:36,440
which we generate the disease and the
 

801
00:17:36,440 --> 00:17:38,080
which we generate the disease and the
animal has nothing to do with how that

802
00:17:38,080 --> 00:17:38,090
animal has nothing to do with how that
 

803
00:17:38,090 --> 00:17:40,020
animal has nothing to do with how that
disease actually comes about in a human

804
00:17:40,020 --> 00:17:40,030
disease actually comes about in a human
 

805
00:17:40,030 --> 00:17:42,549
disease actually comes about in a human
it's what you might think of as a copy

806
00:17:42,549 --> 00:17:42,559
it's what you might think of as a copy
 

807
00:17:42,559 --> 00:17:43,799
it's what you might think of as a copy
of the of

808
00:17:43,799 --> 00:17:43,809
of the of
 

809
00:17:43,809 --> 00:17:45,919
of the of
phenotype a copy of the clinical outcome

810
00:17:45,919 --> 00:17:45,929
phenotype a copy of the clinical outcome
 

811
00:17:45,929 --> 00:17:48,419
phenotype a copy of the clinical outcome
but the mechanisms are quite different

812
00:17:48,419 --> 00:17:48,429
but the mechanisms are quite different
 

813
00:17:48,429 --> 00:17:51,629
but the mechanisms are quite different
and so curing the disease in the animal

814
00:17:51,629 --> 00:17:51,639
and so curing the disease in the animal
 

815
00:17:51,639 --> 00:17:54,149
and so curing the disease in the animal
which in most cases doesn't happen

816
00:17:54,149 --> 00:17:54,159
which in most cases doesn't happen
 

817
00:17:54,159 --> 00:17:56,070
which in most cases doesn't happen
naturally mice don't get Alzheimer's

818
00:17:56,070 --> 00:17:56,080
naturally mice don't get Alzheimer's
 

819
00:17:56,080 --> 00:17:57,539
naturally mice don't get Alzheimer's
they don't get diabetes they don't get

820
00:17:57,539 --> 00:17:57,549
they don't get diabetes they don't get
 

821
00:17:57,549 --> 00:18:00,060
they don't get diabetes they don't get
atherosclerosis they don't get autism or

822
00:18:00,060 --> 00:18:00,070
atherosclerosis they don't get autism or
 

823
00:18:00,070 --> 00:18:04,320
atherosclerosis they don't get autism or
schizophrenia those cures don't

824
00:18:04,320 --> 00:18:04,330
schizophrenia those cures don't
 

825
00:18:04,330 --> 00:18:07,619
schizophrenia those cures don't
translate over to what happens in the

826
00:18:07,619 --> 00:18:07,629
translate over to what happens in the
 

827
00:18:07,629 --> 00:18:10,619
translate over to what happens in the
human and that's where most drugs fails

828
00:18:10,619 --> 00:18:10,629
human and that's where most drugs fails
 

829
00:18:10,629 --> 00:18:13,350
human and that's where most drugs fails
just because the findings that we had in

830
00:18:13,350 --> 00:18:13,360
just because the findings that we had in
 

831
00:18:13,360 --> 00:18:16,830
just because the findings that we had in
the mouse don't translate to a human the

832
00:18:16,830 --> 00:18:16,840
the mouse don't translate to a human the
 

833
00:18:16,840 --> 00:18:19,710
the mouse don't translate to a human the
disease in the dish bottles is a fairly

834
00:18:19,710 --> 00:18:19,720
disease in the dish bottles is a fairly
 

835
00:18:19,720 --> 00:18:22,759
disease in the dish bottles is a fairly
new approach it's been enabled by

836
00:18:22,759 --> 00:18:22,769
new approach it's been enabled by
 

837
00:18:22,769 --> 00:18:26,940
new approach it's been enabled by
technologies that have not existed for

838
00:18:26,940 --> 00:18:26,950
technologies that have not existed for
 

839
00:18:26,950 --> 00:18:28,830
technologies that have not existed for
more than five to ten years so for

840
00:18:28,830 --> 00:18:28,840
more than five to ten years so for
 

841
00:18:28,840 --> 00:18:32,399
more than five to ten years so for
instance the ability for us to take a

842
00:18:32,399 --> 00:18:32,409
instance the ability for us to take a
 

843
00:18:32,409 --> 00:18:35,940
instance the ability for us to take a
cell from any one of us you or me revert

844
00:18:35,940 --> 00:18:35,950
cell from any one of us you or me revert
 

845
00:18:35,950 --> 00:18:38,700
cell from any one of us you or me revert
thats a skin cell to what's called stem

846
00:18:38,700 --> 00:18:38,710
thats a skin cell to what's called stem
 

847
00:18:38,710 --> 00:18:42,840
thats a skin cell to what's called stem
cell status which is a what if it was

848
00:18:42,840 --> 00:18:42,850
cell status which is a what if it was
 

849
00:18:42,850 --> 00:18:45,299
cell status which is a what if it was
called a pluripotent cell that can then

850
00:18:45,299 --> 00:18:45,309
called a pluripotent cell that can then
 

851
00:18:45,309 --> 00:18:47,279
called a pluripotent cell that can then
be differentiated into different types

852
00:18:47,279 --> 00:18:47,289
be differentiated into different types
 

853
00:18:47,289 --> 00:18:49,289
be differentiated into different types
of cells so from that flurry potent cell

854
00:18:49,289 --> 00:18:49,299
of cells so from that flurry potent cell
 

855
00:18:49,299 --> 00:18:52,879
of cells so from that flurry potent cell
one can create a wax neuron or a lex

856
00:18:52,879 --> 00:18:52,889
one can create a wax neuron or a lex
 

857
00:18:52,889 --> 00:18:56,609
one can create a wax neuron or a lex
cardiomyocyte or alexa parasite that has

858
00:18:56,609 --> 00:18:56,619
cardiomyocyte or alexa parasite that has
 

859
00:18:56,619 --> 00:18:59,580
cardiomyocyte or alexa parasite that has
your genetics but that right our cell

860
00:18:59,580 --> 00:18:59,590
your genetics but that right our cell
 

861
00:18:59,590 --> 00:19:03,840
your genetics but that right our cell
type and so if there is a genetic burden

862
00:19:03,840 --> 00:19:03,850
type and so if there is a genetic burden
 

863
00:19:03,850 --> 00:19:06,119
type and so if there is a genetic burden
of disease that would manifest in that

864
00:19:06,119 --> 00:19:06,129
of disease that would manifest in that
 

865
00:19:06,129 --> 00:19:07,649
of disease that would manifest in that
particular cell type you might be able

866
00:19:07,649 --> 00:19:07,659
particular cell type you might be able
 

867
00:19:07,659 --> 00:19:09,899
particular cell type you might be able
to see it by looking at those cells and

868
00:19:09,899 --> 00:19:09,909
to see it by looking at those cells and
 

869
00:19:09,909 --> 00:19:12,960
to see it by looking at those cells and
saying oh that's what potentially sick

870
00:19:12,960 --> 00:19:12,970
saying oh that's what potentially sick
 

871
00:19:12,970 --> 00:19:16,159
saying oh that's what potentially sick
cells look like versus healthy cells and

872
00:19:16,159 --> 00:19:16,169
cells look like versus healthy cells and
 

873
00:19:16,169 --> 00:19:19,619
cells look like versus healthy cells and
understand how and then explore what

874
00:19:19,619 --> 00:19:19,629
understand how and then explore what
 

875
00:19:19,629 --> 00:19:22,139
understand how and then explore what
kind of interventions might revert the

876
00:19:22,139 --> 00:19:22,149
kind of interventions might revert the
 

877
00:19:22,149 --> 00:19:24,239
kind of interventions might revert the
unhealthy looking cell to a healthy cell

878
00:19:24,239 --> 00:19:24,249
unhealthy looking cell to a healthy cell
 

879
00:19:24,249 --> 00:19:27,480
unhealthy looking cell to a healthy cell
now of course curing cells is not the

880
00:19:27,480 --> 00:19:27,490
now of course curing cells is not the
 

881
00:19:27,490 --> 00:19:30,450
now of course curing cells is not the
same as curing people and so there's

882
00:19:30,450 --> 00:19:30,460
same as curing people and so there's
 

883
00:19:30,460 --> 00:19:32,600
same as curing people and so there's
still potentially translate ability gap

884
00:19:32,600 --> 00:19:32,610
still potentially translate ability gap
 

885
00:19:32,610 --> 00:19:37,470
still potentially translate ability gap
but at least for diseases that are

886
00:19:37,470 --> 00:19:37,480
but at least for diseases that are
 

887
00:19:37,480 --> 00:19:41,009
but at least for diseases that are
driven say by human genetics and where

888
00:19:41,009 --> 00:19:41,019
driven say by human genetics and where
 

889
00:19:41,019 --> 00:19:42,690
driven say by human genetics and where
the human genetics is what drives the

890
00:19:42,690 --> 00:19:42,700
the human genetics is what drives the
 

891
00:19:42,700 --> 00:19:45,060
the human genetics is what drives the
cellular phenotype there is some reason

892
00:19:45,060 --> 00:19:45,070
cellular phenotype there is some reason
 

893
00:19:45,070 --> 00:19:47,789
cellular phenotype there is some reason
to hope that if we revert those cells in

894
00:19:47,789 --> 00:19:47,799
to hope that if we revert those cells in
 

895
00:19:47,799 --> 00:19:50,220
to hope that if we revert those cells in
which the disease begins and where the

896
00:19:50,220 --> 00:19:50,230
which the disease begins and where the
 

897
00:19:50,230 --> 00:19:52,830
which the disease begins and where the
disease is driven by genetics and we can

898
00:19:52,830 --> 00:19:52,840
disease is driven by genetics and we can
 

899
00:19:52,840 --> 00:19:54,720
disease is driven by genetics and we can
revert that cell back to a healthy state

900
00:19:54,720 --> 00:19:54,730
revert that cell back to a healthy state
 

901
00:19:54,730 --> 00:19:57,660
revert that cell back to a healthy state
maybe that will help also

902
00:19:57,660 --> 00:19:57,670
maybe that will help also
 

903
00:19:57,670 --> 00:20:00,840
maybe that will help also
the more global clinical phenotypes

904
00:20:00,840 --> 00:20:00,850
the more global clinical phenotypes
 

905
00:20:00,850 --> 00:20:02,280
the more global clinical phenotypes
that's really what we're hoping to do

906
00:20:02,280 --> 00:20:02,290
that's really what we're hoping to do
 

907
00:20:02,290 --> 00:20:05,250
that's really what we're hoping to do
that step that backward step I was

908
00:20:05,250 --> 00:20:05,260
that step that backward step I was
 

909
00:20:05,260 --> 00:20:08,870
that step that backward step I was
reading about it the Yamanaka factor yes

910
00:20:08,870 --> 00:20:08,880
reading about it the Yamanaka factor yes
 

911
00:20:08,880 --> 00:20:11,400
reading about it the Yamanaka factor yes
so think that the reverse step back to

912
00:20:11,400 --> 00:20:11,410
so think that the reverse step back to
 

913
00:20:11,410 --> 00:20:13,860
so think that the reverse step back to
stem cells yes I think seems like magic

914
00:20:13,860 --> 00:20:13,870
stem cells yes I think seems like magic
 

915
00:20:13,870 --> 00:20:17,640
stem cells yes I think seems like magic
it is I'm honestly before that happened

916
00:20:17,640 --> 00:20:17,650
it is I'm honestly before that happened
 

917
00:20:17,650 --> 00:20:19,170
it is I'm honestly before that happened
I think very few people would have

918
00:20:19,170 --> 00:20:19,180
I think very few people would have
 

919
00:20:19,180 --> 00:20:21,780
I think very few people would have
predicted that to be possible it's

920
00:20:21,780 --> 00:20:21,790
predicted that to be possible it's
 

921
00:20:21,790 --> 00:20:24,210
predicted that to be possible it's
amazing can you maybe elaborate is it

922
00:20:24,210 --> 00:20:24,220
amazing can you maybe elaborate is it
 

923
00:20:24,220 --> 00:20:26,850
amazing can you maybe elaborate is it
actually possible like word like how

924
00:20:26,850 --> 00:20:26,860
actually possible like word like how
 

925
00:20:26,860 --> 00:20:29,430
actually possible like word like how
state so this result was maybe like I

926
00:20:29,430 --> 00:20:29,440
state so this result was maybe like I
 

927
00:20:29,440 --> 00:20:30,990
state so this result was maybe like I
don't know how many years ago maybe ten

928
00:20:30,990 --> 00:20:31,000
don't know how many years ago maybe ten
 

929
00:20:31,000 --> 00:20:32,610
don't know how many years ago maybe ten
years ago was first demonstrated

930
00:20:32,610 --> 00:20:32,620
years ago was first demonstrated
 

931
00:20:32,620 --> 00:20:33,480
years ago was first demonstrated
something like that

932
00:20:33,480 --> 00:20:33,490
something like that
 

933
00:20:33,490 --> 00:20:36,480
something like that
is this how hard is this like how noisy

934
00:20:36,480 --> 00:20:36,490
is this how hard is this like how noisy
 

935
00:20:36,490 --> 00:20:38,250
is this how hard is this like how noisy
is this backward step it seems quite

936
00:20:38,250 --> 00:20:38,260
is this backward step it seems quite
 

937
00:20:38,260 --> 00:20:40,740
is this backward step it seems quite
incredible and cool it is it is

938
00:20:40,740 --> 00:20:40,750
incredible and cool it is it is
 

939
00:20:40,750 --> 00:20:44,580
incredible and cool it is it is
incredible and cool it was much more I

940
00:20:44,580 --> 00:20:44,590
incredible and cool it was much more I
 

941
00:20:44,590 --> 00:20:47,670
incredible and cool it was much more I
think finicky and bespoke at the early

942
00:20:47,670 --> 00:20:47,680
think finicky and bespoke at the early
 

943
00:20:47,680 --> 00:20:49,770
think finicky and bespoke at the early
stages when the discovery was first made

944
00:20:49,770 --> 00:20:49,780
stages when the discovery was first made
 

945
00:20:49,780 --> 00:20:53,340
stages when the discovery was first made
but at this point it's become almost

946
00:20:53,340 --> 00:20:53,350
but at this point it's become almost
 

947
00:20:53,350 --> 00:20:57,300
but at this point it's become almost
industrialized there are what's called

948
00:20:57,300 --> 00:20:57,310
industrialized there are what's called
 

949
00:20:57,310 --> 00:20:59,850
industrialized there are what's called
contract research organizations vendors

950
00:20:59,850 --> 00:20:59,860
contract research organizations vendors
 

951
00:20:59,860 --> 00:21:02,400
contract research organizations vendors
that will take a sample from a human and

952
00:21:02,400 --> 00:21:02,410
that will take a sample from a human and
 

953
00:21:02,410 --> 00:21:04,620
that will take a sample from a human and
reverted back to stem cell status and it

954
00:21:04,620 --> 00:21:04,630
reverted back to stem cell status and it
 

955
00:21:04,630 --> 00:21:06,390
reverted back to stem cell status and it
works a very good fraction of the time

956
00:21:06,390 --> 00:21:06,400
works a very good fraction of the time
 

957
00:21:06,400 --> 00:21:09,870
works a very good fraction of the time
now there are people who will ask I

958
00:21:09,870 --> 00:21:09,880
now there are people who will ask I
 

959
00:21:09,880 --> 00:21:12,810
now there are people who will ask I
think good questions is this really

960
00:21:12,810 --> 00:21:12,820
think good questions is this really
 

961
00:21:12,820 --> 00:21:14,750
think good questions is this really
truly a stem cell er doesn't remember

962
00:21:14,750 --> 00:21:14,760
truly a stem cell er doesn't remember
 

963
00:21:14,760 --> 00:21:18,630
truly a stem cell er doesn't remember
certain aspects of what of changes that

964
00:21:18,630 --> 00:21:18,640
certain aspects of what of changes that
 

965
00:21:18,640 --> 00:21:21,840
certain aspects of what of changes that
were made in the human beyond the

966
00:21:21,840 --> 00:21:21,850
were made in the human beyond the
 

967
00:21:21,850 --> 00:21:24,090
were made in the human beyond the
genetics it's fast as a skin cell yeah

968
00:21:24,090 --> 00:21:24,100
genetics it's fast as a skin cell yeah
 

969
00:21:24,100 --> 00:21:26,820
genetics it's fast as a skin cell yeah
it's fast as a skin cell or its past in

970
00:21:26,820 --> 00:21:26,830
it's fast as a skin cell or its past in
 

971
00:21:26,830 --> 00:21:28,230
it's fast as a skin cell or its past in
terms of exposures to different

972
00:21:28,230 --> 00:21:28,240
terms of exposures to different
 

973
00:21:28,240 --> 00:21:31,110
terms of exposures to different
environmental factors and so on so I

974
00:21:31,110 --> 00:21:31,120
environmental factors and so on so I
 

975
00:21:31,120 --> 00:21:33,540
environmental factors and so on so I
think the consensus right now is that

976
00:21:33,540 --> 00:21:33,550
think the consensus right now is that
 

977
00:21:33,550 --> 00:21:36,630
think the consensus right now is that
these are not always perfect and there

978
00:21:36,630 --> 00:21:36,640
these are not always perfect and there
 

979
00:21:36,640 --> 00:21:38,790
these are not always perfect and there
is a little bits and pieces of memory

980
00:21:38,790 --> 00:21:38,800
is a little bits and pieces of memory
 

981
00:21:38,800 --> 00:21:41,670
is a little bits and pieces of memory
sometimes but by and large these are

982
00:21:41,670 --> 00:21:41,680
sometimes but by and large these are
 

983
00:21:41,680 --> 00:21:46,680
sometimes but by and large these are
actually pretty good so one of the key

984
00:21:46,680 --> 00:21:46,690
actually pretty good so one of the key
 

985
00:21:46,690 --> 00:21:48,540
actually pretty good so one of the key
things well maybe maybe you can correct

986
00:21:48,540 --> 00:21:48,550
things well maybe maybe you can correct
 

987
00:21:48,550 --> 00:21:50,130
things well maybe maybe you can correct
me but one of the useful things for

988
00:21:50,130 --> 00:21:50,140
me but one of the useful things for
 

989
00:21:50,140 --> 00:21:53,460
me but one of the useful things for
machine learning is size scale of data

990
00:21:53,460 --> 00:21:53,470
machine learning is size scale of data
 

991
00:21:53,470 --> 00:21:57,120
machine learning is size scale of data
how easy it is to do these kinds of

992
00:21:57,120 --> 00:21:57,130
how easy it is to do these kinds of
 

993
00:21:57,130 --> 00:22:00,360
how easy it is to do these kinds of
reversals to stem cells and then disease

994
00:22:00,360 --> 00:22:00,370
reversals to stem cells and then disease
 

995
00:22:00,370 --> 00:22:03,150
reversals to stem cells and then disease
in a dish models at scale is this that a

996
00:22:03,150 --> 00:22:03,160
in a dish models at scale is this that a
 

997
00:22:03,160 --> 00:22:07,530
in a dish models at scale is this that a
huge challenge or or not so the reverse

998
00:22:07,530 --> 00:22:07,540
huge challenge or or not so the reverse
 

999
00:22:07,540 --> 00:22:11,640
huge challenge or or not so the reverse
the reversal is not as of this point

1000
00:22:11,640 --> 00:22:11,650
the reversal is not as of this point
 

1001
00:22:11,650 --> 00:22:13,800
the reversal is not as of this point
something that can be done at the scale

1002
00:22:13,800 --> 00:22:13,810
something that can be done at the scale
 

1003
00:22:13,810 --> 00:22:17,010
something that can be done at the scale
of tens of thousands or hundreds of

1004
00:22:17,010 --> 00:22:17,020
of tens of thousands or hundreds of
 

1005
00:22:17,020 --> 00:22:20,430
of tens of thousands or hundreds of
thousands I think total number of stem

1006
00:22:20,430 --> 00:22:20,440
thousands I think total number of stem
 

1007
00:22:20,440 --> 00:22:23,100
thousands I think total number of stem
cells or iPS cells that are what's

1008
00:22:23,100 --> 00:22:23,110
cells or iPS cells that are what's
 

1009
00:22:23,110 --> 00:22:24,990
cells or iPS cells that are what's
called induced pluripotent stem cells in

1010
00:22:24,990 --> 00:22:25,000
called induced pluripotent stem cells in
 

1011
00:22:25,000 --> 00:22:27,740
called induced pluripotent stem cells in
the world I think is somewhere between

1012
00:22:27,740 --> 00:22:27,750
the world I think is somewhere between
 

1013
00:22:27,750 --> 00:22:31,530
the world I think is somewhere between
five and ten thousand last I looked now

1014
00:22:31,530 --> 00:22:31,540
five and ten thousand last I looked now
 

1015
00:22:31,540 --> 00:22:33,870
five and ten thousand last I looked now
again that might not count things that

1016
00:22:33,870 --> 00:22:33,880
again that might not count things that
 

1017
00:22:33,880 --> 00:22:36,120
again that might not count things that
exist in this or that academic center

1018
00:22:36,120 --> 00:22:36,130
exist in this or that academic center
 

1019
00:22:36,130 --> 00:22:38,040
exist in this or that academic center
and they may add up to a bit more but

1020
00:22:38,040 --> 00:22:38,050
and they may add up to a bit more but
 

1021
00:22:38,050 --> 00:22:40,560
and they may add up to a bit more but
that's about the range so it's not

1022
00:22:40,560 --> 00:22:40,570
that's about the range so it's not
 

1023
00:22:40,570 --> 00:22:41,820
that's about the range so it's not
something that you could this point

1024
00:22:41,820 --> 00:22:41,830
something that you could this point
 

1025
00:22:41,830 --> 00:22:44,880
something that you could this point
generate IPS cells from a million people

1026
00:22:44,880 --> 00:22:44,890
generate IPS cells from a million people
 

1027
00:22:44,890 --> 00:22:48,270
generate IPS cells from a million people
but maybe you don't need to because

1028
00:22:48,270 --> 00:22:48,280
but maybe you don't need to because
 

1029
00:22:48,280 --> 00:22:52,080
but maybe you don't need to because
maybe that background is enough because

1030
00:22:52,080 --> 00:22:52,090
maybe that background is enough because
 

1031
00:22:52,090 --> 00:22:55,260
maybe that background is enough because
it can also be now perturbed in

1032
00:22:55,260 --> 00:22:55,270
it can also be now perturbed in
 

1033
00:22:55,270 --> 00:22:57,180
it can also be now perturbed in
different ways and some people have done

1034
00:22:57,180 --> 00:22:57,190
different ways and some people have done
 

1035
00:22:57,190 --> 00:23:01,470
different ways and some people have done
really interesting experiments in for

1036
00:23:01,470 --> 00:23:01,480
really interesting experiments in for
 

1037
00:23:01,480 --> 00:23:05,220
really interesting experiments in for
instance taking cells from a healthy

1038
00:23:05,220 --> 00:23:05,230
instance taking cells from a healthy
 

1039
00:23:05,230 --> 00:23:07,860
instance taking cells from a healthy
human and then introducing a mutation

1040
00:23:07,860 --> 00:23:07,870
human and then introducing a mutation
 

1041
00:23:07,870 --> 00:23:10,200
human and then introducing a mutation
into it using some of the using one of

1042
00:23:10,200 --> 00:23:10,210
into it using some of the using one of
 

1043
00:23:10,210 --> 00:23:12,030
into it using some of the using one of
the other miracle technologies that's

1044
00:23:12,030 --> 00:23:12,040
the other miracle technologies that's
 

1045
00:23:12,040 --> 00:23:14,880
the other miracle technologies that's
emerged last decade which is CRISPR gene

1046
00:23:14,880 --> 00:23:14,890
emerged last decade which is CRISPR gene
 

1047
00:23:14,890 --> 00:23:18,390
emerged last decade which is CRISPR gene
editing and introduced mutation that is

1048
00:23:18,390 --> 00:23:18,400
editing and introduced mutation that is
 

1049
00:23:18,400 --> 00:23:20,220
editing and introduced mutation that is
known to be pathogenic and so you can

1050
00:23:20,220 --> 00:23:20,230
known to be pathogenic and so you can
 

1051
00:23:20,230 --> 00:23:22,500
known to be pathogenic and so you can
now look at the healthy cells and

1052
00:23:22,500 --> 00:23:22,510
now look at the healthy cells and
 

1053
00:23:22,510 --> 00:23:24,150
now look at the healthy cells and
unhealthy cells the one with the

1054
00:23:24,150 --> 00:23:24,160
unhealthy cells the one with the
 

1055
00:23:24,160 --> 00:23:26,040
unhealthy cells the one with the
mutation and do a one-on-one comparison

1056
00:23:26,040 --> 00:23:26,050
mutation and do a one-on-one comparison
 

1057
00:23:26,050 --> 00:23:28,230
mutation and do a one-on-one comparison
where everything else is held constant

1058
00:23:28,230 --> 00:23:28,240
where everything else is held constant
 

1059
00:23:28,240 --> 00:23:30,450
where everything else is held constant
and so you could really start to

1060
00:23:30,450 --> 00:23:30,460
and so you could really start to
 

1061
00:23:30,460 --> 00:23:32,100
and so you could really start to
understand specifically what the

1062
00:23:32,100 --> 00:23:32,110
understand specifically what the
 

1063
00:23:32,110 --> 00:23:34,590
understand specifically what the
mutation does at the cellular level so

1064
00:23:34,590 --> 00:23:34,600
mutation does at the cellular level so
 

1065
00:23:34,600 --> 00:23:37,530
mutation does at the cellular level so
the IPS cells are a great starting point

1066
00:23:37,530 --> 00:23:37,540
the IPS cells are a great starting point
 

1067
00:23:37,540 --> 00:23:39,630
the IPS cells are a great starting point
and obviously more diversity is better

1068
00:23:39,630 --> 00:23:39,640
and obviously more diversity is better
 

1069
00:23:39,640 --> 00:23:41,760
and obviously more diversity is better
because you also want to capture ethnic

1070
00:23:41,760 --> 00:23:41,770
because you also want to capture ethnic
 

1071
00:23:41,770 --> 00:23:43,470
because you also want to capture ethnic
background and how that affects things

1072
00:23:43,470 --> 00:23:43,480
background and how that affects things
 

1073
00:23:43,480 --> 00:23:45,030
background and how that affects things
but maybe you don't need one from every

1074
00:23:45,030 --> 00:23:45,040
but maybe you don't need one from every
 

1075
00:23:45,040 --> 00:23:47,700
but maybe you don't need one from every
single patient with every single type of

1076
00:23:47,700 --> 00:23:47,710
single patient with every single type of
 

1077
00:23:47,710 --> 00:23:49,140
single patient with every single type of
disease because we have other tools at

1078
00:23:49,140 --> 00:23:49,150
disease because we have other tools at
 

1079
00:23:49,150 --> 00:23:51,570
disease because we have other tools at
our disposal well how much difference is

1080
00:23:51,570 --> 00:23:51,580
our disposal well how much difference is
 

1081
00:23:51,580 --> 00:23:53,190
our disposal well how much difference is
there between people I mentioned ethnic

1082
00:23:53,190 --> 00:23:53,200
there between people I mentioned ethnic
 

1083
00:23:53,200 --> 00:23:55,050
there between people I mentioned ethnic
background in terms of IPS cells so

1084
00:23:55,050 --> 00:23:55,060
background in terms of IPS cells so
 

1085
00:23:55,060 --> 00:23:57,590
background in terms of IPS cells so
we're all like it seems like these

1086
00:23:57,590 --> 00:23:57,600
we're all like it seems like these
 

1087
00:23:57,600 --> 00:24:00,720
we're all like it seems like these
magical cells that can do it to create

1088
00:24:00,720 --> 00:24:00,730
magical cells that can do it to create
 

1089
00:24:00,730 --> 00:24:03,060
magical cells that can do it to create
anything between different populations

1090
00:24:03,060 --> 00:24:03,070
anything between different populations
 

1091
00:24:03,070 --> 00:24:04,530
anything between different populations
different people is there a lot of

1092
00:24:04,530 --> 00:24:04,540
different people is there a lot of
 

1093
00:24:04,540 --> 00:24:07,170
different people is there a lot of
variability between stem cells well

1094
00:24:07,170 --> 00:24:07,180
variability between stem cells well
 

1095
00:24:07,180 --> 00:24:09,300
variability between stem cells well
first of all there's the variability

1096
00:24:09,300 --> 00:24:09,310
first of all there's the variability
 

1097
00:24:09,310 --> 00:24:11,600
first of all there's the variability
that's driven simply by the fact that

1098
00:24:11,600 --> 00:24:11,610
that's driven simply by the fact that
 

1099
00:24:11,610 --> 00:24:14,340
that's driven simply by the fact that
genetically we're different so a stem

1100
00:24:14,340 --> 00:24:14,350
genetically we're different so a stem
 

1101
00:24:14,350 --> 00:24:15,900
genetically we're different so a stem
cell let's drive for my genotype is

1102
00:24:15,900 --> 00:24:15,910
cell let's drive for my genotype is
 

1103
00:24:15,910 --> 00:24:18,150
cell let's drive for my genotype is
gonna be different from itself stem

1104
00:24:18,150 --> 00:24:18,160
gonna be different from itself stem
 

1105
00:24:18,160 --> 00:24:20,670
gonna be different from itself stem
cells derive from your genotype there's

1106
00:24:20,670 --> 00:24:20,680
cells derive from your genotype there's
 

1107
00:24:20,680 --> 00:24:22,350
cells derive from your genotype there's
also some differences that I have more

1108
00:24:22,350 --> 00:24:22,360
also some differences that I have more
 

1109
00:24:22,360 --> 00:24:25,200
also some differences that I have more
to do with for whatever reason

1110
00:24:25,200 --> 00:24:25,210
to do with for whatever reason
 

1111
00:24:25,210 --> 00:24:27,660
to do with for whatever reason
some people stem cells differentiate

1112
00:24:27,660 --> 00:24:27,670
some people stem cells differentiate
 

1113
00:24:27,670 --> 00:24:29,940
some people stem cells differentiate
better than other people stem cells we

1114
00:24:29,940 --> 00:24:29,950
better than other people stem cells we
 

1115
00:24:29,950 --> 00:24:31,890
better than other people stem cells we
don't entirely understand why so there's

1116
00:24:31,890 --> 00:24:31,900
don't entirely understand why so there's
 

1117
00:24:31,900 --> 00:24:33,660
don't entirely understand why so there's
certainly some differences there as well

1118
00:24:33,660 --> 00:24:33,670
certainly some differences there as well
 

1119
00:24:33,670 --> 00:24:35,640
certainly some differences there as well
but the fundamental difference and the

1120
00:24:35,640 --> 00:24:35,650
but the fundamental difference and the
 

1121
00:24:35,650 --> 00:24:37,580
but the fundamental difference and the
one that we really care about and is a

1122
00:24:37,580 --> 00:24:37,590
one that we really care about and is a
 

1123
00:24:37,590 --> 00:24:41,610
one that we really care about and is a
positive is that the is the fact that

1124
00:24:41,610 --> 00:24:41,620
positive is that the is the fact that
 

1125
00:24:41,620 --> 00:24:43,620
positive is that the is the fact that
the genetics are different and therefore

1126
00:24:43,620 --> 00:24:43,630
the genetics are different and therefore
 

1127
00:24:43,630 --> 00:24:46,350
the genetics are different and therefore
we capitulate my disease burden versus

1128
00:24:46,350 --> 00:24:46,360
we capitulate my disease burden versus
 

1129
00:24:46,360 --> 00:24:48,360
we capitulate my disease burden versus
your disease burden what's the disease

1130
00:24:48,360 --> 00:24:48,370
your disease burden what's the disease
 

1131
00:24:48,370 --> 00:24:51,870
your disease burden what's the disease
burden well it disease burden is just if

1132
00:24:51,870 --> 00:24:51,880
burden well it disease burden is just if
 

1133
00:24:51,880 --> 00:24:53,490
burden well it disease burden is just if
you think I mean it's not a well-defined

1134
00:24:53,490 --> 00:24:53,500
you think I mean it's not a well-defined
 

1135
00:24:53,500 --> 00:24:55,650
you think I mean it's not a well-defined
mathematical term although there are

1136
00:24:55,650 --> 00:24:55,660
mathematical term although there are
 

1137
00:24:55,660 --> 00:24:57,660
mathematical term although there are
mathematical formulations of it

1138
00:24:57,660 --> 00:24:57,670
mathematical formulations of it
 

1139
00:24:57,670 --> 00:25:00,210
mathematical formulations of it
it if you think about the fact that some

1140
00:25:00,210 --> 00:25:00,220
it if you think about the fact that some
 

1141
00:25:00,220 --> 00:25:02,370
it if you think about the fact that some
of us are more likely to get a certain

1142
00:25:02,370 --> 00:25:02,380
of us are more likely to get a certain
 

1143
00:25:02,380 --> 00:25:05,360
of us are more likely to get a certain
disease than others because we have more

1144
00:25:05,360 --> 00:25:05,370
disease than others because we have more
 

1145
00:25:05,370 --> 00:25:07,850
disease than others because we have more
variations in our genome that are

1146
00:25:07,850 --> 00:25:07,860
variations in our genome that are
 

1147
00:25:07,860 --> 00:25:10,080
variations in our genome that are
causative of the disease maybe fewer

1148
00:25:10,080 --> 00:25:10,090
causative of the disease maybe fewer
 

1149
00:25:10,090 --> 00:25:11,870
causative of the disease maybe fewer
that are protective of the disease

1150
00:25:11,870 --> 00:25:11,880
that are protective of the disease
 

1151
00:25:11,880 --> 00:25:15,360
that are protective of the disease
people have quantified that using what

1152
00:25:15,360 --> 00:25:15,370
people have quantified that using what
 

1153
00:25:15,370 --> 00:25:18,060
people have quantified that using what
are called polygenic risk scores which

1154
00:25:18,060 --> 00:25:18,070
are called polygenic risk scores which
 

1155
00:25:18,070 --> 00:25:21,810
are called polygenic risk scores which
look at all of the variations in an

1156
00:25:21,810 --> 00:25:21,820
look at all of the variations in an
 

1157
00:25:21,820 --> 00:25:24,180
look at all of the variations in an
individual person's genome and add them

1158
00:25:24,180 --> 00:25:24,190
individual person's genome and add them
 

1159
00:25:24,190 --> 00:25:26,130
individual person's genome and add them
all up in terms of how much risk they

1160
00:25:26,130 --> 00:25:26,140
all up in terms of how much risk they
 

1161
00:25:26,140 --> 00:25:28,110
all up in terms of how much risk they
confer for a particular disease and then

1162
00:25:28,110 --> 00:25:28,120
confer for a particular disease and then
 

1163
00:25:28,120 --> 00:25:30,600
confer for a particular disease and then
they've put people on a spectrum of

1164
00:25:30,600 --> 00:25:30,610
they've put people on a spectrum of
 

1165
00:25:30,610 --> 00:25:33,960
they've put people on a spectrum of
their disease risk and for certain

1166
00:25:33,960 --> 00:25:33,970
their disease risk and for certain
 

1167
00:25:33,970 --> 00:25:36,390
their disease risk and for certain
diseases where we've been sufficiently

1168
00:25:36,390 --> 00:25:36,400
diseases where we've been sufficiently
 

1169
00:25:36,400 --> 00:25:38,220
diseases where we've been sufficiently
powered to really understand the

1170
00:25:38,220 --> 00:25:38,230
powered to really understand the
 

1171
00:25:38,230 --> 00:25:40,370
powered to really understand the
connection between the many many small

1172
00:25:40,370 --> 00:25:40,380
connection between the many many small
 

1173
00:25:40,380 --> 00:25:42,750
connection between the many many small
variations that give rise to an

1174
00:25:42,750 --> 00:25:42,760
variations that give rise to an
 

1175
00:25:42,760 --> 00:25:45,420
variations that give rise to an
increased disease risk there is some

1176
00:25:45,420 --> 00:25:45,430
increased disease risk there is some
 

1177
00:25:45,430 --> 00:25:47,400
increased disease risk there is some
pretty significant differences in terms

1178
00:25:47,400 --> 00:25:47,410
pretty significant differences in terms
 

1179
00:25:47,410 --> 00:25:49,530
pretty significant differences in terms
of the risk between the people say at

1180
00:25:49,530 --> 00:25:49,540
of the risk between the people say at
 

1181
00:25:49,540 --> 00:25:51,660
of the risk between the people say at
the highest decile of this polygenic

1182
00:25:51,660 --> 00:25:51,670
the highest decile of this polygenic
 

1183
00:25:51,670 --> 00:25:53,040
the highest decile of this polygenic
risk score and the people at the lowest

1184
00:25:53,040 --> 00:25:53,050
risk score and the people at the lowest
 

1185
00:25:53,050 --> 00:25:55,320
risk score and the people at the lowest
decile sometimes those other differences

1186
00:25:55,320 --> 00:25:55,330
decile sometimes those other differences
 

1187
00:25:55,330 --> 00:25:58,320
decile sometimes those other differences
are you know factor of 10 or 12 higher

1188
00:25:58,320 --> 00:25:58,330
are you know factor of 10 or 12 higher
 

1189
00:25:58,330 --> 00:26:03,660
are you know factor of 10 or 12 higher
so there's definitely a lot that our

1190
00:26:03,660 --> 00:26:03,670
so there's definitely a lot that our
 

1191
00:26:03,670 --> 00:26:06,030
so there's definitely a lot that our
genetics contributes to disease risk

1192
00:26:06,030 --> 00:26:06,040
genetics contributes to disease risk
 

1193
00:26:06,040 --> 00:26:08,340
genetics contributes to disease risk
even if it's not by any stretch the full

1194
00:26:08,340 --> 00:26:08,350
even if it's not by any stretch the full
 

1195
00:26:08,350 --> 00:26:09,690
even if it's not by any stretch the full
explanation and from the machine

1196
00:26:09,690 --> 00:26:09,700
explanation and from the machine
 

1197
00:26:09,700 --> 00:26:11,280
explanation and from the machine
learning perspective their signal there

1198
00:26:11,280 --> 00:26:11,290
learning perspective their signal there
 

1199
00:26:11,290 --> 00:26:13,650
learning perspective their signal there
there is definitely signal in the

1200
00:26:13,650 --> 00:26:13,660
there is definitely signal in the
 

1201
00:26:13,660 --> 00:26:17,610
there is definitely signal in the
genetics and there is even more signal

1202
00:26:17,610 --> 00:26:17,620
genetics and there is even more signal
 

1203
00:26:17,620 --> 00:26:20,820
genetics and there is even more signal
we believe in looking at the cells that

1204
00:26:20,820 --> 00:26:20,830
we believe in looking at the cells that
 

1205
00:26:20,830 --> 00:26:22,860
we believe in looking at the cells that
are derived from those different

1206
00:26:22,860 --> 00:26:22,870
are derived from those different
 

1207
00:26:22,870 --> 00:26:25,680
are derived from those different
genetics because in principle you could

1208
00:26:25,680 --> 00:26:25,690
genetics because in principle you could
 

1209
00:26:25,690 --> 00:26:27,930
genetics because in principle you could
say all the signal is there the at the

1210
00:26:27,930 --> 00:26:27,940
say all the signal is there the at the
 

1211
00:26:27,940 --> 00:26:29,580
say all the signal is there the at the
genetics level so we don't need to look

1212
00:26:29,580 --> 00:26:29,590
genetics level so we don't need to look
 

1213
00:26:29,590 --> 00:26:31,200
genetics level so we don't need to look
at the cells but our understanding of

1214
00:26:31,200 --> 00:26:31,210
at the cells but our understanding of
 

1215
00:26:31,210 --> 00:26:34,350
at the cells but our understanding of
the biology so limited at this point

1216
00:26:34,350 --> 00:26:34,360
the biology so limited at this point
 

1217
00:26:34,360 --> 00:26:36,690
the biology so limited at this point
then seeing what actually happens at the

1218
00:26:36,690 --> 00:26:36,700
then seeing what actually happens at the
 

1219
00:26:36,700 --> 00:26:39,000
then seeing what actually happens at the
cellular level is a heck of a lot

1220
00:26:39,000 --> 00:26:39,010
cellular level is a heck of a lot
 

1221
00:26:39,010 --> 00:26:41,370
cellular level is a heck of a lot
closer to the human clinical outcome

1222
00:26:41,370 --> 00:26:41,380
closer to the human clinical outcome
 

1223
00:26:41,380 --> 00:26:44,580
closer to the human clinical outcome
than looking at the genetics directly

1224
00:26:44,580 --> 00:26:44,590
than looking at the genetics directly
 

1225
00:26:44,590 --> 00:26:46,680
than looking at the genetics directly
and so we can learn a lot more from it

1226
00:26:46,680 --> 00:26:46,690
and so we can learn a lot more from it
 

1227
00:26:46,690 --> 00:26:48,780
and so we can learn a lot more from it
than we could by looking at genetics

1228
00:26:48,780 --> 00:26:48,790
than we could by looking at genetics
 

1229
00:26:48,790 --> 00:26:50,850
than we could by looking at genetics
alone so just to get a sense that enough

1230
00:26:50,850 --> 00:26:50,860
alone so just to get a sense that enough
 

1231
00:26:50,860 --> 00:26:53,150
alone so just to get a sense that enough
it's easy to do but what kind of data is

1232
00:26:53,150 --> 00:26:53,160
it's easy to do but what kind of data is
 

1233
00:26:53,160 --> 00:26:55,830
it's easy to do but what kind of data is
useful in this disease in a dish model

1234
00:26:55,830 --> 00:26:55,840
useful in this disease in a dish model
 

1235
00:26:55,840 --> 00:26:58,200
useful in this disease in a dish model
like what what are what's what's the

1236
00:26:58,200 --> 00:26:58,210
like what what are what's what's the
 

1237
00:26:58,210 --> 00:27:00,800
like what what are what's what's the
source of raw data information and also

1238
00:27:00,800 --> 00:27:00,810
source of raw data information and also
 

1239
00:27:00,810 --> 00:27:04,170
source of raw data information and also
for my outsider's perspective sort of

1240
00:27:04,170 --> 00:27:04,180
for my outsider's perspective sort of
 

1241
00:27:04,180 --> 00:27:08,130
for my outsider's perspective sort of
biology and cells are squishy things and

1242
00:27:08,130 --> 00:27:08,140
biology and cells are squishy things and
 

1243
00:27:08,140 --> 00:27:10,290
biology and cells are squishy things and
I think they are how do you connect

1244
00:27:10,290 --> 00:27:10,300
I think they are how do you connect
 

1245
00:27:10,300 --> 00:27:13,950
I think they are how do you connect
literally you connect the computer to to

1246
00:27:13,950 --> 00:27:13,960
literally you connect the computer to to
 

1247
00:27:13,960 --> 00:27:17,970
literally you connect the computer to to
that which sensory mechanisms I guess so

1248
00:27:17,970 --> 00:27:17,980
that which sensory mechanisms I guess so
 

1249
00:27:17,980 --> 00:27:20,520
that which sensory mechanisms I guess so
that's another one of those revolutions

1250
00:27:20,520 --> 00:27:20,530
that's another one of those revolutions
 

1251
00:27:20,530 --> 00:27:22,020
that's another one of those revolutions
that have happened the last ten years

1252
00:27:22,020 --> 00:27:22,030
that have happened the last ten years
 

1253
00:27:22,030 --> 00:27:25,500
that have happened the last ten years
and that our ability to measure cells

1254
00:27:25,500 --> 00:27:25,510
and that our ability to measure cells
 

1255
00:27:25,510 --> 00:27:28,610
and that our ability to measure cells
very quantitatively has also

1256
00:27:28,610 --> 00:27:28,620
very quantitatively has also
 

1257
00:27:28,620 --> 00:27:31,740
very quantitatively has also
dramatically increased so back when I

1258
00:27:31,740 --> 00:27:31,750
dramatically increased so back when I
 

1259
00:27:31,750 --> 00:27:34,460
dramatically increased so back when I
started doing biology and you know late

1260
00:27:34,460 --> 00:27:34,470
started doing biology and you know late
 

1261
00:27:34,470 --> 00:27:40,950
started doing biology and you know late
90s early 2000s that was the initial era

1262
00:27:40,950 --> 00:27:40,960
90s early 2000s that was the initial era
 

1263
00:27:40,960 --> 00:27:42,900
90s early 2000s that was the initial era
where we started to measure biology in

1264
00:27:42,900 --> 00:27:42,910
where we started to measure biology in
 

1265
00:27:42,910 --> 00:27:45,240
where we started to measure biology in
really quantitative ways using things

1266
00:27:45,240 --> 00:27:45,250
really quantitative ways using things
 

1267
00:27:45,250 --> 00:27:47,910
really quantitative ways using things
like microarrays where you would measure

1268
00:27:47,910 --> 00:27:47,920
like microarrays where you would measure
 

1269
00:27:47,920 --> 00:27:52,140
like microarrays where you would measure
in a single experiment the activity

1270
00:27:52,140 --> 00:27:52,150
in a single experiment the activity
 

1271
00:27:52,150 --> 00:27:54,000
in a single experiment the activity
level what's called expression level of

1272
00:27:54,000 --> 00:27:54,010
level what's called expression level of
 

1273
00:27:54,010 --> 00:27:56,250
level what's called expression level of
multiple of every gene in the genome in

1274
00:27:56,250 --> 00:27:56,260
multiple of every gene in the genome in
 

1275
00:27:56,260 --> 00:27:59,610
multiple of every gene in the genome in
that sample and that ability is what

1276
00:27:59,610 --> 00:27:59,620
that sample and that ability is what
 

1277
00:27:59,620 --> 00:28:02,130
that sample and that ability is what
actually allowed us to even understand

1278
00:28:02,130 --> 00:28:02,140
actually allowed us to even understand
 

1279
00:28:02,140 --> 00:28:04,590
actually allowed us to even understand
that there are molecular subtypes of

1280
00:28:04,590 --> 00:28:04,600
that there are molecular subtypes of
 

1281
00:28:04,600 --> 00:28:06,840
that there are molecular subtypes of
diseases like cancer where up until that

1282
00:28:06,840 --> 00:28:06,850
diseases like cancer where up until that
 

1283
00:28:06,850 --> 00:28:08,720
diseases like cancer where up until that
point is like oh you have breast cancer

1284
00:28:08,720 --> 00:28:08,730
point is like oh you have breast cancer
 

1285
00:28:08,730 --> 00:28:12,210
point is like oh you have breast cancer
but then we looked we looked at the

1286
00:28:12,210 --> 00:28:12,220
but then we looked we looked at the
 

1287
00:28:12,220 --> 00:28:14,490
but then we looked we looked at the
molecular data it was clear that there's

1288
00:28:14,490 --> 00:28:14,500
molecular data it was clear that there's
 

1289
00:28:14,500 --> 00:28:16,080
molecular data it was clear that there's
different subtypes of breast cancer that

1290
00:28:16,080 --> 00:28:16,090
different subtypes of breast cancer that
 

1291
00:28:16,090 --> 00:28:17,970
different subtypes of breast cancer that
at the level of gene activity look

1292
00:28:17,970 --> 00:28:17,980
at the level of gene activity look
 

1293
00:28:17,980 --> 00:28:21,180
at the level of gene activity look
completely different to each other so

1294
00:28:21,180 --> 00:28:21,190
completely different to each other so
 

1295
00:28:21,190 --> 00:28:23,310
completely different to each other so
that was the beginning of this process

1296
00:28:23,310 --> 00:28:23,320
that was the beginning of this process
 

1297
00:28:23,320 --> 00:28:25,460
that was the beginning of this process
now we have the ability to measure

1298
00:28:25,460 --> 00:28:25,470
now we have the ability to measure
 

1299
00:28:25,470 --> 00:28:28,350
now we have the ability to measure
individual cells in terms of their gene

1300
00:28:28,350 --> 00:28:28,360
individual cells in terms of their gene
 

1301
00:28:28,360 --> 00:28:30,120
individual cells in terms of their gene
activity using what's called single cell

1302
00:28:30,120 --> 00:28:30,130
activity using what's called single cell
 

1303
00:28:30,130 --> 00:28:33,330
activity using what's called single cell
RNA sequencing which basically sequences

1304
00:28:33,330 --> 00:28:33,340
RNA sequencing which basically sequences
 

1305
00:28:33,340 --> 00:28:37,050
RNA sequencing which basically sequences
the RNA which is that activity level of

1306
00:28:37,050 --> 00:28:37,060
the RNA which is that activity level of
 

1307
00:28:37,060 --> 00:28:40,170
the RNA which is that activity level of
different genes for every gene in the

1308
00:28:40,170 --> 00:28:40,180
different genes for every gene in the
 

1309
00:28:40,180 --> 00:28:42,090
different genes for every gene in the
genome and you could do that at single

1310
00:28:42,090 --> 00:28:42,100
genome and you could do that at single
 

1311
00:28:42,100 --> 00:28:43,710
genome and you could do that at single
cell level so that's an incredibly

1312
00:28:43,710 --> 00:28:43,720
cell level so that's an incredibly
 

1313
00:28:43,720 --> 00:28:45,600
cell level so that's an incredibly
powerful way of measuring cells I mean

1314
00:28:45,600 --> 00:28:45,610
powerful way of measuring cells I mean
 

1315
00:28:45,610 --> 00:28:47,340
powerful way of measuring cells I mean
you literally count the number of

1316
00:28:47,340 --> 00:28:47,350
you literally count the number of
 

1317
00:28:47,350 --> 00:28:49,710
you literally count the number of
transcripts oh really turns that squishy

1318
00:28:49,710 --> 00:28:49,720
transcripts oh really turns that squishy
 

1319
00:28:49,720 --> 00:28:51,140
transcripts oh really turns that squishy
thing in something that's digital

1320
00:28:51,140 --> 00:28:51,150
thing in something that's digital
 

1321
00:28:51,150 --> 00:28:52,860
thing in something that's digital
another tremendous

1322
00:28:52,860 --> 00:28:52,870
another tremendous
 

1323
00:28:52,870 --> 00:28:55,410
another tremendous
this data source that's emerged the last

1324
00:28:55,410 --> 00:28:55,420
this data source that's emerged the last
 

1325
00:28:55,420 --> 00:28:58,049
this data source that's emerged the last
few years is microscopy and and

1326
00:28:58,049 --> 00:28:58,059
few years is microscopy and and
 

1327
00:28:58,059 --> 00:28:59,700
few years is microscopy and and
specifically even super resolution

1328
00:28:59,700 --> 00:28:59,710
specifically even super resolution
 

1329
00:28:59,710 --> 00:29:02,549
specifically even super resolution
microscopy where you could use digital

1330
00:29:02,549 --> 00:29:02,559
microscopy where you could use digital
 

1331
00:29:02,559 --> 00:29:05,670
microscopy where you could use digital
reconstruction to look at sub cellular

1332
00:29:05,670 --> 00:29:05,680
reconstruction to look at sub cellular
 

1333
00:29:05,680 --> 00:29:07,860
reconstruction to look at sub cellular
structures sometimes even things that

1334
00:29:07,860 --> 00:29:07,870
structures sometimes even things that
 

1335
00:29:07,870 --> 00:29:10,350
structures sometimes even things that
are below the diffraction limit of light

1336
00:29:10,350 --> 00:29:10,360
are below the diffraction limit of light
 

1337
00:29:10,360 --> 00:29:13,230
are below the diffraction limit of light
by doing a sophisticated reconstruction

1338
00:29:13,230 --> 00:29:13,240
by doing a sophisticated reconstruction
 

1339
00:29:13,240 --> 00:29:14,730
by doing a sophisticated reconstruction
and again that gives you tremendous

1340
00:29:14,730 --> 00:29:14,740
and again that gives you tremendous
 

1341
00:29:14,740 --> 00:29:17,010
and again that gives you tremendous
amount of information at the sub

1342
00:29:17,010 --> 00:29:17,020
amount of information at the sub
 

1343
00:29:17,020 --> 00:29:19,950
amount of information at the sub
cellular level there's now more and more

1344
00:29:19,950 --> 00:29:19,960
cellular level there's now more and more
 

1345
00:29:19,960 --> 00:29:23,010
cellular level there's now more and more
ways that an amazing scientists out

1346
00:29:23,010 --> 00:29:23,020
ways that an amazing scientists out
 

1347
00:29:23,020 --> 00:29:26,480
ways that an amazing scientists out
there are developing for getting new

1348
00:29:26,480 --> 00:29:26,490
there are developing for getting new
 

1349
00:29:26,490 --> 00:29:29,640
there are developing for getting new
types of information from even single

1350
00:29:29,640 --> 00:29:29,650
types of information from even single
 

1351
00:29:29,650 --> 00:29:34,049
types of information from even single
cells and so that is a way of turning

1352
00:29:34,049 --> 00:29:34,059
cells and so that is a way of turning
 

1353
00:29:34,059 --> 00:29:36,530
cells and so that is a way of turning
those squishy things into digital data

1354
00:29:36,530 --> 00:29:36,540
those squishy things into digital data
 

1355
00:29:36,540 --> 00:29:40,680
those squishy things into digital data
into beautiful datasets but so that data

1356
00:29:40,680 --> 00:29:40,690
into beautiful datasets but so that data
 

1357
00:29:40,690 --> 00:29:42,390
into beautiful datasets but so that data
said then with machine learning tools

1358
00:29:42,390 --> 00:29:42,400
said then with machine learning tools
 

1359
00:29:42,400 --> 00:29:44,820
said then with machine learning tools
allows you to maybe understand the

1360
00:29:44,820 --> 00:29:44,830
allows you to maybe understand the
 

1361
00:29:44,830 --> 00:29:47,310
allows you to maybe understand the
developmental like the mechanism of the

1362
00:29:47,310 --> 00:29:47,320
developmental like the mechanism of the
 

1363
00:29:47,320 --> 00:29:51,120
developmental like the mechanism of the
a particular disease and if it's

1364
00:29:51,120 --> 00:29:51,130
a particular disease and if it's
 

1365
00:29:51,130 --> 00:29:53,190
a particular disease and if it's
possible to sort of at a high level

1366
00:29:53,190 --> 00:29:53,200
possible to sort of at a high level
 

1367
00:29:53,200 --> 00:29:58,610
possible to sort of at a high level
describe how does how does that help

1368
00:29:58,610 --> 00:29:58,620
describe how does how does that help
 

1369
00:29:58,620 --> 00:30:02,000
describe how does how does that help
lead to drug discovery that can help

1370
00:30:02,000 --> 00:30:02,010
lead to drug discovery that can help
 

1371
00:30:02,010 --> 00:30:05,549
lead to drug discovery that can help
prevent reverse that mechanism so I

1372
00:30:05,549 --> 00:30:05,559
prevent reverse that mechanism so I
 

1373
00:30:05,559 --> 00:30:07,049
prevent reverse that mechanism so I
think there's different ways in which

1374
00:30:07,049 --> 00:30:07,059
think there's different ways in which
 

1375
00:30:07,059 --> 00:30:10,740
think there's different ways in which
this data could potentially be used some

1376
00:30:10,740 --> 00:30:10,750
this data could potentially be used some
 

1377
00:30:10,750 --> 00:30:13,680
this data could potentially be used some
people use it for scientific discovery

1378
00:30:13,680 --> 00:30:13,690
people use it for scientific discovery
 

1379
00:30:13,690 --> 00:30:17,220
people use it for scientific discovery
and say oh look we see this phenotype at

1380
00:30:17,220 --> 00:30:17,230
and say oh look we see this phenotype at
 

1381
00:30:17,230 --> 00:30:21,690
and say oh look we see this phenotype at
the cellular level so let's try and work

1382
00:30:21,690 --> 00:30:21,700
the cellular level so let's try and work
 

1383
00:30:21,700 --> 00:30:23,910
the cellular level so let's try and work
our way backwards and think which genes

1384
00:30:23,910 --> 00:30:23,920
our way backwards and think which genes
 

1385
00:30:23,920 --> 00:30:26,490
our way backwards and think which genes
might be involved in pathways that give

1386
00:30:26,490 --> 00:30:26,500
might be involved in pathways that give
 

1387
00:30:26,500 --> 00:30:30,410
might be involved in pathways that give
rise that so that's a very sort of

1388
00:30:30,410 --> 00:30:30,420

 

1389
00:30:30,420 --> 00:30:34,230

analytical method to sort of work our

1390
00:30:34,230 --> 00:30:34,240
analytical method to sort of work our
 

1391
00:30:34,240 --> 00:30:36,570
analytical method to sort of work our
way backwards using our understanding of

1392
00:30:36,570 --> 00:30:36,580
way backwards using our understanding of
 

1393
00:30:36,580 --> 00:30:40,410
way backwards using our understanding of
known biology some people use it in a

1394
00:30:40,410 --> 00:30:40,420
known biology some people use it in a
 

1395
00:30:40,420 --> 00:30:44,850
known biology some people use it in a
somewhat more you know sort of forward

1396
00:30:44,850 --> 00:30:44,860
somewhat more you know sort of forward
 

1397
00:30:44,860 --> 00:30:46,740
somewhat more you know sort of forward
that would if that was a backward this

1398
00:30:46,740 --> 00:30:46,750
that would if that was a backward this
 

1399
00:30:46,750 --> 00:30:48,510
that would if that was a backward this
would be forward which is to say okay if

1400
00:30:48,510 --> 00:30:48,520
would be forward which is to say okay if
 

1401
00:30:48,520 --> 00:30:51,870
would be forward which is to say okay if
I can perturb this gene doesn't show a

1402
00:30:51,870 --> 00:30:51,880
I can perturb this gene doesn't show a
 

1403
00:30:51,880 --> 00:30:54,810
I can perturb this gene doesn't show a
phenotype that is similar to what I see

1404
00:30:54,810 --> 00:30:54,820
phenotype that is similar to what I see
 

1405
00:30:54,820 --> 00:30:56,790
phenotype that is similar to what I see
in disease patients and so maybe that

1406
00:30:56,790 --> 00:30:56,800
in disease patients and so maybe that
 

1407
00:30:56,800 --> 00:30:58,830
in disease patients and so maybe that
gene is actually causal of the disease

1408
00:30:58,830 --> 00:30:58,840
gene is actually causal of the disease
 

1409
00:30:58,840 --> 00:31:00,630
gene is actually causal of the disease
so that's a different way and then

1410
00:31:00,630 --> 00:31:00,640
so that's a different way and then
 

1411
00:31:00,640 --> 00:31:03,690
so that's a different way and then
there's what we do which is basically to

1412
00:31:03,690 --> 00:31:03,700
there's what we do which is basically to
 

1413
00:31:03,700 --> 00:31:06,630
there's what we do which is basically to
take that very large collection of the

1414
00:31:06,630 --> 00:31:06,640
take that very large collection of the
 

1415
00:31:06,640 --> 00:31:09,960
take that very large collection of the
and use machine learning to uncover the

1416
00:31:09,960 --> 00:31:09,970
and use machine learning to uncover the
 

1417
00:31:09,970 --> 00:31:12,840
and use machine learning to uncover the
patterns that emerge from it so for

1418
00:31:12,840 --> 00:31:12,850
patterns that emerge from it so for
 

1419
00:31:12,850 --> 00:31:14,820
patterns that emerge from it so for
instance what are those subtypes that

1420
00:31:14,820 --> 00:31:14,830
instance what are those subtypes that
 

1421
00:31:14,830 --> 00:31:18,210
instance what are those subtypes that
might be similar at the human clinical

1422
00:31:18,210 --> 00:31:18,220
might be similar at the human clinical
 

1423
00:31:18,220 --> 00:31:19,980
might be similar at the human clinical
outcome but quite distinct when you look

1424
00:31:19,980 --> 00:31:19,990
outcome but quite distinct when you look
 

1425
00:31:19,990 --> 00:31:23,250
outcome but quite distinct when you look
at the molecular data and then if we can

1426
00:31:23,250 --> 00:31:23,260
at the molecular data and then if we can
 

1427
00:31:23,260 --> 00:31:25,620
at the molecular data and then if we can
identify such a subtype are there

1428
00:31:25,620 --> 00:31:25,630
identify such a subtype are there
 

1429
00:31:25,630 --> 00:31:28,340
identify such a subtype are there
interventions that if I apply it to

1430
00:31:28,340 --> 00:31:28,350
interventions that if I apply it to
 

1431
00:31:28,350 --> 00:31:30,690
interventions that if I apply it to
cells that come from this subtype of the

1432
00:31:30,690 --> 00:31:30,700
cells that come from this subtype of the
 

1433
00:31:30,700 --> 00:31:34,140
cells that come from this subtype of the
disease and you apply that intervention

1434
00:31:34,140 --> 00:31:34,150
disease and you apply that intervention
 

1435
00:31:34,150 --> 00:31:35,930
disease and you apply that intervention
it could be a drug or it could be a

1436
00:31:35,930 --> 00:31:35,940
it could be a drug or it could be a
 

1437
00:31:35,940 --> 00:31:39,270
it could be a drug or it could be a
CRISPR gene intervention it does it

1438
00:31:39,270 --> 00:31:39,280
CRISPR gene intervention it does it
 

1439
00:31:39,280 --> 00:31:41,850
CRISPR gene intervention it does it
revert the disease state to something

1440
00:31:41,850 --> 00:31:41,860
revert the disease state to something
 

1441
00:31:41,860 --> 00:31:43,260
revert the disease state to something
that looks more like normal happy

1442
00:31:43,260 --> 00:31:43,270
that looks more like normal happy
 

1443
00:31:43,270 --> 00:31:46,110
that looks more like normal happy
healthy cells and so hopefully if you

1444
00:31:46,110 --> 00:31:46,120
healthy cells and so hopefully if you
 

1445
00:31:46,120 --> 00:31:49,950
healthy cells and so hopefully if you
see that that gives you a certain hope

1446
00:31:49,950 --> 00:31:49,960
see that that gives you a certain hope
 

1447
00:31:49,960 --> 00:31:53,010
see that that gives you a certain hope
that that intervention will also have a

1448
00:31:53,010 --> 00:31:53,020
that that intervention will also have a
 

1449
00:31:53,020 --> 00:31:55,050
that that intervention will also have a
meaningful clinical benefit to people

1450
00:31:55,050 --> 00:31:55,060
meaningful clinical benefit to people
 

1451
00:31:55,060 --> 00:31:56,610
meaningful clinical benefit to people
and there's obviously a bunch of things

1452
00:31:56,610 --> 00:31:56,620
and there's obviously a bunch of things
 

1453
00:31:56,620 --> 00:31:57,930
and there's obviously a bunch of things
that you would want to do after that to

1454
00:31:57,930 --> 00:31:57,940
that you would want to do after that to
 

1455
00:31:57,940 --> 00:32:00,360
that you would want to do after that to
validate that but it's a very different

1456
00:32:00,360 --> 00:32:00,370
validate that but it's a very different
 

1457
00:32:00,370 --> 00:32:03,720
validate that but it's a very different
and much less hypothesis-driven way of

1458
00:32:03,720 --> 00:32:03,730
and much less hypothesis-driven way of
 

1459
00:32:03,730 --> 00:32:06,000
and much less hypothesis-driven way of
uncovering new potential interventions

1460
00:32:06,000 --> 00:32:06,010
uncovering new potential interventions
 

1461
00:32:06,010 --> 00:32:08,040
uncovering new potential interventions
and might give rise to things that are

1462
00:32:08,040 --> 00:32:08,050
and might give rise to things that are
 

1463
00:32:08,050 --> 00:32:10,620
and might give rise to things that are
not the same things that everyone else

1464
00:32:10,620 --> 00:32:10,630
not the same things that everyone else
 

1465
00:32:10,630 --> 00:32:13,860
not the same things that everyone else
is already looking at that's uh I don't

1466
00:32:13,860 --> 00:32:13,870
is already looking at that's uh I don't
 

1467
00:32:13,870 --> 00:32:16,920
is already looking at that's uh I don't
know I'm just like to psychoanalyze my

1468
00:32:16,920 --> 00:32:16,930
know I'm just like to psychoanalyze my
 

1469
00:32:16,930 --> 00:32:18,120
know I'm just like to psychoanalyze my
own feeling about our discussion

1470
00:32:18,120 --> 00:32:18,130
own feeling about our discussion
 

1471
00:32:18,130 --> 00:32:19,910
own feeling about our discussion
currently it's so exciting to talk about

1472
00:32:19,910 --> 00:32:19,920
currently it's so exciting to talk about
 

1473
00:32:19,920 --> 00:32:22,470
currently it's so exciting to talk about
so if I'm Ashiya fundamentally well

1474
00:32:22,470 --> 00:32:22,480
so if I'm Ashiya fundamentally well
 

1475
00:32:22,480 --> 00:32:24,030
so if I'm Ashiya fundamentally well
something that's been turned into a

1476
00:32:24,030 --> 00:32:24,040
something that's been turned into a
 

1477
00:32:24,040 --> 00:32:26,730
something that's been turned into a
machine learning problem and that says

1478
00:32:26,730 --> 00:32:26,740
machine learning problem and that says
 

1479
00:32:26,740 --> 00:32:29,420
machine learning problem and that says
can have so much real-world impact

1480
00:32:29,420 --> 00:32:29,430
can have so much real-world impact
 

1481
00:32:29,430 --> 00:32:32,010
can have so much real-world impact
that's kind of exciting because I'm so

1482
00:32:32,010 --> 00:32:32,020
that's kind of exciting because I'm so
 

1483
00:32:32,020 --> 00:32:35,880
that's kind of exciting because I'm so
most of my days spent with datasets that

1484
00:32:35,880 --> 00:32:35,890
most of my days spent with datasets that
 

1485
00:32:35,890 --> 00:32:38,280
most of my days spent with datasets that
I guess closer to the news groups okay

1486
00:32:38,280 --> 00:32:38,290
I guess closer to the news groups okay
 

1487
00:32:38,290 --> 00:32:41,340
I guess closer to the news groups okay
so this is a kind of it just feels good

1488
00:32:41,340 --> 00:32:41,350
so this is a kind of it just feels good
 

1489
00:32:41,350 --> 00:32:42,900
so this is a kind of it just feels good
to talk about in fact I don't almost

1490
00:32:42,900 --> 00:32:42,910
to talk about in fact I don't almost
 

1491
00:32:42,910 --> 00:32:44,280
to talk about in fact I don't almost
don't want to talk about machine

1492
00:32:44,280 --> 00:32:44,290
don't want to talk about machine
 

1493
00:32:44,290 --> 00:32:46,260
don't want to talk about machine
learning I want to talk about the

1494
00:32:46,260 --> 00:32:46,270
learning I want to talk about the
 

1495
00:32:46,270 --> 00:32:47,760
learning I want to talk about the
fundamentals of the data set which is

1496
00:32:47,760 --> 00:32:47,770
fundamentals of the data set which is
 

1497
00:32:47,770 --> 00:32:51,030
fundamentals of the data set which is
which is an exciting place to be I agree

1498
00:32:51,030 --> 00:32:51,040
which is an exciting place to be I agree
 

1499
00:32:51,040 --> 00:32:53,190
which is an exciting place to be I agree
with you it's what gets me up in the

1500
00:32:53,190 --> 00:32:53,200
with you it's what gets me up in the
 

1501
00:32:53,200 --> 00:32:56,190
with you it's what gets me up in the
morning it's also what attracts a lot of

1502
00:32:56,190 --> 00:32:56,200
morning it's also what attracts a lot of
 

1503
00:32:56,200 --> 00:32:58,470
morning it's also what attracts a lot of
the people who work at in seat row two

1504
00:32:58,470 --> 00:32:58,480
the people who work at in seat row two
 

1505
00:32:58,480 --> 00:33:01,140
the people who work at in seat row two
in seat row because I think all of the

1506
00:33:01,140 --> 00:33:01,150
in seat row because I think all of the
 

1507
00:33:01,150 --> 00:33:02,670
in seat row because I think all of the
certainly all of our machine learning

1508
00:33:02,670 --> 00:33:02,680
certainly all of our machine learning
 

1509
00:33:02,680 --> 00:33:05,460
certainly all of our machine learning
people are outstanding and could go get

1510
00:33:05,460 --> 00:33:05,470
people are outstanding and could go get
 

1511
00:33:05,470 --> 00:33:09,000
people are outstanding and could go get
a job you know selling ads online or

1512
00:33:09,000 --> 00:33:09,010
a job you know selling ads online or
 

1513
00:33:09,010 --> 00:33:12,270
a job you know selling ads online or
doing commerce or even self-driving cars

1514
00:33:12,270 --> 00:33:12,280
doing commerce or even self-driving cars
 

1515
00:33:12,280 --> 00:33:16,800
doing commerce or even self-driving cars
yes but but I think they would want they

1516
00:33:16,800 --> 00:33:16,810
yes but but I think they would want they
 

1517
00:33:16,810 --> 00:33:18,810
yes but but I think they would want they
they come to us because what because

1518
00:33:18,810 --> 00:33:18,820
they come to us because what because
 

1519
00:33:18,820 --> 00:33:20,300
they come to us because what because
they want to work on something that

1520
00:33:20,300 --> 00:33:20,310
they want to work on something that
 

1521
00:33:20,310 --> 00:33:22,700
they want to work on something that
more of an aspirational nature and can

1522
00:33:22,700 --> 00:33:22,710
more of an aspirational nature and can
 

1523
00:33:22,710 --> 00:33:25,460
more of an aspirational nature and can
really benefit humanity what with these

1524
00:33:25,460 --> 00:33:25,470
really benefit humanity what with these
 

1525
00:33:25,470 --> 00:33:28,100
really benefit humanity what with these
with these approaches what do you hope

1526
00:33:28,100 --> 00:33:28,110
with these approaches what do you hope
 

1527
00:33:28,110 --> 00:33:31,250
with these approaches what do you hope
what kind of diseases can be helped we

1528
00:33:31,250 --> 00:33:31,260
what kind of diseases can be helped we
 

1529
00:33:31,260 --> 00:33:33,050
what kind of diseases can be helped we
mentioned Alzheimer said schizophrenia

1530
00:33:33,050 --> 00:33:33,060
mentioned Alzheimer said schizophrenia
 

1531
00:33:33,060 --> 00:33:34,610
mentioned Alzheimer said schizophrenia
type 2 diabetes can you just describe

1532
00:33:34,610 --> 00:33:34,620
type 2 diabetes can you just describe
 

1533
00:33:34,620 --> 00:33:36,860
type 2 diabetes can you just describe
the various kinds of diseases that this

1534
00:33:36,860 --> 00:33:36,870
the various kinds of diseases that this
 

1535
00:33:36,870 --> 00:33:39,020
the various kinds of diseases that this
approach can it can help well we don't

1536
00:33:39,020 --> 00:33:39,030
approach can it can help well we don't
 

1537
00:33:39,030 --> 00:33:42,140
approach can it can help well we don't
know and I try and be very cautious

1538
00:33:42,140 --> 00:33:42,150
know and I try and be very cautious
 

1539
00:33:42,150 --> 00:33:44,630
know and I try and be very cautious
about making promises about some things

1540
00:33:44,630 --> 00:33:44,640
about making promises about some things
 

1541
00:33:44,640 --> 00:33:47,150
about making promises about some things
that o we will cure X that people make

1542
00:33:47,150 --> 00:33:47,160
that o we will cure X that people make
 

1543
00:33:47,160 --> 00:33:50,300
that o we will cure X that people make
that promise and I think it's I tried to

1544
00:33:50,300 --> 00:33:50,310
that promise and I think it's I tried to
 

1545
00:33:50,310 --> 00:33:52,790
that promise and I think it's I tried to
first deliver and then promise as

1546
00:33:52,790 --> 00:33:52,800
first deliver and then promise as
 

1547
00:33:52,800 --> 00:33:54,590
first deliver and then promise as
opposed to the other way around there

1548
00:33:54,590 --> 00:33:54,600
opposed to the other way around there
 

1549
00:33:54,600 --> 00:33:57,470
opposed to the other way around there
are characteristics of a disease that

1550
00:33:57,470 --> 00:33:57,480
are characteristics of a disease that
 

1551
00:33:57,480 --> 00:33:59,870
are characteristics of a disease that
make it more likely that this type of

1552
00:33:59,870 --> 00:33:59,880
make it more likely that this type of
 

1553
00:33:59,880 --> 00:34:02,900
make it more likely that this type of
approach can potentially be helpful so

1554
00:34:02,900 --> 00:34:02,910
approach can potentially be helpful so
 

1555
00:34:02,910 --> 00:34:05,270
approach can potentially be helpful so
for instance diseases have a very strong

1556
00:34:05,270 --> 00:34:05,280
for instance diseases have a very strong
 

1557
00:34:05,280 --> 00:34:09,680
for instance diseases have a very strong
genetic basis are ones that are more

1558
00:34:09,680 --> 00:34:09,690
genetic basis are ones that are more
 

1559
00:34:09,690 --> 00:34:11,600
genetic basis are ones that are more
likely to manifest and a stem cell

1560
00:34:11,600 --> 00:34:11,610
likely to manifest and a stem cell
 

1561
00:34:11,610 --> 00:34:15,740
likely to manifest and a stem cell
derived model we would want the cellular

1562
00:34:15,740 --> 00:34:15,750
derived model we would want the cellular
 

1563
00:34:15,750 --> 00:34:19,310
derived model we would want the cellular
models to be relatively reproducible and

1564
00:34:19,310 --> 00:34:19,320
models to be relatively reproducible and
 

1565
00:34:19,320 --> 00:34:23,290
models to be relatively reproducible and
robust so that you could actually get a

1566
00:34:23,290 --> 00:34:23,300
robust so that you could actually get a
 

1567
00:34:23,300 --> 00:34:26,690
robust so that you could actually get a
enough of those cells and in a way that

1568
00:34:26,690 --> 00:34:26,700
enough of those cells and in a way that
 

1569
00:34:26,700 --> 00:34:30,290
enough of those cells and in a way that
isn't very highly variable and noisy you

1570
00:34:30,290 --> 00:34:30,300
isn't very highly variable and noisy you
 

1571
00:34:30,300 --> 00:34:33,320
isn't very highly variable and noisy you
would want the disease to be relatively

1572
00:34:33,320 --> 00:34:33,330
would want the disease to be relatively
 

1573
00:34:33,330 --> 00:34:36,080
would want the disease to be relatively
contained in one or a small number of

1574
00:34:36,080 --> 00:34:36,090
contained in one or a small number of
 

1575
00:34:36,090 --> 00:34:37,250
contained in one or a small number of
cell types that you could actually

1576
00:34:37,250 --> 00:34:37,260
cell types that you could actually
 

1577
00:34:37,260 --> 00:34:40,880
cell types that you could actually
create in an in vitro in a dish setting

1578
00:34:40,880 --> 00:34:40,890
create in an in vitro in a dish setting
 

1579
00:34:40,890 --> 00:34:41,930
create in an in vitro in a dish setting
whereas if it's something that's really

1580
00:34:41,930 --> 00:34:41,940
whereas if it's something that's really
 

1581
00:34:41,940 --> 00:34:44,990
whereas if it's something that's really
broad and systemic and involves multiple

1582
00:34:44,990 --> 00:34:45,000
broad and systemic and involves multiple
 

1583
00:34:45,000 --> 00:34:47,750
broad and systemic and involves multiple
cells that are in very distal parts of

1584
00:34:47,750 --> 00:34:47,760
cells that are in very distal parts of
 

1585
00:34:47,760 --> 00:34:49,490
cells that are in very distal parts of
your body putting that all in the dish

1586
00:34:49,490 --> 00:34:49,500
your body putting that all in the dish
 

1587
00:34:49,500 --> 00:34:52,130
your body putting that all in the dish
is really challenging so we want to

1588
00:34:52,130 --> 00:34:52,140
is really challenging so we want to
 

1589
00:34:52,140 --> 00:34:55,130
is really challenging so we want to
focus on the ones that are most likely

1590
00:34:55,130 --> 00:34:55,140
focus on the ones that are most likely
 

1591
00:34:55,140 --> 00:34:57,890
focus on the ones that are most likely
to be successful today with the hope I

1592
00:34:57,890 --> 00:34:57,900
to be successful today with the hope I
 

1593
00:34:57,900 --> 00:35:01,700
to be successful today with the hope I
think that it's really smart

1594
00:35:01,700 --> 00:35:01,710
think that it's really smart
 

1595
00:35:01,710 --> 00:35:04,190
think that it's really smart
bioengineers out there are developing

1596
00:35:04,190 --> 00:35:04,200
bioengineers out there are developing
 

1597
00:35:04,200 --> 00:35:06,080
bioengineers out there are developing
better and better systems all the time

1598
00:35:06,080 --> 00:35:06,090
better and better systems all the time
 

1599
00:35:06,090 --> 00:35:07,640
better and better systems all the time
so the diseases that might not be

1600
00:35:07,640 --> 00:35:07,650
so the diseases that might not be
 

1601
00:35:07,650 --> 00:35:10,550
so the diseases that might not be
tractable today might be tractable in

1602
00:35:10,550 --> 00:35:10,560
tractable today might be tractable in
 

1603
00:35:10,560 --> 00:35:14,000
tractable today might be tractable in
three years so for instance five years

1604
00:35:14,000 --> 00:35:14,010
three years so for instance five years
 

1605
00:35:14,010 --> 00:35:16,190
three years so for instance five years
ago these stem cell drive models didn't

1606
00:35:16,190 --> 00:35:16,200
ago these stem cell drive models didn't
 

1607
00:35:16,200 --> 00:35:17,570
ago these stem cell drive models didn't
really exist people were doing most of

1608
00:35:17,570 --> 00:35:17,580
really exist people were doing most of
 

1609
00:35:17,580 --> 00:35:19,550
really exist people were doing most of
the work in cancer cells and the cancer

1610
00:35:19,550 --> 00:35:19,560
the work in cancer cells and the cancer
 

1611
00:35:19,560 --> 00:35:22,460
the work in cancer cells and the cancer
cells are very very poor models of most

1612
00:35:22,460 --> 00:35:22,470
cells are very very poor models of most
 

1613
00:35:22,470 --> 00:35:25,130
cells are very very poor models of most
human biology because they're a they

1614
00:35:25,130 --> 00:35:25,140
human biology because they're a they
 

1615
00:35:25,140 --> 00:35:27,440
human biology because they're a they
were cancer to begin with and B as you

1616
00:35:27,440 --> 00:35:27,450
were cancer to begin with and B as you
 

1617
00:35:27,450 --> 00:35:30,200
were cancer to begin with and B as you
passage them and they proliferate in a

1618
00:35:30,200 --> 00:35:30,210
passage them and they proliferate in a
 

1619
00:35:30,210 --> 00:35:32,420
passage them and they proliferate in a
dish they become because of the genomic

1620
00:35:32,420 --> 00:35:32,430
dish they become because of the genomic
 

1621
00:35:32,430 --> 00:35:33,859
dish they become because of the genomic
instability even less

1622
00:35:33,859 --> 00:35:33,869
instability even less
 

1623
00:35:33,869 --> 00:35:36,710
instability even less
similar to human biology now we have

1624
00:35:36,710 --> 00:35:36,720
similar to human biology now we have
 

1625
00:35:36,720 --> 00:35:40,009
similar to human biology now we have
these stem cell derived models we have

1626
00:35:40,009 --> 00:35:40,019
these stem cell derived models we have
 

1627
00:35:40,019 --> 00:35:42,829
these stem cell derived models we have
the capability to reasonably robustly

1628
00:35:42,829 --> 00:35:42,839
the capability to reasonably robustly
 

1629
00:35:42,839 --> 00:35:45,289
the capability to reasonably robustly
not quite at the right scale yet but

1630
00:35:45,289 --> 00:35:45,299
not quite at the right scale yet but
 

1631
00:35:45,299 --> 00:35:48,289
not quite at the right scale yet but
close to derive what's called organoids

1632
00:35:48,289 --> 00:35:48,299
close to derive what's called organoids
 

1633
00:35:48,299 --> 00:35:51,079
close to derive what's called organoids
which are these teeny little sort of

1634
00:35:51,079 --> 00:35:51,089
which are these teeny little sort of
 

1635
00:35:51,089 --> 00:35:56,900
which are these teeny little sort of
multicellular organ of an organ system

1636
00:35:56,900 --> 00:35:56,910
multicellular organ of an organ system
 

1637
00:35:56,910 --> 00:35:58,999
multicellular organ of an organ system
so there's cerebral organoids and liver

1638
00:35:58,999 --> 00:35:59,009
so there's cerebral organoids and liver
 

1639
00:35:59,009 --> 00:36:01,789
so there's cerebral organoids and liver
organoids and kidney organoids and yeah

1640
00:36:01,789 --> 00:36:01,799
organoids and kidney organoids and yeah
 

1641
00:36:01,799 --> 00:36:04,160
organoids and kidney organoids and yeah
brain organize organize possibly the

1642
00:36:04,160 --> 00:36:04,170
brain organize organize possibly the
 

1643
00:36:04,170 --> 00:36:08,930
brain organize organize possibly the
coolest thing I've ever seen and then I

1644
00:36:08,930 --> 00:36:08,940
coolest thing I've ever seen and then I
 

1645
00:36:08,940 --> 00:36:11,089
coolest thing I've ever seen and then I
think we're starting to see things like

1646
00:36:11,089 --> 00:36:11,099
think we're starting to see things like
 

1647
00:36:11,099 --> 00:36:13,789
think we're starting to see things like
connecting these organize to each other

1648
00:36:13,789 --> 00:36:13,799
connecting these organize to each other
 

1649
00:36:13,799 --> 00:36:15,319
connecting these organize to each other
so that you could actually start and

1650
00:36:15,319 --> 00:36:15,329
so that you could actually start and
 

1651
00:36:15,329 --> 00:36:16,670
so that you could actually start and
there's some really cool papers that

1652
00:36:16,670 --> 00:36:16,680
there's some really cool papers that
 

1653
00:36:16,680 --> 00:36:18,410
there's some really cool papers that
start to do that where you can actually

1654
00:36:18,410 --> 00:36:18,420
start to do that where you can actually
 

1655
00:36:18,420 --> 00:36:20,120
start to do that where you can actually
start to say okay can we do multi organ

1656
00:36:20,120 --> 00:36:20,130
start to say okay can we do multi organ
 

1657
00:36:20,130 --> 00:36:23,180
start to say okay can we do multi organ
system stuff there's many challenges

1658
00:36:23,180 --> 00:36:23,190
system stuff there's many challenges
 

1659
00:36:23,190 --> 00:36:26,839
system stuff there's many challenges
that it's not easy by any stretch but it

1660
00:36:26,839 --> 00:36:26,849
that it's not easy by any stretch but it
 

1661
00:36:26,849 --> 00:36:29,329
that it's not easy by any stretch but it
might I'm sure people will figure it out

1662
00:36:29,329 --> 00:36:29,339
might I'm sure people will figure it out
 

1663
00:36:29,339 --> 00:36:31,759
might I'm sure people will figure it out
and in three years or five years there

1664
00:36:31,759 --> 00:36:31,769
and in three years or five years there
 

1665
00:36:31,769 --> 00:36:34,009
and in three years or five years there
will be disease moles that we could make

1666
00:36:34,009 --> 00:36:34,019
will be disease moles that we could make
 

1667
00:36:34,019 --> 00:36:35,630
will be disease moles that we could make
for things that we can't make today yeah

1668
00:36:35,630 --> 00:36:35,640
for things that we can't make today yeah
 

1669
00:36:35,640 --> 00:36:37,460
for things that we can't make today yeah
and this conversation would seem almost

1670
00:36:37,460 --> 00:36:37,470
and this conversation would seem almost
 

1671
00:36:37,470 --> 00:36:39,950
and this conversation would seem almost
outdated with a kind of scale that could

1672
00:36:39,950 --> 00:36:39,960
outdated with a kind of scale that could
 

1673
00:36:39,960 --> 00:36:41,410
outdated with a kind of scale that could
be achieved in like three years

1674
00:36:41,410 --> 00:36:41,420
be achieved in like three years
 

1675
00:36:41,420 --> 00:36:44,859
be achieved in like three years
that would be so cool the you've

1676
00:36:44,859 --> 00:36:44,869
that would be so cool the you've
 

1677
00:36:44,869 --> 00:36:47,420
that would be so cool the you've
co-founded Coursera with injurying and

1678
00:36:47,420 --> 00:36:47,430
co-founded Coursera with injurying and
 

1679
00:36:47,430 --> 00:36:50,680
co-founded Coursera with injurying and
were part of the whole MOOC revolution

1680
00:36:50,680 --> 00:36:50,690
were part of the whole MOOC revolution
 

1681
00:36:50,690 --> 00:36:54,170
were part of the whole MOOC revolution
so to jump topics a little bit can you

1682
00:36:54,170 --> 00:36:54,180
so to jump topics a little bit can you
 

1683
00:36:54,180 --> 00:36:56,650
so to jump topics a little bit can you
maybe tell the origin story of the

1684
00:36:56,650 --> 00:36:56,660
maybe tell the origin story of the
 

1685
00:36:56,660 --> 00:36:59,479
maybe tell the origin story of the
history the origin story of MOOCs of

1686
00:36:59,479 --> 00:36:59,489
history the origin story of MOOCs of
 

1687
00:36:59,489 --> 00:37:04,039
history the origin story of MOOCs of
Coursera and in general the your

1688
00:37:04,039 --> 00:37:04,049
Coursera and in general the your
 

1689
00:37:04,049 --> 00:37:08,259
Coursera and in general the your
teaching to huge audiences on a very

1690
00:37:08,259 --> 00:37:08,269
teaching to huge audiences on a very
 

1691
00:37:08,269 --> 00:37:12,410
teaching to huge audiences on a very
sort of impactful topic of AI general so

1692
00:37:12,410 --> 00:37:12,420
sort of impactful topic of AI general so
 

1693
00:37:12,420 --> 00:37:15,829
sort of impactful topic of AI general so
I think the origin story of MOOCs

1694
00:37:15,829 --> 00:37:15,839
I think the origin story of MOOCs
 

1695
00:37:15,839 --> 00:37:18,170
I think the origin story of MOOCs
emanates from a number of efforts that

1696
00:37:18,170 --> 00:37:18,180
emanates from a number of efforts that
 

1697
00:37:18,180 --> 00:37:21,549
emanates from a number of efforts that
occurred at Stanford University around

1698
00:37:21,549 --> 00:37:21,559
occurred at Stanford University around
 

1699
00:37:21,559 --> 00:37:26,690
occurred at Stanford University around
you know the late 2000s where different

1700
00:37:26,690 --> 00:37:26,700
you know the late 2000s where different
 

1701
00:37:26,700 --> 00:37:28,970
you know the late 2000s where different
individuals within Stanford myself

1702
00:37:28,970 --> 00:37:28,980
individuals within Stanford myself
 

1703
00:37:28,980 --> 00:37:31,489
individuals within Stanford myself
included were getting really excited

1704
00:37:31,489 --> 00:37:31,499
included were getting really excited
 

1705
00:37:31,499 --> 00:37:34,089
included were getting really excited
about the opportunities of using online

1706
00:37:34,089 --> 00:37:34,099
about the opportunities of using online
 

1707
00:37:34,099 --> 00:37:36,819
about the opportunities of using online
technologies as a way of achieving both

1708
00:37:36,819 --> 00:37:36,829
technologies as a way of achieving both
 

1709
00:37:36,829 --> 00:37:39,319
technologies as a way of achieving both
improved quality of teaching and also

1710
00:37:39,319 --> 00:37:39,329
improved quality of teaching and also
 

1711
00:37:39,329 --> 00:37:43,940
improved quality of teaching and also
improved scale and so Andrew for

1712
00:37:43,940 --> 00:37:43,950
improved scale and so Andrew for
 

1713
00:37:43,950 --> 00:37:47,569
improved scale and so Andrew for
instance led the the

1714
00:37:47,569 --> 00:37:47,579
instance led the the
 

1715
00:37:47,579 --> 00:37:49,190
instance led the the
for engineering everywhere which was

1716
00:37:49,190 --> 00:37:49,200
for engineering everywhere which was
 

1717
00:37:49,200 --> 00:37:51,140
for engineering everywhere which was
sort of an attempt to take ten Stanford

1718
00:37:51,140 --> 00:37:51,150
sort of an attempt to take ten Stanford
 

1719
00:37:51,150 --> 00:37:54,289
sort of an attempt to take ten Stanford
courses and put them online just as you

1720
00:37:54,289 --> 00:37:54,299
courses and put them online just as you
 

1721
00:37:54,299 --> 00:37:57,440
courses and put them online just as you
know video lectures I led an effort

1722
00:37:57,440 --> 00:37:57,450
know video lectures I led an effort
 

1723
00:37:57,450 --> 00:38:00,019
know video lectures I led an effort
within Stanford to take some of the

1724
00:38:00,019 --> 00:38:00,029
within Stanford to take some of the
 

1725
00:38:00,029 --> 00:38:02,329
within Stanford to take some of the
courses and really create a very

1726
00:38:02,329 --> 00:38:02,339
courses and really create a very
 

1727
00:38:02,339 --> 00:38:05,120
courses and really create a very
different teaching model that broke

1728
00:38:05,120 --> 00:38:05,130
different teaching model that broke
 

1729
00:38:05,130 --> 00:38:08,180
different teaching model that broke
those up into smaller units and had some

1730
00:38:08,180 --> 00:38:08,190
those up into smaller units and had some
 

1731
00:38:08,190 --> 00:38:10,279
those up into smaller units and had some
of those embedded interactions and and

1732
00:38:10,279 --> 00:38:10,289
of those embedded interactions and and
 

1733
00:38:10,289 --> 00:38:12,969
of those embedded interactions and and
so on which got a lot of support from

1734
00:38:12,969 --> 00:38:12,979
so on which got a lot of support from
 

1735
00:38:12,979 --> 00:38:16,009
so on which got a lot of support from
University leaders because they felt

1736
00:38:16,009 --> 00:38:16,019
University leaders because they felt
 

1737
00:38:16,019 --> 00:38:17,509
University leaders because they felt
like it was potentially a way of

1738
00:38:17,509 --> 00:38:17,519
like it was potentially a way of
 

1739
00:38:17,519 --> 00:38:19,099
like it was potentially a way of
improving the quality of instruction in

1740
00:38:19,099 --> 00:38:19,109
improving the quality of instruction in
 

1741
00:38:19,109 --> 00:38:21,170
improving the quality of instruction in
Stanford by moving to what's now called

1742
00:38:21,170 --> 00:38:21,180
Stanford by moving to what's now called
 

1743
00:38:21,180 --> 00:38:24,049
Stanford by moving to what's now called
the flipped classroom model and so those

1744
00:38:24,049 --> 00:38:24,059
the flipped classroom model and so those
 

1745
00:38:24,059 --> 00:38:26,749
the flipped classroom model and so those
efforts eventually sort of started to

1746
00:38:26,749 --> 00:38:26,759
efforts eventually sort of started to
 

1747
00:38:26,759 --> 00:38:28,759
efforts eventually sort of started to
interplay with each other and created a

1748
00:38:28,759 --> 00:38:28,769
interplay with each other and created a
 

1749
00:38:28,769 --> 00:38:30,410
interplay with each other and created a
tremendous sense of excitement and

1750
00:38:30,410 --> 00:38:30,420
tremendous sense of excitement and
 

1751
00:38:30,420 --> 00:38:31,940
tremendous sense of excitement and
energy within the Stanford community

1752
00:38:31,940 --> 00:38:31,950
energy within the Stanford community
 

1753
00:38:31,950 --> 00:38:35,660
energy within the Stanford community
about the potential of online teaching

1754
00:38:35,660 --> 00:38:35,670
about the potential of online teaching
 

1755
00:38:35,670 --> 00:38:40,279
about the potential of online teaching
and led in the fall of 2011 to the

1756
00:38:40,279 --> 00:38:40,289
and led in the fall of 2011 to the
 

1757
00:38:40,289 --> 00:38:43,940
and led in the fall of 2011 to the
launch of the first inferred MOOCs by

1758
00:38:43,940 --> 00:38:43,950
launch of the first inferred MOOCs by
 

1759
00:38:43,950 --> 00:38:46,219
launch of the first inferred MOOCs by
the way MOOCs it's probably impossible

1760
00:38:46,219 --> 00:38:46,229
the way MOOCs it's probably impossible
 

1761
00:38:46,229 --> 00:38:47,870
the way MOOCs it's probably impossible
that people don't know but I guess

1762
00:38:47,870 --> 00:38:47,880
that people don't know but I guess
 

1763
00:38:47,880 --> 00:38:50,749
that people don't know but I guess
massive open online courses but online

1764
00:38:50,749 --> 00:38:50,759
massive open online courses but online
 

1765
00:38:50,759 --> 00:38:53,269
massive open online courses but online
courses so they're not come up with the

1766
00:38:53,269 --> 00:38:53,279
courses so they're not come up with the
 

1767
00:38:53,279 --> 00:38:56,539
courses so they're not come up with the
acronym I'm not particularly fond of the

1768
00:38:56,539 --> 00:38:56,549
acronym I'm not particularly fond of the
 

1769
00:38:56,549 --> 00:38:58,309
acronym I'm not particularly fond of the
acronym but it is what it is where this

1770
00:38:58,309 --> 00:38:58,319
acronym but it is what it is where this
 

1771
00:38:58,319 --> 00:39:00,410
acronym but it is what it is where this
Big Bang is not a great term for the

1772
00:39:00,410 --> 00:39:00,420
Big Bang is not a great term for the
 

1773
00:39:00,420 --> 00:39:01,969
Big Bang is not a great term for the
start of the universe but it is what it

1774
00:39:01,969 --> 00:39:01,979
start of the universe but it is what it
 

1775
00:39:01,979 --> 00:39:07,069
start of the universe but it is what it
is probably so anyway we so those

1776
00:39:07,069 --> 00:39:07,079
is probably so anyway we so those
 

1777
00:39:07,079 --> 00:39:09,979
is probably so anyway we so those
courses launched in in the fall of 2011

1778
00:39:09,979 --> 00:39:09,989
courses launched in in the fall of 2011
 

1779
00:39:09,989 --> 00:39:13,370
courses launched in in the fall of 2011
and there were within a matter of weeks

1780
00:39:13,370 --> 00:39:13,380
and there were within a matter of weeks
 

1781
00:39:13,380 --> 00:39:16,609
and there were within a matter of weeks
with no real publicity campaign just a

1782
00:39:16,609 --> 00:39:16,619
with no real publicity campaign just a
 

1783
00:39:16,619 --> 00:39:19,420
with no real publicity campaign just a
New York Times article that went viral

1784
00:39:19,420 --> 00:39:19,430
New York Times article that went viral
 

1785
00:39:19,430 --> 00:39:22,099
New York Times article that went viral
about a hundred thousand students or

1786
00:39:22,099 --> 00:39:22,109
about a hundred thousand students or
 

1787
00:39:22,109 --> 00:39:25,539
about a hundred thousand students or
more in each of those courses and I

1788
00:39:25,539 --> 00:39:25,549
more in each of those courses and I
 

1789
00:39:25,549 --> 00:39:28,699
more in each of those courses and I
remember this conversation that Andrew

1790
00:39:28,699 --> 00:39:28,709
remember this conversation that Andrew
 

1791
00:39:28,709 --> 00:39:31,910
remember this conversation that Andrew
and I had was like wow just there's this

1792
00:39:31,910 --> 00:39:31,920
and I had was like wow just there's this
 

1793
00:39:31,920 --> 00:39:35,150
and I had was like wow just there's this
real need here and I think we both felt

1794
00:39:35,150 --> 00:39:35,160
real need here and I think we both felt
 

1795
00:39:35,160 --> 00:39:38,870
real need here and I think we both felt
like sure we were accomplished academics

1796
00:39:38,870 --> 00:39:38,880
like sure we were accomplished academics
 

1797
00:39:38,880 --> 00:39:40,910
like sure we were accomplished academics
and we could go back and you know go

1798
00:39:40,910 --> 00:39:40,920
and we could go back and you know go
 

1799
00:39:40,920 --> 00:39:42,799
and we could go back and you know go
back to our lives write more papers but

1800
00:39:42,799 --> 00:39:42,809
back to our lives write more papers but
 

1801
00:39:42,809 --> 00:39:45,380
back to our lives write more papers but
if we did that then this wouldn't happen

1802
00:39:45,380 --> 00:39:45,390
if we did that then this wouldn't happen
 

1803
00:39:45,390 --> 00:39:47,420
if we did that then this wouldn't happen
and it seemed too important not to

1804
00:39:47,420 --> 00:39:47,430
and it seemed too important not to
 

1805
00:39:47,430 --> 00:39:50,599
and it seemed too important not to
happen and so we spent a fair bit of

1806
00:39:50,599 --> 00:39:50,609
happen and so we spent a fair bit of
 

1807
00:39:50,609 --> 00:39:53,299
happen and so we spent a fair bit of
time debating do we want to do this as a

1808
00:39:53,299 --> 00:39:53,309
time debating do we want to do this as a
 

1809
00:39:53,309 --> 00:39:55,969
time debating do we want to do this as a
Stanford efforts kind of building on

1810
00:39:55,969 --> 00:39:55,979
Stanford efforts kind of building on
 

1811
00:39:55,979 --> 00:39:57,559
Stanford efforts kind of building on
what we'd started do we want to do this

1812
00:39:57,559 --> 00:39:57,569
what we'd started do we want to do this
 

1813
00:39:57,569 --> 00:40:00,049
what we'd started do we want to do this
as a for-profit company doing this is a

1814
00:40:00,049 --> 00:40:00,059
as a for-profit company doing this is a
 

1815
00:40:00,059 --> 00:40:01,520
as a for-profit company doing this is a
non-profit and we decided

1816
00:40:01,520 --> 00:40:01,530
non-profit and we decided
 

1817
00:40:01,530 --> 00:40:03,110
non-profit and we decided
ultimately to do it as we did with

1818
00:40:03,110 --> 00:40:03,120
ultimately to do it as we did with
 

1819
00:40:03,120 --> 00:40:08,990
ultimately to do it as we did with
Coursera and so you know we started

1820
00:40:08,990 --> 00:40:09,000
Coursera and so you know we started
 

1821
00:40:09,000 --> 00:40:10,670
Coursera and so you know we started
really operating as a company at the

1822
00:40:10,670 --> 00:40:10,680
really operating as a company at the
 

1823
00:40:10,680 --> 00:40:16,850
really operating as a company at the
beginning of 2012 but how did you was

1824
00:40:16,850 --> 00:40:16,860
beginning of 2012 but how did you was
 

1825
00:40:16,860 --> 00:40:19,970
beginning of 2012 but how did you was
that really surprising to you how how do

1826
00:40:19,970 --> 00:40:19,980
that really surprising to you how how do
 

1827
00:40:19,980 --> 00:40:21,890
that really surprising to you how how do
you at that how did you at that time and

1828
00:40:21,890 --> 00:40:21,900
you at that how did you at that time and
 

1829
00:40:21,900 --> 00:40:26,570
you at that how did you at that time and
at this time make sense of this need for

1830
00:40:26,570 --> 00:40:26,580
at this time make sense of this need for
 

1831
00:40:26,580 --> 00:40:28,100
at this time make sense of this need for
sort of global education you mentioned

1832
00:40:28,100 --> 00:40:28,110
sort of global education you mentioned
 

1833
00:40:28,110 --> 00:40:29,870
sort of global education you mentioned
that you felt that while the the

1834
00:40:29,870 --> 00:40:29,880
that you felt that while the the
 

1835
00:40:29,880 --> 00:40:32,630
that you felt that while the the
popularity indicates that there's a

1836
00:40:32,630 --> 00:40:32,640
popularity indicates that there's a
 

1837
00:40:32,640 --> 00:40:36,490
popularity indicates that there's a
hunger for sort of globalization of

1838
00:40:36,490 --> 00:40:36,500
hunger for sort of globalization of
 

1839
00:40:36,500 --> 00:40:41,570
hunger for sort of globalization of
learning I think there is a hunger for

1840
00:40:41,570 --> 00:40:41,580
learning I think there is a hunger for
 

1841
00:40:41,580 --> 00:40:45,740
learning I think there is a hunger for
learning that you know globalization is

1842
00:40:45,740 --> 00:40:45,750
learning that you know globalization is
 

1843
00:40:45,750 --> 00:40:47,090
learning that you know globalization is
part of it but I think it's just a

1844
00:40:47,090 --> 00:40:47,100
part of it but I think it's just a
 

1845
00:40:47,100 --> 00:40:49,370
part of it but I think it's just a
hunger for learning the world has

1846
00:40:49,370 --> 00:40:49,380
hunger for learning the world has
 

1847
00:40:49,380 --> 00:40:52,190
hunger for learning the world has
changed in the last 50 years it used to

1848
00:40:52,190 --> 00:40:52,200
changed in the last 50 years it used to
 

1849
00:40:52,200 --> 00:40:55,160
changed in the last 50 years it used to
be that you finished college you got a

1850
00:40:55,160 --> 00:40:55,170
be that you finished college you got a
 

1851
00:40:55,170 --> 00:40:57,380
be that you finished college you got a
job by and large the skills that you

1852
00:40:57,380 --> 00:40:57,390
job by and large the skills that you
 

1853
00:40:57,390 --> 00:40:59,930
job by and large the skills that you
learned in college were pretty much what

1854
00:40:59,930 --> 00:40:59,940
learned in college were pretty much what
 

1855
00:40:59,940 --> 00:41:01,880
learned in college were pretty much what
got you through the rest of your job

1856
00:41:01,880 --> 00:41:01,890
got you through the rest of your job
 

1857
00:41:01,890 --> 00:41:03,920
got you through the rest of your job
history and and yeah you learned some

1858
00:41:03,920 --> 00:41:03,930
history and and yeah you learned some
 

1859
00:41:03,930 --> 00:41:06,260
history and and yeah you learned some
stuff but it wasn't a dramatic change

1860
00:41:06,260 --> 00:41:06,270
stuff but it wasn't a dramatic change
 

1861
00:41:06,270 --> 00:41:09,290
stuff but it wasn't a dramatic change
today we're in a world where the skills

1862
00:41:09,290 --> 00:41:09,300
today we're in a world where the skills
 

1863
00:41:09,300 --> 00:41:11,570
today we're in a world where the skills
that you need for a lot of jobs they

1864
00:41:11,570 --> 00:41:11,580
that you need for a lot of jobs they
 

1865
00:41:11,580 --> 00:41:12,980
that you need for a lot of jobs they
didn't even exist when you went to

1866
00:41:12,980 --> 00:41:12,990
didn't even exist when you went to
 

1867
00:41:12,990 --> 00:41:15,050
didn't even exist when you went to
college and the jobs and many of the

1868
00:41:15,050 --> 00:41:15,060
college and the jobs and many of the
 

1869
00:41:15,060 --> 00:41:16,460
college and the jobs and many of the
jobs that exist when you went the

1870
00:41:16,460 --> 00:41:16,470
jobs that exist when you went the
 

1871
00:41:16,470 --> 00:41:19,280
jobs that exist when you went the
college don't even exist today or dying

1872
00:41:19,280 --> 00:41:19,290
college don't even exist today or dying
 

1873
00:41:19,290 --> 00:41:22,580
college don't even exist today or dying
so part of that is due to AI but not

1874
00:41:22,580 --> 00:41:22,590
so part of that is due to AI but not
 

1875
00:41:22,590 --> 00:41:27,020
so part of that is due to AI but not
only and we need to find a way of

1876
00:41:27,020 --> 00:41:27,030
only and we need to find a way of
 

1877
00:41:27,030 --> 00:41:29,780
only and we need to find a way of
keeping people giving people access to

1878
00:41:29,780 --> 00:41:29,790
keeping people giving people access to
 

1879
00:41:29,790 --> 00:41:31,370
keeping people giving people access to
the skills that they need today and I

1880
00:41:31,370 --> 00:41:31,380
the skills that they need today and I
 

1881
00:41:31,380 --> 00:41:33,620
the skills that they need today and I
think that's really what's driving a lot

1882
00:41:33,620 --> 00:41:33,630
think that's really what's driving a lot
 

1883
00:41:33,630 --> 00:41:36,800
think that's really what's driving a lot
of this hunger so I think if we even

1884
00:41:36,800 --> 00:41:36,810
of this hunger so I think if we even
 

1885
00:41:36,810 --> 00:41:39,830
of this hunger so I think if we even
take a step back all for you all the

1886
00:41:39,830 --> 00:41:39,840
take a step back all for you all the
 

1887
00:41:39,840 --> 00:41:42,080
take a step back all for you all the
start in trying to think of new ways to

1888
00:41:42,080 --> 00:41:42,090
start in trying to think of new ways to
 

1889
00:41:42,090 --> 00:41:45,880
start in trying to think of new ways to
teach or to you know new ways to sort of

1890
00:41:45,880 --> 00:41:45,890
teach or to you know new ways to sort of
 

1891
00:41:45,890 --> 00:41:48,740
teach or to you know new ways to sort of
organize the material and present the

1892
00:41:48,740 --> 00:41:48,750
organize the material and present the
 

1893
00:41:48,750 --> 00:41:50,180
organize the material and present the
material in a way that would help the

1894
00:41:50,180 --> 00:41:50,190
material in a way that would help the
 

1895
00:41:50,190 --> 00:41:52,400
material in a way that would help the
education process the better gotcha yeah

1896
00:41:52,400 --> 00:41:52,410
education process the better gotcha yeah
 

1897
00:41:52,410 --> 00:41:56,660
education process the better gotcha yeah
so what have you learned about effective

1898
00:41:56,660 --> 00:41:56,670
so what have you learned about effective
 

1899
00:41:56,670 --> 00:41:58,550
so what have you learned about effective
education from this process of playing

1900
00:41:58,550 --> 00:41:58,560
education from this process of playing
 

1901
00:41:58,560 --> 00:42:02,000
education from this process of playing
of experimenting with different ideas so

1902
00:42:02,000 --> 00:42:02,010
of experimenting with different ideas so
 

1903
00:42:02,010 --> 00:42:04,580
of experimenting with different ideas so
we learned a number of things some of

1904
00:42:04,580 --> 00:42:04,590
we learned a number of things some of
 

1905
00:42:04,590 --> 00:42:06,950
we learned a number of things some of
which I think could translate back and

1906
00:42:06,950 --> 00:42:06,960
which I think could translate back and
 

1907
00:42:06,960 --> 00:42:08,900
which I think could translate back and
have translated back effectively to how

1908
00:42:08,900 --> 00:42:08,910
have translated back effectively to how
 

1909
00:42:08,910 --> 00:42:10,580
have translated back effectively to how
people teach on campus and some of which

1910
00:42:10,580 --> 00:42:10,590
people teach on campus and some of which
 

1911
00:42:10,590 --> 00:42:12,950
people teach on campus and some of which
I think are more specific to people who

1912
00:42:12,950 --> 00:42:12,960
I think are more specific to people who
 

1913
00:42:12,960 --> 00:42:14,720
I think are more specific to people who
learn online

1914
00:42:14,720 --> 00:42:14,730
learn online
 

1915
00:42:14,730 --> 00:42:17,180
learn online
and more sort of people who learn as

1916
00:42:17,180 --> 00:42:17,190
and more sort of people who learn as
 

1917
00:42:17,190 --> 00:42:19,910
and more sort of people who learn as
part of their daily life so we learned

1918
00:42:19,910 --> 00:42:19,920
part of their daily life so we learned
 

1919
00:42:19,920 --> 00:42:22,220
part of their daily life so we learned
for instance very quickly that short is

1920
00:42:22,220 --> 00:42:22,230
for instance very quickly that short is
 

1921
00:42:22,230 --> 00:42:25,400
for instance very quickly that short is
better so people who are especially in

1922
00:42:25,400 --> 00:42:25,410
better so people who are especially in
 

1923
00:42:25,410 --> 00:42:28,220
better so people who are especially in
the workforce can't do a 15-week

1924
00:42:28,220 --> 00:42:28,230
the workforce can't do a 15-week
 

1925
00:42:28,230 --> 00:42:31,130
the workforce can't do a 15-week
semester long course they just can't fit

1926
00:42:31,130 --> 00:42:31,140
semester long course they just can't fit
 

1927
00:42:31,140 --> 00:42:32,450
semester long course they just can't fit
that into their lives

1928
00:42:32,450 --> 00:42:32,460
that into their lives
 

1929
00:42:32,460 --> 00:42:34,850
that into their lives
shortly can you uh can you describe the

1930
00:42:34,850 --> 00:42:34,860
shortly can you uh can you describe the
 

1931
00:42:34,860 --> 00:42:37,490
shortly can you uh can you describe the
shortness of what the the the entirety

1932
00:42:37,490 --> 00:42:37,500
shortness of what the the the entirety
 

1933
00:42:37,500 --> 00:42:40,070
shortness of what the the the entirety
so every aspects of the little lecture

1934
00:42:40,070 --> 00:42:40,080
so every aspects of the little lecture
 

1935
00:42:40,080 --> 00:42:42,080
so every aspects of the little lecture
short this the less your short

1936
00:42:42,080 --> 00:42:42,090
short this the less your short
 

1937
00:42:42,090 --> 00:42:44,600
short this the less your short
the course is short both we started out

1938
00:42:44,600 --> 00:42:44,610
the course is short both we started out
 

1939
00:42:44,610 --> 00:42:47,510
the course is short both we started out
you know the first online education

1940
00:42:47,510 --> 00:42:47,520
you know the first online education
 

1941
00:42:47,520 --> 00:42:49,160
you know the first online education
efforts were actually mi t--'s

1942
00:42:49,160 --> 00:42:49,170
efforts were actually mi t--'s
 

1943
00:42:49,170 --> 00:42:51,230
efforts were actually mi t--'s
OpenCourseWare initiatives and that was

1944
00:42:51,230 --> 00:42:51,240
OpenCourseWare initiatives and that was
 

1945
00:42:51,240 --> 00:42:54,890
OpenCourseWare initiatives and that was
you know recording of classroom lectures

1946
00:42:54,890 --> 00:42:54,900
you know recording of classroom lectures
 

1947
00:42:54,900 --> 00:42:56,840
you know recording of classroom lectures
and you know hour and a half or

1948
00:42:56,840 --> 00:42:56,850
and you know hour and a half or
 

1949
00:42:56,850 --> 00:42:58,640
and you know hour and a half or
something like that yeah that didn't

1950
00:42:58,640 --> 00:42:58,650
something like that yeah that didn't
 

1951
00:42:58,650 --> 00:43:00,860
something like that yeah that didn't
really work very well I mean some people

1952
00:43:00,860 --> 00:43:00,870
really work very well I mean some people
 

1953
00:43:00,870 --> 00:43:03,320
really work very well I mean some people
benefit I mean of course they did but

1954
00:43:03,320 --> 00:43:03,330
benefit I mean of course they did but
 

1955
00:43:03,330 --> 00:43:05,300
benefit I mean of course they did but
it's not really very palatable

1956
00:43:05,300 --> 00:43:05,310
it's not really very palatable
 

1957
00:43:05,310 --> 00:43:09,380
it's not really very palatable
experience for someone who has a job and

1958
00:43:09,380 --> 00:43:09,390
experience for someone who has a job and
 

1959
00:43:09,390 --> 00:43:12,590
experience for someone who has a job and
you know three kids and that they need

1960
00:43:12,590 --> 00:43:12,600
you know three kids and that they need
 

1961
00:43:12,600 --> 00:43:15,170
you know three kids and that they need
to run errands and such they can't fit

1962
00:43:15,170 --> 00:43:15,180
to run errands and such they can't fit
 

1963
00:43:15,180 --> 00:43:19,250
to run errands and such they can't fit
15 weeks into their life and and the

1964
00:43:19,250 --> 00:43:19,260
15 weeks into their life and and the
 

1965
00:43:19,260 --> 00:43:20,990
15 weeks into their life and and the
hour and a half is really hard so we

1966
00:43:20,990 --> 00:43:21,000
hour and a half is really hard so we
 

1967
00:43:21,000 --> 00:43:23,660
hour and a half is really hard so we
learned very quickly and we started out

1968
00:43:23,660 --> 00:43:23,670
learned very quickly and we started out
 

1969
00:43:23,670 --> 00:43:27,350
learned very quickly and we started out
with short video modules and over time

1970
00:43:27,350 --> 00:43:27,360
with short video modules and over time
 

1971
00:43:27,360 --> 00:43:29,270
with short video modules and over time
we made them shorter because we realized

1972
00:43:29,270 --> 00:43:29,280
we made them shorter because we realized
 

1973
00:43:29,280 --> 00:43:31,820
we made them shorter because we realized
that 15 minutes was still too long if

1974
00:43:31,820 --> 00:43:31,830
that 15 minutes was still too long if
 

1975
00:43:31,830 --> 00:43:33,500
that 15 minutes was still too long if
you want to fit in when you're waiting

1976
00:43:33,500 --> 00:43:33,510
you want to fit in when you're waiting
 

1977
00:43:33,510 --> 00:43:35,030
you want to fit in when you're waiting
in line for your kids doctor's

1978
00:43:35,030 --> 00:43:35,040
in line for your kids doctor's
 

1979
00:43:35,040 --> 00:43:37,870
in line for your kids doctor's
appointment it's better if it's 5 to 7

1980
00:43:37,870 --> 00:43:37,880
appointment it's better if it's 5 to 7
 

1981
00:43:37,880 --> 00:43:42,200
appointment it's better if it's 5 to 7
we learned that 15 week courses don't

1982
00:43:42,200 --> 00:43:42,210
we learned that 15 week courses don't
 

1983
00:43:42,210 --> 00:43:43,640
we learned that 15 week courses don't
work and you really want to break this

1984
00:43:43,640 --> 00:43:43,650
work and you really want to break this
 

1985
00:43:43,650 --> 00:43:45,410
work and you really want to break this
up into shorter units so that there is a

1986
00:43:45,410 --> 00:43:45,420
up into shorter units so that there is a
 

1987
00:43:45,420 --> 00:43:47,330
up into shorter units so that there is a
natural completion point gives people a

1988
00:43:47,330 --> 00:43:47,340
natural completion point gives people a
 

1989
00:43:47,340 --> 00:43:48,830
natural completion point gives people a
sense of they're really close to

1990
00:43:48,830 --> 00:43:48,840
sense of they're really close to
 

1991
00:43:48,840 --> 00:43:50,720
sense of they're really close to
finishing something meaningful they can

1992
00:43:50,720 --> 00:43:50,730
finishing something meaningful they can
 

1993
00:43:50,730 --> 00:43:52,040
finishing something meaningful they can
always come back and take part two and

1994
00:43:52,040 --> 00:43:52,050
always come back and take part two and
 

1995
00:43:52,050 --> 00:43:54,350
always come back and take part two and
part three we also learned that

1996
00:43:54,350 --> 00:43:54,360
part three we also learned that
 

1997
00:43:54,360 --> 00:43:56,690
part three we also learned that
compressing the content works really

1998
00:43:56,690 --> 00:43:56,700
compressing the content works really
 

1999
00:43:56,700 --> 00:43:59,450
compressing the content works really
well because if some people that pace

2000
00:43:59,450 --> 00:43:59,460
well because if some people that pace
 

2001
00:43:59,460 --> 00:44:01,550
well because if some people that pace
works well for others they can always

2002
00:44:01,550 --> 00:44:01,560
works well for others they can always
 

2003
00:44:01,560 --> 00:44:04,190
works well for others they can always
rewind and watch again and so people

2004
00:44:04,190 --> 00:44:04,200
rewind and watch again and so people
 

2005
00:44:04,200 --> 00:44:06,050
rewind and watch again and so people
have the ability to then learn at their

2006
00:44:06,050 --> 00:44:06,060
have the ability to then learn at their
 

2007
00:44:06,060 --> 00:44:10,460
have the ability to then learn at their
own pace and so that flexibility the the

2008
00:44:10,460 --> 00:44:10,470
own pace and so that flexibility the the
 

2009
00:44:10,470 --> 00:44:12,050
own pace and so that flexibility the the
brevity and the flexibility are both

2010
00:44:12,050 --> 00:44:12,060
brevity and the flexibility are both
 

2011
00:44:12,060 --> 00:44:14,240
brevity and the flexibility are both
things that we found to be very

2012
00:44:14,240 --> 00:44:14,250
things that we found to be very
 

2013
00:44:14,250 --> 00:44:16,340
things that we found to be very
important we learned that engagement

2014
00:44:16,340 --> 00:44:16,350
important we learned that engagement
 

2015
00:44:16,350 --> 00:44:19,010
important we learned that engagement
during the content is important and the

2016
00:44:19,010 --> 00:44:19,020
during the content is important and the
 

2017
00:44:19,020 --> 00:44:20,720
during the content is important and the
quicker you give people feedback the

2018
00:44:20,720 --> 00:44:20,730
quicker you give people feedback the
 

2019
00:44:20,730 --> 00:44:22,250
quicker you give people feedback the
more likely they are to be engaged

2020
00:44:22,250 --> 00:44:22,260
more likely they are to be engaged
 

2021
00:44:22,260 --> 00:44:24,860
more likely they are to be engaged
hence the introduction of these which we

2022
00:44:24,860 --> 00:44:24,870
hence the introduction of these which we
 

2023
00:44:24,870 --> 00:44:26,870
hence the introduction of these which we
actually was an intuition that I had

2024
00:44:26,870 --> 00:44:26,880
actually was an intuition that I had
 

2025
00:44:26,880 --> 00:44:28,099
actually was an intuition that I had
going in and and

2026
00:44:28,099 --> 00:44:28,109
going in and and
 

2027
00:44:28,109 --> 00:44:30,880
going in and and
was then validated using data that

2028
00:44:30,880 --> 00:44:30,890
was then validated using data that
 

2029
00:44:30,890 --> 00:44:32,929
was then validated using data that
introducing some of these sort of little

2030
00:44:32,929 --> 00:44:32,939
introducing some of these sort of little
 

2031
00:44:32,939 --> 00:44:35,089
introducing some of these sort of little
quick micro quizzes into the lectures

2032
00:44:35,089 --> 00:44:35,099
quick micro quizzes into the lectures
 

2033
00:44:35,099 --> 00:44:37,579
quick micro quizzes into the lectures
really helps self graded as

2034
00:44:37,579 --> 00:44:37,589
really helps self graded as
 

2035
00:44:37,589 --> 00:44:39,559
really helps self graded as
automatically graded assessments really

2036
00:44:39,559 --> 00:44:39,569
automatically graded assessments really
 

2037
00:44:39,569 --> 00:44:41,239
automatically graded assessments really
help too because it gives people

2038
00:44:41,239 --> 00:44:41,249
help too because it gives people
 

2039
00:44:41,249 --> 00:44:43,819
help too because it gives people
feedback see there you are so all these

2040
00:44:43,819 --> 00:44:43,829
feedback see there you are so all these
 

2041
00:44:43,829 --> 00:44:46,339
feedback see there you are so all these
are valuable and then we learn about two

2042
00:44:46,339 --> 00:44:46,349
are valuable and then we learn about two
 

2043
00:44:46,349 --> 00:44:47,989
are valuable and then we learn about two
other things - oh we did some really

2044
00:44:47,989 --> 00:44:47,999
other things - oh we did some really
 

2045
00:44:47,999 --> 00:44:49,519
other things - oh we did some really
interesting experiments for instance on

2046
00:44:49,519 --> 00:44:49,529
interesting experiments for instance on
 

2047
00:44:49,529 --> 00:44:52,579
interesting experiments for instance on
though gender bias and how having a

2048
00:44:52,579 --> 00:44:52,589
though gender bias and how having a
 

2049
00:44:52,589 --> 00:44:55,329
though gender bias and how having a
female role model as an instructor can

2050
00:44:55,329 --> 00:44:55,339
female role model as an instructor can
 

2051
00:44:55,339 --> 00:44:59,419
female role model as an instructor can
change the balance of men to women in

2052
00:44:59,419 --> 00:44:59,429
change the balance of men to women in
 

2053
00:44:59,429 --> 00:45:01,759
change the balance of men to women in
terms of especially in stem courses and

2054
00:45:01,759 --> 00:45:01,769
terms of especially in stem courses and
 

2055
00:45:01,769 --> 00:45:04,219
terms of especially in stem courses and
you could do that online by doing a/b

2056
00:45:04,219 --> 00:45:04,229
you could do that online by doing a/b
 

2057
00:45:04,229 --> 00:45:06,019
you could do that online by doing a/b
testing in ways that would be really

2058
00:45:06,019 --> 00:45:06,029
testing in ways that would be really
 

2059
00:45:06,029 --> 00:45:07,999
testing in ways that would be really
difficult to go on campus oh that's

2060
00:45:07,999 --> 00:45:08,009
difficult to go on campus oh that's
 

2061
00:45:08,009 --> 00:45:10,640
difficult to go on campus oh that's
exciting but so the shortness the

2062
00:45:10,640 --> 00:45:10,650
exciting but so the shortness the
 

2063
00:45:10,650 --> 00:45:14,329
exciting but so the shortness the
compression I mean that's actually so

2064
00:45:14,329 --> 00:45:14,339
compression I mean that's actually so
 

2065
00:45:14,339 --> 00:45:16,519
compression I mean that's actually so
that that probably is true for all you

2066
00:45:16,519 --> 00:45:16,529
that that probably is true for all you
 

2067
00:45:16,529 --> 00:45:19,759
that that probably is true for all you
know good editing is always just

2068
00:45:19,759 --> 00:45:19,769
know good editing is always just
 

2069
00:45:19,769 --> 00:45:21,319
know good editing is always just
compressing the content making it

2070
00:45:21,319 --> 00:45:21,329
compressing the content making it
 

2071
00:45:21,329 --> 00:45:23,329
compressing the content making it
shorter so that puts a lot of burden on

2072
00:45:23,329 --> 00:45:23,339
shorter so that puts a lot of burden on
 

2073
00:45:23,339 --> 00:45:25,669
shorter so that puts a lot of burden on
the creator of the the instructor and

2074
00:45:25,669 --> 00:45:25,679
the creator of the the instructor and
 

2075
00:45:25,679 --> 00:45:27,910
the creator of the the instructor and
the creator of the educational content

2076
00:45:27,910 --> 00:45:27,920
the creator of the educational content
 

2077
00:45:27,920 --> 00:45:30,559
the creator of the educational content
probably most lectures at MIT or

2078
00:45:30,559 --> 00:45:30,569
probably most lectures at MIT or
 

2079
00:45:30,569 --> 00:45:33,890
probably most lectures at MIT or
Stanford could be five times shorter if

2080
00:45:33,890 --> 00:45:33,900
Stanford could be five times shorter if
 

2081
00:45:33,900 --> 00:45:37,219
Stanford could be five times shorter if
the preparation was put was put enough

2082
00:45:37,219 --> 00:45:37,229
the preparation was put was put enough
 

2083
00:45:37,229 --> 00:45:41,449
the preparation was put was put enough
so maybe people might disagree with that

2084
00:45:41,449 --> 00:45:41,459
so maybe people might disagree with that
 

2085
00:45:41,459 --> 00:45:44,179
so maybe people might disagree with that
but like the Christmas the clarity that

2086
00:45:44,179 --> 00:45:44,189
but like the Christmas the clarity that
 

2087
00:45:44,189 --> 00:45:47,439
but like the Christmas the clarity that
a lot of them like Coursera delivers is

2088
00:45:47,439 --> 00:45:47,449
a lot of them like Coursera delivers is
 

2089
00:45:47,449 --> 00:45:50,569
a lot of them like Coursera delivers is
how much effort does that take so first

2090
00:45:50,569 --> 00:45:50,579
how much effort does that take so first
 

2091
00:45:50,579 --> 00:45:53,989
how much effort does that take so first
of all let me say that it's not clear

2092
00:45:53,989 --> 00:45:53,999
of all let me say that it's not clear
 

2093
00:45:53,999 --> 00:45:56,059
of all let me say that it's not clear
that that crispness would work as

2094
00:45:56,059 --> 00:45:56,069
that that crispness would work as
 

2095
00:45:56,069 --> 00:45:58,640
that that crispness would work as
effectively and a face-to-face setting

2096
00:45:58,640 --> 00:45:58,650
effectively and a face-to-face setting
 

2097
00:45:58,650 --> 00:46:00,979
effectively and a face-to-face setting
because people need time to absorb the

2098
00:46:00,979 --> 00:46:00,989
because people need time to absorb the
 

2099
00:46:00,989 --> 00:46:03,769
because people need time to absorb the
material and so you need to at least

2100
00:46:03,769 --> 00:46:03,779
material and so you need to at least
 

2101
00:46:03,779 --> 00:46:05,630
material and so you need to at least
pause and give people a chance to

2102
00:46:05,630 --> 00:46:05,640
pause and give people a chance to
 

2103
00:46:05,640 --> 00:46:07,609
pause and give people a chance to
reflect that maybe practice and that's

2104
00:46:07,609 --> 00:46:07,619
reflect that maybe practice and that's
 

2105
00:46:07,619 --> 00:46:09,469
reflect that maybe practice and that's
what MOOCs do is that they give you

2106
00:46:09,469 --> 00:46:09,479
what MOOCs do is that they give you
 

2107
00:46:09,479 --> 00:46:11,749
what MOOCs do is that they give you
these chunks of content and then ask you

2108
00:46:11,749 --> 00:46:11,759
these chunks of content and then ask you
 

2109
00:46:11,759 --> 00:46:14,059
these chunks of content and then ask you
to practice with it and that's where I

2110
00:46:14,059 --> 00:46:14,069
to practice with it and that's where I
 

2111
00:46:14,069 --> 00:46:16,579
to practice with it and that's where I
think some of the newer pedagogy that

2112
00:46:16,579 --> 00:46:16,589
think some of the newer pedagogy that
 

2113
00:46:16,589 --> 00:46:18,709
think some of the newer pedagogy that
people are adopting and face-to-face

2114
00:46:18,709 --> 00:46:18,719
people are adopting and face-to-face
 

2115
00:46:18,719 --> 00:46:19,849
people are adopting and face-to-face
teaching they have to do with

2116
00:46:19,849 --> 00:46:19,859
teaching they have to do with
 

2117
00:46:19,859 --> 00:46:21,919
teaching they have to do with
interactive learning and such it can be

2118
00:46:21,919 --> 00:46:21,929
interactive learning and such it can be
 

2119
00:46:21,929 --> 00:46:26,599
interactive learning and such it can be
really helpful but both those approaches

2120
00:46:26,599 --> 00:46:26,609
really helpful but both those approaches
 

2121
00:46:26,609 --> 00:46:28,359
really helpful but both those approaches
whether you're doing that type of

2122
00:46:28,359 --> 00:46:28,369
whether you're doing that type of
 

2123
00:46:28,369 --> 00:46:31,009
whether you're doing that type of
methodology and online teaching or in

2124
00:46:31,009 --> 00:46:31,019
methodology and online teaching or in
 

2125
00:46:31,019 --> 00:46:33,559
methodology and online teaching or in
that flipped classroom interactive

2126
00:46:33,559 --> 00:46:33,569
that flipped classroom interactive
 

2127
00:46:33,569 --> 00:46:35,929
that flipped classroom interactive
teaching what site applause what's

2128
00:46:35,929 --> 00:46:35,939
teaching what site applause what's
 

2129
00:46:35,939 --> 00:46:39,349
teaching what site applause what's
flipped classroom flipped classroom is a

2130
00:46:39,349 --> 00:46:39,359
flipped classroom flipped classroom is a
 

2131
00:46:39,359 --> 00:46:41,809
flipped classroom flipped classroom is a
way in which online content is

2132
00:46:41,809 --> 00:46:41,819
way in which online content is
 

2133
00:46:41,819 --> 00:46:44,660
way in which online content is
used a supplement face-to-face teaching

2134
00:46:44,660 --> 00:46:44,670
used a supplement face-to-face teaching
 

2135
00:46:44,670 --> 00:46:46,910
used a supplement face-to-face teaching
where people watch the videos perhaps

2136
00:46:46,910 --> 00:46:46,920
where people watch the videos perhaps
 

2137
00:46:46,920 --> 00:46:48,949
where people watch the videos perhaps
and do some of the exercises before

2138
00:46:48,949 --> 00:46:48,959
and do some of the exercises before
 

2139
00:46:48,959 --> 00:46:50,809
and do some of the exercises before
coming to class and then when they come

2140
00:46:50,809 --> 00:46:50,819
coming to class and then when they come
 

2141
00:46:50,819 --> 00:46:52,609
coming to class and then when they come
to classes actually to do much deeper

2142
00:46:52,609 --> 00:46:52,619
to classes actually to do much deeper
 

2143
00:46:52,619 --> 00:46:55,299
to classes actually to do much deeper
problem solving oftentimes in a group

2144
00:46:55,299 --> 00:46:55,309
problem solving oftentimes in a group
 

2145
00:46:55,309 --> 00:46:58,329
problem solving oftentimes in a group
but any one of those different

2146
00:46:58,329 --> 00:46:58,339
but any one of those different
 

2147
00:46:58,339 --> 00:47:02,420
but any one of those different
pedagogy's that are beyond just standing

2148
00:47:02,420 --> 00:47:02,430
pedagogy's that are beyond just standing
 

2149
00:47:02,430 --> 00:47:04,160
pedagogy's that are beyond just standing
there and droning on in front of the

2150
00:47:04,160 --> 00:47:04,170
there and droning on in front of the
 

2151
00:47:04,170 --> 00:47:05,959
there and droning on in front of the
classroom for an hour and 15 minutes

2152
00:47:05,959 --> 00:47:05,969
classroom for an hour and 15 minutes
 

2153
00:47:05,969 --> 00:47:07,999
classroom for an hour and 15 minutes
require a heck of a lot more preparation

2154
00:47:07,999 --> 00:47:08,009
require a heck of a lot more preparation
 

2155
00:47:08,009 --> 00:47:11,660
require a heck of a lot more preparation
and so it's one of the challenges I

2156
00:47:11,660 --> 00:47:11,670
and so it's one of the challenges I
 

2157
00:47:11,670 --> 00:47:14,449
and so it's one of the challenges I
think that people have that we had when

2158
00:47:14,449 --> 00:47:14,459
think that people have that we had when
 

2159
00:47:14,459 --> 00:47:16,009
think that people have that we had when
trying to convince instructors to teach

2160
00:47:16,009 --> 00:47:16,019
trying to convince instructors to teach
 

2161
00:47:16,019 --> 00:47:17,660
trying to convince instructors to teach
on Coursera and it's part of the

2162
00:47:17,660 --> 00:47:17,670
on Coursera and it's part of the
 

2163
00:47:17,670 --> 00:47:20,479
on Coursera and it's part of the
challenges that pedagogy experts on

2164
00:47:20,479 --> 00:47:20,489
challenges that pedagogy experts on
 

2165
00:47:20,489 --> 00:47:22,160
challenges that pedagogy experts on
campus have in trying to get faculty to

2166
00:47:22,160 --> 00:47:22,170
campus have in trying to get faculty to
 

2167
00:47:22,170 --> 00:47:23,239
campus have in trying to get faculty to
teach differently is that it's actually

2168
00:47:23,239 --> 00:47:23,249
teach differently is that it's actually
 

2169
00:47:23,249 --> 00:47:25,339
teach differently is that it's actually
harder to teach that way than it is to

2170
00:47:25,339 --> 00:47:25,349
harder to teach that way than it is to
 

2171
00:47:25,349 --> 00:47:29,359
harder to teach that way than it is to
stand there drone do you think MOOCs

2172
00:47:29,359 --> 00:47:29,369
stand there drone do you think MOOCs
 

2173
00:47:29,369 --> 00:47:32,509
stand there drone do you think MOOCs
will replace in-person education or

2174
00:47:32,509 --> 00:47:32,519
will replace in-person education or
 

2175
00:47:32,519 --> 00:47:37,430
will replace in-person education or
become the majority of in-person of

2176
00:47:37,430 --> 00:47:37,440
become the majority of in-person of
 

2177
00:47:37,440 --> 00:47:40,640
become the majority of in-person of
Education of the way people learn in the

2178
00:47:40,640 --> 00:47:40,650
Education of the way people learn in the
 

2179
00:47:40,650 --> 00:47:42,739
Education of the way people learn in the
future again the future could be very

2180
00:47:42,739 --> 00:47:42,749
future again the future could be very
 

2181
00:47:42,749 --> 00:47:45,380
future again the future could be very
far away but where's the trend going do

2182
00:47:45,380 --> 00:47:45,390
far away but where's the trend going do
 

2183
00:47:45,390 --> 00:47:48,499
far away but where's the trend going do
you think so I think it's a nuanced and

2184
00:47:48,499 --> 00:47:48,509
you think so I think it's a nuanced and
 

2185
00:47:48,509 --> 00:47:51,979
you think so I think it's a nuanced and
complicated answer I don't think MOOCs

2186
00:47:51,979 --> 00:47:51,989
complicated answer I don't think MOOCs
 

2187
00:47:51,989 --> 00:47:55,880
complicated answer I don't think MOOCs
will replace face-to-face teaching I

2188
00:47:55,880 --> 00:47:55,890
will replace face-to-face teaching I
 

2189
00:47:55,890 --> 00:47:59,420
will replace face-to-face teaching I
think learning is in many cases a social

2190
00:47:59,420 --> 00:47:59,430
think learning is in many cases a social
 

2191
00:47:59,430 --> 00:48:02,870
think learning is in many cases a social
experience and even at Coursera we had

2192
00:48:02,870 --> 00:48:02,880
experience and even at Coursera we had
 

2193
00:48:02,880 --> 00:48:06,289
experience and even at Coursera we had
people who naturally formed study groups

2194
00:48:06,289 --> 00:48:06,299
people who naturally formed study groups
 

2195
00:48:06,299 --> 00:48:08,269
people who naturally formed study groups
even when they didn't have to just come

2196
00:48:08,269 --> 00:48:08,279
even when they didn't have to just come
 

2197
00:48:08,279 --> 00:48:11,479
even when they didn't have to just come
and talk to each other and we found that

2198
00:48:11,479 --> 00:48:11,489
and talk to each other and we found that
 

2199
00:48:11,489 --> 00:48:13,819
and talk to each other and we found that
that actually benefited their learning

2200
00:48:13,819 --> 00:48:13,829
that actually benefited their learning
 

2201
00:48:13,829 --> 00:48:16,579
that actually benefited their learning
in very important ways so there was more

2202
00:48:16,579 --> 00:48:16,589
in very important ways so there was more
 

2203
00:48:16,589 --> 00:48:20,209
in very important ways so there was more
success in among learners who had those

2204
00:48:20,209 --> 00:48:20,219
success in among learners who had those
 

2205
00:48:20,219 --> 00:48:21,949
success in among learners who had those
study groups than among ones who didn't

2206
00:48:21,949 --> 00:48:21,959
study groups than among ones who didn't
 

2207
00:48:21,959 --> 00:48:23,900
study groups than among ones who didn't
so I don't think it's just gonna oh

2208
00:48:23,900 --> 00:48:23,910
so I don't think it's just gonna oh
 

2209
00:48:23,910 --> 00:48:25,309
so I don't think it's just gonna oh
we're all gonna just suddenly learn

2210
00:48:25,309 --> 00:48:25,319
we're all gonna just suddenly learn
 

2211
00:48:25,319 --> 00:48:27,620
we're all gonna just suddenly learn
online with a computer and no one else

2212
00:48:27,620 --> 00:48:27,630
online with a computer and no one else
 

2213
00:48:27,630 --> 00:48:30,380
online with a computer and no one else
in the same way that you know recorded

2214
00:48:30,380 --> 00:48:30,390
in the same way that you know recorded
 

2215
00:48:30,390 --> 00:48:34,219
in the same way that you know recorded
music has not replaced live concerts but

2216
00:48:34,219 --> 00:48:34,229
music has not replaced live concerts but
 

2217
00:48:34,229 --> 00:48:37,870
music has not replaced live concerts but
I do think that especially when you are

2218
00:48:37,870 --> 00:48:37,880
I do think that especially when you are
 

2219
00:48:37,880 --> 00:48:41,839
I do think that especially when you are
thinking about continuing education the

2220
00:48:41,839 --> 00:48:41,849
thinking about continuing education the
 

2221
00:48:41,849 --> 00:48:43,539
thinking about continuing education the
stuff that people get when they're

2222
00:48:43,539 --> 00:48:43,549
stuff that people get when they're
 

2223
00:48:43,549 --> 00:48:46,099
stuff that people get when they're
traditional whatever high school college

2224
00:48:46,099 --> 00:48:46,109
traditional whatever high school college
 

2225
00:48:46,109 --> 00:48:49,729
traditional whatever high school college
education is done and they yet have to

2226
00:48:49,729 --> 00:48:49,739
education is done and they yet have to
 

2227
00:48:49,739 --> 00:48:52,489
education is done and they yet have to
maintain their level of expertise and

2228
00:48:52,489 --> 00:48:52,499
maintain their level of expertise and
 

2229
00:48:52,499 --> 00:48:54,709
maintain their level of expertise and
skills in a rapidly changing world I

2230
00:48:54,709 --> 00:48:54,719
skills in a rapidly changing world I
 

2231
00:48:54,719 --> 00:48:55,670
skills in a rapidly changing world I
think people will

2232
00:48:55,670 --> 00:48:55,680
think people will
 

2233
00:48:55,680 --> 00:48:57,559
think people will
sooo more and more educational content

2234
00:48:57,559 --> 00:48:57,569
sooo more and more educational content
 

2235
00:48:57,569 --> 00:49:00,770
sooo more and more educational content
in this online format because going back

2236
00:49:00,770 --> 00:49:00,780
in this online format because going back
 

2237
00:49:00,780 --> 00:49:02,990
in this online format because going back
to school for formal education is not an

2238
00:49:02,990 --> 00:49:03,000
to school for formal education is not an
 

2239
00:49:03,000 --> 00:49:04,270
to school for formal education is not an
option for most people

2240
00:49:04,270 --> 00:49:04,280
option for most people
 

2241
00:49:04,280 --> 00:49:06,740
option for most people
briefly I know it might be a difficult

2242
00:49:06,740 --> 00:49:06,750
briefly I know it might be a difficult
 

2243
00:49:06,750 --> 00:49:08,089
briefly I know it might be a difficult
question to ask but there's a lot of

2244
00:49:08,089 --> 00:49:08,099
question to ask but there's a lot of
 

2245
00:49:08,099 --> 00:49:11,420
question to ask but there's a lot of
people fascinated by artificial

2246
00:49:11,420 --> 00:49:11,430
people fascinated by artificial
 

2247
00:49:11,430 --> 00:49:12,950
people fascinated by artificial
intelligence by machine learning but

2248
00:49:12,950 --> 00:49:12,960
intelligence by machine learning but
 

2249
00:49:12,960 --> 00:49:15,069
intelligence by machine learning but
deep learning is there a recommendation

2250
00:49:15,069 --> 00:49:15,079
deep learning is there a recommendation
 

2251
00:49:15,079 --> 00:49:18,950
deep learning is there a recommendation
for the next year or for a lifelong

2252
00:49:18,950 --> 00:49:18,960
for the next year or for a lifelong
 

2253
00:49:18,960 --> 00:49:20,750
for the next year or for a lifelong
journey as somebody interested in this

2254
00:49:20,750 --> 00:49:20,760
journey as somebody interested in this
 

2255
00:49:20,760 --> 00:49:23,960
journey as somebody interested in this
how do they how do they begin how do

2256
00:49:23,960 --> 00:49:23,970
how do they how do they begin how do
 

2257
00:49:23,970 --> 00:49:28,250
how do they how do they begin how do
they enter that learning journey I think

2258
00:49:28,250 --> 00:49:28,260
they enter that learning journey I think
 

2259
00:49:28,260 --> 00:49:30,829
they enter that learning journey I think
the important thing is first to just get

2260
00:49:30,829 --> 00:49:30,839
the important thing is first to just get
 

2261
00:49:30,839 --> 00:49:34,309
the important thing is first to just get
started and there's plenty of online

2262
00:49:34,309 --> 00:49:34,319
started and there's plenty of online
 

2263
00:49:34,319 --> 00:49:38,089
started and there's plenty of online
content that one can get for both the

2264
00:49:38,089 --> 00:49:38,099
content that one can get for both the
 

2265
00:49:38,099 --> 00:49:41,359
content that one can get for both the
core foundations of mathematics and

2266
00:49:41,359 --> 00:49:41,369
core foundations of mathematics and
 

2267
00:49:41,369 --> 00:49:43,730
core foundations of mathematics and
statistics and programming and then from

2268
00:49:43,730 --> 00:49:43,740
statistics and programming and then from
 

2269
00:49:43,740 --> 00:49:45,500
statistics and programming and then from
there to machine learning I would

2270
00:49:45,500 --> 00:49:45,510
there to machine learning I would
 

2271
00:49:45,510 --> 00:49:48,170
there to machine learning I would
encourage people not to skip too quickly

2272
00:49:48,170 --> 00:49:48,180
encourage people not to skip too quickly
 

2273
00:49:48,180 --> 00:49:50,450
encourage people not to skip too quickly
past the foundations because I find that

2274
00:49:50,450 --> 00:49:50,460
past the foundations because I find that
 

2275
00:49:50,460 --> 00:49:52,849
past the foundations because I find that
there is a lot of people who learn

2276
00:49:52,849 --> 00:49:52,859
there is a lot of people who learn
 

2277
00:49:52,859 --> 00:49:54,410
there is a lot of people who learn
machine learning whether it's online or

2278
00:49:54,410 --> 00:49:54,420
machine learning whether it's online or
 

2279
00:49:54,420 --> 00:49:55,970
machine learning whether it's online or
on campus without getting those

2280
00:49:55,970 --> 00:49:55,980
on campus without getting those
 

2281
00:49:55,980 --> 00:49:58,220
on campus without getting those
foundations and they basically just turn

2282
00:49:58,220 --> 00:49:58,230
foundations and they basically just turn
 

2283
00:49:58,230 --> 00:50:01,010
foundations and they basically just turn
the crank on existing models in ways

2284
00:50:01,010 --> 00:50:01,020
the crank on existing models in ways
 

2285
00:50:01,020 --> 00:50:03,099
the crank on existing models in ways
that they don't allow for a lot of

2286
00:50:03,099 --> 00:50:03,109
that they don't allow for a lot of
 

2287
00:50:03,109 --> 00:50:07,280
that they don't allow for a lot of
innovation and an adjustment to the

2288
00:50:07,280 --> 00:50:07,290
innovation and an adjustment to the
 

2289
00:50:07,290 --> 00:50:09,770
innovation and an adjustment to the
problem at hand but also be or sometimes

2290
00:50:09,770 --> 00:50:09,780
problem at hand but also be or sometimes
 

2291
00:50:09,780 --> 00:50:11,030
problem at hand but also be or sometimes
just wrong and they don't even realize

2292
00:50:11,030 --> 00:50:11,040
just wrong and they don't even realize
 

2293
00:50:11,040 --> 00:50:13,670
just wrong and they don't even realize
that their application is wrong because

2294
00:50:13,670 --> 00:50:13,680
that their application is wrong because
 

2295
00:50:13,680 --> 00:50:15,170
that their application is wrong because
there's artifacts that they haven't

2296
00:50:15,170 --> 00:50:15,180
there's artifacts that they haven't
 

2297
00:50:15,180 --> 00:50:17,299
there's artifacts that they haven't
fully understood so I think the

2298
00:50:17,299 --> 00:50:17,309
fully understood so I think the
 

2299
00:50:17,309 --> 00:50:19,460
fully understood so I think the
foundations machine learning is an

2300
00:50:19,460 --> 00:50:19,470
foundations machine learning is an
 

2301
00:50:19,470 --> 00:50:22,510
foundations machine learning is an
important step and then and then

2302
00:50:22,510 --> 00:50:22,520
important step and then and then
 

2303
00:50:22,520 --> 00:50:26,150
important step and then and then
actually start solving problems try and

2304
00:50:26,150 --> 00:50:26,160
actually start solving problems try and
 

2305
00:50:26,160 --> 00:50:27,950
actually start solving problems try and
find someone to solve them with because

2306
00:50:27,950 --> 00:50:27,960
find someone to solve them with because
 

2307
00:50:27,960 --> 00:50:29,930
find someone to solve them with because
especially at the beginning is useful to

2308
00:50:29,930 --> 00:50:29,940
especially at the beginning is useful to
 

2309
00:50:29,940 --> 00:50:31,970
especially at the beginning is useful to
have someone to bounce ideas off and fix

2310
00:50:31,970 --> 00:50:31,980
have someone to bounce ideas off and fix
 

2311
00:50:31,980 --> 00:50:34,789
have someone to bounce ideas off and fix
mistakes that you make and and you can

2312
00:50:34,789 --> 00:50:34,799
mistakes that you make and and you can
 

2313
00:50:34,799 --> 00:50:37,730
mistakes that you make and and you can
fix mistakes that they make but but then

2314
00:50:37,730 --> 00:50:37,740
fix mistakes that they make but but then
 

2315
00:50:37,740 --> 00:50:40,730
fix mistakes that they make but but then
just find practical problems whether

2316
00:50:40,730 --> 00:50:40,740
just find practical problems whether
 

2317
00:50:40,740 --> 00:50:42,620
just find practical problems whether
it's in your workplace or if you don't

2318
00:50:42,620 --> 00:50:42,630
it's in your workplace or if you don't
 

2319
00:50:42,630 --> 00:50:44,839
it's in your workplace or if you don't
have that catechol competitions or such

2320
00:50:44,839 --> 00:50:44,849
have that catechol competitions or such
 

2321
00:50:44,849 --> 00:50:46,760
have that catechol competitions or such
are a really great place to find

2322
00:50:46,760 --> 00:50:46,770
are a really great place to find
 

2323
00:50:46,770 --> 00:50:49,609
are a really great place to find
interesting problems and just practice

2324
00:50:49,609 --> 00:50:49,619
interesting problems and just practice
 

2325
00:50:49,619 --> 00:50:53,960
interesting problems and just practice
practice perhaps a bit of a romanticized

2326
00:50:53,960 --> 00:50:53,970
practice perhaps a bit of a romanticized
 

2327
00:50:53,970 --> 00:50:56,950
practice perhaps a bit of a romanticized
question but what idea in deep learning

2328
00:50:56,950 --> 00:50:56,960
question but what idea in deep learning
 

2329
00:50:56,960 --> 00:51:00,380
question but what idea in deep learning
do you find have you found in your

2330
00:51:00,380 --> 00:51:00,390
do you find have you found in your
 

2331
00:51:00,390 --> 00:51:02,990
do you find have you found in your
journey the most beautiful or surprising

2332
00:51:02,990 --> 00:51:03,000
journey the most beautiful or surprising
 

2333
00:51:03,000 --> 00:51:06,970
journey the most beautiful or surprising
or interesting

2334
00:51:06,970 --> 00:51:06,980

 

2335
00:51:06,980 --> 00:51:11,060

perhaps not just deep learning but AI in

2336
00:51:11,060 --> 00:51:11,070
perhaps not just deep learning but AI in
 

2337
00:51:11,070 --> 00:51:15,710
perhaps not just deep learning but AI in
general statistics good answer with two

2338
00:51:15,710 --> 00:51:15,720
general statistics good answer with two
 

2339
00:51:15,720 --> 00:51:20,570
general statistics good answer with two
things one would be the foundational

2340
00:51:20,570 --> 00:51:20,580
things one would be the foundational
 

2341
00:51:20,580 --> 00:51:23,540
things one would be the foundational
concept of end to end training which is

2342
00:51:23,540 --> 00:51:23,550
concept of end to end training which is
 

2343
00:51:23,550 --> 00:51:27,590
concept of end to end training which is
that you start from the raw data and you

2344
00:51:27,590 --> 00:51:27,600
that you start from the raw data and you
 

2345
00:51:27,600 --> 00:51:30,830
that you start from the raw data and you
train something that is not like a

2346
00:51:30,830 --> 00:51:30,840
train something that is not like a
 

2347
00:51:30,840 --> 00:51:37,010
train something that is not like a
single piece but rather the towards the

2348
00:51:37,010 --> 00:51:37,020
single piece but rather the towards the
 

2349
00:51:37,020 --> 00:51:39,140
single piece but rather the towards the
actual goal that you're looking to from

2350
00:51:39,140 --> 00:51:39,150
actual goal that you're looking to from
 

2351
00:51:39,150 --> 00:51:41,210
actual goal that you're looking to from
the raw data to the outcome like and

2352
00:51:41,210 --> 00:51:41,220
the raw data to the outcome like and
 

2353
00:51:41,220 --> 00:51:43,670
the raw data to the outcome like and
nothing no no details in between well

2354
00:51:43,670 --> 00:51:43,680
nothing no no details in between well
 

2355
00:51:43,680 --> 00:51:45,500
nothing no no details in between well
not no details but the fact that you I

2356
00:51:45,500 --> 00:51:45,510
not no details but the fact that you I
 

2357
00:51:45,510 --> 00:51:46,580
not no details but the fact that you I
mean you could certainly introduce

2358
00:51:46,580 --> 00:51:46,590
mean you could certainly introduce
 

2359
00:51:46,590 --> 00:51:49,010
mean you could certainly introduce
building blocks that were trained

2360
00:51:49,010 --> 00:51:49,020
building blocks that were trained
 

2361
00:51:49,020 --> 00:51:50,810
building blocks that were trained
towards other tasks and actually coming

2362
00:51:50,810 --> 00:51:50,820
towards other tasks and actually coming
 

2363
00:51:50,820 --> 00:51:52,370
towards other tasks and actually coming
to that in my second half of the answer

2364
00:51:52,370 --> 00:51:52,380
to that in my second half of the answer
 

2365
00:51:52,380 --> 00:51:55,670
to that in my second half of the answer
but it doesn't have to be like a single

2366
00:51:55,670 --> 00:51:55,680
but it doesn't have to be like a single
 

2367
00:51:55,680 --> 00:51:58,640
but it doesn't have to be like a single
monolithic blob in the middle actually I

2368
00:51:58,640 --> 00:51:58,650
monolithic blob in the middle actually I
 

2369
00:51:58,650 --> 00:52:01,010
monolithic blob in the middle actually I
think that's not ideal but rather the

2370
00:52:01,010 --> 00:52:01,020
think that's not ideal but rather the
 

2371
00:52:01,020 --> 00:52:03,050
think that's not ideal but rather the
fact that at the end of the day you can

2372
00:52:03,050 --> 00:52:03,060
fact that at the end of the day you can
 

2373
00:52:03,060 --> 00:52:04,550
fact that at the end of the day you can
actually train something and goes all

2374
00:52:04,550 --> 00:52:04,560
actually train something and goes all
 

2375
00:52:04,560 --> 00:52:05,510
actually train something and goes all
the way from the beginning to the end

2376
00:52:05,510 --> 00:52:05,520
the way from the beginning to the end
 

2377
00:52:05,520 --> 00:52:08,420
the way from the beginning to the end
and the other one that I find really

2378
00:52:08,420 --> 00:52:08,430
and the other one that I find really
 

2379
00:52:08,430 --> 00:52:11,920
and the other one that I find really
compelling is the notion of learning a

2380
00:52:11,920 --> 00:52:11,930
compelling is the notion of learning a
 

2381
00:52:11,930 --> 00:52:16,670
compelling is the notion of learning a
representation that in its turn even if

2382
00:52:16,670 --> 00:52:16,680
representation that in its turn even if
 

2383
00:52:16,680 --> 00:52:19,360
representation that in its turn even if
it was trained to another task can

2384
00:52:19,360 --> 00:52:19,370
it was trained to another task can
 

2385
00:52:19,370 --> 00:52:22,790
it was trained to another task can
potentially be used as a much more rapid

2386
00:52:22,790 --> 00:52:22,800
potentially be used as a much more rapid
 

2387
00:52:22,800 --> 00:52:25,970
potentially be used as a much more rapid
starting point to solving a different

2388
00:52:25,970 --> 00:52:25,980
starting point to solving a different
 

2389
00:52:25,980 --> 00:52:29,780
starting point to solving a different
task and that's I think reminiscent of

2390
00:52:29,780 --> 00:52:29,790
task and that's I think reminiscent of
 

2391
00:52:29,790 --> 00:52:31,760
task and that's I think reminiscent of
what makes people successful learners

2392
00:52:31,760 --> 00:52:31,770
what makes people successful learners
 

2393
00:52:31,770 --> 00:52:35,420
what makes people successful learners
it's something that is relatively new in

2394
00:52:35,420 --> 00:52:35,430
it's something that is relatively new in
 

2395
00:52:35,430 --> 00:52:37,100
it's something that is relatively new in
the machine learning space I think it's

2396
00:52:37,100 --> 00:52:37,110
the machine learning space I think it's
 

2397
00:52:37,110 --> 00:52:39,350
the machine learning space I think it's
underutilized even relative to today's

2398
00:52:39,350 --> 00:52:39,360
underutilized even relative to today's
 

2399
00:52:39,360 --> 00:52:42,080
underutilized even relative to today's
capabilities but more and more of how do

2400
00:52:42,080 --> 00:52:42,090
capabilities but more and more of how do
 

2401
00:52:42,090 --> 00:52:45,970
capabilities but more and more of how do
we learn sort of reusable representation

2402
00:52:45,970 --> 00:52:45,980
we learn sort of reusable representation
 

2403
00:52:45,980 --> 00:52:50,140
we learn sort of reusable representation
so end to end and transfer learning yeah

2404
00:52:50,140 --> 00:52:50,150
so end to end and transfer learning yeah
 

2405
00:52:50,150 --> 00:52:53,060
so end to end and transfer learning yeah
is it surprising to you that neural

2406
00:52:53,060 --> 00:52:53,070
is it surprising to you that neural
 

2407
00:52:53,070 --> 00:52:55,550
is it surprising to you that neural
networks are able to in many cases do

2408
00:52:55,550 --> 00:52:55,560
networks are able to in many cases do
 

2409
00:52:55,560 --> 00:52:59,210
networks are able to in many cases do
these things it says it may be taking

2410
00:52:59,210 --> 00:52:59,220
these things it says it may be taking
 

2411
00:52:59,220 --> 00:53:01,220
these things it says it may be taking
back to when you when you first would

2412
00:53:01,220 --> 00:53:01,230
back to when you when you first would
 

2413
00:53:01,230 --> 00:53:03,590
back to when you when you first would
dive deep into neural networks or in

2414
00:53:03,590 --> 00:53:03,600
dive deep into neural networks or in
 

2415
00:53:03,600 --> 00:53:06,290
dive deep into neural networks or in
general even today is it surprising that

2416
00:53:06,290 --> 00:53:06,300
general even today is it surprising that
 

2417
00:53:06,300 --> 00:53:09,400
general even today is it surprising that
neural networks work at all and work

2418
00:53:09,400 --> 00:53:09,410
neural networks work at all and work
 

2419
00:53:09,410 --> 00:53:13,100
neural networks work at all and work
wonderfully to do this kind of raw and

2420
00:53:13,100 --> 00:53:13,110
wonderfully to do this kind of raw and
 

2421
00:53:13,110 --> 00:53:15,380
wonderfully to do this kind of raw and
then learning and even transfer learning

2422
00:53:15,380 --> 00:53:15,390
then learning and even transfer learning
 

2423
00:53:15,390 --> 00:53:20,359
then learning and even transfer learning
I think I was surprised by how

2424
00:53:20,359 --> 00:53:20,369
I think I was surprised by how
 

2425
00:53:20,369 --> 00:53:24,829
I think I was surprised by how
well when you have large enough amounts

2426
00:53:24,829 --> 00:53:24,839
well when you have large enough amounts
 

2427
00:53:24,839 --> 00:53:30,440
well when you have large enough amounts
of data it's possible to find a

2428
00:53:30,440 --> 00:53:30,450
of data it's possible to find a
 

2429
00:53:30,450 --> 00:53:33,559
of data it's possible to find a
meaningful representation in what is an

2430
00:53:33,559 --> 00:53:33,569
meaningful representation in what is an
 

2431
00:53:33,569 --> 00:53:35,839
meaningful representation in what is an
exceedingly high dimensional space and

2432
00:53:35,839 --> 00:53:35,849
exceedingly high dimensional space and
 

2433
00:53:35,849 --> 00:53:39,410
exceedingly high dimensional space and
so I find that to be really exciting and

2434
00:53:39,410 --> 00:53:39,420
so I find that to be really exciting and
 

2435
00:53:39,420 --> 00:53:40,880
so I find that to be really exciting and
people are still working out the math

2436
00:53:40,880 --> 00:53:40,890
people are still working out the math
 

2437
00:53:40,890 --> 00:53:43,039
people are still working out the math
for that there's more papers on that

2438
00:53:43,039 --> 00:53:43,049
for that there's more papers on that
 

2439
00:53:43,049 --> 00:53:44,839
for that there's more papers on that
every year and I think it's would be

2440
00:53:44,839 --> 00:53:44,849
every year and I think it's would be
 

2441
00:53:44,849 --> 00:53:48,970
every year and I think it's would be
really cool if we figured that out but

2442
00:53:48,970 --> 00:53:48,980
really cool if we figured that out but
 

2443
00:53:48,980 --> 00:53:52,819
really cool if we figured that out but
that to me was a surprise because in the

2444
00:53:52,819 --> 00:53:52,829
that to me was a surprise because in the
 

2445
00:53:52,829 --> 00:53:55,339
that to me was a surprise because in the
early days when I was starting my weigh

2446
00:53:55,339 --> 00:53:55,349
early days when I was starting my weigh
 

2447
00:53:55,349 --> 00:53:56,900
early days when I was starting my weigh
in machine learning and the data sets

2448
00:53:56,900 --> 00:53:56,910
in machine learning and the data sets
 

2449
00:53:56,910 --> 00:54:01,069
in machine learning and the data sets
were rather small I think we we believed

2450
00:54:01,069 --> 00:54:01,079
were rather small I think we we believed
 

2451
00:54:01,079 --> 00:54:03,529
were rather small I think we we believed
I believe that you needed to have a much

2452
00:54:03,529 --> 00:54:03,539
I believe that you needed to have a much
 

2453
00:54:03,539 --> 00:54:06,859
I believe that you needed to have a much
more constrained and knowledge rich

2454
00:54:06,859 --> 00:54:06,869
more constrained and knowledge rich
 

2455
00:54:06,869 --> 00:54:10,880
more constrained and knowledge rich
search space to really make to really

2456
00:54:10,880 --> 00:54:10,890
search space to really make to really
 

2457
00:54:10,890 --> 00:54:12,079
search space to really make to really
get to a meaningful answer and I think

2458
00:54:12,079 --> 00:54:12,089
get to a meaningful answer and I think
 

2459
00:54:12,089 --> 00:54:15,549
get to a meaningful answer and I think
it was true at the time what I think is

2460
00:54:15,549 --> 00:54:15,559
it was true at the time what I think is
 

2461
00:54:15,559 --> 00:54:20,299
it was true at the time what I think is
is still a question is will a completely

2462
00:54:20,299 --> 00:54:20,309
is still a question is will a completely
 

2463
00:54:20,309 --> 00:54:23,979
is still a question is will a completely
knowledge free approach where there's no

2464
00:54:23,979 --> 00:54:23,989
knowledge free approach where there's no
 

2465
00:54:23,989 --> 00:54:26,450
knowledge free approach where there's no
prior knowledge going into the

2466
00:54:26,450 --> 00:54:26,460
prior knowledge going into the
 

2467
00:54:26,460 --> 00:54:29,420
prior knowledge going into the
construction of the model is that going

2468
00:54:29,420 --> 00:54:29,430
construction of the model is that going
 

2469
00:54:29,430 --> 00:54:31,970
construction of the model is that going
to be the solution or not it's not

2470
00:54:31,970 --> 00:54:31,980
to be the solution or not it's not
 

2471
00:54:31,980 --> 00:54:34,640
to be the solution or not it's not
actually the solution today in the sense

2472
00:54:34,640 --> 00:54:34,650
actually the solution today in the sense
 

2473
00:54:34,650 --> 00:54:38,059
actually the solution today in the sense
that the architecture of a you know

2474
00:54:38,059 --> 00:54:38,069
that the architecture of a you know
 

2475
00:54:38,069 --> 00:54:40,160
that the architecture of a you know
convolutional neural network that's used

2476
00:54:40,160 --> 00:54:40,170
convolutional neural network that's used
 

2477
00:54:40,170 --> 00:54:42,920
convolutional neural network that's used
for images is actually quite different

2478
00:54:42,920 --> 00:54:42,930
for images is actually quite different
 

2479
00:54:42,930 --> 00:54:45,309
for images is actually quite different
to the type of networks it's used for

2480
00:54:45,309 --> 00:54:45,319
to the type of networks it's used for
 

2481
00:54:45,319 --> 00:54:48,259
to the type of networks it's used for
language and yet different from the one

2482
00:54:48,259 --> 00:54:48,269
language and yet different from the one
 

2483
00:54:48,269 --> 00:54:51,380
language and yet different from the one
that's used for speech or biology or any

2484
00:54:51,380 --> 00:54:51,390
that's used for speech or biology or any
 

2485
00:54:51,390 --> 00:54:54,370
that's used for speech or biology or any
other application there's still some

2486
00:54:54,370 --> 00:54:54,380
other application there's still some
 

2487
00:54:54,380 --> 00:54:57,079
other application there's still some
insight that goes into the structure of

2488
00:54:57,079 --> 00:54:57,089
insight that goes into the structure of
 

2489
00:54:57,089 --> 00:54:59,839
insight that goes into the structure of
the network to get the the right

2490
00:54:59,839 --> 00:54:59,849
the network to get the the right
 

2491
00:54:59,849 --> 00:55:01,640
the network to get the the right
performance will you be able to come up

2492
00:55:01,640 --> 00:55:01,650
performance will you be able to come up
 

2493
00:55:01,650 --> 00:55:03,140
performance will you be able to come up
with the universal learning machine I

2494
00:55:03,140 --> 00:55:03,150
with the universal learning machine I
 

2495
00:55:03,150 --> 00:55:06,140
with the universal learning machine I
don't know I wonder if there's always

2496
00:55:06,140 --> 00:55:06,150
don't know I wonder if there's always
 

2497
00:55:06,150 --> 00:55:07,759
don't know I wonder if there's always
has to be some insight injected

2498
00:55:07,759 --> 00:55:07,769
has to be some insight injected
 

2499
00:55:07,769 --> 00:55:11,109
has to be some insight injected
somewhere or whether it can converge so

2500
00:55:11,109 --> 00:55:11,119
somewhere or whether it can converge so
 

2501
00:55:11,119 --> 00:55:13,279
somewhere or whether it can converge so
you've done a lot of interesting work

2502
00:55:13,279 --> 00:55:13,289
you've done a lot of interesting work
 

2503
00:55:13,289 --> 00:55:15,859
you've done a lot of interesting work
with probabilistic graphical models in

2504
00:55:15,859 --> 00:55:15,869
with probabilistic graphical models in
 

2505
00:55:15,869 --> 00:55:17,539
with probabilistic graphical models in
general Bayesian deep learning and and

2506
00:55:17,539 --> 00:55:17,549
general Bayesian deep learning and and
 

2507
00:55:17,549 --> 00:55:20,229
general Bayesian deep learning and and
so on so can you maybe speak high level

2508
00:55:20,229 --> 00:55:20,239
so on so can you maybe speak high level
 

2509
00:55:20,239 --> 00:55:23,989
so on so can you maybe speak high level
how can learning systems deal with

2510
00:55:23,989 --> 00:55:23,999
how can learning systems deal with
 

2511
00:55:23,999 --> 00:55:27,650
how can learning systems deal with
uncertainty one of the limitations I

2512
00:55:27,650 --> 00:55:27,660
uncertainty one of the limitations I
 

2513
00:55:27,660 --> 00:55:30,950
uncertainty one of the limitations I
think of a lot of machine learning

2514
00:55:30,950 --> 00:55:30,960
think of a lot of machine learning
 

2515
00:55:30,960 --> 00:55:33,400
think of a lot of machine learning
models is that

2516
00:55:33,400 --> 00:55:33,410
models is that
 

2517
00:55:33,410 --> 00:55:36,700
models is that
they come up with an answer and you

2518
00:55:36,700 --> 00:55:36,710
they come up with an answer and you
 

2519
00:55:36,710 --> 00:55:39,280
they come up with an answer and you
don't know how much you can believe that

2520
00:55:39,280 --> 00:55:39,290
don't know how much you can believe that
 

2521
00:55:39,290 --> 00:55:46,870
don't know how much you can believe that
answer and oftentimes the the the answer

2522
00:55:46,870 --> 00:55:46,880
answer and oftentimes the the the answer
 

2523
00:55:46,880 --> 00:55:49,150
answer and oftentimes the the the answer
is actually quite poorly calibrated

2524
00:55:49,150 --> 00:55:49,160
is actually quite poorly calibrated
 

2525
00:55:49,160 --> 00:55:50,860
is actually quite poorly calibrated
relative to its uncertainties even if

2526
00:55:50,860 --> 00:55:50,870
relative to its uncertainties even if
 

2527
00:55:50,870 --> 00:55:54,130
relative to its uncertainties even if
you look at where the um you know the

2528
00:55:54,130 --> 00:55:54,140
you look at where the um you know the
 

2529
00:55:54,140 --> 00:55:56,500
you look at where the um you know the
the the confidence that comes out of the

2530
00:55:56,500 --> 00:55:56,510
the the confidence that comes out of the
 

2531
00:55:56,510 --> 00:55:58,690
the the confidence that comes out of the
say the neural network at the end and

2532
00:55:58,690 --> 00:55:58,700
say the neural network at the end and
 

2533
00:55:58,700 --> 00:56:02,290
say the neural network at the end and
you ask how much more likely is an

2534
00:56:02,290 --> 00:56:02,300
you ask how much more likely is an
 

2535
00:56:02,300 --> 00:56:04,120
you ask how much more likely is an
answer of zero point eight versus zero

2536
00:56:04,120 --> 00:56:04,130
answer of zero point eight versus zero
 

2537
00:56:04,130 --> 00:56:06,250
answer of zero point eight versus zero
point nine it's not really in any way

2538
00:56:06,250 --> 00:56:06,260
point nine it's not really in any way
 

2539
00:56:06,260 --> 00:56:10,470
point nine it's not really in any way
calibrated to the to the actual

2540
00:56:10,470 --> 00:56:10,480
calibrated to the to the actual
 

2541
00:56:10,480 --> 00:56:12,790
calibrated to the to the actual
reliability of that network and how true

2542
00:56:12,790 --> 00:56:12,800
reliability of that network and how true
 

2543
00:56:12,800 --> 00:56:14,590
reliability of that network and how true
it is and the further away you move from

2544
00:56:14,590 --> 00:56:14,600
it is and the further away you move from
 

2545
00:56:14,600 --> 00:56:19,150
it is and the further away you move from
the training data the more not only the

2546
00:56:19,150 --> 00:56:19,160
the training data the more not only the
 

2547
00:56:19,160 --> 00:56:21,070
the training data the more not only the
more wrong then that workers often is

2548
00:56:21,070 --> 00:56:21,080
more wrong then that workers often is
 

2549
00:56:21,080 --> 00:56:22,750
more wrong then that workers often is
more wrong and more confident in a

2550
00:56:22,750 --> 00:56:22,760
more wrong and more confident in a
 

2551
00:56:22,760 --> 00:56:25,780
more wrong and more confident in a
strong answer and that is a serious

2552
00:56:25,780 --> 00:56:25,790
strong answer and that is a serious
 

2553
00:56:25,790 --> 00:56:29,410
strong answer and that is a serious
issue in a lot of application areas so

2554
00:56:29,410 --> 00:56:29,420
issue in a lot of application areas so
 

2555
00:56:29,420 --> 00:56:30,400
issue in a lot of application areas so
when you think for instance about

2556
00:56:30,400 --> 00:56:30,410
when you think for instance about
 

2557
00:56:30,410 --> 00:56:32,740
when you think for instance about
medical diagnosis as being maybe an

2558
00:56:32,740 --> 00:56:32,750
medical diagnosis as being maybe an
 

2559
00:56:32,750 --> 00:56:34,960
medical diagnosis as being maybe an
epitome of how problematic this can be

2560
00:56:34,960 --> 00:56:34,970
epitome of how problematic this can be
 

2561
00:56:34,970 --> 00:56:38,170
epitome of how problematic this can be
if you were training your network on a

2562
00:56:38,170 --> 00:56:38,180
if you were training your network on a
 

2563
00:56:38,180 --> 00:56:40,540
if you were training your network on a
certain set of patients on a certain

2564
00:56:40,540 --> 00:56:40,550
certain set of patients on a certain
 

2565
00:56:40,550 --> 00:56:42,580
certain set of patients on a certain
patient population and I have a patient

2566
00:56:42,580 --> 00:56:42,590
patient population and I have a patient
 

2567
00:56:42,590 --> 00:56:45,460
patient population and I have a patient
that is an outlier and there's no human

2568
00:56:45,460 --> 00:56:45,470
that is an outlier and there's no human
 

2569
00:56:45,470 --> 00:56:48,040
that is an outlier and there's no human
that looks at this and that patient is

2570
00:56:48,040 --> 00:56:48,050
that looks at this and that patient is
 

2571
00:56:48,050 --> 00:56:49,270
that looks at this and that patient is
put into a neural network in your

2572
00:56:49,270 --> 00:56:49,280
put into a neural network in your
 

2573
00:56:49,280 --> 00:56:51,010
put into a neural network in your
network not only gives a completely

2574
00:56:51,010 --> 00:56:51,020
network not only gives a completely
 

2575
00:56:51,020 --> 00:56:52,750
network not only gives a completely
incorrect diagnosis but it's supremely

2576
00:56:52,750 --> 00:56:52,760
incorrect diagnosis but it's supremely
 

2577
00:56:52,760 --> 00:56:54,910
incorrect diagnosis but it's supremely
confident and it's wrong answer you

2578
00:56:54,910 --> 00:56:54,920
confident and it's wrong answer you
 

2579
00:56:54,920 --> 00:56:58,450
confident and it's wrong answer you
could kill people so I think creating

2580
00:56:58,450 --> 00:56:58,460
could kill people so I think creating
 

2581
00:56:58,460 --> 00:57:03,660
could kill people so I think creating
more of an understanding of how do you

2582
00:57:03,660 --> 00:57:03,670
more of an understanding of how do you
 

2583
00:57:03,670 --> 00:57:08,350
more of an understanding of how do you
do snut works that are calibrated in our

2584
00:57:08,350 --> 00:57:08,360
do snut works that are calibrated in our
 

2585
00:57:08,360 --> 00:57:10,150
do snut works that are calibrated in our
uncertainty and can also say you know I

2586
00:57:10,150 --> 00:57:10,160
uncertainty and can also say you know I
 

2587
00:57:10,160 --> 00:57:12,760
uncertainty and can also say you know I
give up I don't know what to say about

2588
00:57:12,760 --> 00:57:12,770
give up I don't know what to say about
 

2589
00:57:12,770 --> 00:57:14,950
give up I don't know what to say about
this particular data instance because

2590
00:57:14,950 --> 00:57:14,960
this particular data instance because
 

2591
00:57:14,960 --> 00:57:16,420
this particular data instance because
I've never seen something that

2592
00:57:16,420 --> 00:57:16,430
I've never seen something that
 

2593
00:57:16,430 --> 00:57:18,250
I've never seen something that
sufficiently liked it before I think

2594
00:57:18,250 --> 00:57:18,260
sufficiently liked it before I think
 

2595
00:57:18,260 --> 00:57:20,560
sufficiently liked it before I think
it's going to be really important in

2596
00:57:20,560 --> 00:57:20,570
it's going to be really important in
 

2597
00:57:20,570 --> 00:57:23,170
it's going to be really important in
mission-critical applications especially

2598
00:57:23,170 --> 00:57:23,180
mission-critical applications especially
 

2599
00:57:23,180 --> 00:57:25,240
mission-critical applications especially
ones where human life is at stake and

2600
00:57:25,240 --> 00:57:25,250
ones where human life is at stake and
 

2601
00:57:25,250 --> 00:57:27,240
ones where human life is at stake and
that includes the you know medical

2602
00:57:27,240 --> 00:57:27,250
that includes the you know medical
 

2603
00:57:27,250 --> 00:57:29,620
that includes the you know medical
applications but it also includes you

2604
00:57:29,620 --> 00:57:29,630
applications but it also includes you
 

2605
00:57:29,630 --> 00:57:31,660
applications but it also includes you
know automated driving because you'd

2606
00:57:31,660 --> 00:57:31,670
know automated driving because you'd
 

2607
00:57:31,670 --> 00:57:33,400
know automated driving because you'd
want the network to be able to you know

2608
00:57:33,400 --> 00:57:33,410
want the network to be able to you know
 

2609
00:57:33,410 --> 00:57:35,530
want the network to be able to you know
what I have no idea what this blob is

2610
00:57:35,530 --> 00:57:35,540
what I have no idea what this blob is
 

2611
00:57:35,540 --> 00:57:37,000
what I have no idea what this blob is
that I'm seeing in the middle of the

2612
00:57:37,000 --> 00:57:37,010
that I'm seeing in the middle of the
 

2613
00:57:37,010 --> 00:57:39,100
that I'm seeing in the middle of the
rest I'm just gonna stop because I don't

2614
00:57:39,100 --> 00:57:39,110
rest I'm just gonna stop because I don't
 

2615
00:57:39,110 --> 00:57:40,630
rest I'm just gonna stop because I don't
want to potentially run over a

2616
00:57:40,630 --> 00:57:40,640
want to potentially run over a
 

2617
00:57:40,640 --> 00:57:42,850
want to potentially run over a
pedestrian that I don't recognize is

2618
00:57:42,850 --> 00:57:42,860
pedestrian that I don't recognize is
 

2619
00:57:42,860 --> 00:57:45,600
pedestrian that I don't recognize is
there good mechanisms ideas of how to

2620
00:57:45,600 --> 00:57:45,610
there good mechanisms ideas of how to
 

2621
00:57:45,610 --> 00:57:47,420
there good mechanisms ideas of how to
allow

2622
00:57:47,420 --> 00:57:47,430
allow
 

2623
00:57:47,430 --> 00:57:50,839
allow
learning systems to provide that

2624
00:57:50,839 --> 00:57:50,849
learning systems to provide that
 

2625
00:57:50,849 --> 00:57:52,760
learning systems to provide that
uncertainty whatever along with their

2626
00:57:52,760 --> 00:57:52,770
uncertainty whatever along with their
 

2627
00:57:52,770 --> 00:57:55,760
uncertainty whatever along with their
predictions certainly people have come

2628
00:57:55,760 --> 00:57:55,770
predictions certainly people have come
 

2629
00:57:55,770 --> 00:57:58,880
predictions certainly people have come
up with mechanisms that involve Bayesian

2630
00:57:58,880 --> 00:57:58,890
up with mechanisms that involve Bayesian
 

2631
00:57:58,890 --> 00:58:01,400
up with mechanisms that involve Bayesian
deep learning deep learning that

2632
00:58:01,400 --> 00:58:01,410
deep learning deep learning that
 

2633
00:58:01,410 --> 00:58:04,940
deep learning deep learning that
involves Gaussian processes I mean there

2634
00:58:04,940 --> 00:58:04,950
involves Gaussian processes I mean there
 

2635
00:58:04,950 --> 00:58:07,549
involves Gaussian processes I mean there
is a slew of different approaches that

2636
00:58:07,549 --> 00:58:07,559
is a slew of different approaches that
 

2637
00:58:07,559 --> 00:58:08,900
is a slew of different approaches that
people have come up with

2638
00:58:08,900 --> 00:58:08,910
people have come up with
 

2639
00:58:08,910 --> 00:58:11,839
people have come up with
there's methods that use ensembles of

2640
00:58:11,839 --> 00:58:11,849
there's methods that use ensembles of
 

2641
00:58:11,849 --> 00:58:14,480
there's methods that use ensembles of
networks with trained with different

2642
00:58:14,480 --> 00:58:14,490
networks with trained with different
 

2643
00:58:14,490 --> 00:58:16,280
networks with trained with different
subsets of theta or different random

2644
00:58:16,280 --> 00:58:16,290
subsets of theta or different random
 

2645
00:58:16,290 --> 00:58:18,290
subsets of theta or different random
starting points those are actually

2646
00:58:18,290 --> 00:58:18,300
starting points those are actually
 

2647
00:58:18,300 --> 00:58:20,900
starting points those are actually
sometimes surprisingly good at creating

2648
00:58:20,900 --> 00:58:20,910
sometimes surprisingly good at creating
 

2649
00:58:20,910 --> 00:58:24,470
sometimes surprisingly good at creating
a sort of set of how confident or not

2650
00:58:24,470 --> 00:58:24,480
a sort of set of how confident or not
 

2651
00:58:24,480 --> 00:58:27,440
a sort of set of how confident or not
you are in your answer it's very much an

2652
00:58:27,440 --> 00:58:27,450
you are in your answer it's very much an
 

2653
00:58:27,450 --> 00:58:30,740
you are in your answer it's very much an
area of open research let's cautiously

2654
00:58:30,740 --> 00:58:30,750
area of open research let's cautiously
 

2655
00:58:30,750 --> 00:58:32,530
area of open research let's cautiously
French your back into the land of

2656
00:58:32,530 --> 00:58:32,540
French your back into the land of
 

2657
00:58:32,540 --> 00:58:36,290
French your back into the land of
philosophy and speaking of AI systems

2658
00:58:36,290 --> 00:58:36,300
philosophy and speaking of AI systems
 

2659
00:58:36,300 --> 00:58:38,329
philosophy and speaking of AI systems
providing uncertainty somebody like

2660
00:58:38,329 --> 00:58:38,339
providing uncertainty somebody like
 

2661
00:58:38,339 --> 00:58:41,750
providing uncertainty somebody like
Stuart Russell believes that as we

2662
00:58:41,750 --> 00:58:41,760
Stuart Russell believes that as we
 

2663
00:58:41,760 --> 00:58:43,309
Stuart Russell believes that as we
create more and more intelligent systems

2664
00:58:43,309 --> 00:58:43,319
create more and more intelligent systems
 

2665
00:58:43,319 --> 00:58:45,559
create more and more intelligent systems
it's really important for them to be

2666
00:58:45,559 --> 00:58:45,569
it's really important for them to be
 

2667
00:58:45,569 --> 00:58:47,829
it's really important for them to be
full of self-doubt

2668
00:58:47,829 --> 00:58:47,839
full of self-doubt
 

2669
00:58:47,839 --> 00:58:50,390
full of self-doubt
because you know if they're given more

2670
00:58:50,390 --> 00:58:50,400
because you know if they're given more
 

2671
00:58:50,400 --> 00:58:53,000
because you know if they're given more
and more power we want them the way to

2672
00:58:53,000 --> 00:58:53,010
and more power we want them the way to
 

2673
00:58:53,010 --> 00:58:55,970
and more power we want them the way to
maintain human control over a systems or

2674
00:58:55,970 --> 00:58:55,980
maintain human control over a systems or
 

2675
00:58:55,980 --> 00:58:58,160
maintain human control over a systems or
human supervision which is true like you

2676
00:58:58,160 --> 00:58:58,170
human supervision which is true like you
 

2677
00:58:58,170 --> 00:58:59,450
human supervision which is true like you
just mentioned with autonomous vehicles

2678
00:58:59,450 --> 00:58:59,460
just mentioned with autonomous vehicles
 

2679
00:58:59,460 --> 00:59:01,010
just mentioned with autonomous vehicles
it's really important to get human

2680
00:59:01,010 --> 00:59:01,020
it's really important to get human
 

2681
00:59:01,020 --> 00:59:03,589
it's really important to get human
supervision when the car is not sure

2682
00:59:03,589 --> 00:59:03,599
supervision when the car is not sure
 

2683
00:59:03,599 --> 00:59:05,839
supervision when the car is not sure
because if it's really confident it can

2684
00:59:05,839 --> 00:59:05,849
because if it's really confident it can
 

2685
00:59:05,849 --> 00:59:07,910
because if it's really confident it can
in cases when it can get in trouble is

2686
00:59:07,910 --> 00:59:07,920
in cases when it can get in trouble is
 

2687
00:59:07,920 --> 00:59:09,620
in cases when it can get in trouble is
going to be really problematic so let me

2688
00:59:09,620 --> 00:59:09,630
going to be really problematic so let me
 

2689
00:59:09,630 --> 00:59:12,530
going to be really problematic so let me
ask about sort of the questions of AGI

2690
00:59:12,530 --> 00:59:12,540
ask about sort of the questions of AGI
 

2691
00:59:12,540 --> 00:59:15,170
ask about sort of the questions of AGI
in human level intelligence I mean we

2692
00:59:15,170 --> 00:59:15,180
in human level intelligence I mean we
 

2693
00:59:15,180 --> 00:59:18,829
in human level intelligence I mean we
talked about curing diseases now which

2694
00:59:18,829 --> 00:59:18,839
talked about curing diseases now which
 

2695
00:59:18,839 --> 00:59:20,359
talked about curing diseases now which
is sort of fundamental thing we could

2696
00:59:20,359 --> 00:59:20,369
is sort of fundamental thing we could
 

2697
00:59:20,369 --> 00:59:23,359
is sort of fundamental thing we could
have an impact today but yet people also

2698
00:59:23,359 --> 00:59:23,369
have an impact today but yet people also
 

2699
00:59:23,369 --> 00:59:27,490
have an impact today but yet people also
dream of both understanding and creating

2700
00:59:27,490 --> 00:59:27,500
dream of both understanding and creating
 

2701
00:59:27,500 --> 00:59:29,990
dream of both understanding and creating
intelligence is that something you think

2702
00:59:29,990 --> 00:59:30,000
intelligence is that something you think
 

2703
00:59:30,000 --> 00:59:31,420
intelligence is that something you think
about is that something you dream about

2704
00:59:31,420 --> 00:59:31,430
about is that something you dream about
 

2705
00:59:31,430 --> 00:59:35,270
about is that something you dream about
is that something you think is within

2706
00:59:35,270 --> 00:59:35,280
is that something you think is within
 

2707
00:59:35,280 --> 00:59:38,240
is that something you think is within
our reach to be thinking about as

2708
00:59:38,240 --> 00:59:38,250
our reach to be thinking about as
 

2709
00:59:38,250 --> 00:59:42,020
our reach to be thinking about as
computer scientists boy let me tease

2710
00:59:42,020 --> 00:59:42,030
computer scientists boy let me tease
 

2711
00:59:42,030 --> 00:59:44,289
computer scientists boy let me tease
apart different parts of that question

2712
00:59:44,289 --> 00:59:44,299
apart different parts of that question
 

2713
00:59:44,299 --> 00:59:47,840
apart different parts of that question
the first question

2714
00:59:47,840 --> 00:59:47,850
the first question
 

2715
00:59:47,850 --> 00:59:51,590
the first question
yeah it's a multi-part question so let

2716
00:59:51,590 --> 00:59:51,600
yeah it's a multi-part question so let
 

2717
00:59:51,600 --> 00:59:56,960
yeah it's a multi-part question so let
me start with the feasibility of AGI

2718
00:59:56,960 --> 00:59:56,970
me start with the feasibility of AGI
 

2719
00:59:56,970 --> 01:00:00,830
me start with the feasibility of AGI
then I'll talk about the timelines a

2720
01:00:00,830 --> 01:00:00,840
then I'll talk about the timelines a
 

2721
01:00:00,840 --> 01:00:03,340
then I'll talk about the timelines a
little bit and then talk about well what

2722
01:00:03,340 --> 01:00:03,350
little bit and then talk about well what
 

2723
01:00:03,350 --> 01:00:07,150
little bit and then talk about well what
controls does one need when protecting

2724
01:00:07,150 --> 01:00:07,160
controls does one need when protecting
 

2725
01:00:07,160 --> 01:00:09,620
controls does one need when protecting
when thinking about protections and the

2726
01:00:09,620 --> 01:00:09,630
when thinking about protections and the
 

2727
01:00:09,630 --> 01:00:14,210
when thinking about protections and the
AI space so you know I think AGI

2728
01:00:14,210 --> 01:00:14,220
AI space so you know I think AGI
 

2729
01:00:14,220 --> 01:00:17,330
AI space so you know I think AGI
obviously is a long-standing dream that

2730
01:00:17,330 --> 01:00:17,340
obviously is a long-standing dream that
 

2731
01:00:17,340 --> 01:00:20,720
obviously is a long-standing dream that
even our early pioneers in the space had

2732
01:00:20,720 --> 01:00:20,730
even our early pioneers in the space had
 

2733
01:00:20,730 --> 01:00:23,650
even our early pioneers in the space had
you know the Turing test and so on are

2734
01:00:23,650 --> 01:00:23,660
you know the Turing test and so on are
 

2735
01:00:23,660 --> 01:00:27,770
you know the Turing test and so on are
the earliest discussions of that we're

2736
01:00:27,770 --> 01:00:27,780
the earliest discussions of that we're
 

2737
01:00:27,780 --> 01:00:31,880
the earliest discussions of that we're
obviously closer than we were 70 or so

2738
01:00:31,880 --> 01:00:31,890
obviously closer than we were 70 or so
 

2739
01:00:31,890 --> 01:00:35,510
obviously closer than we were 70 or so
years ago but I think it's still very

2740
01:00:35,510 --> 01:00:35,520
years ago but I think it's still very
 

2741
01:00:35,520 --> 01:00:36,200
years ago but I think it's still very
far away

2742
01:00:36,200 --> 01:00:36,210
far away
 

2743
01:00:36,210 --> 01:00:40,460
far away
I think machine learning algorithms

2744
01:00:40,460 --> 01:00:40,470
I think machine learning algorithms
 

2745
01:00:40,470 --> 01:00:45,070
I think machine learning algorithms
today are Yui exquisitely good pattern

2746
01:00:45,070 --> 01:00:45,080
today are Yui exquisitely good pattern
 

2747
01:00:45,080 --> 01:00:48,890
today are Yui exquisitely good pattern
recognizers in very specific problem

2748
01:00:48,890 --> 01:00:48,900
recognizers in very specific problem
 

2749
01:00:48,900 --> 01:00:51,020
recognizers in very specific problem
domains where they have seen enough

2750
01:00:51,020 --> 01:00:51,030
domains where they have seen enough
 

2751
01:00:51,030 --> 01:00:53,080
domains where they have seen enough
training data to make good predictions

2752
01:00:53,080 --> 01:00:53,090
training data to make good predictions
 

2753
01:00:53,090 --> 01:00:57,890
training data to make good predictions
you take a machine learning algorithm

2754
01:00:57,890 --> 01:00:57,900
you take a machine learning algorithm
 

2755
01:00:57,900 --> 01:01:01,430
you take a machine learning algorithm
and you move a different version of even

2756
01:01:01,430 --> 01:01:01,440
and you move a different version of even
 

2757
01:01:01,440 --> 01:01:03,290
and you move a different version of even
that same problem far less one that's

2758
01:01:03,290 --> 01:01:03,300
that same problem far less one that's
 

2759
01:01:03,300 --> 01:01:05,720
that same problem far less one that's
different and it will just completely

2760
01:01:05,720 --> 01:01:05,730
different and it will just completely
 

2761
01:01:05,730 --> 01:01:09,560
different and it will just completely
choke so I think we're nowhere close to

2762
01:01:09,560 --> 01:01:09,570
choke so I think we're nowhere close to
 

2763
01:01:09,570 --> 01:01:14,540
choke so I think we're nowhere close to
the versatility and flexibility of even

2764
01:01:14,540 --> 01:01:14,550
the versatility and flexibility of even
 

2765
01:01:14,550 --> 01:01:17,900
the versatility and flexibility of even
a human toddler in terms of their

2766
01:01:17,900 --> 01:01:17,910
a human toddler in terms of their
 

2767
01:01:17,910 --> 01:01:20,240
a human toddler in terms of their
ability to context switch and solve

2768
01:01:20,240 --> 01:01:20,250
ability to context switch and solve
 

2769
01:01:20,250 --> 01:01:22,120
ability to context switch and solve
different problems using a single

2770
01:01:22,120 --> 01:01:22,130
different problems using a single
 

2771
01:01:22,130 --> 01:01:26,800
different problems using a single
knowledge-based single brain so am i

2772
01:01:26,800 --> 01:01:26,810
knowledge-based single brain so am i
 

2773
01:01:26,810 --> 01:01:31,340
knowledge-based single brain so am i
desperately worried about the machines

2774
01:01:31,340 --> 01:01:31,350
desperately worried about the machines
 

2775
01:01:31,350 --> 01:01:34,340
desperately worried about the machines
taking over the universe and you know

2776
01:01:34,340 --> 01:01:34,350
taking over the universe and you know
 

2777
01:01:34,350 --> 01:01:35,990
taking over the universe and you know
starting to kill people because they

2778
01:01:35,990 --> 01:01:36,000
starting to kill people because they
 

2779
01:01:36,000 --> 01:01:38,420
starting to kill people because they
want to have more power I don't think so

2780
01:01:38,420 --> 01:01:38,430
want to have more power I don't think so
 

2781
01:01:38,430 --> 01:01:40,670
want to have more power I don't think so
well sort of to pause on that so you

2782
01:01:40,670 --> 01:01:40,680
well sort of to pause on that so you
 

2783
01:01:40,680 --> 01:01:43,550
well sort of to pause on that so you
kind of intuited that super intelligence

2784
01:01:43,550 --> 01:01:43,560
kind of intuited that super intelligence
 

2785
01:01:43,560 --> 01:01:45,680
kind of intuited that super intelligence
is a very difficult thing to achieve

2786
01:01:45,680 --> 01:01:45,690
is a very difficult thing to achieve
 

2787
01:01:45,690 --> 01:01:48,500
is a very difficult thing to achieve
that were intelligent intelligent super

2788
01:01:48,500 --> 01:01:48,510
that were intelligent intelligent super
 

2789
01:01:48,510 --> 01:01:49,670
that were intelligent intelligent super
intelligence we're not even close to

2790
01:01:49,670 --> 01:01:49,680
intelligence we're not even close to
 

2791
01:01:49,680 --> 01:01:51,650
intelligence we're not even close to
intelligence even just the greater

2792
01:01:51,650 --> 01:01:51,660
intelligence even just the greater
 

2793
01:01:51,660 --> 01:01:53,810
intelligence even just the greater
abilities of generalization of our

2794
01:01:53,810 --> 01:01:53,820
abilities of generalization of our
 

2795
01:01:53,820 --> 01:01:58,400
abilities of generalization of our
current systems but we haven't answered

2796
01:01:58,400 --> 01:01:58,410
current systems but we haven't answered
 

2797
01:01:58,410 --> 01:01:59,930
current systems but we haven't answered
all the parts you don't want to go into

2798
01:01:59,930 --> 01:01:59,940
all the parts you don't want to go into
 

2799
01:01:59,940 --> 01:02:00,620
all the parts you don't want to go into
the second

2800
01:02:00,620 --> 01:02:00,630
the second
 

2801
01:02:00,630 --> 01:02:02,870
the second
oh good we take but maybe another

2802
01:02:02,870 --> 01:02:02,880
oh good we take but maybe another
 

2803
01:02:02,880 --> 01:02:06,020
oh good we take but maybe another
tangent you can also pick up as can we

2804
01:02:06,020 --> 01:02:06,030
tangent you can also pick up as can we
 

2805
01:02:06,030 --> 01:02:07,910
tangent you can also pick up as can we
get in trouble with much Dumber systems

2806
01:02:07,910 --> 01:02:07,920
get in trouble with much Dumber systems
 

2807
01:02:07,920 --> 01:02:10,580
get in trouble with much Dumber systems
yes that is exactly where I was going

2808
01:02:10,580 --> 01:02:10,590
yes that is exactly where I was going
 

2809
01:02:10,590 --> 01:02:11,150
yes that is exactly where I was going
okay

2810
01:02:11,150 --> 01:02:11,160
okay
 

2811
01:02:11,160 --> 01:02:14,900
okay
so I so just to wrap up on the threats

2812
01:02:14,900 --> 01:02:14,910
so I so just to wrap up on the threats
 

2813
01:02:14,910 --> 01:02:19,190
so I so just to wrap up on the threats
of AGI I think that it seems to me a

2814
01:02:19,190 --> 01:02:19,200
of AGI I think that it seems to me a
 

2815
01:02:19,200 --> 01:02:24,410
of AGI I think that it seems to me a
little early today to figure out

2816
01:02:24,410 --> 01:02:24,420
little early today to figure out
 

2817
01:02:24,420 --> 01:02:27,110
little early today to figure out
protections against a human level or

2818
01:02:27,110 --> 01:02:27,120
protections against a human level or
 

2819
01:02:27,120 --> 01:02:29,890
protections against a human level or
superhuman level intelligence who's

2820
01:02:29,890 --> 01:02:29,900
superhuman level intelligence who's
 

2821
01:02:29,900 --> 01:02:32,420
superhuman level intelligence who's
where we don't even see the skeleton of

2822
01:02:32,420 --> 01:02:32,430
where we don't even see the skeleton of
 

2823
01:02:32,430 --> 01:02:34,700
where we don't even see the skeleton of
what that would look like so it seems

2824
01:02:34,700 --> 01:02:34,710
what that would look like so it seems
 

2825
01:02:34,710 --> 01:02:37,850
what that would look like so it seems
that it's very speculative on how what

2826
01:02:37,850 --> 01:02:37,860
that it's very speculative on how what
 

2827
01:02:37,860 --> 01:02:41,060
that it's very speculative on how what
how to protect against that but we can

2828
01:02:41,060 --> 01:02:41,070
how to protect against that but we can
 

2829
01:02:41,070 --> 01:02:44,120
how to protect against that but we can
definitely and have gotten into trouble

2830
01:02:44,120 --> 01:02:44,130
definitely and have gotten into trouble
 

2831
01:02:44,130 --> 01:02:47,870
definitely and have gotten into trouble
on much Dumber systems and a lot of that

2832
01:02:47,870 --> 01:02:47,880
on much Dumber systems and a lot of that
 

2833
01:02:47,880 --> 01:02:50,660
on much Dumber systems and a lot of that
has to do with the fact that the systems

2834
01:02:50,660 --> 01:02:50,670
has to do with the fact that the systems
 

2835
01:02:50,670 --> 01:02:52,670
has to do with the fact that the systems
that we're building are increasingly

2836
01:02:52,670 --> 01:02:52,680
that we're building are increasingly
 

2837
01:02:52,680 --> 01:02:56,950
that we're building are increasingly
complex increasingly poorly understood

2838
01:02:56,950 --> 01:02:56,960
complex increasingly poorly understood
 

2839
01:02:56,960 --> 01:03:00,730
complex increasingly poorly understood
and there's ripple effects that are

2840
01:03:00,730 --> 01:03:00,740
and there's ripple effects that are
 

2841
01:03:00,740 --> 01:03:03,890
and there's ripple effects that are
unpredictable in changing little things

2842
01:03:03,890 --> 01:03:03,900
unpredictable in changing little things
 

2843
01:03:03,900 --> 01:03:05,650
unpredictable in changing little things
that's gonna have dramatic consequences

2844
01:03:05,650 --> 01:03:05,660
that's gonna have dramatic consequences
 

2845
01:03:05,660 --> 01:03:10,310
that's gonna have dramatic consequences
on the outcome and by the way that's not

2846
01:03:10,310 --> 01:03:10,320
on the outcome and by the way that's not
 

2847
01:03:10,320 --> 01:03:12,260
on the outcome and by the way that's not
unique to artificial now this is I think

2848
01:03:12,260 --> 01:03:12,270
unique to artificial now this is I think
 

2849
01:03:12,270 --> 01:03:14,300
unique to artificial now this is I think
artificial intelligence exacerbates that

2850
01:03:14,300 --> 01:03:14,310
artificial intelligence exacerbates that
 

2851
01:03:14,310 --> 01:03:15,350
artificial intelligence exacerbates that
brings it to a new level

2852
01:03:15,350 --> 01:03:15,360
brings it to a new level
 

2853
01:03:15,360 --> 01:03:17,480
brings it to a new level
but the heck our electric grid is really

2854
01:03:17,480 --> 01:03:17,490
but the heck our electric grid is really
 

2855
01:03:17,490 --> 01:03:20,180
but the heck our electric grid is really
complicated the software that runs our

2856
01:03:20,180 --> 01:03:20,190
complicated the software that runs our
 

2857
01:03:20,190 --> 01:03:22,340
complicated the software that runs our
financial markets is really complicated

2858
01:03:22,340 --> 01:03:22,350
financial markets is really complicated
 

2859
01:03:22,350 --> 01:03:25,180
financial markets is really complicated
and we've seen those ripple effects

2860
01:03:25,180 --> 01:03:25,190
and we've seen those ripple effects
 

2861
01:03:25,190 --> 01:03:27,950
and we've seen those ripple effects
translate to dramatic negative

2862
01:03:27,950 --> 01:03:27,960
translate to dramatic negative
 

2863
01:03:27,960 --> 01:03:31,550
translate to dramatic negative
consequences like for instance financial

2864
01:03:31,550 --> 01:03:31,560
consequences like for instance financial
 

2865
01:03:31,560 --> 01:03:33,740
consequences like for instance financial
crashes that have to do with feedback

2866
01:03:33,740 --> 01:03:33,750
crashes that have to do with feedback
 

2867
01:03:33,750 --> 01:03:35,990
crashes that have to do with feedback
loops that we didn't anticipate so I

2868
01:03:35,990 --> 01:03:36,000
loops that we didn't anticipate so I
 

2869
01:03:36,000 --> 01:03:38,540
loops that we didn't anticipate so I
think that's an issue that we need to be

2870
01:03:38,540 --> 01:03:38,550
think that's an issue that we need to be
 

2871
01:03:38,550 --> 01:03:41,920
think that's an issue that we need to be
thoughtful about in many places

2872
01:03:41,920 --> 01:03:41,930
thoughtful about in many places
 

2873
01:03:41,930 --> 01:03:43,610
thoughtful about in many places
artificial intelligence being one of

2874
01:03:43,610 --> 01:03:43,620
artificial intelligence being one of
 

2875
01:03:43,620 --> 01:03:47,510
artificial intelligence being one of
them and we should and I think it's

2876
01:03:47,510 --> 01:03:47,520
them and we should and I think it's
 

2877
01:03:47,520 --> 01:03:49,010
them and we should and I think it's
really important that people are

2878
01:03:49,010 --> 01:03:49,020
really important that people are
 

2879
01:03:49,020 --> 01:03:53,180
really important that people are
thinking about ways in which we can have

2880
01:03:53,180 --> 01:03:53,190
thinking about ways in which we can have
 

2881
01:03:53,190 --> 01:03:54,920
thinking about ways in which we can have
better interpret ability of systems

2882
01:03:54,920 --> 01:03:54,930
better interpret ability of systems
 

2883
01:03:54,930 --> 01:03:59,570
better interpret ability of systems
better tests for for instance measuring

2884
01:03:59,570 --> 01:03:59,580
better tests for for instance measuring
 

2885
01:03:59,580 --> 01:04:01,610
better tests for for instance measuring
the extent to which a machine learning

2886
01:04:01,610 --> 01:04:01,620
the extent to which a machine learning
 

2887
01:04:01,620 --> 01:04:03,320
the extent to which a machine learning
system that was trained in one set of

2888
01:04:03,320 --> 01:04:03,330
system that was trained in one set of
 

2889
01:04:03,330 --> 01:04:06,680
system that was trained in one set of
circumstances how well does it actually

2890
01:04:06,680 --> 01:04:06,690
circumstances how well does it actually
 

2891
01:04:06,690 --> 01:04:08,570
circumstances how well does it actually
work in a very different set of

2892
01:04:08,570 --> 01:04:08,580
work in a very different set of
 

2893
01:04:08,580 --> 01:04:11,360
work in a very different set of
circumstances where you might say for

2894
01:04:11,360 --> 01:04:11,370
circumstances where you might say for
 

2895
01:04:11,370 --> 01:04:13,010
circumstances where you might say for
instance well I'm not going to be able

2896
01:04:13,010 --> 01:04:13,020
instance well I'm not going to be able
 

2897
01:04:13,020 --> 01:04:14,520
instance well I'm not going to be able
to test my automated via

2898
01:04:14,520 --> 01:04:14,530
to test my automated via
 

2899
01:04:14,530 --> 01:04:18,230
to test my automated via
call in every possible City Village

2900
01:04:18,230 --> 01:04:18,240
call in every possible City Village
 

2901
01:04:18,240 --> 01:04:21,090
call in every possible City Village
weather condition and so on but if you

2902
01:04:21,090 --> 01:04:21,100
weather condition and so on but if you
 

2903
01:04:21,100 --> 01:04:23,430
weather condition and so on but if you
trained it on this set of conditions and

2904
01:04:23,430 --> 01:04:23,440
trained it on this set of conditions and
 

2905
01:04:23,440 --> 01:04:27,450
trained it on this set of conditions and
then tested it on 50 or 100 others that

2906
01:04:27,450 --> 01:04:27,460
then tested it on 50 or 100 others that
 

2907
01:04:27,460 --> 01:04:29,280
then tested it on 50 or 100 others that
were quite different from the ones that

2908
01:04:29,280 --> 01:04:29,290
were quite different from the ones that
 

2909
01:04:29,290 --> 01:04:31,530
were quite different from the ones that
you trained it on then I can it worked

2910
01:04:31,530 --> 01:04:31,540
you trained it on then I can it worked
 

2911
01:04:31,540 --> 01:04:33,450
you trained it on then I can it worked
then that gives you confidence that the

2912
01:04:33,450 --> 01:04:33,460
then that gives you confidence that the
 

2913
01:04:33,460 --> 01:04:35,280
then that gives you confidence that the
next 50 that you didn't test it on might

2914
01:04:35,280 --> 01:04:35,290
next 50 that you didn't test it on might
 

2915
01:04:35,290 --> 01:04:37,440
next 50 that you didn't test it on might
also work so effectively testing for

2916
01:04:37,440 --> 01:04:37,450
also work so effectively testing for
 

2917
01:04:37,450 --> 01:04:39,900
also work so effectively testing for
generalizability so I think there's ways

2918
01:04:39,900 --> 01:04:39,910
generalizability so I think there's ways
 

2919
01:04:39,910 --> 01:04:41,940
generalizability so I think there's ways
that we should be constantly thinking

2920
01:04:41,940 --> 01:04:41,950
that we should be constantly thinking
 

2921
01:04:41,950 --> 01:04:46,140
that we should be constantly thinking
about to validate the robustness of our

2922
01:04:46,140 --> 01:04:46,150
about to validate the robustness of our
 

2923
01:04:46,150 --> 01:04:49,860
about to validate the robustness of our
systems I think it's very different from

2924
01:04:49,860 --> 01:04:49,870
systems I think it's very different from
 

2925
01:04:49,870 --> 01:04:51,780
systems I think it's very different from
the let's make sure robots don't take

2926
01:04:51,780 --> 01:04:51,790
the let's make sure robots don't take
 

2927
01:04:51,790 --> 01:04:52,560
the let's make sure robots don't take
over the world

2928
01:04:52,560 --> 01:04:52,570
over the world
 

2929
01:04:52,570 --> 01:04:54,840
over the world
and then the other place where I think

2930
01:04:54,840 --> 01:04:54,850
and then the other place where I think
 

2931
01:04:54,850 --> 01:04:58,080
and then the other place where I think
we have a threat which is also important

2932
01:04:58,080 --> 01:04:58,090
we have a threat which is also important
 

2933
01:04:58,090 --> 01:05:00,930
we have a threat which is also important
for us to think about is the extent to

2934
01:05:00,930 --> 01:05:00,940
for us to think about is the extent to
 

2935
01:05:00,940 --> 01:05:02,700
for us to think about is the extent to
which technology can be abused

2936
01:05:02,700 --> 01:05:02,710
which technology can be abused
 

2937
01:05:02,710 --> 01:05:07,130
which technology can be abused
so like any really powerful technology

2938
01:05:07,130 --> 01:05:07,140
so like any really powerful technology
 

2939
01:05:07,140 --> 01:05:10,890
so like any really powerful technology
machine learning can be very much used

2940
01:05:10,890 --> 01:05:10,900
machine learning can be very much used
 

2941
01:05:10,900 --> 01:05:14,640
machine learning can be very much used
badly as well as too good and that goes

2942
01:05:14,640 --> 01:05:14,650
badly as well as too good and that goes
 

2943
01:05:14,650 --> 01:05:16,560
badly as well as too good and that goes
back to many other technologies that

2944
01:05:16,560 --> 01:05:16,570
back to many other technologies that
 

2945
01:05:16,570 --> 01:05:19,880
back to many other technologies that
have come up with when people invented

2946
01:05:19,880 --> 01:05:19,890
have come up with when people invented
 

2947
01:05:19,890 --> 01:05:22,200
have come up with when people invented
projectile missiles and it turns into

2948
01:05:22,200 --> 01:05:22,210
projectile missiles and it turns into
 

2949
01:05:22,210 --> 01:05:25,380
projectile missiles and it turns into
guns and people invented nuclear power

2950
01:05:25,380 --> 01:05:25,390
guns and people invented nuclear power
 

2951
01:05:25,390 --> 01:05:28,860
guns and people invented nuclear power
and it turned nuclear bombs and I think

2952
01:05:28,860 --> 01:05:28,870
and it turned nuclear bombs and I think
 

2953
01:05:28,870 --> 01:05:31,530
and it turned nuclear bombs and I think
honestly I would say that to me gene

2954
01:05:31,530 --> 01:05:31,540
honestly I would say that to me gene
 

2955
01:05:31,540 --> 01:05:33,540
honestly I would say that to me gene
editing and CRISPR is at least as

2956
01:05:33,540 --> 01:05:33,550
editing and CRISPR is at least as
 

2957
01:05:33,550 --> 01:05:35,960
editing and CRISPR is at least as
dangerous at technology if used

2958
01:05:35,960 --> 01:05:35,970
dangerous at technology if used
 

2959
01:05:35,970 --> 01:05:38,900
dangerous at technology if used
badly than machine as machine learning

2960
01:05:38,900 --> 01:05:38,910
badly than machine as machine learning
 

2961
01:05:38,910 --> 01:05:42,960
badly than machine as machine learning
you could create really nasty viruses

2962
01:05:42,960 --> 01:05:42,970
you could create really nasty viruses
 

2963
01:05:42,970 --> 01:05:48,210
you could create really nasty viruses
and such using gene editing that are you

2964
01:05:48,210 --> 01:05:48,220
and such using gene editing that are you
 

2965
01:05:48,220 --> 01:05:51,300
and such using gene editing that are you
know you would be really careful about

2966
01:05:51,300 --> 01:05:51,310
know you would be really careful about
 

2967
01:05:51,310 --> 01:05:56,190
know you would be really careful about
so anyway that's something that we need

2968
01:05:56,190 --> 01:05:56,200
so anyway that's something that we need
 

2969
01:05:56,200 --> 01:05:58,860
so anyway that's something that we need
to be really thoughtful about whenever

2970
01:05:58,860 --> 01:05:58,870
to be really thoughtful about whenever
 

2971
01:05:58,870 --> 01:06:00,960
to be really thoughtful about whenever
we have any really powerful new

2972
01:06:00,960 --> 01:06:00,970
we have any really powerful new
 

2973
01:06:00,970 --> 01:06:03,510
we have any really powerful new
technology yeah and on the case of

2974
01:06:03,510 --> 01:06:03,520
technology yeah and on the case of
 

2975
01:06:03,520 --> 01:06:06,240
technology yeah and on the case of
machine learning is at the stereo

2976
01:06:06,240 --> 01:06:06,250
machine learning is at the stereo
 

2977
01:06:06,250 --> 01:06:07,410
machine learning is at the stereo
machine learning so all the kinds of

2978
01:06:07,410 --> 01:06:07,420
machine learning so all the kinds of
 

2979
01:06:07,420 --> 01:06:09,300
machine learning so all the kinds of
attacks like security almost threats and

2980
01:06:09,300 --> 01:06:09,310
attacks like security almost threats and
 

2981
01:06:09,310 --> 01:06:10,680
attacks like security almost threats and
there's a social engineering with

2982
01:06:10,680 --> 01:06:10,690
there's a social engineering with
 

2983
01:06:10,690 --> 01:06:14,010
there's a social engineering with
machine learning algorithm and big

2984
01:06:14,010 --> 01:06:14,020
machine learning algorithm and big
 

2985
01:06:14,020 --> 01:06:17,910
machine learning algorithm and big
brother's watching you and there is the

2986
01:06:17,910 --> 01:06:17,920
brother's watching you and there is the
 

2987
01:06:17,920 --> 01:06:20,910
brother's watching you and there is the
killer drones that can potentially go

2988
01:06:20,910 --> 01:06:20,920
killer drones that can potentially go
 

2989
01:06:20,920 --> 01:06:24,120
killer drones that can potentially go
and targeted execution of people in a

2990
01:06:24,120 --> 01:06:24,130
and targeted execution of people in a
 

2991
01:06:24,130 --> 01:06:27,420
and targeted execution of people in a
different country I don't you know want

2992
01:06:27,420 --> 01:06:27,430
different country I don't you know want
 

2993
01:06:27,430 --> 01:06:28,440
different country I don't you know want
them are he that

2994
01:06:28,440 --> 01:06:28,450
them are he that
 

2995
01:06:28,450 --> 01:06:30,650
them are he that
are not necessarily that much better but

2996
01:06:30,650 --> 01:06:30,660
are not necessarily that much better but
 

2997
01:06:30,660 --> 01:06:33,930
are not necessarily that much better but
but you know people want to kill someone

2998
01:06:33,930 --> 01:06:33,940
but you know people want to kill someone
 

2999
01:06:33,940 --> 01:06:36,450
but you know people want to kill someone
they'll find a way to do it so if you if

3000
01:06:36,450 --> 01:06:36,460
they'll find a way to do it so if you if
 

3001
01:06:36,460 --> 01:06:38,190
they'll find a way to do it so if you if
in general if you look at trends in the

3002
01:06:38,190 --> 01:06:38,200
in general if you look at trends in the
 

3003
01:06:38,200 --> 01:06:40,589
in general if you look at trends in the
data there's less Wars there's just

3004
01:06:40,589 --> 01:06:40,599
data there's less Wars there's just
 

3005
01:06:40,599 --> 01:06:43,079
data there's less Wars there's just
violence there's more human rights so

3006
01:06:43,079 --> 01:06:43,089
violence there's more human rights so
 

3007
01:06:43,089 --> 01:06:47,130
violence there's more human rights so
we've been doing overall quite good as a

3008
01:06:47,130 --> 01:06:47,140
we've been doing overall quite good as a
 

3009
01:06:47,140 --> 01:06:51,920
we've been doing overall quite good as a
human species are you are you optimistic

3010
01:06:51,920 --> 01:06:51,930
human species are you are you optimistic
 

3011
01:06:51,930 --> 01:06:54,599
human species are you are you optimistic
maybe another way to ask is do you think

3012
01:06:54,599 --> 01:06:54,609
maybe another way to ask is do you think
 

3013
01:06:54,609 --> 01:06:59,190
maybe another way to ask is do you think
most people are good and fundamentally

3014
01:06:59,190 --> 01:06:59,200
most people are good and fundamentally
 

3015
01:06:59,200 --> 01:07:03,540
most people are good and fundamentally
we tend towards a better world which is

3016
01:07:03,540 --> 01:07:03,550
we tend towards a better world which is
 

3017
01:07:03,550 --> 01:07:06,030
we tend towards a better world which is
underlying the question well machine

3018
01:07:06,030 --> 01:07:06,040
underlying the question well machine
 

3019
01:07:06,040 --> 01:07:09,720
underlying the question well machine
learning what gene editing ultimately

3020
01:07:09,720 --> 01:07:09,730
learning what gene editing ultimately
 

3021
01:07:09,730 --> 01:07:12,329
learning what gene editing ultimately
land us somewhere good are you

3022
01:07:12,329 --> 01:07:12,339
land us somewhere good are you
 

3023
01:07:12,339 --> 01:07:17,660
land us somewhere good are you
optimistic I think by and large I'm

3024
01:07:17,660 --> 01:07:17,670
optimistic I think by and large I'm
 

3025
01:07:17,670 --> 01:07:24,300
optimistic I think by and large I'm
optimistic I think that most people mean

3026
01:07:24,300 --> 01:07:24,310
optimistic I think that most people mean
 

3027
01:07:24,310 --> 01:07:26,819
optimistic I think that most people mean
well that doesn't mean that most people

3028
01:07:26,819 --> 01:07:26,829
well that doesn't mean that most people
 

3029
01:07:26,829 --> 01:07:29,730
well that doesn't mean that most people
are you know altruistic do-gooders but I

3030
01:07:29,730 --> 01:07:29,740
are you know altruistic do-gooders but I
 

3031
01:07:29,740 --> 01:07:32,609
are you know altruistic do-gooders but I
think most people mean well but I think

3032
01:07:32,609 --> 01:07:32,619
think most people mean well but I think
 

3033
01:07:32,619 --> 01:07:34,710
think most people mean well but I think
it's also really important for us as a

3034
01:07:34,710 --> 01:07:34,720
it's also really important for us as a
 

3035
01:07:34,720 --> 01:07:39,079
it's also really important for us as a
society to create social norms we're

3036
01:07:39,079 --> 01:07:39,089
society to create social norms we're
 

3037
01:07:39,089 --> 01:07:46,079
society to create social norms we're
doing good and being perceived well by

3038
01:07:46,079 --> 01:07:46,089
doing good and being perceived well by
 

3039
01:07:46,089 --> 01:07:50,700
doing good and being perceived well by
our peers is are positively correlated I

3040
01:07:50,700 --> 01:07:50,710
our peers is are positively correlated I
 

3041
01:07:50,710 --> 01:07:53,300
our peers is are positively correlated I
mean it's very easy to create

3042
01:07:53,300 --> 01:07:53,310
mean it's very easy to create
 

3043
01:07:53,310 --> 01:07:55,319
mean it's very easy to create
dysfunctional societies there's

3044
01:07:55,319 --> 01:07:55,329
dysfunctional societies there's
 

3045
01:07:55,329 --> 01:07:56,910
dysfunctional societies there's
certainly multiple psychological

3046
01:07:56,910 --> 01:07:56,920
certainly multiple psychological
 

3047
01:07:56,920 --> 01:08:00,450
certainly multiple psychological
experiments as well as sadly real-world

3048
01:08:00,450 --> 01:08:00,460
experiments as well as sadly real-world
 

3049
01:08:00,460 --> 01:08:04,410
experiments as well as sadly real-world
events where people have devolved to a

3050
01:08:04,410 --> 01:08:04,420
events where people have devolved to a
 

3051
01:08:04,420 --> 01:08:08,040
events where people have devolved to a
world where being perceived well by your

3052
01:08:08,040 --> 01:08:08,050
world where being perceived well by your
 

3053
01:08:08,050 --> 01:08:11,280
world where being perceived well by your
peers is correlated with really

3054
01:08:11,280 --> 01:08:11,290
peers is correlated with really
 

3055
01:08:11,290 --> 01:08:16,550
peers is correlated with really
atrocious often genocide 'el behaviors

3056
01:08:16,550 --> 01:08:16,560
atrocious often genocide 'el behaviors
 

3057
01:08:16,560 --> 01:08:19,349
atrocious often genocide 'el behaviors
so we really want to make sure that we

3058
01:08:19,349 --> 01:08:19,359
so we really want to make sure that we
 

3059
01:08:19,359 --> 01:08:21,740
so we really want to make sure that we
maintain a set of social norms where

3060
01:08:21,740 --> 01:08:21,750
maintain a set of social norms where
 

3061
01:08:21,750 --> 01:08:23,999
maintain a set of social norms where
people know that to be a successful

3062
01:08:23,999 --> 01:08:24,009
people know that to be a successful
 

3063
01:08:24,009 --> 01:08:26,519
people know that to be a successful
member of society you want to be doing

3064
01:08:26,519 --> 01:08:26,529
member of society you want to be doing
 

3065
01:08:26,529 --> 01:08:29,490
member of society you want to be doing
good and one of the things that I

3066
01:08:29,490 --> 01:08:29,500
good and one of the things that I
 

3067
01:08:29,500 --> 01:08:33,479
good and one of the things that I
sometimes worry about is that some

3068
01:08:33,479 --> 01:08:33,489
sometimes worry about is that some
 

3069
01:08:33,489 --> 01:08:35,190
sometimes worry about is that some
societies don't seem to necessarily be

3070
01:08:35,190 --> 01:08:35,200
societies don't seem to necessarily be
 

3071
01:08:35,200 --> 01:08:36,990
societies don't seem to necessarily be
moving in the forward direction in that

3072
01:08:36,990 --> 01:08:37,000
moving in the forward direction in that
 

3073
01:08:37,000 --> 01:08:39,749
moving in the forward direction in that
regard where it's not necessarily the

3074
01:08:39,749 --> 01:08:39,759
regard where it's not necessarily the
 

3075
01:08:39,759 --> 01:08:42,760
regard where it's not necessarily the
case that doing

3076
01:08:42,760 --> 01:08:42,770
case that doing
 

3077
01:08:42,770 --> 01:08:45,460
case that doing
that being a good person is what makes

3078
01:08:45,460 --> 01:08:45,470
that being a good person is what makes
 

3079
01:08:45,470 --> 01:08:47,740
that being a good person is what makes
you be perceived well by your peers and

3080
01:08:47,740 --> 01:08:47,750
you be perceived well by your peers and
 

3081
01:08:47,750 --> 01:08:49,210
you be perceived well by your peers and
I think that's a really important thing

3082
01:08:49,210 --> 01:08:49,220
I think that's a really important thing
 

3083
01:08:49,220 --> 01:08:51,099
I think that's a really important thing
for us as a society to remember it's

3084
01:08:51,099 --> 01:08:51,109
for us as a society to remember it's
 

3085
01:08:51,109 --> 01:08:54,420
for us as a society to remember it's
very easy to degenerate back into a

3086
01:08:54,420 --> 01:08:54,430
very easy to degenerate back into a
 

3087
01:08:54,430 --> 01:08:58,870
very easy to degenerate back into a
universe where it's okay to do really

3088
01:08:58,870 --> 01:08:58,880
universe where it's okay to do really
 

3089
01:08:58,880 --> 01:09:01,960
universe where it's okay to do really
bad stuff and still have your peers

3090
01:09:01,960 --> 01:09:01,970
bad stuff and still have your peers
 

3091
01:09:01,970 --> 01:09:05,890
bad stuff and still have your peers
think you're amazing it's fun to ask a

3092
01:09:05,890 --> 01:09:05,900
think you're amazing it's fun to ask a
 

3093
01:09:05,900 --> 01:09:07,750
think you're amazing it's fun to ask a
world-class computer scientist and

3094
01:09:07,750 --> 01:09:07,760
world-class computer scientist and
 

3095
01:09:07,760 --> 01:09:10,570
world-class computer scientist and
engineer a ridiculously philosophical

3096
01:09:10,570 --> 01:09:10,580
engineer a ridiculously philosophical
 

3097
01:09:10,580 --> 01:09:12,370
engineer a ridiculously philosophical
question like what is the meaning of

3098
01:09:12,370 --> 01:09:12,380
question like what is the meaning of
 

3099
01:09:12,380 --> 01:09:15,640
question like what is the meaning of
life let me ask what gives your life

3100
01:09:15,640 --> 01:09:15,650
life let me ask what gives your life
 

3101
01:09:15,650 --> 01:09:18,910
life let me ask what gives your life
meaning what are what is the source of

3102
01:09:18,910 --> 01:09:18,920
meaning what are what is the source of
 

3103
01:09:18,920 --> 01:09:27,340
meaning what are what is the source of
fulfilment happiness joy purpose when we

3104
01:09:27,340 --> 01:09:27,350
fulfilment happiness joy purpose when we
 

3105
01:09:27,350 --> 01:09:30,250
fulfilment happiness joy purpose when we
were starting Coursera in the fall of

3106
01:09:30,250 --> 01:09:30,260
were starting Coursera in the fall of
 

3107
01:09:30,260 --> 01:09:34,539
were starting Coursera in the fall of
2011 that was right around the time that

3108
01:09:34,539 --> 01:09:34,549
2011 that was right around the time that
 

3109
01:09:34,549 --> 01:09:38,530
2011 that was right around the time that
Steve Jobs passed away and so the media

3110
01:09:38,530 --> 01:09:38,540
Steve Jobs passed away and so the media
 

3111
01:09:38,540 --> 01:09:42,039
Steve Jobs passed away and so the media
was full various famous quotes Heath uh

3112
01:09:42,039 --> 01:09:42,049
was full various famous quotes Heath uh
 

3113
01:09:42,049 --> 01:09:45,039
was full various famous quotes Heath uh
turd and one of them that really stuck

3114
01:09:45,039 --> 01:09:45,049
turd and one of them that really stuck
 

3115
01:09:45,049 --> 01:09:47,769
turd and one of them that really stuck
with me because it resonated with stuff

3116
01:09:47,769 --> 01:09:47,779
with me because it resonated with stuff
 

3117
01:09:47,779 --> 01:09:50,260
with me because it resonated with stuff
that I'd been feeling for even years

3118
01:09:50,260 --> 01:09:50,270
that I'd been feeling for even years
 

3119
01:09:50,270 --> 01:09:52,269
that I'd been feeling for even years
before that is that our goal in life

3120
01:09:52,269 --> 01:09:52,279
before that is that our goal in life
 

3121
01:09:52,279 --> 01:09:54,480
before that is that our goal in life
should be to make a dent in the universe

3122
01:09:54,480 --> 01:09:54,490
should be to make a dent in the universe
 

3123
01:09:54,490 --> 01:09:58,720
should be to make a dent in the universe
so I think that to me what gives my life

3124
01:09:58,720 --> 01:09:58,730
so I think that to me what gives my life
 

3125
01:09:58,730 --> 01:10:04,320
so I think that to me what gives my life
meaning is that I would hope that when I

3126
01:10:04,320 --> 01:10:04,330
meaning is that I would hope that when I
 

3127
01:10:04,330 --> 01:10:07,030
meaning is that I would hope that when I
am lying there on my deathbed and

3128
01:10:07,030 --> 01:10:07,040
am lying there on my deathbed and
 

3129
01:10:07,040 --> 01:10:09,730
am lying there on my deathbed and
looking at what I'd done in my life that

3130
01:10:09,730 --> 01:10:09,740
looking at what I'd done in my life that
 

3131
01:10:09,740 --> 01:10:14,950
looking at what I'd done in my life that
I can point to ways in which I have left

3132
01:10:14,950 --> 01:10:14,960
I can point to ways in which I have left
 

3133
01:10:14,960 --> 01:10:18,760
I can point to ways in which I have left
the world a better place than it was

3134
01:10:18,760 --> 01:10:18,770
the world a better place than it was
 

3135
01:10:18,770 --> 01:10:21,160
the world a better place than it was
when I entered it this is something I

3136
01:10:21,160 --> 01:10:21,170
when I entered it this is something I
 

3137
01:10:21,170 --> 01:10:24,370
when I entered it this is something I
tell my kids all the time because I also

3138
01:10:24,370 --> 01:10:24,380
tell my kids all the time because I also
 

3139
01:10:24,380 --> 01:10:28,030
tell my kids all the time because I also
think that the burden of that is much

3140
01:10:28,030 --> 01:10:28,040
think that the burden of that is much
 

3141
01:10:28,040 --> 01:10:30,760
think that the burden of that is much
greater for those of us who were born to

3142
01:10:30,760 --> 01:10:30,770
greater for those of us who were born to
 

3143
01:10:30,770 --> 01:10:32,920
greater for those of us who were born to
privilege and in some ways I was I mean

3144
01:10:32,920 --> 01:10:32,930
privilege and in some ways I was I mean
 

3145
01:10:32,930 --> 01:10:34,600
privilege and in some ways I was I mean
it wasn't more than wealthy or anything

3146
01:10:34,600 --> 01:10:34,610
it wasn't more than wealthy or anything
 

3147
01:10:34,610 --> 01:10:37,090
it wasn't more than wealthy or anything
like that but I grew up in an educated

3148
01:10:37,090 --> 01:10:37,100
like that but I grew up in an educated
 

3149
01:10:37,100 --> 01:10:39,790
like that but I grew up in an educated
family with parents who loved me and

3150
01:10:39,790 --> 01:10:39,800
family with parents who loved me and
 

3151
01:10:39,800 --> 01:10:41,830
family with parents who loved me and
took care of me and I had a chance at a

3152
01:10:41,830 --> 01:10:41,840
took care of me and I had a chance at a
 

3153
01:10:41,840 --> 01:10:44,980
took care of me and I had a chance at a
great education and and so I and I've

3154
01:10:44,980 --> 01:10:44,990
great education and and so I and I've
 

3155
01:10:44,990 --> 01:10:47,410
great education and and so I and I've
always had enough to eat so I was in

3156
01:10:47,410 --> 01:10:47,420
always had enough to eat so I was in
 

3157
01:10:47,420 --> 01:10:49,240
always had enough to eat so I was in
many ways born to privilege more than

3158
01:10:49,240 --> 01:10:49,250
many ways born to privilege more than
 

3159
01:10:49,250 --> 01:10:52,690
many ways born to privilege more than
the vast majority of humanity and my

3160
01:10:52,690 --> 01:10:52,700
the vast majority of humanity and my
 

3161
01:10:52,700 --> 01:10:55,090
the vast majority of humanity and my
kids I think are even more so born to

3162
01:10:55,090 --> 01:10:55,100
kids I think are even more so born to
 

3163
01:10:55,100 --> 01:10:55,840
kids I think are even more so born to
privilege

3164
01:10:55,840 --> 01:10:55,850
privilege
 

3165
01:10:55,850 --> 01:10:58,090
privilege
then I was fortunate enough to be and I

3166
01:10:58,090 --> 01:10:58,100
then I was fortunate enough to be and I
 

3167
01:10:58,100 --> 01:11:00,370
then I was fortunate enough to be and I
think it's really important that for

3168
01:11:00,370 --> 01:11:00,380
think it's really important that for
 

3169
01:11:00,380 --> 01:11:02,200
think it's really important that for
especially for those of us who have that

3170
01:11:02,200 --> 01:11:02,210
especially for those of us who have that
 

3171
01:11:02,210 --> 01:11:05,020
especially for those of us who have that
opportunity that we use our lives to

3172
01:11:05,020 --> 01:11:05,030
opportunity that we use our lives to
 

3173
01:11:05,030 --> 01:11:07,540
opportunity that we use our lives to
make the world a better place I don't

3174
01:11:07,540 --> 01:11:07,550
make the world a better place I don't
 

3175
01:11:07,550 --> 01:11:09,430
make the world a better place I don't
think there's a better way to end it

3176
01:11:09,430 --> 01:11:09,440
think there's a better way to end it
 

3177
01:11:09,440 --> 01:11:11,770
think there's a better way to end it
that needs a honor to talk to you thank

3178
01:11:11,770 --> 01:11:11,780
that needs a honor to talk to you thank
 

3179
01:11:11,780 --> 01:11:14,250
that needs a honor to talk to you thank
you so much for talking to you

3180
01:11:14,250 --> 01:11:14,260
you so much for talking to you
 

3181
01:11:14,260 --> 01:11:15,270
you so much for talking to you
thanks for listening to this

3182
01:11:15,270 --> 01:11:15,280
thanks for listening to this
 

3183
01:11:15,280 --> 01:11:16,830
thanks for listening to this
conversation with Daphne Koller and

3184
01:11:16,830 --> 01:11:16,840
conversation with Daphne Koller and
 

3185
01:11:16,840 --> 01:11:18,990
conversation with Daphne Koller and
thank you to our presenting sponsor cash

3186
01:11:18,990 --> 01:11:19,000
thank you to our presenting sponsor cash
 

3187
01:11:19,000 --> 01:11:20,970
thank you to our presenting sponsor cash
app please consider supporting the

3188
01:11:20,970 --> 01:11:20,980
app please consider supporting the
 

3189
01:11:20,980 --> 01:11:22,950
app please consider supporting the
podcast by downloading cash app and

3190
01:11:22,950 --> 01:11:22,960
podcast by downloading cash app and
 

3191
01:11:22,960 --> 01:11:26,549
podcast by downloading cash app and
using code lex podcast enjoy this

3192
01:11:26,549 --> 01:11:26,559
using code lex podcast enjoy this
 

3193
01:11:26,559 --> 01:11:29,009
using code lex podcast enjoy this
podcast subscribe on youtube review it

3194
01:11:29,009 --> 01:11:29,019
podcast subscribe on youtube review it
 

3195
01:11:29,019 --> 01:11:30,479
podcast subscribe on youtube review it
with five stars an apple podcast

3196
01:11:30,479 --> 01:11:30,489
with five stars an apple podcast
 

3197
01:11:30,489 --> 01:11:33,089
with five stars an apple podcast
supported on patreon simply connect with

3198
01:11:33,089 --> 01:11:33,099
supported on patreon simply connect with
 

3199
01:11:33,099 --> 01:11:36,930
supported on patreon simply connect with
me on Twitter Alex Friedman and now let

3200
01:11:36,930 --> 01:11:36,940
me on Twitter Alex Friedman and now let
 

3201
01:11:36,940 --> 01:11:38,970
me on Twitter Alex Friedman and now let
me leave you some words from Hippocrates

3202
01:11:38,970 --> 01:11:38,980
me leave you some words from Hippocrates
 

3203
01:11:38,980 --> 01:11:42,000
me leave you some words from Hippocrates
a physician from ancient Greece who's

3204
01:11:42,000 --> 01:11:42,010
a physician from ancient Greece who's
 

3205
01:11:42,010 --> 01:11:44,750
a physician from ancient Greece who's
considered to be the father of medicine

3206
01:11:44,750 --> 01:11:44,760
considered to be the father of medicine
 

3207
01:11:44,760 --> 01:11:47,580
considered to be the father of medicine
wherever the art of medicine is loved

3208
01:11:47,580 --> 01:11:47,590
wherever the art of medicine is loved
 

3209
01:11:47,590 --> 01:11:51,990
wherever the art of medicine is loved
there's also love of humanity thank you

3210
01:11:51,990 --> 01:11:52,000
there's also love of humanity thank you
 

3211
01:11:52,000 --> 01:11:54,120
there's also love of humanity thank you
for listening and hope to see you next

3212
01:11:54,120 --> 01:11:54,130
for listening and hope to see you next
 

3213
01:11:54,130 --> 01:12:01,069
for listening and hope to see you next
time

3214
01:12:01,069 --> 01:12:01,079

 

3215
01:12:01,079 --> 01:12:03,139

you

